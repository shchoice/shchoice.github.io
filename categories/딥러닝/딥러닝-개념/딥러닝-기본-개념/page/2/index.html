<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë… - Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a></li><li><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a></li><li class="is-active"><a href="#" aria-current="page">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-27T14:59:02.000Z" title="7/27/2023, 11:59:02â€¯PM">2023-07-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:04:14.000Z" title="9/6/2024, 12:04:14â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">2 minutes read (About 356 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%A4%91%EA%B8%89%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Probabilistic-Perspective-Introduction/">2ì¥. Probabilistic Perspective - Introduction</a></h1><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Again-our-objective-is"><a href="#Again-our-objective-is" class="headerlink" title="Again, our objective is"></a>Again, our objective is</h3><ul>
<li>ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ì—¬, ì›í•˜ëŠ” ì¶œë ¥ê°’ì„ ë°˜í™˜í•˜ëŠ” ì‹ ê²½ë§ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì.</li>
<li>ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” Deep Neural Networksë¥¼ ì´ì•¼ê¸°í•  ë•Œ,<ul>
<li>Gradient Descent</li>
<li>Back-Propagation</li>
<li>Feature Vector</li>
<li>and blah blah..</li>
</ul>
</li>
<li>ì´ì œëŠ” ìš°ë¦¬ì˜ ìƒê°ì„ í™•ì¥ì‹œì¼œì•¼ í•  ë•Œ! â†’ Probabilistic Perspective!</li>
</ul>
<h3 id="Probabilistic-Perspective"><a href="#Probabilistic-Perspective" class="headerlink" title="Probabilistic Perspective"></a>Probabilistic Perspective</h3><ul>
<li><p>ì´ ì„¸ìƒì€ í™•ë¥ ì— ê¸°ë°˜</p>
<ul>
<li><p>ì•„ë˜ì˜ ê·¸ë¦¼ì— ëŒ€í•´ì„œ ëª¨ë‘ê°€ ê°™ì€ ëŒ€ë‹µì„ í•˜ì§€ëŠ” ì•Šì„ ê²ƒ <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702" alt="duckrabbit"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702">https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702</a></p>
</li>
<li><p>ìš°ë¦¬ì˜ ìƒˆë¡œìš´ ëª©í‘œ: <code>í™•ë¥  ë¶„í¬</code>ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒ</p>
</li>
</ul>
</li>
<li><p>Before vs After</p>
<ul>
<li>Before<ul>
<li>í•¨ìˆ˜ë¥¼ ë°°ìš°ì(ëª¨ì‚¬í•˜ì)</li>
</ul>
</li>
<li>After<ul>
<li>í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ë°°ìš°ì<ul>
<li>ìˆ˜í•™ì ìœ¼ë¡œ ë” ì„¤ëª…ì´ ê°€ëŠ¥í•´ì§</li>
<li>ë¶ˆí™•ì‹¤ì„±ê¹Œì§€ í•™ìŠµ</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a" alt="BeforeAfter"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a">https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a</a></p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Neural NetworksëŠ” í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ëª¨ë¸ë§í•  ìˆ˜ ìˆìŒ</li>
<li>ì´ë¥¼ í†µí•´ ê°€ìƒì˜ í™•ë¥  ë¶„í¬ í•¨ìˆ˜ ğ‘ƒ(ğ‘¦ | ğ‘¥)ë¥¼ ê·¼ì‚¬(approximation)í•  ê²ƒ</li>
<li>ëŒ€ë¶€ë¶„ì˜ ìµœì‹  ê¸°ìˆ ë“¤ì€ ì´ ê´€ì ì— ê¸°ë°˜ì„ ë‘ê³  ë§Œë“¤ì–´ì§</li>
<li>DNNì„ í™•ë¥  ë¶„í¬ë¡œ ë³´ì•˜ì„ ë•Œ, ê°€ëŠ¥í•œ ì´ë¡ ë“¤ì— ëŒ€í•´ì„œ ì•ìœ¼ë¡œ ì´ì•¼ê¸° í•  ê²ƒ<ul>
<li>Likelihood</li>
<li>Maximum Likelihood Estimation(MLE)</li>
<li>Maximum A Posterior(MAP) Estimation</li>
<li>Cross Entropy &amp; KL-Divergence</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-26T14:21:28.000Z" title="7/26/2023, 11:21:28â€¯PM">2023-07-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:40.000Z" title="9/6/2024, 12:03:40â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">7 minutes read (About 999 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%A4%91%EA%B8%89%20%EA%B0%9C%EB%85%90/1%EC%9E%A5-Representation-Learning-AutoEncoders/">1ì¥. Representation Learning - AutoEncoders</a></h1><div class="content"><h2 id="AutoEncoders"><a href="#AutoEncoders" class="headerlink" title="AutoEncoders"></a>AutoEncoders</h2><ul>
<li><p>Overview</p>
<ul>
<li>ì¸ì½”ë”(encoder)ì™€ ë””ì½”ë”(decoder)ë¥¼ í†µí•´ ì••ì¶•ê³¼ í•´ì œë¥¼ ì‹¤í–‰<ul>
<li>ì¸ì½”ë”ëŠ” ì…ë ¥(ğ‘¥)ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•˜ë„ë¡ ì†ì‹¤ ì••ì¶•ì„ ìˆ˜í–‰</li>
<li>ë””ì½”ë”ëŠ” ì¤‘ê°„ ê²°ê³¼ë¬¼(ğ‘§)ì˜ ì •ë³´ë¥¼ ì…ë ¥(ğ‘¥)ê³¼ ê°™ì•„ì§€ë„ë¡ ì••ì¶• í•´ì œ(ë³µì›)ë¥¼ ìˆ˜í–‰</li>
</ul>
</li>
<li>ë³µì›ì„ ì„±ê³µì ìœ¼ë¡œ í•˜ê¸° ìœ„í•´, autoencoderëŠ” íŠ¹<strong>ì§•(feature)ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ìë™ìœ¼ë¡œ í•™ìŠµ</strong></li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/f9947a9e-f1f4-4e4c-b8ab-bba2427ffa45" alt="Encoder-Decoder"></p>
</li>
<li><p>Encoder</p>
<ul>
<li><p>ë³µì›ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì†ì‹¤ ì••ì¶•ì„ ìˆ˜í–‰</p>
</li>
<li><p>í•„ìš”ì—†ëŠ” ì •ë³´(ë»”í•œ íŠ¹ì§•)ëŠ” ë²„ë¦´ ìˆ˜ë„ ìˆìŒ</p>
<ul>
<li><p>ì˜ˆì‹œ1) ì¼ë°˜ì ì¸ ì‚¬ëŒì˜ ì–¼êµ´ì„ í•™ìŠµí•  ë•Œ: ì‚¬ëŒì˜ ì–¼êµ´ì—ì„œ ëˆˆì€ 2ê°œì´ë‹¤ ë“±</p>
</li>
<li><p>ì˜ˆì‹œ2)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2e64e11e-6879-4644-bb6c-d416e8cb5ebc" alt="NoMeaningMNIST"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Bottleneck(ğ’›)</p>
<ul>
<li>ì…ë ¥(ğ’™)ì— ë¹„í•´ ì‘ì€ ì°¨ì›ìœ¼ë¡œ êµ¬ì„±</li>
<li>ë”°ë¼ì„œ ì •ë³´ì˜ ì„ íƒê³¼ ì••ì¶•ì´ ë°œìƒ, ì°¨ì›ì— ë”°ë¼ ì••ì¶•ì˜ ì •ë„ë¥¼ ê²°ì •í•¨<ul>
<li>ì§‘ì— ë¶ˆì´ ë‚˜ì„œ íƒˆì¶œí•  ë•Œ, ë¬´ì—‡ì„ ë“¤ê³  ë‚˜ê°ˆ ê²ƒì¸ê°€?</li>
</ul>
</li>
<li>ê·¸ëŸ¬ë¯€ë¡œ ğ’› ëŠ” ì…ë ¥(ğ’™)ì— ëŒ€í•œ feature vectorë¼ê³  í•  ìˆ˜ ìˆë‹¤.</li>
<li>ì••ì¶•ì˜ íš¨ìœ¨ì´ ë†’ì•„ì•¼ í•˜ë¯€ë¡œ, ì…ë ¥ì— ë¹„í•´ dense vectorì¼ ê²ƒ</li>
</ul>
</li>
<li><p>Decoder</p>
<ul>
<li>ì••ì¶•ëœ ì¤‘ê°„ ê²°ê³¼ë¬¼(ğ’™)ì„ ë°”íƒ•ìœ¼ë¡œ ìµœëŒ€í•œ ì…ë ¥(ğ’›)ê³¼ ë¹„ìŠ·í•˜ê²Œ ë³µì› : $\hat{x}$</li>
<li>ë³´í†µ MSELoss ë¥¼ í†µí•´ ìµœì í™” ìˆ˜í–‰ ($MSE&#x3D;|\hat{x}-x|^2_2$)</li>
<li>ë»”í•œ ì •ë³´ëŠ” ì£¼ì–´ì§€ì§€ ì•Šë”ë¼ë„ ì–´ì°¨í”¼ ì•Œ ìˆ˜ ìˆê¸°ì— ë³µì› ê°€ëŠ¥</li>
</ul>
</li>
</ul>
<h2 id="Hidden-Representation"><a href="#Hidden-Representation" class="headerlink" title="Hidden Representation"></a>Hidden Representation</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li><p>ì¸ì½”ë”ë¡œë¶€í„° ë‚˜ì˜¨ ì¤‘ê°„ ê²°ê³¼ë¬¼(ğ’›)ì€ ì…ë ¥(ğ’™)ì— ëŒ€í•œ feature vectorì´ë‹¤.</p>
</li>
<li><p>feature vectorì˜ ê° ì°¨ì›ì€ ì–´ë–¤ ì˜ë¯¸ë¥¼ ë‚´í¬í•˜ê³  ìˆì„ê¹Œ?</p>
<ul>
<li><p>ì¸ì½”ë”ì˜ ê²°ê³¼ë¬¼ ğ’›ë¥¼ plot í•˜ì˜€ì„ ë•Œ, ë¹„ìŠ·í•œ ìƒ˜í”Œë“¤ì€ ë¹„ìŠ·í•œ ê³³ì— ìœ„ì¹˜í•¨ì„ í™•ì¸</p>
</li>
<li><p>ì´ plotì´ ë¿Œë ¤ì§„ ê³µê°„ì„ hidden(latent) spaceë¼ê³  ë¶€ë¦„(ì ì¬ê³µê°„, feature vectorê°€ ìœ„ì¹˜í•˜ëŠ” ê³³)</p>
<ul>
<li>Input spaceì˜ MNIST ìƒ˜í”Œì´ latent spaceì— embedding ëœ ê²ƒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c02a4df6-74c9-49f3-b269-87abd0764629" alt="LatentSpace"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Mapping-to-Hidden-Latent-Space"><a href="#Mapping-to-Hidden-Latent-Space" class="headerlink" title="Mapping to Hidden(Latent) Space"></a>Mapping to Hidden(Latent) Space</h3><ul>
<li>ê° <strong>ë ˆì´ì–´ì˜ ê²°ê³¼ë¬¼</strong>ì„ <code>hidden vector</code> ë¼ê³  ë¶€ë¦„</li>
<li>ëª¨ë‘ feature vectorë¼ê³  ë³¼ ìˆ˜ ìˆìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/118c8c4d-dd4d-41cf-bc22-e524f3c77867" alt="hiddenSpace"></p>
<h3 id="Hidden-Latent-Representation"><a href="#Hidden-Latent-Representation" class="headerlink" title="Hidden(Latent) Representation"></a>Hidden(Latent) Representation</h3><ul>
<li><p>Tabular dataì˜ feature vectorì™€ ë‹¬ë¦¬, hidden vectorëŠ” í•´ì„ì´ ì–´ë ¤ì›€</p>
<ul>
<li>í•´ì„í•˜ê³ ì í•˜ëŠ” ì—°êµ¬(XAI. Explainable AI)ë“¤ì´ ì´ì–´ì§€ê³  ìˆìœ¼ë‚˜, ì•„ì§ ê°ˆ ê¸¸ì´ ë©€ë‹¤.</li>
</ul>
</li>
<li><p>í•˜ì§€ë§Œ, ë¹„ìŠ·í•œ íŠ¹ì§•ì„ ê°€ì§„ ìƒ˜í”Œì€ ë¹„ìŠ·í•œ hidden vectorë¥¼ ê°€ì§ˆ ê²ƒ</p>
</li>
<li><p>ë§Œì•½ ê° ì°¨ì›ì´ ëª…í™•í•˜ê²Œ í•˜ë‚˜ì˜ ì˜ë¯¸ë¥¼ ì§€ë‹Œë‹¤ë©´ ê° ì°¨ì›ì˜ ìˆ«ìë¥¼ ì¡°ì ˆí•˜ì—¬ ì›í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ í•©ì„±í•´ ë‚¼ ìˆ˜ ìˆì„ ê²ƒ</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4acbea3d-5fa3-4503-8cd8-4662a03b798f" alt="hiddenSpace02"></p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>ì˜¤í† ì¸ì½”ë”(AE)ëŠ” ì••ì¶•ê³¼ í•´ì œë¥¼ ë°˜ë³µí•˜ë©° íŠ¹ì§• ì¶”ì¶œì„ ìë™ìœ¼ë¡œ í•™ìŠµ<ul>
<li>í•„ìš”í•œ ì •ë³´ì™€ í•„ìš”ì—†ëŠ” ì •ë³´ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆê²Œë˜ëŠ” ê²ƒ</li>
</ul>
</li>
<li>ì¸ì½”ë”ë¡œë¶€í„° ë‚˜ì˜¨ ì¤‘ê°„ ê²°ê³¼ë¬¼(ğ’›)ì€ ì…ë ¥(ğ‘¥)ì— ëŒ€í•œ feature vectorì´ë‹¤.<ul>
<li>a.k.a Embedding vector</li>
<li>ì¸ì½”ë”ì— í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì€ feature vectorì— ëŒ€í•œ embedding ê³¼ì •ì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
<li>Hidden layerì˜ ê²°ê³¼ê°’ë“¤ì„ hidden vectorsë¼ ë¶€ë¥´ë©°, ì´ë“¤ì€ ìƒ˜í”Œì˜ featureë¥¼ ë‹´ê³  ìˆìŒ<ul>
<li>ì—¬ëŸ¬ê°œì˜ hidden vectorë“¤ì„ feature vectorë¼ ë¶€ë¥¼ ìˆ˜ ìˆìŒ</li>
<li>ë”¥ëŸ¬ë‹ì—ì„œëŠ” labelì„ classifyí•˜ê¸° ìœ„í•œ feature ë¥¼ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ í•™ìŠµ(ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ê³¼ì˜ ì°¨ì´ì )</li>
</ul>
</li>
<li>ì‹ ê²½ë§(ë˜ëŠ” ë ˆì´ì–´)ì„ í†µê³¼ì‹œí‚¤ëŠ” ê²ƒì€ ì…ë ¥ ê³µê°„(input space)ì—ì„œ ì ì¬ ê³µê°„(latent space)ë¡œì˜ ë§µí•‘ ê³¼ì •<ul>
<li>ê³ ì°¨ì› ê³µê°„(high-dimensional space) â†’ ì €ì°¨ì› ê³µê°„(lower-dimensional space)</li>
</ul>
</li>
<li>Hidden representaionì„ í•´ì„í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë ¤ì›€<ul>
<li>í•˜ì§€ë§Œ ë¹„ìŠ·í•œ ìƒ˜í”Œì€ ë¹„ìŠ·í•œ hidden representationì„ ì§€ë‹ ê²ƒ!</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-25T14:56:47.000Z" title="7/25/2023, 11:56:47â€¯PM">2023-07-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:50.000Z" title="9/6/2024, 12:03:50â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">8 minutes read (About 1171 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%A4%91%EA%B8%89%20%EA%B0%9C%EB%85%90/1%EC%9E%A5-Representation-Learning-One-hot-Encoding-%EB%B0%8F-Embedding-Vector/">1ì¥. Representation Learning - One-hot Encoding ë° Embedding Vector</a></h1><div class="content"><h2 id="One-hot-Encoding"><a href="#One-hot-Encoding" class="headerlink" title="One-hot Encoding"></a>One-hot Encoding</h2><h3 id="Categorical-Value-vs-Continuous-Value"><a href="#Categorical-Value-vs-Continuous-Value" class="headerlink" title="Categorical Value vs Continuous Value"></a>Categorical Value vs Continuous Value</h3><ul>
<li>Categorical Value<ul>
<li>ë³´í†µì€ discrete value</li>
<li>ë‹¨ì–´, í´ë˜ìŠ¤</li>
</ul>
</li>
<li>Continuous Value<ul>
<li>í‚¤, ëª¸ë¬´ê²Œ</li>
</ul>
</li>
<li>Categorical Valueì™€ Continuous Valueì˜ ê°€ì¥ ê²°ì •ì ì¸ ì°¨ì´ì <ul>
<li>Continous valueëŠ” ë¹„ìŠ·í•œ ê°’ì€ ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ì§€ë‹ˆì§€ë§Œ</li>
<li>Categorical valueëŠ” ë¹„ìŠ·í•œ ê°’ì¼ì§€ë¼ë„ ìƒê´€ì—†ëŠ” ì˜ë¯¸ë¥¼ ì§€ë‹Œë‹¤.</li>
</ul>
</li>
</ul>
<h3 id="One-hot-Encodingì˜-í•„ìš”ì„±"><a href="#One-hot-Encodingì˜-í•„ìš”ì„±" class="headerlink" title="One-hot Encodingì˜ í•„ìš”ì„±"></a>One-hot Encodingì˜ í•„ìš”ì„±</h3><ul>
<li><p>One-hot Encodingì˜ í•„ìš”ì„±ì„ ëŠë¼ê¸° ìœ„í•´ ì•„ë˜ì˜ ë‹¨ì–´ë¥¼ ì‚¬ì „ ìˆœìœ¼ë¡œ indexì— mapping í•´ë³´ì</p>
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody><tr>
<td>ê³µì±…</td>
<td>ë”±í’€</td>
<td>ë³¼íœ</td>
<td>ìƒ¤í”„</td>
<td>ì—°í•„</td>
<td>ì</td>
<td>í•„ê¸°ì¥</td>
</tr>
</tbody></table>
<ul>
<li>ìƒì‹ì ìœ¼ë¡œëŠ”<ul>
<li>distance(ì—°í•„, ë³¼íœ) &lt; distance(ì—°í•„, ì)</li>
<li>distance(ê³µì±…, í•„ê¸°ì¥) &lt; distance(ê³µì±…, ë”±í’€)</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ ì´ í…Œì´ë¸”ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¨ë‹¤.<ul>
<li>|ì—°í•„ - ë³¼íœ| &#x3D; 2	&gt;	1 &#x3D; |ì—°í•„ - ì|</li>
<li>|ê³µì±… - í•„ê¸°ì¥| &#x3D; 6	&gt;	1 &#x3D; |ê³µì±… - ë”±í’€|</li>
</ul>
</li>
<li>ì¦‰, ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì„ì˜ì˜ ìˆ«ìë¡œ í‘œí˜„í•˜ê²Œ ë˜ë©´, í…ìŠ¤íŠ¸ ê°„ì— ì›ë˜ ì¡´ì¬í•˜ì§€ ì•Šì•˜ë˜ â€˜í¬ê¸°â€™ë‚˜ â€˜ìˆœì„œâ€™ì˜ ê°œë…ì´ ë¶€ì—¬ë¨. ì´ë¡œ ì¸í•´ ë²”ì£¼í˜• ë°ì´í„° ê°„ì— ì‹¤ì œë¡œëŠ” ì—†ëŠ” ê±°ë¦¬ í˜¹ì€ ì°¨ì´ê°€ ì¡´ì¬í•˜ëŠ” ê²ƒì²˜ëŸ¼ í•´ì„ë˜ì–´, ë¶ˆí•„ìš”í•˜ê±°ë‚˜ ì˜ëª»ëœ ì •ë³´ë¥¼ í•™ìŠµí•˜ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<h3 id="One-hot-Encoding-ì´ë€"><a href="#One-hot-Encoding-ì´ë€" class="headerlink" title="One-hot Encoding ì´ë€"></a>One-hot Encoding ì´ë€</h3><ul>
<li><p>One-hot ì¸ì½”ë”©ì€ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•</p>
</li>
<li><p>ê°ê°ì˜ ë²”ì£¼ë¥¼ ë²¡í„°ì˜ í˜•íƒœë¡œ í‘œí˜„í•˜ë©°, ê° ë²”ì£¼ì˜ ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ” ì¸ë±ìŠ¤ë§Œ 1ë¡œ í‘œì‹œí•˜ê³  ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ í‘œì‹œ</p>
</li>
<li><p>í¬ê¸°ê°€ ì˜ë¯¸ë¥¼ ê°–ëŠ” integer ê°’ ëŒ€ì‹ , 1ê°œì˜ 1ê³¼ n-1ê°œì˜ 0ìœ¼ë¡œ ì´ë£¨ì–´ì§„ nì°¨ì›ì˜ ë²¡í„°</p>
<table>
<thead>
<tr>
<th></th>
<th>index</th>
<th>ê³µì±…</th>
<th>ë”±í’€</th>
<th>ë³¼íœ</th>
<th>ìƒ¤í”„</th>
<th>ì—°í•„</th>
<th>ì</th>
</tr>
</thead>
<tbody><tr>
<td>ë”±í’€</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>ì—°í•„</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>ì</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li>nê°œì˜ í•­ëª© â†’ nì°¨ì›</li>
<li>ì¦‰, 6ê°œì˜ í•­ëª© â†’ 6ì°¨ì›</li>
</ul>
</li>
<li><p>Vectorì˜ ëŒ€ë¶€ë¶„ì˜ elementê°€ 0ì¸ ê²½ìš° Sparse Vectorë¼ê³  ë¶€ë¦„</p>
<ul>
<li>ë°˜ëŒ€ ê°œë… : Dense Vector â†” Sparse Vector</li>
</ul>
</li>
<li><p>One-hot Encodingì˜ ì¥ì </p>
<ul>
<li>ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ë³€í™˜</li>
<li>ë²”ì£¼ ê°„ì˜ ìˆœì„œ ì—†ìŒ</li>
<li>íŠ¹ì„± ê°„ì˜ ë…ë¦½ì„± ë³´ì¥</li>
</ul>
</li>
<li><p>One-hot Encodingì˜ ë‹¨ì </p>
<ul>
<li>ì„œë¡œ ë‹¤ë¥¸ ë‘ ë²¡í„°ëŠ” í•­ìƒ ì§êµ(orthogonal)í•œë‹¤. (element-wise ê³± &#x3D; 0)<ul>
<li>Cosine Similarityê°€ 0, ë”°ë¼ì„œ ë‘ ìƒ˜í”Œ ì‚¬ì´ì˜ ìœ ì‚¬ë„(ê±°ë¦¬)ë¥¼ êµ¬í•  ìˆ˜ ì—†ìŒ</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Embedding-Vectors"><a href="#Embedding-Vectors" class="headerlink" title="Embedding Vectors"></a>Embedding Vectors</h2><h3 id="Motivation-of-Embedding-Vectors"><a href="#Motivation-of-Embedding-Vectors" class="headerlink" title="Motivation of Embedding Vectors"></a>Motivation of Embedding Vectors</h3><ul>
<li><p>NLPì—ì„œ ë‹¨ì–´ëŠ” categorical value &amp; discrete valueì˜ ì†ì„±ì„ ê°–ìŒ</p>
<ul>
<li>ë”°ë¼ì„œ one-hot representationìœ¼ë¡œ í‘œí˜„</li>
<li>í•˜ì§€ë§Œ ì´ëŠ” ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•  ìˆ˜ ì—†ìŒ</li>
<li>ë”°ë¼ì„œ ì‹¤ì œì ìœ¼ë¡œëŠ” ì¢€ë” ê³ ê¸‰í™”ëœ Embedding ê¸°ë²•ì„ ì‚¬ìš©</li>
</ul>
</li>
<li><p>ë‹¤ë¥¸ Embedding Vectors í‘œí˜„ ê¸°ë²•</p>
<ul>
<li><p>Contextual Word Embedding (ë¬¸ë§¥ì  ë‹¨ì–´ ì„ë² ë”©)</p>
<ul>
<li><p>ê¸°ì¡´ì˜ ë‹¨ì–´ ì„ë² ë”© ë°©ë²•ì€ ë‹¨ì–´ì˜ ì˜ë¯¸ê°€ ë¬¸ë§¥ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤ëŠ” ì ì„ ê³ ë ¤í•˜ì§€ ëª»í–ˆëŠ”ë° ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë“±ì¥</p>
</li>
<li><p>ë‹¨ì–´ë¥¼ ì„ë² ë”©í•  ë•Œ ì£¼ë³€ ë¬¸ë§¥ì„ ê³ ë ¤í•´ ë™ì¼í•œ ë‹¨ì–´ë¼ë„ ë‹¤ë¥¸ ë¬¸ë§¥ì—ì„œëŠ” ë‹¤ë¥¸ ì„ë² ë”© ë²¡í„°ë¥¼ ê°–ê²Œí•¨</p>
</li>
<li><p>BERT, ELMO ë“±ì´ í•´ë‹¹ë¨</p>
</li>
<li><p>ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, BertModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># BERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì´ˆê¸°í™”</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line">model = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì…ë ¥ ë¬¸ì¥</span></span><br><span class="line">sentences = [<span class="string">&quot;I went to the store&quot;</span>, <span class="string">&quot;I went to the school&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># í† í°í™” ë° ì„ë² ë”©</span></span><br><span class="line">inputs = tokenizer(sentences, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = model(**inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ê° ë¬¸ì¥ì˜ [CLS] í† í°ì— ëŒ€í•œ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°</span></span><br><span class="line">embeddings = outputs.last_hidden_state[:, <span class="number">0</span>, :]</span><br><span class="line"><span class="built_in">print</span>(embeddings)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Subword Embedding (ì„œë¸Œì›Œë“œ ì„ë² ë”©)</p>
<ul>
<li>íŠ¹ì • ì–¸ì–´ë“¤ì€ ë‹¨ì–´ë¥¼ ë” ì‘ì€ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•  ìˆ˜ ìˆìŒ</li>
<li>ì´ëŸ° ê²½ìš°, ì„œë¸Œì›Œë“œ ì„ë² ë”©ì„ ì‚¬ìš©í•˜ì—¬ ì‘ì€ ë‹¨ìœ„ë“¤ì„ í•™ìŠµí•  ìˆ˜ ìˆìŒ</li>
<li>BPE(Byte Pair Encoding), SentencePiece ë“±ì´ í•´ë‹¹ë¨</li>
</ul>
</li>
<li><p>Document Embedding (ë¬¸ì„œ ì„ë² ë”©)</p>
<ul>
<li>ë¬¸ì„œ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•</li>
<li>ë¬¸ì„œ ì„ë² ë”©ì€ ë¬¸ì„œì˜ ì „ì²´ì ì¸ ì˜ë¯¸ë¥¼ ì´í•´í•˜ëŠ”ë° ë„ì›€ì´ ë¨</li>
<li>Doc2Vec, FastText ë“±ì´ í•´ë‹¹</li>
</ul>
</li>
<li><p>Word Embedding (ë‹¨ì–´ ì„ë² ë”©)</p>
<ul>
<li>ê³ ì°¨ì›ì˜ One-hot ë²¡í„°ë¥¼ ì €ì°¨ì›ì˜ ì‹¤ìˆ˜ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ë²•</li>
<li>ë¹„ìŠ·í•œ ì˜ë¯¸ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ì´ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜í•˜ë„ë¡ í•™ìŠµ</li>
<li>Word2Vec, GloVe ë“±ì´ í•´ë‹¹ë¨</li>
</ul>
</li>
</ul>
</li>
<li><p>ê°œì¸ì ì¸ ê²½í—˜ìœ¼ë¡œëŠ” Contextual Word Embedding + Subword Embeddingì„ ê²°í•©í•´ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ê²ƒ ê°™ìœ¼ë©°, Word Embeddingì€ ê¹€ê¸°í˜„ ë‹˜ì˜ ë§ì”€ì— ì˜í•˜ë©´ Embeddingì— ì í•©í•˜ì§€ ì•Šë‹¤ê³  ë§ì”€í•´ì£¼ì‹  ê²ƒìœ¼ë¡œ ì•Œê³  ìˆë‹¤.</p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Categorical ValueëŠ” One-hot Encodingì„ í†µí•´ ë²¡í„°ë¡œ í‘œí˜„ë¨</li>
<li>Sparse VectorëŠ” ë²¡í„° ê°„ ìœ ì‚¬ë„ ê³„ì‚°ì´ ì–´ë ¤ì›€ â†’ One-hotì˜ ë‹¨ì </li>
<li>ë”°ë¼ì„œ Dense Vectorë¡œ í‘œí˜„í•  í•„ìš”ê°€ ìˆìŒ â†’ Contextual Embedding ë“±ì„ ì‚¬ìš©!</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-24T14:40:25.000Z" title="7/24/2023, 11:40:25â€¯PM">2023-07-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:45.000Z" title="9/6/2024, 12:03:45â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">6 minutes read (About 889 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%A4%91%EA%B8%89%20%EA%B0%9C%EB%85%90/1%EC%9E%A5-Representation-Learning-Feature-Vector/">1ì¥. Representation Learning - Feature Vector</a></h1><div class="content"><h2 id="Representation-Learning-í‘œí˜„-í•™ìŠµ"><a href="#Representation-Learning-í‘œí˜„-í•™ìŠµ" class="headerlink" title="Representation Learning (í‘œí˜„ í•™ìŠµ)"></a>Representation Learning (í‘œí˜„ í•™ìŠµ)</h2><ul>
<li>ë¨¸ì‹ ëŸ¬ë‹ì˜ í•˜ìœ„ ë¶„ì•¼ë¡œì„œ, ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ì—¬ ë³µì¡í•œ ë°ì´í„°ë¥¼ íš¨ìœ¨ì ì´ê³  ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í‘œí˜„ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” ë°©ë²•ì„ ì—°êµ¬í•˜ëŠ” ë¶„ì•¼</li>
<li>ì´ ë³€í™˜ëœ í˜•íƒœë¥¼ í†µí•´ ì›ë³¸ ë°ì´í„°ì˜ ì¤‘ìš”í•œ íŠ¹ì„±ì´ë‚˜ íŒ¨í„´ì„ ì°¾ì•„ë‚´ê³ , ì´ë¥¼ ì‚¬ìš©í•´ íš¨ê³¼ì ìœ¼ë¡œ í•™ìŠµ ë° ì˜ˆì¸¡ì„ ìˆ˜í–‰</li>
<li>ì›ë³¸ ë°ì´í„°ì˜ ë³µì¡ì„±ì„ ì¤„ì´ê³ , ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë©°, ë°ì´í„°ì˜ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ë³´ë‹¤ ëª…í™•í•˜ê²Œ ê°•ì¡°í•˜ëŠ” ì—­í• , ì´ë¥¼ í†µí•´ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ , í•™ìŠµ ê³¼ì •ì„ ë‹¨ìˆœí™”</li>
<li>ì˜¤í† ì¸ì½”ë”, ë”¥ ë¹„ì§€ë„ í•™ìŠµ, ì„ë² ë”© í•™ìŠµ ë“±ì€ í‘œí˜„ í•™ìŠµì˜ ëŒ€í‘œì ì¸ ì˜ˆì‹œ<ul>
<li>ì›ë³¸ ë°ì´í„°ì—ì„œ ì¤‘ìš”í•œ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ê³ </li>
<li>ì°¨ì› ê³µê°„ì—ì„œ í‘œí˜„í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•˜ë©°</li>
<li>ê²°ê³¼ì ìœ¼ë¡œ ë°ì´í„°ì˜ ê°€ì¥ í•µì‹¬ì ì¸ íŠ¹ì„±ë§Œì„ ì˜ ë³´ì¡´í•˜ëŠ” í‘œí˜„ì„ ì°¾ì•„ëƒ„</li>
</ul>
</li>
</ul>
<h2 id="Feature-íŠ¹ì§•"><a href="#Feature-íŠ¹ì§•" class="headerlink" title="Feature(íŠ¹ì§•)"></a>Feature(íŠ¹ì§•)</h2><h3 id="Featureë€"><a href="#Featureë€" class="headerlink" title="Featureë€?"></a>Featureë€?</h3><ul>
<li>ìƒ˜í”Œì„ ì˜ ì„¤ëª…í•˜ëŠ” íŠ¹ì§•</li>
<li>ì‚¬ëŒì„ ì„¤ëª…í•  ë•Œ ì¢‹ì€ íŠ¹ì§•<ul>
<li>Continuous: ë‚˜ì´, í‚¤, ëª¸ë¬´ê²Œ, ì†Œë“</li>
<li>Categorical: ì„±ë³„, ì§ì—…, ê±°ì£¼ì§€, ì¶œì‹  í•™êµ&#x2F;í•™ê³¼</li>
</ul>
</li>
<li>ë‚˜ìœ íŠ¹ì§•<ul>
<li>(ìƒë¬¼ ë¶„ë¥˜í•™ì ) ì¢…<ul>
<li>ëª¨ë‘ê°€ í˜¸ëª¨ ì‚¬í”¼ì—”ìŠ¤ì´ë¯€ë¡œ êµ¬ë¶„ì´ ë¶ˆê°€ëŠ¥</li>
</ul>
</li>
<li>ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, ì´ë¦„<ul>
<li>ì „ êµ­ë¯¼ì˜ ìˆ˜ ë§Œí¼ momoryê°€ í•„ìš”í•  ê²ƒ</li>
<li>ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ë§Œìœ¼ë¡œëŠ” (ë¹„ë¡ ì¼ë¶€ íŠ¹ì§•ì´ ìœ ì‚¬í•˜ì—¬ë„) ë‘ ì‚¬ëŒì˜ ìœ ì‚¬ë„ë¥¼ ì•Œ ìˆ˜ ì—†ìŒ</li>
<li>Categorical valueë¡œ ë³¼ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
</li>
<li><strong>íŠ¹ì§•ì„ í†µí•´ ìš°ë¦¬ëŠ” íŠ¹ì • ìƒ˜í”Œì„ ìˆ˜ì¹˜í™”</strong> í•  ìˆ˜ ìˆìŒ</li>
<li>í˜„ì‹¤ì—ì„œì˜ ëŒ€í‘œì ì¸ Featureì˜ ì˜ˆ - ëª½íƒ€ì£¼(Montage)<ul>
<li>ë²”ì¸ì˜ ì–¼êµ´ì„ íŠ¹ì •í•˜ê¸° ìœ„í•´ì„œ, ëª©ê²©ìë“¤ì—ê²Œ ë¬¼ì–´ì„œ ë‚˜ì˜¨ íŠ¹ì§•ë“¤ì„ í•©ì³ ë§Œë“  ê²ƒ<ul>
<li>ì¢‹ì€ ë‹¨ì„œ<ul>
<li>ëº¨ì— í° ë¶‰ì€ ë°˜ì </li>
<li>ì³ì§„ ëˆˆ</li>
<li>ê¸´ ìƒë¨¸ë¦¬</li>
</ul>
</li>
<li>ë‚˜ìœ ë‹¨ì„œ<ul>
<li>ëˆˆì´ 2ê°œ</li>
<li>ê·€ê°€ 2ê°œ</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Feature-in-Machine-Learning"><a href="#Feature-in-Machine-Learning" class="headerlink" title="Feature in Machine Learning"></a>Feature in Machine Learning</h3><ul>
<li>MNIST Classifcation<ul>
<li>íŠ¹ì • ìœ„ì¹˜ì— ê³§ì€(íœ˜ì–´ì§„) ì„ ì´ ì–¼ë§ˆë‚˜ ìˆëŠ”ê°€?</li>
<li>íŠ¹ì • ìœ„ì¹˜ì— ì„ ì´ ì–¼ë§ˆë‚˜ êµµì€ê°€?</li>
<li>íŠ¹ì • ìœ„ì¹˜ì— ì„ ì´ ì–¼ë§ˆë‚˜ ê¸°ìš¸ì–´ì ¸ ìˆëŠ”ê°€?</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de">https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de</a></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de" alt="MNIST"></p>
<h3 id="No-Need-of-Hand-crafted-Feature-in-Deep-Learning"><a href="#No-Need-of-Hand-crafted-Feature-in-Deep-Learning" class="headerlink" title="No Need of Hand-crafted Feature in Deep Learning"></a>No Need of Hand-crafted Feature in Deep Learning</h3><ul>
<li>Traditional Machine Learning<ul>
<li>ì‚¬ëŒì´ ë°ì´í„°ë¥¼ ë©´ë°€íˆ ë¶„ì„ í›„, ê°€ì •ì„ ì„¸ì›€</li>
<li>ê°€ì •ì— ë”°ë¼ ì „ì²˜ë¦¬ë¥¼ í•˜ì—¬ featureë¥¼ ì¶”ì¶œ</li>
<li>ì¶”ì¶œëœ featureë¥¼ modelì— ë„£ì–´ í•™ìŠµ</li>
<li>ì¥ì  : ì‚¬ëŒì´ í•´ì„í•˜ê¸° ì‰¬ì›€</li>
<li>ë‹¨ì  : ì‚¬ëŒì´ ë¯¸ì²˜ ìƒê°í•˜ì§€ ëª»í•œ íŠ¹ì§•ì˜ ì¡´ì¬ ê°€ëŠ¥ì„±</li>
</ul>
</li>
<li>Current Deep Learning<ul>
<li>Raw ë°ì´í„°ì— <strong>ìµœì†Œí•œì˜ ì „ì²˜ë¦¬</strong>(e.g. scale)ë¥¼ ìˆ˜í–‰</li>
<li>ë°ì´í„°ë¥¼ modelì— ë„£ì–´ í•™ìŠµ</li>
<li>ì¥ì  : êµ¬í˜„ì´ ìš©ì´í•¨, ë¯¸ì²˜ ë°œê²¬í•˜ì§€ ëª»í•œ íŠ¹ì§•ë„ í™œìš©</li>
<li>ë‹¨ì  : ì‚¬ëŒì´ í•´ì„í•˜ê¸° ì–´ë ¤ì›€</li>
</ul>
</li>
</ul>
<h3 id="Feature-Vector"><a href="#Feature-Vector" class="headerlink" title="Feature Vector"></a>Feature Vector</h3><ul>
<li>ê° <code>íŠ¹ì§•ë“¤ì„ ëª¨ì•„ì„œ í•˜ë‚˜ì˜ vector</code>ë¡œ ë§Œë“  ê²ƒ<ul>
<li>Tabular Datasetì˜ ê° rowë„ ì´ì— í•´ë‹¹</li>
</ul>
</li>
<li>ê° ì°¨ì›(dimension)ì€ ì–´ë–¤ ì†ì„±ì— ëŒ€í•œ levelì„ ë‚˜íƒ€ëƒ„<ul>
<li>ê° ì†ì„±ì— ëŒ€í•œ levelì´ ë¹„ìŠ·í• ìˆ˜ë¡ ë¹„ìŠ·í•œ ìƒ˜í”Œì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
<li>ìš°ë¦¬ëŠ” feature vectorë¥¼ í†µí•´ ìƒ˜í”Œ ì‚¬ì´ì˜ ê±°ë¦¬(ìœ ì‚¬ë„)ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆìŒ</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>í‚¤</th>
<th>ëª¸ë¬´ê²Œ</th>
<th>ë‚˜ì´</th>
<th>ì›” ì†Œë“</th>
<th>ì¶œì‹ </th>
</tr>
</thead>
<tbody><tr>
<td>ë¡œë²„íŠ¸</td>
<td>174cm</td>
<td>78kg</td>
<td>42</td>
<td>100</td>
<td>ë¯¸êµ­ ë§¤ì‚¬ì¶”ì„¸ì¸ </td>
</tr>
<tr>
<td>ìº¡í‹´ì•„ë©”ë¦¬ì¹´</td>
<td>183cm</td>
<td>88kg</td>
<td>58</td>
<td>1000</td>
<td>ë¯¸êµ­ ë‰´ìš•</td>
</tr>
</tbody></table>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-23T14:44:53.000Z" title="7/23/2023, 11:44:53â€¯PM">2023-07-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:25.000Z" title="9/6/2024, 12:03:25â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">4 minutes read (About 565 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/7%EC%9E%A5-%EA%B8%B0%EC%B4%88-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%A9%EB%B2%95-Gradient-Descent-Learning-Rate/">7ì¥. ê¸°ì´ˆ ìµœì í™” ë°©ë²• Gradient Descent - Learning Rate</a></h1><div class="content"><h2 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h2><h3 id="Learning-Rate-in-Gradient-Descent"><a href="#Learning-Rate-in-Gradient-Descent" class="headerlink" title="Learning Rate in Gradient Descent"></a>Learning Rate in Gradient Descent</h3><ul>
<li>íŒŒë¼ë¯¸í„°ê°€ ì—…ë°ì´íŠ¸ ë  ë•Œ, gradientì˜ í¬ê¸°ì— ì˜í–¥ì„ ë°›ê²Œ ë¨<ul>
<li>ì´ ë•Œ, learning rateê°€ step-sizeë¥¼ ì •í•´ì£¼ê²Œ ë¨</li>
</ul>
</li>
<li>Equation<ul>
<li>$\theta \gets \theta - \eta \frac{\partial L(\theta)}{\partial \theta} &#x3D; \theta - \eta \nabla_\theta L(\theta)$</li>
</ul>
</li>
</ul>
<h3 id="Learning-Rate-ì—-ë”°ë¥¸-ìµœì í™”-ë°ì´í„°ë‚˜-ëª¨ë¸-ì•„í‚¤í…ì²˜ì—-ë”°ë¼-lrì€-ë³€í•¨"><a href="#Learning-Rate-ì—-ë”°ë¥¸-ìµœì í™”-ë°ì´í„°ë‚˜-ëª¨ë¸-ì•„í‚¤í…ì²˜ì—-ë”°ë¼-lrì€-ë³€í•¨" class="headerlink" title="Learning Rate ì— ë”°ë¥¸ ìµœì í™” (ë°ì´í„°ë‚˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¼ lrì€ ë³€í•¨)"></a>Learning Rate ì— ë”°ë¥¸ ìµœì í™” (ë°ì´í„°ë‚˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ì— ë”°ë¼ lrì€ ë³€í•¨)</h3><ul>
<li>Large LR<ul>
<li>ë„ˆë¬´ í° Lossê°€ ë°œì‚°í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
<li>Small LR<ul>
<li>ë„ˆë¬´ ì‘ì€ LRì€ ìˆ˜ë ´ì´ ëŠ¦ìŒ</li>
<li>ìì¹« local minimaì— ë¹ ì§ˆ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589" alt="LearningRate"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589">https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589</a></p>
<h3 id="Learning-Rate-ëŠ”-ì¤‘ìš”í•œ-í•˜ì´í¼íŒŒë¼ë¯¸í„°"><a href="#Learning-Rate-ëŠ”-ì¤‘ìš”í•œ-í•˜ì´í¼íŒŒë¼ë¯¸í„°" class="headerlink" title="Learning Rate ëŠ” ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°"></a>Learning Rate ëŠ” ì¤‘ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°</h3><ul>
<li><strong>ì‹¤í—˜ì„ í†µí•´ ìµœì í™”</strong>í•˜ëŠ” ê²ƒì´ í•„ìš”</li>
<li>ì´ˆë³´ìë“¤ì€ ì²˜ìŒì— ì–´ë–¤ ê°’ì„ ì •í•´ì•¼ í• ì§€ ë‚œê°<ul>
<li>ê³ ë¯¼í•  ë°”ì— ê·¸ëƒ¥ ì•„ì£¼ ì‘ì€ ê°’(eg. 1e-4)ìœ¼ë¡œ ì˜¤ë˜ ëŒë ¤ë„ ê´œì°®ìŒ</li>
</ul>
</li>
<li>ë‚˜ì¤‘ì— Adam Optimizerë¥¼ í†µí•´ Learning Rateì— ëŒ€í•œ ê³ ë¯¼ì„ ì—†ì•¨ ìˆ˜ ìˆìŒ</li>
</ul>
<p>â€» í•˜ì´í¼íŒŒë¼ë¯¸í„° : ëª¨ë¸ ì„±ëŠ¥ì— ì˜í–¥ì„ ë¼ì¹˜ì§€ë§Œ, ë°ì´í„°ë¥¼ í†µí•´ í•™ìŠµí•  ìˆ˜ ì—†ëŠ” íŒŒë¼ë¯¸í„° (ìš°ë¦¬ê°€ ì§ì ‘ í…ŒìŠ¤íŠ¸í•˜ê³  íŠœë‹ì„ í•´ì•¼í•¨)</p>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°</h3><ul>
<li><p>Gradient Descent + Learning Rate ì‹¤ìŠµ</p>
<ul>
<li>$L(x)&#x3D;| targert - x |_2^2$</li>
<li>$x \gets x - \eta \nabla_x L(x)$<ul>
<li>cf) $\nabla_x L(x) &#x3D; x.grad$</li>
</ul>
</li>
<li>$\hat{x} &#x3D; \text{argmin}L(x)$, $x \in \mathbb{R}^{3,3}$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">target = torch.FloatTensor([[<span class="number">.1</span>, <span class="number">.2</span>, <span class="number">.3</span>],</span><br><span class="line">                            [<span class="number">.4</span>, <span class="number">.5</span>, <span class="number">.6</span>],</span><br><span class="line">                            [<span class="number">.7</span>, <span class="number">.8</span>, <span class="number">.9</span>]])</span><br><span class="line"></span><br><span class="line">x = torch.rand_like(target)</span><br><span class="line"><span class="comment"># This means the final scalar will be differentiate by x.</span></span><br><span class="line">x.requires_grad = <span class="literal">True</span></span><br><span class="line"><span class="comment"># You can get gradient of x, after differentiation.</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># tensor([[0.4176, 0.6465, 0.3522],</span></span><br><span class="line"><span class="comment">#         [0.9164, 0.7576, 0.0892],</span></span><br><span class="line"><span class="comment">#         [0.4854, 0.0136, 0.9467]], requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">loss = F.mse_loss(x, target)</span><br><span class="line"><span class="built_in">print</span>(loss) <span class="comment"># tensor(0.1737, grad_fn=&lt;MseLossBackward&gt;)</span></span><br><span class="line"></span><br><span class="line">threshold = <span class="number">1e-5</span></span><br><span class="line">learning_rate = <span class="number">1.</span></span><br><span class="line">iter_cnt = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> loss &gt; threshold:</span><br><span class="line">    iter_cnt += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    loss.backward() <span class="comment"># Calculate gradients.</span></span><br><span class="line"></span><br><span class="line">    x = x - learning_rate * x.grad</span><br><span class="line">    </span><br><span class="line">    x.detach_()</span><br><span class="line">    x.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(x, target)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%d-th Loss: %.4e&#x27;</span> % (iter_cnt, loss))</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    1 - th Loss: 1.0510e-01</span></span><br><span class="line"><span class="string">    tensor([[0.3470, 0.5473, 0.3406],</span></span><br><span class="line"><span class="string">            [0.8016, 0.7003, 0.2027],</span></span><br><span class="line"><span class="string">            [0.5331, 0.1883, 0.9363]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    2 - th Loss: 6.3576e-02</span></span><br><span class="line"><span class="string">    tensor([[0.2921, 0.4701, 0.3316],</span></span><br><span class="line"><span class="string">            [0.7124, 0.6558, 0.2910],</span></span><br><span class="line"><span class="string">            [0.5702, 0.3242, 0.9282]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    3 - th Loss: 3.8460e-02</span></span><br><span class="line"><span class="string">    tensor([[0.2494, 0.4101, 0.3246],</span></span><br><span class="line"><span class="string">            [0.6430, 0.6212, 0.3597],</span></span><br><span class="line"><span class="string">            [0.5990, 0.4300, 0.9220]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    19 - th Loss: 1.2370e-05</span></span><br><span class="line"><span class="string">    tensor([[0.1027, 0.2038, 0.3004],</span></span><br><span class="line"><span class="string">            [0.4044, 0.5022, 0.5957],</span></span><br><span class="line"><span class="string">            [0.6982, 0.7934, 0.9004]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    20 - th Loss: 7.4833e-06</span></span><br><span class="line"><span class="string">    tensor([[0.1021, 0.2029, 0.3003],</span></span><br><span class="line"><span class="string">            [0.4034, 0.5017, 0.5966],</span></span><br><span class="line"><span class="string">            [0.6986, 0.7948, 0.9003]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="7ì¥-Wrap-up"><a href="#7ì¥-Wrap-up" class="headerlink" title="7ì¥ Wrap up"></a>7ì¥ Wrap up</h2><h3 id="Why-we-do-gradient-descent"><a href="#Why-we-do-gradient-descent" class="headerlink" title="Why we do gradient descent?"></a>Why we do gradient descent?</h3><ul>
<li>ì‹¤ì¬í•˜ì§€ë§Œ ì•Œ ìˆ˜ ì—†ëŠ” í•¨ìˆ˜ $f^*$ë¥¼ ê·¼ì‚¬í•˜ê³  ì‹¶ìŒ</li>
<li>ë‚˜ì˜ ëª¨ë¸(í•¨ìˆ˜)ì˜ $f_\theta$ íŒŒë¼ë¯¸í„° ğœ½ë¥¼ ì¡°ì ˆ</li>
<li><strong>ì†ì‹¤ í•¨ìˆ˜(Loss Function)ë¥¼ ìµœì†Œí™” í•˜ë„ë¡ íŒŒë¼ë¯¸í„° ğœ½ë¥¼ ì¡°ì ˆ</strong></li>
<li>ë¯¸ë¶„ì„ í†µí•´ gradient($\frac{\partial Loss}{\partial \theta}$)ë¥¼ ì–»ê³ , lossë¥¼ ë‚®ì¶”ëŠ” ë°©í–¥ìœ¼ë¡œ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-21T14:58:47.000Z" title="7/21/2023, 11:58:47â€¯PM">2023-07-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:19.000Z" title="9/6/2024, 12:03:19â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">12 minutes read (About 1774 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/7%EC%9E%A5-%EA%B8%B0%EC%B4%88-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%A9%EB%B2%95-Gradient-Descent-Gradient-Descent/">7ì¥. ê¸°ì´ˆ ìµœì í™” ë°©ë²• Gradient Descent - Gradient Descent</a></h1><div class="content"><h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><h3 id="Again-Our-Objective-is"><a href="#Again-Our-Objective-is" class="headerlink" title="Again, Our Objective is"></a>Again, Our Objective is</h3><ul>
<li><p>ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ì„œ ì¶œë ¥ ê°’ì„ ë˜‘ê°™ì´ ëª¨ì‚¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì°¾ê³  ì‹¶ë‹¤.</p>
</li>
<li><p>Loss ê°’ì„ ìµœì†Œë¡œ í•˜ëŠ” Loss Functionì˜ ì…ë ¥ ê°’(ğœƒ)ë¥¼ ì°¾ì. How?</p>
<ul>
<li><p>ğœƒ ê°’ì„ í•˜ë‚˜í•˜ë‚˜ ë‹¤ ëœë¤í•˜ê²Œ ë„£ì–´ë³¼ ìˆ˜ê°€ ì—†ë‹¤!! ë”°ë¼ì„œ Loss Functionì„ ìµœì†Œí™”í•˜ëŠ” ğœƒë¥¼ ì–»ëŠ” ë°©ë²•ì´ ë°”ë¡œ Gradient Descent!</p>
<p>$D &#x3D; {(x_i, y_i)}_{i&#x3D;1}^N$    &#x2F;&#x2F; (ë°ì´í„° ì…‹ë“¤ì´ ëª¨ì—¬ì ¸ ìˆì„ë•Œ)</p>
<p>$L(\theta) &#x3D; \sum_{i&#x3D;1}^{N} |y_i - \hat{y_i}|^2_2 &#x3D; \sum_{i&#x3D;1}^{N} |y_i - f_\theta(x_i)|^2_2, \text { where } \theta&#x3D;{W,b}, \text{ }f(x)&#x3D;x \cdot W+b$</p>
<p>$\hat{\theta} &#x3D; \operatorname{argmin}_{\theta} L(\theta)$</p>
<p>Loss í•¨ìˆ˜ì˜ ì¶œë ¥ ê²°ê³¼ê°€ ìµœì†Œê°€ ë˜ê³  ì‹¶ì–´í•˜ëŠ” ì…ë ¥ê°’ì„ ì ì§„ì ìœ¼ë¡œ ì°¾ê³  ì‹¶ê² ë‹¤. ì˜ëœë‹¤ë©´ ëª©ì í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•  ìˆ˜ ìˆìŒ($f^* \approx f_{\hat{\theta}}$)</p>
</li>
</ul>
</li>
</ul>
<h3 id="Gradient-Descent-1D-Case"><a href="#Gradient-Descent-1D-Case" class="headerlink" title="Gradient Descent 1D Case"></a>Gradient Descent 1D Case</h3><ul>
<li><p>ğ‘¥ë¡œ ë¯¸ë¶„í•˜ì—¬ ê¸°ìš¸ê¸°ë¥¼ í™œìš©í•˜ì—¬ ì¢€ ë” ë‚®ì€ ê³³ìœ¼ë¡œ ì ì°¨ ë‚˜ì•„ê°€ì</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/fb0d94f4-622c-4a79-af25-3526e39efec2" alt="GradientDescent05"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/fb0d94f4-622c-4a79-af25-3526e39efec2">https://github.com/shchoice/shchoice.github.io/assets/100276387/fb0d94f4-622c-4a79-af25-3526e39efec2</a></p>
<p>$x \gets x - \eta \frac{dy}{dx}, \text{ where } y &#x3D; f(x)$</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">â¬‡ï¸</span><br></pre></td></tr></table></figure>

<p>$\theta \gets \theta - \eta \frac{\partial L(\theta)}{\partial \theta} &#x3D; \theta - \eta \nabla_\theta L(\theta)$</p>
<p>â€» ğœ‚ : Learning rate(0~1, hyper parameter), â…†ğ‘¦&#x2F;â…†ğ‘¥ : ê¸°ìš¸ê¸°</p>
<p>â€» ğ¿(ğœƒ) : ì†ì‹¤ í•¨ìˆ˜(loss function)ë¡œì¨ ìŠ¤ì¹¼ë¼ ê°’ì„ ê°–ìŒ , ğœƒ: íŒŒë¼ë¯¸í„° ë˜ëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°ë¡œ vectorê°’ì„ ê°–ìŒ(ê³ ì°¨ì›ì˜ ì‹ ê²½ë§ì—ì„œëŠ” ğœƒê°€ ë²¡í„° ë¿ë§Œ ì•„ë‹ˆë¼ í–‰ë ¬, ë˜ëŠ” ê³ ì°¨ì› í…ì„œì˜ í˜•íƒœë¥¼ ê°€ì§ˆ ìˆ˜ë„ ìˆìŒ, ì—¬ê¸°ì„œëŠ” 1Dë¡œ ê°€ì •í•˜ê¸°ì— Vector) ë”°ë¼ì„œ $âˆ‡_Î¸L(Î¸)$ëŠ” ë²¡í„° <em>Î¸ì— ëŒ€í•œ L</em>(<em>Î¸</em>)ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ëŠ” <em>Î¸ì˜ ê° ìš”ì†Œì— ëŒ€í•´ L</em>(<em>Î¸</em>)ë¥¼ í¸ë¯¸ë¶„í•œ ê²°ê³¼ë¥¼ ë²¡í„° í˜•íƒœë¡œ í‘œí˜„í•œ ê²ƒ</p>
</li>
<li><p>ê°€ì¥ lossê°€ ë‚®ì€ ê³³ì´ ì•„ë‹Œ ê³¨ì§œê¸°ì— ë¹ ì§ˆ ê°€ëŠ¥ì„±ì´ ìˆìŒ <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2c81e7ab-68e0-4fc9-8306-112d39cec17e" alt="GradientDescent06"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/2c81e7ab-68e0-4fc9-8306-112d39cec17e">https://github.com/shchoice/shchoice.github.io/assets/100276387/2c81e7ab-68e0-4fc9-8306-112d39cec17e</a></p>
<ul>
<li>ê·¸ë¦¼ì€ 2ì°¨ì› ì´ì§€ë§Œ, ì‚¬ì‹¤ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ë§Œí¼ì˜ ì°¨ì›ìœ¼ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŒ Convex í•œ 2ì°¨ í•¨ìˆ˜ê°€ ì•„ë‹Œ ì´ìƒ, Global Minimaë¥¼ ì•Œ ìˆ˜ê°€ ì—†ë‹¤.</li>
</ul>
</li>
</ul>
<h3 id="Loss-Minimization-using-Gradient-Descent"><a href="#Loss-Minimization-using-Gradient-Descent" class="headerlink" title="Loss Minimization using Gradient Descent"></a>Loss Minimization using Gradient Descent</h3><p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/e26fa081-eeb0-441e-8ea0-90d3aa418444">https://github.com/shchoice/shchoice.github.io/assets/100276387/e26fa081-eeb0-441e-8ea0-90d3aa418444</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/e26fa081-eeb0-441e-8ea0-90d3aa418444">https://github.com/shchoice/shchoice.github.io/assets/100276387/e26fa081-eeb0-441e-8ea0-90d3aa418444</a></p>
<ul>
<li><p>1D ì¼€ì´ìŠ¤ë¥¼ ë†’ì€ ì°¨ì›ì˜ íŒŒë¼ë¯¸í„°(*Î¸)*ë¡œ í™•ì¥í•˜ì</p>
<ul>
<li><p>$\hat{\theta} &#x3D; \operatorname{argmin}_{\theta} L(\theta)$</p>
<p>$W \gets W - \eta \frac{\partial L(\theta)}{\partial W} \text{, }$</p>
<p>$b \gets b - \eta \frac{\partial L(\theta)}{\partial b},$</p>
<p>$\text{where } \theta &#x3D; {W,b}$</p>
</li>
</ul>
</li>
<li><p>Number of Parameters in Linear Layer</p>
<ul>
<li><p>íŒŒë¼ë¯¸í„° ìˆ˜ : n x m + m &#x3D; (n + 1) x m</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942">https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942</a></p>
<ul>
<li><p>|ğœƒ|&#x3D;(18,) , &#x2F;&#x2F; 18ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆìŒ! ğ‘Š &#x3D; 5x3 &#x3D;15, ğ‘ &#x3D; 3</p>
</li>
<li><p>$y &#x3D; f(k) &#x3D; x \cdot W + b$</p>
<p>$\text{ where } x \in \mathbb{R}^{k \times n}, W \in \mathbb{R}^{n \times m}, b \in \mathbb{R}^{n \times m} \text{ and } y \in \mathbb{R}^{n \times m}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Local-Minima-in-Practice"><a href="#Local-Minima-in-Practice" class="headerlink" title="Local Minima in Practice"></a>Local Minima in Practice</h3><ul>
<li>ì‹¤ì œ ë”¥ëŸ¬ë‹ì˜ ê²½ìš°ì— íŒŒë¼ë¯¸í„°ì˜ í¬ê¸°ê°€ ìˆ˜ë°±ë§Œ ë‹¨ìœ„</li>
<li>ìˆ˜ë°±ë§Œ ì°¨ì›ì˜ loss í•¨ìˆ˜ surface ì—ì„œ global minmaë¥¼ ì°¾ëŠ” ë¬¸ì œ</li>
<li>ìˆ˜ ë§ì€ ì°¨ì›ì—ì„œ ë™ì‹œì— local minimaë¥¼ ìœ„í•œ ì¡°ê±´ì´ ë§Œì¡±ë˜ê¸°ëŠ” ì–´ë ¤ì›€</li>
<li><strong>ë”°ë¼ì„œ local mimaì— ëŒ€í•œ ê±±ì •ì„ í¬ê²Œ í•  í•„ìš” ì—†ìŒ</strong></li>
</ul>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°</h3><ul>
<li><p>Gradient Descent ì‹¤ìŠµ -  backward() &amp; requires_grad_()</p>
<ul>
<li>$x &#x3D; \begin{bmatrix} x_{(1,1)} &amp; x_{(1,2)} \ x_{(2,1)} &amp; x_{(2,2)} \end{bmatrix}$</li>
<li>$x_1&#x3D;x+2$</li>
<li>$x_2&#x3D;x-2$</li>
<li>$x_3&#x3D;x^2-4$</li>
<li>$y&#x3D;sum(x_3)&#x3D;x_{3(1,1)} + x_{3(1,2)} + x_{3(2,1)} + x_{3(2,2)}$</li>
<li>$x.grad&#x3D;\begin{bmatrix} \frac{\partial y}{\partial x_{(1,1)}} &amp; \frac{\partial y}{\partial x_{(1,2)}} \ \frac{\partial y}{\partial x_{(2,1)}} &amp; \frac{\partial y}{\partial x_{(2,2)}} \end{bmatrix}$</li>
<li>$\frac{dy}{dx}&#x3D;2x$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>]]).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">x1 = x + <span class="number">2</span></span><br><span class="line">x2 = x - <span class="number">2</span></span><br><span class="line">x3 = x1 * x2</span><br><span class="line">y = x3.<span class="built_in">sum</span>() </span><br><span class="line"><span class="comment"># ìŠ¤ì¹¼ë¼ ê°’ì´ì–´ì•¼ ë¯¸ë¶„ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸ì— .sum()ì´ ë¶™ìŒ ì—†ìœ¼ë©´ RuntimeError: grad can be implicitly created only for scalar outputs ì—ëŸ¬ ë°œìƒ</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x1)</span><br><span class="line"><span class="comment">#tensor([[3., 4.],</span></span><br><span class="line"><span class="comment">#       [5., 6.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x2)</span><br><span class="line"><span class="comment"># tensor([[-1.,  0.],</span></span><br><span class="line"><span class="comment">#         [ 1.,  2.]], grad_fn=&lt;SubBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x3)</span><br><span class="line"><span class="comment"># tensor([[-3.,  0.],</span></span><br><span class="line"><span class="comment">#        [ 5., 12.]], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># tensor(14., grad_fn=&lt;SumBackward0&gt;)</span></span><br><span class="line"></span><br><span class="line">y.backward() <span class="comment"># ìŠ¤ì¹¼ë¼ì—¬ì•¼ë§Œ ë¯¸ë¶„ ê°€ëŠ¥í•˜ë‹¤. ìŠ¤ì¹¼ë¼ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°˜í™˜ # grequired_grad_(True) ëŠ” ë‹¤ ë¯¸ë¶„</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">.backward() ë©”ì„œë“œëŠ” PyTorchì—ì„œ ì œê³µí•˜ëŠ” ìë™ ë¯¸ë¶„ ê¸°ëŠ¥ìœ¼ë¡œ, ì‹¤ì œë¡œëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ë©°</span></span><br><span class="line"><span class="string">íŒŒì´í† ì¹˜ì˜ ê³„ì‚° ê·¸ë˜í”„(computation graph)ì˜ íŠ¹ì„±ì—ì„œ ë¹„ë¡¯ë¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ë˜ì„œ y.backward()ì—ì„œ yëŠ” ë³´í†µ ìŠ¤ì¹¼ë¼(scalar)ê°€ ë¨</span></span><br><span class="line"><span class="string">ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ê°€ ê´€ì‹¬ì„ ê°–ëŠ” ëŒ€ìƒì´ ë³´í†µ ì†ì‹¤ í•¨ìˆ˜(loss function)ì´ê¸° ë•Œë¬¸ì´ê³ , ì´ëŠ” ìŠ¤ì¹¼ë¼ ê°’ì„ ë°˜í™˜</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ°ë° ë§Œì•½ yê°€ ë²¡í„°ë‚˜ í–‰ë ¬ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ í…ì„œë¼ë©´? </span></span><br><span class="line"><span class="string">ì´ ê²½ìš°ì—ë„ .backward() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì´ë¥¼ ìœ„í•´ì„œëŠ” ì¸ìë¡œ ë²¡í„°ë¥¼ ì œê³µí•´ì•¼ í•¨ </span></span><br><span class="line"><span class="string">ì´ ë²¡í„°ëŠ” yì˜ ê° ìš”ì†Œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ë¥¼ í†µí•´ ìŠ¤ì¹¼ë¼ ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŒ</span></span><br><span class="line"><span class="string">ì˜ˆì‹œ) v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)  # ê°€ì¤‘ì¹˜ ë²¡í„°, y.backward(v)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ì´ëŸ° ë³µì¡ì„± ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ ê²½ìš°, .backward()ëŠ” ì†ì‹¤ ê°’ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ í…ì„œì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë˜ë©°, </span></span><br><span class="line"><span class="string">ì´ëŠ” ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚° </span></span><br><span class="line"><span class="string">ì´ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” íŒŒë¼ë¯¸í„°ì˜ .grad ì†ì„±ì— ì €ì¥ë˜ë©°, ì´ë¥¼ ì‚¬ìš©í•´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="comment"># tensor([[2., 4.],</span></span><br><span class="line"><span class="comment">#        [6., 8.]])</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">print(x3.numpy())</span></span><br><span class="line"><span class="string"># RuntimeError: Can&#x27;t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.</span></span><br><span class="line"><span class="string">print(x3.detach_().numpy())</span></span><br><span class="line"><span class="string"># array([[-3.,  0.],</span></span><br><span class="line"><span class="string">#       [ 5., 12.]], dtype=float32)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PyTorchì—ì„œ í…ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ requires_grad ì†ì„±ì´ Falseë¡œ ì„¤ì •ë˜ë‚˜, </span></span><br><span class="line"><span class="string">ì´ ì†ì„±ì´ Trueë¡œ ì„¤ì •ë˜ë©´, </span></span><br><span class="line"><span class="string">í•´ë‹¹ í…ì„œì— ì—°ì‚°ì´ ìˆ˜í–‰ë  ë•Œë§ˆë‹¤ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ëŠ” ê³„ì‚° ê·¸ë˜í”„ì— ì´ ì •ë³´ê°€ ì¶”ê°€ë¨</span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—­ì „íŒŒ(backpropagation) ë‹¨ê³„ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆê²Œë¨.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ¬ë‚˜ requires_gradê°€ Trueì¸ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ì§ì ‘ ë³€í™˜í•  ìˆ˜ ì—†ìŒ. </span></span><br><span class="line"><span class="string">ì´ëŠ” PyTorchì˜ ê³„ì‚° ê·¸ë˜í”„ì™€ Numpyê°€ ì„œë¡œ í˜¸í™˜ë˜ì§€ ì•Šê¸° ë•Œë¬¸. </span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ requires_gradê°€ Trueì¸ í…ì„œë¥¼ Numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ë ¤ë©´ ë¨¼ì € detach() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬</span></span><br><span class="line"><span class="string"> ê³„ì‚° ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ í…ì„œë¥¼ ë¶„ë¦¬í•œ í›„ ë³€í™˜í•´ì•¼ í•¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ì œì•ˆí•˜ëŠ” ê²ƒì²˜ëŸ¼, x3.detach().numpy()ë¥¼ ì‚¬ìš©í•˜ë©´ x3ë¥¼ Numpy ë°°ì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•  ìˆ˜ ìˆìŒ. </span></span><br><span class="line"><span class="string">ì´ë ‡ê²Œ í•˜ë©´ x3ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ í•„ìš”í•˜ì§€ ì•Šì€ ìƒˆë¡œìš´ í…ì„œê°€ ìƒì„±ë˜ê³ , ì´ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ë³€í™˜ë  ìˆ˜ ìˆìŒ.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="ìš”ì•½-ì •ë¦¬"><a href="#ìš”ì•½-ì •ë¦¬" class="headerlink" title="ìš”ì•½ ì •ë¦¬"></a>ìš”ì•½ ì •ë¦¬</h3><ul>
<li>DNNì„ í†µí•´ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ê³  ì‹¶ì„ ê²½ìš°, ìš°ë¦¬ê°€ ë§Œë“  í•¨ìˆ˜ê°€ ë‚´ë±‰ëŠ” ì¶œë ¥ê³¼ ì‹¤ì œ ì •ë‹µì˜ ì°¨ì´ëŠ” lossì´ë‹¤.</li>
<li>lossë¥¼ loss functionìœ¼ë¡œ ë§Œë“¤ê³  loss functionì€ íŒŒë¼ë¯¸í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ìŒ</li>
<li>ë”°ë¼ì„œ loss functionì˜ ì¶œë ¥ì„ ìµœì†Œë¡œ í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ê²ƒì´ ëª©ì ì´ ë¨</li>
<li>lossë¥¼ ìµœì†Œí™”í•˜ëŠ” ì…ë ¥ íŒŒë¼ë¯¸í„°ë¥¼ Gradiend Descentë¡œ ì°¾ì„ ìˆ˜ ìˆìŒ</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-20T14:21:57.000Z" title="7/20/2023, 11:21:57â€¯PM">2023-07-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:32.000Z" title="9/6/2024, 12:03:32â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">21 minutes read (About 3218 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/7%EC%9E%A5-%EA%B8%B0%EC%B4%88-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%A9%EB%B2%95-Gradient-Descent-%ED%8E%B8%EB%AF%B8%EB%B6%84/">7ì¥. ê¸°ì´ˆ ìµœì í™” ë°©ë²• Gradient Descent - í¸ë¯¸ë¶„</a></h1><div class="content"><h2 id="í¸ë¯¸ë¶„"><a href="#í¸ë¯¸ë¶„" class="headerlink" title="í¸ë¯¸ë¶„"></a>í¸ë¯¸ë¶„</h2><h3 id="ë‹¤ë³€ìˆ˜-í•¨ìˆ˜-Multivariation-Function"><a href="#ë‹¤ë³€ìˆ˜-í•¨ìˆ˜-Multivariation-Function" class="headerlink" title="ë‹¤ë³€ìˆ˜ í•¨ìˆ˜(Multivariation Function)"></a>ë‹¤ë³€ìˆ˜ í•¨ìˆ˜(Multivariation Function)</h3><ul>
<li>ì—¬ëŸ¬ ê°œì˜ ë³€ìˆ˜(multivariate)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” í•¨ìˆ˜<ul>
<li>$z &#x3D; f(x,y)$</li>
<li>$y &#x3D; f(x_1, x_2)$</li>
<li>$x &#x3D; \begin{bmatrix} x_1 \ x_2 \end{bmatrix}$</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2" alt="MultivariateFunction"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2">https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2</a></p>
<h3 id="í¸ë¯¸ë¶„-1"><a href="#í¸ë¯¸ë¶„-1" class="headerlink" title="í¸ë¯¸ë¶„"></a>í¸ë¯¸ë¶„</h3><ul>
<li><p>ë‹¤ë³€ìˆ˜ xì™€ yë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” í•¨ìˆ˜ fë¥¼ xë¡œ ë¯¸ë¶„í•  ê²½ìš°</p>
<ul>
<li>í•˜ë‚˜ì˜ ë³€ìˆ˜ë§Œ ë‚¨ê²¨ ë†“ê³  ë‚˜ë¨¸ì§€ë¥¼ ìƒìˆ˜ ì·¨ê¸‰í•˜ëŠ” ë¯¸ë¶„ ë°©ë²•</li>
</ul>
</li>
<li><p>í•¨ìˆ˜ fë¥¼ xë³€ìˆ˜(xì¶•)ìœ¼ë¡œ ë¯¸ë¶„</p>
<ul>
<li>í¸ë¯¸ë¶„ ê¸°í˜¸ ğœ• (round í˜¹ì€ partial ë¼ê³  ë¶€ë¦„)</li>
</ul>
<p>$\frac{\partial f}{\partial x} &#x3D; \lim_{h \to 0} \frac{f(x+h,y) - f(x,y)}{(x+h) - x}$</p>
</li>
<li><p>Yê°’ì— ëŒ€í•´ ëš ì˜ëì„ ë•Œ xì¶•ì— ëŒ€í•œ ê¸°ìš¸ê¸°</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61" alt="GradientDescent01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61">https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61</a></p>
</li>
</ul>
<h3 id="í•¨ìˆ˜ì˜-ì…ì¶œë ¥-í˜•íƒœ"><a href="#í•¨ìˆ˜ì˜-ì…ì¶œë ¥-í˜•íƒœ" class="headerlink" title="í•¨ìˆ˜ì˜ ì…ì¶œë ¥ í˜•íƒœ"></a>í•¨ìˆ˜ì˜ ì…ì¶œë ¥ í˜•íƒœ</h3><ul>
<li><p>í•¨ìˆ˜ì˜ ì…ë ¥ì´ ë²¡í„°ì¸ ê²½ìš°</p>
<p>$y&#x3D;f(\begin{bmatrix} x_1 \â¦™\x_n \end{bmatrix})&#x3D;f(x), \text{ where } x \in \mathbb{R}^n$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì¶œë ¥ì´ ë²¡í„°ì¸ ê²½ìš° $y&#x3D;f(\begin{bmatrix} y_1 \â¦™\y_n \end{bmatrix})&#x3D;f(x)&#x3D;\begin{bmatrix} f_1(x) \â¦™\f_n(x) \end{bmatrix}, \text{ where } y \in \mathbb{R}^n$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì…ë ¥ì´ í–‰ë ¬ì¸ ê²½ìš°</p>
<p>$y&#x3D;f(\begin{bmatrix} x_{1,1} â‹¯ x_{1,m} \â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ x_{n,1} â‹¯ x_{n,m} \end{bmatrix})&#x3D;f(X), \text{ where } X \in \mathbb{R}^{n \times m}$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì¶œë ¥ì´ í–‰ë ¬ì¸ ê²½ìš° $Y&#x3D;f(\begin{bmatrix} y_{1,1} â‹¯ y_{1,m} \â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ y_{n,1} â‹¯ y_{n,m} \end{bmatrix})&#x3D;f(x), \text{ where } Y \in \mathbb{R}^{n \times m}$</p>
</li>
<li><p>ì…ë ¥ê³¼ ì¶œë ¥ì´ ë²¡í„°ì¸ í•¨ìˆ˜</p>
<p>$y&#x3D;f(\begin{bmatrix} y_1 \â¦™\y_n \end{bmatrix})&#x3D;f(x)&#x3D; f(\begin{bmatrix} x_1 \â¦™\x_n \end{bmatrix}), \text{ where } f: \mathbb{R}^n \rightarrow \mathbb{R}^m$</p>
</li>
</ul>
<h3 id="ìŠ¤ì¹¼ë¼ë¥¼-ë²¡í„°ë¡œ-ìŠ¤ì¹¼ë¼ë¥¼-í–‰ë ¬ë¡œ-ë¯¸ë¶„"><a href="#ìŠ¤ì¹¼ë¼ë¥¼-ë²¡í„°ë¡œ-ìŠ¤ì¹¼ë¼ë¥¼-í–‰ë ¬ë¡œ-ë¯¸ë¶„" class="headerlink" title="ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ, ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„"></a>ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ, ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„</h3><ul>
<li>ë¯¸ë¶„ ê²°ê³¼ëŠ” gradient ë²¡í„°ê°€ ë˜ì–´ ë°©í–¥ê³¼ í¬ê¸°ë¥¼ ëª¨ë‘ ë‚˜íƒ€ëƒ„</li>
</ul>
<ol>
<li><p>ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</p>
<ul>
<li><p>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸</p>
</li>
<li><p>ê²°ê³¼ëŠ” ë²¡í„°ê°€ ë¨</p>
</li>
<li><p>ê° ë²¡í„°ì˜ ìš”ì†ŒëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í•´ë‹¹ ë°©í–¥ì„ ë¯¸ë¶„í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ„, ì´ê²ƒì„ gradientë¼ê³  ë¶€ë¥´ë©°, í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ ë‚˜íƒ€ë‚˜ëŠ”ë° ì‚¬ìš©</p>
</li>
<li><p>$\frac{\partial f}{\partial x} &#x3D; \nabla_x f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_1} \ â¦™\ \frac{\partial f}{\partial x_n} \end{bmatrix}, \text {where }x \in \mathbb{R}^n$</p>
</li>
<li><p>ì˜ˆì œ</p>
<ul>
<li><p>$f(x,y)&#x3D;3x2+2xy+y2$ ë¼ëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ì™€ ë²¡í„° ë³€ìˆ˜ $x$ ì™€ $y$ ê°€ ìˆìŒ</p>
<ul>
<li><p>ì´ í•¨ìˆ˜ë¥¼ ê° ë³€ìˆ˜ì— ëŒ€í•´ í¸ë¯¸ë¶„ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŒ</p>
<p>$\frac{\partial f}{\partial x} &#x3D; 6x + 2y$</p>
<p>$\frac{\partial f}{\partial y} &#x3D; 2x + 2y$</p>
</li>
<li><p>ë”°ë¼ì„œ í•¨ìˆ˜ $f(x,y)$ ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ</p>
<p>$\nabla f &#x3D; \left[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}\right] &#x3D; [6x + 2y, 2x + 2y]$</p>
</li>
<li><p>ì´ ê·¸ë˜ë””ì–¸íŠ¸ ë²¡í„°ëŠ” ê° ì $(x,y)$ì—ì„œ í•¨ìˆ˜ì˜ ê°’ì´ ê°€ì¥ í¬ê²Œ ì¦ê°€í•˜ëŠ” ë°©í–¥ì„ ê°€ë¦¬í‚´, ë”°ë¼ì„œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ìµœì í™” ë¬¸ì œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì—­í• ì„ í•¨ (ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì€ ì¼ë°˜ì ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ì—¬ í•¨ìˆ˜ì˜ ìµœì†Œê°’ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ê²ƒì´ ê·¸ë˜ë””ì–¸íŠ¸ ë””ì„¼íŠ¸ ë°©ë²•ì˜ ê¸°ë³¸ ê°œë…)</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ì½”ë“œë¡œ í™•ì¸í•´ë³´ê¸°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sympy <span class="keyword">import</span> symbols, diff</span><br><span class="line"></span><br><span class="line">x, y = symbols(<span class="string">&#x27;x y&#x27;</span>)</span><br><span class="line">f = <span class="number">3</span>*x**<span class="number">2</span> + <span class="number">2</span>*x*y + y**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">df_dx = diff(f, x)  <span class="comment"># xì— ëŒ€í•œ í¸ë¯¸ë¶„</span></span><br><span class="line">df_dy = diff(f, y)  <span class="comment"># yì— ëŒ€í•œ í¸ë¯¸ë¶„</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;df/dx: <span class="subst">&#123;df_dx&#125;</span>&#x27;</span>)    <span class="comment"># df/dx: 6*x + 2*y</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;df/dy: <span class="subst">&#123;df_dy&#125;</span>&#x27;</span>)    <span class="comment"># df/dy: 2*x + 2*y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì„ì˜ì˜ ì‹œì‘ì </span></span><br><span class="line">x_value = <span class="number">1.0</span></span><br><span class="line">y_value = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># í•™ìŠµë¥ </span></span><br><span class="line">eta = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):  <span class="comment"># 100ë²ˆ ë°˜ë³µ</span></span><br><span class="line">    gradient_x = df_dx.evalf(subs=&#123;x: x_value, y: y_value&#125;)  <span class="comment"># x ìœ„ì¹˜ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</span></span><br><span class="line">    gradient_y = df_dy.evalf(subs=&#123;x: x_value, y: y_value&#125;)  <span class="comment"># y ìœ„ì¹˜ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</span></span><br><span class="line"></span><br><span class="line">    x_value -= eta * gradient_x     <span class="comment"># ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™</span></span><br><span class="line">    y_value -= eta * gradient_y     <span class="comment"># ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Optimized x: <span class="subst">&#123;x_value&#125;</span>&#x27;</span>)    <span class="comment"># Optimized x: -0.0627121858146143</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Optimized y: <span class="subst">&#123;y_value&#125;</span>&#x27;</span>)    <span class="comment"># Optimized y: 0.154295508359253</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„</p>
<ul>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ ë³€ìˆ˜ì— ëŒ€í•´ ë¯¸ë¶„í•˜ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ„</li>
<li>ê²°ê³¼ëŠ” í–‰ë ¬ì´ ë¨</li>
<li>ì´ í–‰ë ¬ì˜ ê° ìš”ì†ŒëŠ” í•´ë‹¹ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ì˜ í•´ë‹¹ ìš”ì†Œë¡œ í¸ë¯¸ë¶„í•œ ê°’, ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„í•œ ê²°ê³¼ëŠ” ìì½”ë¹„ì•ˆ í–‰ë ¬ì´ë¼ê³  ë¶€ë¥´ë©°, ì´ëŠ” í•¨ìˆ˜ì˜ ì§€ì—­ì  ë³€í™”ìœ¨ì„ ë‚˜íƒ€ëƒ„</li>
<li>$\frac{\partial f}{\partial x} &#x3D; \nabla_x f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_{1,1}  } â‹¯ \frac{\partial f}{\partial x_{1,m}} \ â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ \frac{\partial f}{\partial x_{n,1}  } â‹¯ \frac{\partial f}{\partial x_{n,m}} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n \times m}$</li>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ fê°€ í–‰ë ¬ Xì— ì˜ì¡´í•œë‹¤ê³  í•˜ë©´, ì´ í•¨ìˆ˜ë¥¼ í–‰ë ¬ Xì— ëŒ€í•´ ë¯¸ë¶„í•œ ê²°ê³¼ëŠ” í–‰ë ¬ì´ ë¨<ul>
<li>ì´ í–‰ë ¬ì˜ (i, j)ë²ˆì§¸ ìš”ì†ŒëŠ” fë¥¼ Xì˜ (i, j)ë²ˆì§¸ ìš”ì†Œì— ëŒ€í•´ í¸ë¯¸ë¶„í•œ ê°’</li>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ fë¥¼ í–‰ë ¬ $X &#x3D; \begin{bmatrix} x_{11} &amp; x_{12} \ x_{21} &amp; x_{22} \end{bmatrix}$ì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœì˜ í–‰ë ¬ì´ ë‚˜ì˜´<ul>
<li>$\nabla_X f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_{11}} &amp; \frac{\partial f}{\partial x_{12}} \ \frac{\partial f}{\partial x_{21}} &amp; \frac{\partial f}{\partial x_{22}} \end{bmatrix}$</li>
<li>ì´ë•Œ $\frac{\partial f}{\partial x_{ij}}$ëŠ” í•¨ìˆ˜ fë¥¼ í–‰ë ¬ Xì˜ (i,j)ë²ˆì§¸ ìš”ì†Œì— ëŒ€í•´ í¸ë¯¸ë¶„í•œ ê²ƒìœ¼ë¡œ, ì´ë ‡ê²Œ êµ¬í•´ì§„ í–‰ë ¬ì„ ìì½”ë¹„ì•ˆ í–‰ë ¬(Jacobian matrix) ì´ë¼ê³  í•¨</li>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬ì˜ ê° ìš”ì†ŒëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ê°€ ê° ë³€ìˆ˜ë¥¼ ì¡°ê¸ˆì”© ë³€í™”ì‹œí‚¬ ë•Œ, í•¨ìˆ˜ì˜ ì¶œë ¥ì´ ì–¼ë§ˆë‚˜ ë³€í™”í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„, ë”°ë¼ì„œ ìì½”ë¹„ì•ˆ í–‰ë ¬ì€ í•¨ìˆ˜ì˜ ì§€ì—­ì ì¸ ë³€í™”ìœ¨ì„ ì„¤ëª…í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
</li>
<li>ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ì€ ë”¥ëŸ¬ë‹ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ê°œë…<ul>
<li>ì‹ ê²½ë§ì˜ <strong>ê°€ì¤‘ì¹˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í–‰ë ¬ í˜•íƒœ</strong>ë¥¼ ê°€ì§€ë©°, ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸(ë¯¸ë¶„ê°’)ë¥¼ ê³„ì‚°í•´ì•¼ í•¨. ì´ ë•Œ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ë°”ë¡œ ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ìœ¼ë¡œ, ì˜¤ì°¨ í•¨ìˆ˜(ìŠ¤ì¹¼ë¼ í•¨ìˆ˜)ë¥¼ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>ìŠ¤ì¹¼ë¼, ë²¡í„°, í–‰ë ¬</strong></p>
<ul>
<li><strong>ìŠ¤ì¹¼ë¼</strong>ëŠ” ë‹¨ì¼í•œ ìˆ˜ì¹˜ ê°’ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 10ì´ë‚˜ 2.5ì™€ ê°™ì€ ë‹¨ì¼ ìˆ«ìë¥¼ ìŠ¤ì¹¼ë¼ë¼ê³  í•©ë‹ˆë‹¤.</li>
<li><strong>ë²¡í„°</strong>ëŠ” ìˆ«ìë“¤ì˜ ë°°ì—´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [1, 2]ì™€ ê°™ì€ 1ì°¨ì› ë°°ì—´ì´ ë²¡í„°ì…ë‹ˆë‹¤.</li>
<li><strong>í–‰ë ¬</strong>ì€ ìˆ«ìë“¤ì˜ 2ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [[1, 2], [3, 4]]ì™€ ê°™ì€ 2ì°¨ì› ë°°ì—´ì´ í–‰ë ¬ì…ë‹ˆë‹¤.</li>
</ul>
</blockquote>
<blockquote>
<p><strong>ìì½”ë¹„ì•ˆ í–‰ë ¬, í—¤ì‹œì•ˆ í–‰ë ¬</strong></p>
<ul>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬(Jacobian matrix)<ul>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬ì€ ë²¡í„° ê°’ì„ ê°€ì§„ í•¨ìˆ˜ë¥¼ ë²¡í„° ë³€ìˆ˜ì— ëŒ€í•´ ë¯¸ë¶„í•  ë•Œ ì‚¬ìš©</li>
<li>í•¨ìˆ˜ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ëª¨ë‘ ë²¡í„°ì¼ ë•Œ, ê° ì…ë ¥ ë³€ìˆ˜ì— ëŒ€í•œ ê° ì¶œë ¥ ë³€ìˆ˜ì˜ í¸ë¯¸ë¶„ì„ í–‰ë ¬ í˜•íƒœë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ ìì½”ë¹„ì•ˆ í–‰ë ¬</li>
<li>ì¦‰, ë‹¤ë³€ìˆ˜ ë²¡í„° í•¨ìˆ˜ì˜ ì²« ë²ˆì§¸ ë„í•¨ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.</li>
</ul>
</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬(Hessian matrix)<ul>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì€ ìŠ¤ì¹¼ë¼ ê°’ì„ ê°€ì§„ í•¨ìˆ˜ë¥¼ í–‰ë ¬ ë³€ìˆ˜ì— ëŒ€í•´ ë‘ ë²ˆ ë¯¸ë¶„í•  ë•Œ ì‚¬ìš©</li>
<li>ì¦‰, í•¨ìˆ˜ì˜ ë‘ ë²ˆì§¸ ë„í•¨ìˆ˜(2ì°¨ ë¯¸ë¶„)ë¥¼ ë‚˜íƒ€ëƒ„</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì˜ ê° ì„±ë¶„ì€ ì›ë˜ í•¨ìˆ˜ì˜ ë‘ ë³€ìˆ˜ì— ëŒ€í•œ ë‘ ë²ˆì§¸ í¸ë¯¸ë¶„</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì€ ì£¼ë¡œ í•¨ìˆ˜ì˜ ê³¡ë¥ , ì¦‰ ìµœì†Ÿê°’, ìµœëŒ“ê°’, ë˜ëŠ” ì•ˆì¥ì (saddle point) ë“±ì„ íŒë³„í•˜ëŠ” ë° ì‚¬ìš©ë¨</li>
</ul>
</li>
</ul>
<p>ë”°ë¼ì„œ, ìì½”ë¹„ì•ˆì€ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°(1ì°¨ ë„í•¨ìˆ˜)ë¥¼, í—¤ì‹œì•ˆì€ ê³¡ë¥ (2ì°¨ ë„í•¨ìˆ˜)ì„ ë‚˜íƒ€ë‚´ë©°, ë‘ í–‰ë ¬ ëª¨ë‘ í•¨ìˆ˜ì˜ ì§€ì—­ì ì¸ ë™ì‘ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•¨</p>
</blockquote>
<h3 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h3><ul>
<li><p>ìƒë¯¸ë¶„ê³¼ ë‹¬ë¦¬ ë¯¸ë¶„ ê²°ê³¼ê°€ ë²¡í„°</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61" alt="GradientDescent01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61">https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61</a></p>
<p>$\nabla f(x,y) &#x3D; \begin{bmatrix} 2x+y \ x+3y^2 +10y\end{bmatrix} &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x} \ \frac{\partial f}{\partial y} \end{bmatrix}$</p>
</li>
</ul>
<h3 id="ë²¡í„°ë¥¼-ìŠ¤ì¹¼ë¼ë¡œ-ë²¡í„°ë¥¼-ë²¡í„°ë¡œ-ë¯¸ë¶„"><a href="#ë²¡í„°ë¥¼-ìŠ¤ì¹¼ë¼ë¡œ-ë²¡í„°ë¥¼-ë²¡í„°ë¡œ-ë¯¸ë¶„" class="headerlink" title="ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ, ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„"></a>ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ, ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</h3><ol>
<li><p>ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ ë¯¸ë¶„</p>
<p>$\frac{\partial f}{\partial x} &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x}, â€¦ \text { }, \frac{\partial f_n}{\partial x} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n}$</p>
</li>
<li><p>ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</p>
<p>$\frac{\partial f}{\partial x} &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_1} \ â¦™ \ \frac{\partial f}{\partial x_n} \end{bmatrix} &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x}, â€¦ \text { }, \frac{\partial f_m}{\partial x} \end{bmatrix}  &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x_{1}  } â‹¯ \frac{\partial f_m}{\partial x_{1}} \ â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ \frac{\partial f_1}{\partial x_{n}  } â‹¯ \frac{\partial f_m}{\partial x_{n}} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n}\text{ } and\text{ } f(x) \in \mathbb{R}^m$</p>
</li>
</ol>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>]]).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">x1 = x + <span class="number">2</span></span><br><span class="line">x2 = x - <span class="number">2</span></span><br><span class="line">x3 = x1 * x2</span><br><span class="line">y = x3.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x1)</span><br><span class="line"><span class="comment">#tensor([[3., 4.],</span></span><br><span class="line"><span class="comment">#       [5., 6.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x2)</span><br><span class="line"><span class="comment"># tensor([[-1.,  0.],</span></span><br><span class="line"><span class="comment">#         [ 1.,  2.]], grad_fn=&lt;SubBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x3)</span><br><span class="line"><span class="comment"># tensor([[-3.,  0.],</span></span><br><span class="line"><span class="comment">#        [ 5., 12.]], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># tensor(14., grad_fn=&lt;SumBackward0&gt;)</span></span><br><span class="line"></span><br><span class="line">y.backward() <span class="comment"># ìŠ¤ì¹¼ë¼ì—¬ì•¼ë§Œ ë¯¸ë¶„ ê°€ëŠ¥í•˜ë‹¤. ìŠ¤ì¹¼ë¼ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°˜í™˜ # grequired_grad_(True) ëŠ” ë‹¤ ë¯¸ë¶„</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">.backward() ë©”ì„œë“œëŠ” PyTorchì—ì„œ ì œê³µí•˜ëŠ” ìë™ ë¯¸ë¶„ ê¸°ëŠ¥ìœ¼ë¡œ, ì‹¤ì œë¡œëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ë©°</span></span><br><span class="line"><span class="string">íŒŒì´í† ì¹˜ì˜ ê³„ì‚° ê·¸ë˜í”„(computation graph)ì˜ íŠ¹ì„±ì—ì„œ ë¹„ë¡¯ë¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ë˜ì„œ y.backward()ì—ì„œ yëŠ” ë³´í†µ ìŠ¤ì¹¼ë¼(scalar)ê°€ ë¨</span></span><br><span class="line"><span class="string">ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ê°€ ê´€ì‹¬ì„ ê°–ëŠ” ëŒ€ìƒì´ ë³´í†µ ì†ì‹¤ í•¨ìˆ˜(loss function)ì´ê¸° ë•Œë¬¸ì´ê³ , ì´ëŠ” ìŠ¤ì¹¼ë¼ ê°’ì„ ë°˜í™˜</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ°ë° ë§Œì•½ yê°€ ë²¡í„°ë‚˜ í–‰ë ¬ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ í…ì„œë¼ë©´? </span></span><br><span class="line"><span class="string">ì´ ê²½ìš°ì—ë„ .backward() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì´ë¥¼ ìœ„í•´ì„œëŠ” ì¸ìë¡œ ë²¡í„°ë¥¼ ì œê³µí•´ì•¼ í•¨ </span></span><br><span class="line"><span class="string">ì´ ë²¡í„°ëŠ” yì˜ ê° ìš”ì†Œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ë¥¼ í†µí•´ ìŠ¤ì¹¼ë¼ ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŒ</span></span><br><span class="line"><span class="string">ì˜ˆì‹œ) v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)  # ê°€ì¤‘ì¹˜ ë²¡í„°, y.backward(v)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ì´ëŸ° ë³µì¡ì„± ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ ê²½ìš°, .backward()ëŠ” ì†ì‹¤ ê°’ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ í…ì„œì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë˜ë©°, </span></span><br><span class="line"><span class="string">ì´ëŠ” ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚° </span></span><br><span class="line"><span class="string">ì´ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” íŒŒë¼ë¯¸í„°ì˜ .grad ì†ì„±ì— ì €ì¥ë˜ë©°, ì´ë¥¼ ì‚¬ìš©í•´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="comment"># tensor([[2., 4.],</span></span><br><span class="line"><span class="comment">#        [6., 8.]])</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">print(x3.numpy())</span></span><br><span class="line"><span class="string"># RuntimeError: Can&#x27;t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.</span></span><br><span class="line"><span class="string">print(x3.detach_().numpy())</span></span><br><span class="line"><span class="string"># array([[-3.,  0.],</span></span><br><span class="line"><span class="string">#       [ 5., 12.]], dtype=float32)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PyTorchì—ì„œ í…ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ requires_grad ì†ì„±ì´ Falseë¡œ ì„¤ì •ë˜ë‚˜, </span></span><br><span class="line"><span class="string">ì´ ì†ì„±ì´ Trueë¡œ ì„¤ì •ë˜ë©´, </span></span><br><span class="line"><span class="string">í•´ë‹¹ í…ì„œì— ì—°ì‚°ì´ ìˆ˜í–‰ë  ë•Œë§ˆë‹¤ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ëŠ” ê³„ì‚° ê·¸ë˜í”„ì— ì´ ì •ë³´ê°€ ì¶”ê°€ë¨</span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—­ì „íŒŒ(backpropagation) ë‹¨ê³„ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆê²Œë¨.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ¬ë‚˜ requires_gradê°€ Trueì¸ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ì§ì ‘ ë³€í™˜í•  ìˆ˜ ì—†ìŒ. </span></span><br><span class="line"><span class="string">ì´ëŠ” PyTorchì˜ ê³„ì‚° ê·¸ë˜í”„ì™€ Numpyê°€ ì„œë¡œ í˜¸í™˜ë˜ì§€ ì•Šê¸° ë•Œë¬¸. </span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ requires_gradê°€ Trueì¸ í…ì„œë¥¼ Numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ë ¤ë©´ ë¨¼ì € detach() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬</span></span><br><span class="line"><span class="string"> ê³„ì‚° ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ í…ì„œë¥¼ ë¶„ë¦¬í•œ í›„ ë³€í™˜í•´ì•¼ í•¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ì œì•ˆí•˜ëŠ” ê²ƒì²˜ëŸ¼, x3.detach().numpy()ë¥¼ ì‚¬ìš©í•˜ë©´ x3ë¥¼ Numpy ë°°ì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•  ìˆ˜ ìˆìŒ. </span></span><br><span class="line"><span class="string">ì´ë ‡ê²Œ í•˜ë©´ x3ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ í•„ìš”í•˜ì§€ ì•Šì€ ìƒˆë¡œìš´ í…ì„œê°€ ìƒì„±ë˜ê³ , ì´ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ë³€í™˜ë  ìˆ˜ ìˆìŒ.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="Why-we-laern-this"><a href="#Why-we-laern-this" class="headerlink" title="Why we laern this?"></a>Why we laern this?</h3><ul>
<li><p>Loss í•¨ìˆ˜ ê²°ê³¼ê°’ì¸ ìŠ¤ì¹¼ë¼ í˜ìˆ˜ë¥¼ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ë¡œ ë¯¸ë¶„í•´ì•¼ í•œë‹¤ë©´?</p>
</li>
<li><p>DNNì˜ ì¤‘ê°„ ê²°ê³¼ë¬¼ ë²¡í„°(â„)ë¥¼ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ë¡œ ë¯¸ë¶„í•´ì•¼ í•œë‹¤ë©´?</p>
<p>ë”¥ëŸ¬ë‹ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ê°€ í–‰ë ¬ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸(ë¯¸ë¶„ê°’)ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ë•Œ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ë°”ë¡œ ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ìœ¼ë¡œ, ì†ì‹¤ í•¨ìˆ˜(ìŠ¤ì¹¼ë¼ í•¨ìˆ˜)ë¥¼ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë˜í•œ, DNNì—ì„œëŠ” ê° ë ˆì´ì–´ì˜ ì…ë ¥(ì¤‘ê°„ ê²°ê³¼ ê°’)ì„ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ëŸ¬í•œ ë¯¸ë¶„ ê°œë…ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì´í•´í•˜ê³  ìµœì í™”í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ëŸ¬í•œ ì´ìœ ë“¤ë¡œ ì¸í•´ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ì— ëŒ€í•œ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜, ì¦‰ ì†ì‹¤ í•¨ìˆ˜ì˜ ê²°ê³¼ ê°’ì„ ë¯¸ë¶„í•˜ê±°ë‚˜, íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ì— ëŒ€í•œ ì¤‘ê°„ ê²°ê³¼ ê°’ ë²¡í„° (â„)ë¥¼ ë¯¸ë¶„í•˜ëŠ” ê°œë…ì„ ë°°ìš°ëŠ” ê²ƒì´ ë”¥ëŸ¬ë‹ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-19T14:56:59.000Z" title="7/19/2023, 11:56:59â€¯PM">2023-07-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:03:13.000Z" title="9/6/2024, 12:03:13â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">5 minutes read (About 713 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/6%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%B4-%EC%9E%98-%ED%95%99%EC%8A%B5%EB%90%98%EB%8A%94%EC%A7%80-%ED%8C%90%EB%8B%A8%ED%95%98%EA%B8%B0-Loss-Function/">6ì¥. ì‹ ê²½ë§ì´ ì˜ í•™ìŠµë˜ëŠ”ì§€ íŒë‹¨í•˜ê¸° - Loss Function</a></h1><div class="content"><h2 id="Again-Our-object-is"><a href="#Again-Our-object-is" class="headerlink" title="Again, Our object is"></a>Again, Our object is</h2><ul>
<li>ë°ì´í„°ë¥¼ ë„£ì—ˆì„ ë•Œ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ëŠ” ê²ƒ</li>
<li>Linear Layer í•¨ìˆ˜ë¥¼ í†µí•´ ì›í•˜ëŠ” í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•´ë³´ì<ul>
<li>Linear Layer í•¨ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ì›í•˜ëŠ” ë§Œí¼ ë™ì‘í•˜ëŠ”ì§€ ì¸¡ì •í•´ ë³´ì</li>
<li>ì–¼ë§ˆë‚˜ ì˜ ë™ì‘í•˜ëŠ”ì§€, ì ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ë³´ì</li>
</ul>
</li>
</ul>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><ul>
<li>Loss(ì†ì‹¤ê°’): ì›í•˜ëŠ” ì¶œë ¥ê°’(target,ğ‘¦)ê°€ ì‹¤ì œ ì¶œë ¥ê°’(output, $\hat{y}$)ì˜ ì°¨ì´ì˜ í•©<ul>
<li>$\text{Loss} &#x3D; \sum_{i&#x3D;1}^{N} | y_i - \hat{y}<em>i | &#x3D; \sum</em>{i&#x3D;1}^{N} | y_i - f(x_i) |$</li>
</ul>
</li>
<li>ê·¸ëŸ¬ë¯€ë¡œ ìš°ë¦¬ëŠ” Lossê°€ ì‘ì„ìˆ˜ë¡ ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ì˜ ëª¨ì‚¬í•˜ê³  ìˆë‹¤ê³  í•  ìˆ˜ ìˆìŒ</li>
<li>Lossê°€ ì‘ì€ Linear Layerë¥¼ ì„ íƒí•˜ë©´ ë¨</li>
</ul>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><ul>
<li><p>Linear Layerì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°”ê¿€ ë•Œë§ˆë‹¤ Lossë¥¼ ê³„ì‚°</p>
</li>
<li><p>Loss Function</p>
<ul>
<li>ì…ë ¥ : Linear Layerì˜ íŒŒë¼ë¯¸í„°(ğœƒ, ì¦‰, ğ‘Š,ğ‘ê°€ íŒŒë¼ë¯¸í„°)</li>
<li>ì¶œë ¥ : Looss<ul>
<li>ğ¿(ğœƒ)&#x3D;$\sum_{i&#x3D;1}^{n} | y_i - f_{\theta}(x_j) |, \text{ where } \theta &#x3D; {W, b}$</li>
</ul>
</li>
</ul>
</li>
<li><p>ì¢…ë¥˜</p>
<ul>
<li><p>Euclidean Distance</p>
<ul>
<li><p>$| y - \hat{y} |_2 (L2) &#x3D; \sqrt{(y_1 - \hat{y}_1)^2 + \ldots + (y_n - \hat{y}</p>
<p>n)^2} &#x3D; \sqrt{\sum</p>
<p>{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2}, \text{ where } y \in \mathbb{R}^n \text{ and } \hat{y} \in \mathbb{R}^n$</p>
<ul>
<li><strong>ë”¥ëŸ¬ë‹ì€ ì°¨ì›ì œì•½ì´ ì—†ì–´ì„œ ê³ ì°¨ì›ìœ¼ë¡œ ê°€ë©´ ì°¨ì´ê°€ êµ‰ì¥íˆ ì»¤ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— RMSE ê°€ ë“±ì¥</strong></li>
<li>cf) $| y - \hat{y} | : L1$, ì ˆëŒ€ê°’</li>
</ul>
</li>
</ul>
</li>
<li><p>RMSE(Root Mean Square Error)</p>
<ul>
<li>Euclidean Distanceì™€ ë¹„ìŠ·í•œ ê°œë…</li>
<li>$\text{RMSE}(y, \hat{y}) &#x3D; \sqrt{\frac{1}{n} \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2}$</li>
</ul>
</li>
<li><p>&#96;&#96;&#96;<br>MSE</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    (Mean Square Error)</span><br><span class="line"></span><br><span class="line">    - $\text&#123;MSE&#125;(y, \hat&#123;y&#125;) = \frac&#123;1&#125;&#123;n&#125; \sum_&#123;i=1&#125;^&#123;n&#125; (y_i - \hat&#123;y&#125;_i)^2 = \frac&#123;1&#125;&#123;n&#125;(\| y - \hat&#123;y&#125; \|_2)^2 = \frac&#123;1&#125;&#123;n&#125;\| y - \hat&#123;y&#125; \|_2^2 âˆ \| y - \hat&#123;y&#125; \|_2^2$</span><br><span class="line">    - Rootì™€ ìƒìˆ˜ë¥¼ ëºì§€ë§Œ í¬ê¸° ì°¨ì´ë¡œ ì¸í•œ ìˆœì„œ ê²°ê³¼ëŠ” ë°”ë€Œì§€ ì•ŠìŒ</span><br><span class="line">    - **ì†ì‹¤í•¨ìˆ˜ë¡œ ê°€ì¥ ë§ì´ ì‚¬ìš©**</span><br><span class="line"></span><br><span class="line">## ì½”ë“œ êµ¬í˜„í•˜ê¸°</span><br><span class="line"></span><br><span class="line">- Loss Function ì˜ˆì œ (1) â€“ ì§ì ‘ êµ¬í˜„í•˜ê¸°</span><br><span class="line"></span><br><span class="line">  ```python</span><br><span class="line">  import torch</span><br><span class="line">  import torch.nn as nn</span><br><span class="line">  </span><br><span class="line">  def mse(x_hat, x):</span><br><span class="line">      # |x_hat| = (batch_size, dim)</span><br><span class="line">      # |x| = (batch_size, dim)</span><br><span class="line">      y = ((x - x_hat)**2).mean()</span><br><span class="line">      </span><br><span class="line">      return y</span><br><span class="line">  </span><br><span class="line">  x = torch.FloatTensor([[1, 1],</span><br><span class="line">                         [2, 2]])</span><br><span class="line">  x_hat = torch.FloatTensor([[0, 0],</span><br><span class="line">                             [0, 0]])</span><br><span class="line">  </span><br><span class="line">  print(x.size(), x_hat.size()) # torch.Size([2, 2]) torch.Size([2, 2])</span><br><span class="line">  mse(x_hat, x) # tensor(2.5000)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83" alt="LossFunction"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83">https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83</a></p>
</li>
<li><p>Loss Function ì˜ˆì œ (2) â€“ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x_hat = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                           [<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.size(), x_hat.size()) <span class="comment"># torch.Size([2, 2]) torch.Size([2, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x)) <span class="comment"># tensor(2.5000)</span></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x, reduction=<span class="string">&#x27;sum&#x27;</span>)) <span class="comment"># tensor(10.)</span></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x, reduction=<span class="string">&#x27;none&#x27;</span>)) <span class="comment"># tensor([[1., 1.], [4., 4.]])</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Loss Function ì˜ˆì œ (3) â€“ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">mse_loss = nn.MSELoss()</span><br><span class="line"><span class="built_in">print</span>(mse_loss(x_hat, x)) <span class="comment"># tensor(2.5000)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h2><ul>
<li>ìš°ë¦¬ëŠ” ëª©í‘œë¡œ í•˜ëŠ” í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ê¸° ìœ„í•´<ul>
<li>í•™ìŠµìš© ì…ë ¥ ë°ì´í„°ë“¤ì„ Linear Layerì— ë„£ì–´ ì¶œë ¥ ê°’ë“¤ì„ êµ¬í•˜ê³ </li>
<li>ì¶œë ¥ê°’($\hat{y}$)ë“¤ê³¼ ëª©í‘œê°’(${y}$)ë“¤ì˜ ì°¨ì´ì˜ í•©(Loss)ë¥¼ ìµœì†Œí™” í•´ì•¼í•¨</li>
</ul>
</li>
<li>ê²°êµ­, Linear Layer íŒŒë¼ë¯¸í„°(ğœƒ)ë¥¼ ë°”ê¾¸ë©´ì„œ lossë¥¼ ìµœì†Œí™” í•´ì•¼í•¨</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-16T15:05:57.000Z" title="7/17/2023, 12:05:57â€¯AM">2023-07-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:02:30.000Z" title="9/6/2024, 12:02:30â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">10 minutes read (About 1436 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/5%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-Linear-Layer/">5ì¥. ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì‚´í´ë³´ê¸° - Linear Layer</a></h1><div class="content"><h2 id="ëª©í‘œ"><a href="#ëª©í‘œ" class="headerlink" title="ëª©í‘œ"></a>ëª©í‘œ</h2><p>ìš°ë¦¬ëŠ” ë‹¤ìŒì˜ ì´ë¯¸ì§€ë¥¼ í†µí•´ 3ì´ë¼ê³  ë¨¸ë¦¬ê°€ ì¸ì‹í•˜ì§€ë§Œ, ì»´í“¨í„°ê°€ ì–´ë–»ê²Œ ì´ ì´ë¯¸ì§€ë¥¼ 3ìœ¼ë¡œ ê·¼ì‚¬í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì•¼í•œë‹¤</p>
<p>ìš°ë¦¬ëŠ” $f^*$(f optimal)ì„ ëª¨ì‚¬í•˜ëŠ” ìµœì ì˜ $\hat{f}$ (f hat)ì„ ì°¾ì•„ì•¼í•œë‹¤</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d" alt="DigitMnist"></p>
<h3 id="Linear-Layer-ë€"><a href="#Linear-Layer-ë€" class="headerlink" title="Linear Layer ë€"></a>Linear Layer ë€</h3><ul>
<li><code>ì‹ ê²½ë§ì˜ ê°€ì¥ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ</code>, ë”¥ëŸ¬ë‹ì„ í†µí•´ ëª¨ì‚¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ë•Œ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ê²ƒì´ Linear Layer</li>
<li>Fully-connected(FC) Layer ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•¨<ul>
<li>ì…ë ¥ì˜ ëª¨ë“  ë…¸ë“œëŠ” ì¶œë ¥ì˜ ëª¨ë“  ë…¸ë“œì™€ ì»¨ë„¥ì…˜ì´ ìˆìŒ</li>
<li>Dense Layer ë¼ê³ ë„ ë¶ˆë¦¬ê¸°ë„ í•¨</li>
</ul>
</li>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜<ul>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì°¾ì•„ë‚´ë©´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì¶œë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<h3 id="Linear-Layer-ë™ì‘ë°©ì‹"><a href="#Linear-Layer-ë™ì‘ë°©ì‹" class="headerlink" title="Linear Layer ë™ì‘ë°©ì‹"></a>Linear Layer ë™ì‘ë°©ì‹</h3><ul>
<li>ê° ì…ë ¥ ë…¸ë“œë“¤ì— weight(ê°€ì¤‘ì¹˜)ë¥¼ ê³±í•˜ê³  ëª¨ë‘ í•©ì¹œ ë’¤, bias(í¸í–¥)ì„ ë”í•¨</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ed702032-9ad9-491c-b1cd-481a7a412907" alt="FCLayer02"></p>
<ul>
<li>|ğœƒ|&#x3D;(18,) , &#x2F;&#x2F; 18ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆìŒ! ğ‘Š &#x3D; 5x3 &#x3D;15, ğ‘ &#x3D; 3</li>
</ul>
<h3 id="Linear-Layer-Equations"><a href="#Linear-Layer-Equations" class="headerlink" title="Linear Layer Equations"></a>Linear Layer Equations</h3><ul>
<li><p><strong>í–‰ë ¬ ê³±ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥</strong></p>
</li>
<li><p>nì°¨ì›ì—ì„œ mì°¨ì›ìœ¼ë¡œì˜ <code>ì„ í˜• ë³€í™˜ í•¨ìˆ˜</code></p>
<ul>
<li>$x \in R^{k \times n}, w \in R^{n \times m} \rightarrow y \in R^{k \times m}$</li>
<li>$y &#x3D; f(k) &#x3D; x \cdot w + b$</li>
</ul>
</li>
<li><p>ê°™ì€ í‘œí˜„</p>
<ul>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ì— ê´€ê³„ì—†ì´ ë‹¨ìˆœíˆ ë²¡í„°ë¡œ ë³¼ ê²½ìš° : (m,n) x (n,1) &#x3D; (m,1)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; W^T \cdot x + b$</p>
<p>$\text{ where } x \in \mathbb{R}^n, W^T \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m \text{ and } y \in \mathbb{R}^m$</p>
</li>
</ul>
</li>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜(Nê°œ) í…ì„œë¡œ í‘œí˜„í•  ê²½ìš° : (N,n) x (n,m) &#x3D; (N,m)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; x \cdot W + b$</p>
<p>$\text{ where } x \in \mathbb{R}^{k \times n}, W \in \mathbb{R}^{n \times m}, b \in \mathbb{R}^{n \times m} \text{ and } y \in \mathbb{R}^{n \times m}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°</h3><ul>
<li><p>parameter ì •ë³´ í™•ì¸ ì˜ˆì œ</p>
<ul>
<li>gradientì— ê´€í•´ì„œëŠ” ë‹¤ìŒ gradient descent íŒŒíŠ¸ì—ì„œ ë‹¤ë£¸</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># ê°„ë‹¨í•œ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì •ì˜</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)  <span class="comment"># 10ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 5ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">5</span>, <span class="number">1</span>)  <span class="comment"># 5ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 1ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ ê°ì²´ë¥¼ ìƒì„±</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì…ë ¥ ë°ì´í„°</span></span><br><span class="line">input_data = torch.FloatTensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>, <span class="number">10.0</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;input_data : <span class="subst">&#123;input_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># input_data : tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ì„ í†µí•´ ì…ë ¥ ë°ì´í„°ë¥¼ ì „ë‹¬</span></span><br><span class="line">output_data = model(input_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;output: <span class="subst">&#123;output_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># output: tensor([[2.3264]], grad_fn=&lt;AddmmBackward&gt;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.data: <span class="subst">&#123;param.data&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.data: tensor([[-0.2895, -0.1230,  0.1624,  0.0381,  0.2252,  0.2265, -0.1498,  0.0806, -0.1704,  0.2421],</span></span><br><span class="line"><span class="string">        [-0.1162,  0.0786, -0.1140,  0.0178,  0.0470,  0.2920,  0.2933,  0.2919, 0.0493, -0.0025],</span></span><br><span class="line"><span class="string">        [ 0.0196,  0.0492, -0.2049,  0.1628, -0.1038,  0.1221,  0.0516, -0.1309, -0.2128, -0.3086],</span></span><br><span class="line"><span class="string">        [ 0.0129,  0.1872, -0.1641,  0.0406,  0.1779,  0.1346, -0.1623,  0.1618, 0.0410, -0.1538],</span></span><br><span class="line"><span class="string">        [ 0.1166, -0.0591,  0.0349, -0.0866,  0.2066, -0.0777,  0.3119, -0.1021, -0.2297,  0.2657]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.data: tensor([ 0.0787, -0.0037, -0.2033,  0.0398, -0.1233])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.data: tensor([[0.0168, 0.2259, 0.2410, 0.0145, 0.2553]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.data: tensor([0.2295])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Gradient ê³„ì‚°ì„ ìœ„í•œ ëœë¤ íƒ€ê¹ƒ ê°’ ìƒì„±</span></span><br><span class="line">target = torch.FloatTensor([<span class="number">0.5</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;target <span class="subst">&#123;target&#125;</span>&quot;</span>) <span class="comment"># target tensor([[0.5000]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ í•¨ìˆ˜ë¡œ í‰ê·  ì œê³± ì˜¤ì°¨ë¥¼ ì‚¬ìš©</span></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ ê³„ì‚°</span></span><br><span class="line">loss = loss_fn(output_data, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•˜ì—¬ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì˜ ê·¸ë¼ë””ì–¸íŠ¸ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.grad: <span class="subst">&#123;param.grad&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.grad: tensor([[0.0614, 0.1229, 0.1843, 0.2458, 0.3072, 0.3687, 0.4301, 0.4915, 0.5530, 0.6144],</span></span><br><span class="line"><span class="string">        [0.8253, 1.6507, 2.4760, 3.3013, 4.1267, 4.9520, 5.7774, 6.6027, 7.4280, 8.2534],</span></span><br><span class="line"><span class="string">        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">        [0.0529, 0.1057, 0.1586, 0.2114, 0.2643, 0.3171, 0.3700, 0.4228, 0.4757, 0.5285],</span></span><br><span class="line"><span class="string">        [0.9324, 1.8648, 2.7972, 3.7296, 4.6621, 5.5945, 6.5269, 7.4593, 8.3917, 9.3241]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.grad: tensor([0.0614, 0.8253, 0.0000, 0.0529, 0.9324])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.grad: tensor([[11.5118, 23.9645,  0.0000,  2.8603,  7.8742]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.grad: tensor([3.6528])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (1) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">W = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">b = torch.FloatTensor([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(W.size()) <span class="comment"># torch.Size([3, 2])</span></span><br><span class="line"><span class="built_in">print</span>(b.size()) <span class="comment"># torch.Size([2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear</span>(<span class="params">x, W, b</span>):</span><br><span class="line">    y = torch.matmul(x, W) + b</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x, W, b)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (2) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))</span><br><span class="line">        self.b = nn.Parameter(torch.FloatTensor(output_dim))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = torch.matmul(x, self.W) + self.b</span><br><span class="line">        <span class="comment"># |y| = (batch_size, input_dim) * (input_dim, output_dim)</span></span><br><span class="line">        <span class="comment">#     = (batch_size, output_dim)        </span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-3.7895e+32,  7.2868e-43],</span></span><br><span class="line"><span class="string">        [ 2.8026e-45,  0.0000e+00],</span></span><br><span class="line"><span class="string">        [-3.7896e+32,  7.2868e-43]], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (3) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">linear = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.4061,  0.0483,  0.0804],</span></span><br><span class="line"><span class="string">        [ 0.0581,  0.0730,  0.4323]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.4551, 0.4209], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (4) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.linear = nn.Linear(input_dim, output_dim)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="comment"># |y| = (batch_size, output_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.1267,  0.0563,  0.3951],</span></span><br><span class="line"><span class="string">        [ 0.2291,  0.3214,  0.2595]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.3659, 0.4013], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Linear Layer ëŠ” ì„ í˜• í•¨ìˆ˜</li>
<li>ë‚´ë¶€ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°(weight parameter) ğ‘Šì™€ ğ‘ì— ì˜í•´ ì •ì˜ë¨</li>
<li>ìš°ë¦° ì´ í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì¡°ì ˆí•˜ë©´, ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ì›í•˜ëŠ” ì¶œë ¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-16T14:58:32.000Z" title="7/16/2023, 11:58:32â€¯PM">2023-07-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:02:45.000Z" title="9/6/2024, 12:02:45â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">4 minutes read (About 591 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EA%B9%80%EA%B8%B0%ED%98%84%EC%9D%98%20%EC%B2%98%EC%9D%8C%EB%B6%80%ED%84%B0%20%EC%8B%9C%EC%9E%91%ED%95%98%EB%8A%94%20%EB%94%A5%EB%9F%AC%EB%8B%9D/5%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88%EA%B3%BC-%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/">5ì¥. ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì‚´í´ë³´ê¸° - í–‰ë ¬ì˜ ê³±ì…ˆê³¼ ë²¡í„°ì˜ ê³±ì…ˆ</a></h1><div class="content"><h2 id="í–‰ë ¬ì˜-ê³±ì…ˆ-Matrix-Multiplication"><a href="#í–‰ë ¬ì˜-ê³±ì…ˆ-Matrix-Multiplication" class="headerlink" title="í–‰ë ¬ì˜ ê³±ì…ˆ(Matrix Multiplication)"></a>í–‰ë ¬ì˜ ê³±ì…ˆ(Matrix Multiplication)</h2><ul>
<li><p>í–‰ë ¬ì˜ ê³±ì…ˆ</p>
<ul>
<li>2ê°œì˜ í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ <code>ìƒˆë¡œìš´ í–‰ë ¬</code>ì„ ìƒì„±</li>
<li>ì²« ë²ˆì§¸ í–‰ë ¬ì˜ ê° í–‰ê³¼ ë‘ ë²ˆì§¸ í–‰ë ¬ì˜ ê° ì—´ ì‚¬ì´ì˜ ë‚´ì ì„ ìš”ì†Œë¡œ ê°€ì§€ëŠ” ìƒˆë¡œìš´ í–‰ë ¬ì„ ë§Œë“¬</li>
<li>í–‰ë ¬ ê³±ì…ˆì€ ë‚´ì ì˜ ì´í•©ì„ ì‚¬ìš©í•˜ì§€ë§Œ ìì²´ì ìœ¼ë¡œëŠ” ë‹¤ë¥¸ ì—°ì‚°</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># í–‰ë ¬ ê³±ì…ˆ</span></span><br><span class="line">M = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">N = torch.tensor([[<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>], [<span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">matrix_product = torch.mm(M, N) <span class="comment"># ë‘ í…ì„œê°€ ëª¨ë‘ 2ì°¨ì› ì´ìƒì¸ ê²½ìš°, &#x27;@&#x27;ëŠ” í–‰ë ¬ê³±(matrix multiplication)ì„ ê³„ì‚°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Matrix Product:\\n <span class="subst">&#123;matrix_product&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Matrix Product:</span></span><br><span class="line"><span class="comment">#  tensor([[ 58,  64],</span></span><br><span class="line"><span class="comment">#         [139, 154]])</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-Matrix-Multiplication-í–‰ë ¬-ê³±"><a href="#1-Matrix-Multiplication-í–‰ë ¬-ê³±" class="headerlink" title="1. Matrix Multiplication(í–‰ë ¬ ê³±)"></a>1. Matrix Multiplication(í–‰ë ¬ ê³±)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/29973390-4e07-4bf5-a650-be12868b240b" alt="MatrixMultiplication"></p>
<h3 id="2-Vector-Matrix-Multiplication-ë²¡í„°ì™€-í–‰ë ¬ì˜-ê³±"><a href="#2-Vector-Matrix-Multiplication-ë²¡í„°ì™€-í–‰ë ¬ì˜-ê³±" class="headerlink" title="2. Vector Matrix Multiplication (ë²¡í„°ì™€ í–‰ë ¬ì˜ ê³±)"></a>2. Vector Matrix Multiplication (ë²¡í„°ì™€ í–‰ë ¬ì˜ ê³±)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/321590d0-9da0-44bf-945f-90d828b4f084" alt="VectorMatrixMultiplication01"></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4e1cd1aa-2d96-4e75-bb3e-6db31d46b176" alt="VectorMatrixMultiplication02"></p>
<h3 id="3-Batch-Matrix-Multiplication"><a href="#3-Batch-Matrix-Multiplication" class="headerlink" title="3. Batch Matrix Multiplication"></a>3. Batch Matrix Multiplication</h3><ul>
<li>ê°™ì€ ê°¯ìˆ˜ì˜ í–‰ë ¬ ìŒë“¤ì— ëŒ€í•´ì„œ ë³‘ë ¬ë¡œ í–‰ë ¬ ê³± ì‹¤í–‰</li>
<li>ë§Œì•½ 4ì°¨ì› í…ì„œë¼ë©´ (N1, N2, n, h) X (N1, N2, h, m) ì´ ë¨</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4baa6300-8ffc-4ee4-bee2-81c14936e11c" alt="BatchMatrixMultiplication"></p>
<h2 id="ë²¡í„°ì˜-ê³±ì…ˆ-Vector-Multiplication"><a href="#ë²¡í„°ì˜-ê³±ì…ˆ-Vector-Multiplication" class="headerlink" title="ë²¡í„°ì˜ ê³±ì…ˆ(Vector Multiplication)"></a>ë²¡í„°ì˜ ê³±ì…ˆ(Vector Multiplication)</h2><p>ë²¡í„°ì˜ ê³±ì…ˆì—ëŠ” ì£¼ë¡œ 2ê°€ì§€ì˜ í˜•íƒœë¡œ ìˆìŒ</p>
<ul>
<li><p>ë‚´ì  (Dot Product, Inner Product, ì ê³±)</p>
<ul>
<li>ë‘ ê°œì˜ ë²¡í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ <code>ìŠ¤ì¹¼ë¼</code>(ë‹¨ì¼ ìˆ˜ì¹˜) ê°’ì„ ì¶œë ¥</li>
<li>ë²¡í„°ì˜ ë‚´ì ì€ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” ìš”ì†Œë“¤ë¼ë¦¬ ê³±í•œ í›„, ê·¸ ê²°ê³¼ë¥¼ ëª¨ë‘ ë”í•´ì„œ í•˜ë‚˜ì˜ ìˆ«ìë¥¼ ì–»ìŒ</li>
<li>ë‚´ì ì€ ë²¡í„°ë“¤ ì‚¬ì´ì˜ <code>ìœ ì‚¬ì„±</code>ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ë²¡í„° ë‚´ì </span></span><br><span class="line">A = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">B = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">dot_product = torch.mm(A, B) <span class="comment"># ë‘ í…ì„œê°€ ëª¨ë‘ 1ì°¨ì›ì¸ ê²½ìš°, &#x27;@&#x27;ëŠ” ë²¡í„° ë‚´ì (dot product)ì„ ê³„ì‚°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Dot Product: <span class="subst">&#123;dot_product&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Dot Product: 32</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ì™¸ì  (Cross Product)</p>
<ul>
<li>3ì°¨ì› ë²¡í„°ì— í•œì •í•˜ë©°, ë‘ ë²¡í„°ì˜ ì™¸ì ì€ ìƒˆë¡œìš´ ë²¡í„°ë¥¼ ìƒì„±</li>
<li>ìƒˆë¡œìš´ ë²¡í„°ëŠ” ë‘ ì…ë ¥ ë²¡í„°ì— ìˆ˜ì§ì¸ ë°©í–¥ì„ ê°€ì§€ë©°, ê·¸ í¬ê¸°ëŠ” ë‘ ì…ë ¥ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ì— ë”°ë¼ ë‹¬ë¼ì§</li>
<li>ë¬¼ë¦¬í•™ì—ì„œ í˜ì˜ ë°©í–¥ ê³„ì‚° ë“±ì— ì‚¬ìš©</li>
</ul>
</li>
</ul>
<h2 id="ë²¡í„°ì˜-ë‚´ì -vs-ì½”ì‚¬ì¸-ìœ ì‚¬ë„"><a href="#ë²¡í„°ì˜-ë‚´ì -vs-ì½”ì‚¬ì¸-ìœ ì‚¬ë„" class="headerlink" title="ë²¡í„°ì˜ ë‚´ì  vs ì½”ì‚¬ì¸ ìœ ì‚¬ë„"></a>ë²¡í„°ì˜ ë‚´ì  vs ì½”ì‚¬ì¸ ìœ ì‚¬ë„</h2><ul>
<li>Dot Product<ul>
<li>$a \cdot b &#x3D; |a| |b| \cos \theta$</li>
<li>ì–¼ë§ˆë‚˜ ê°™ì€ ë°©í–¥ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ì •ë³´ë¥¼ ë‹´ìœ¼ë©°,</li>
<li>ë²¡í„°ì˜ í¬ê¸°ì—ë„ ì˜í–¥ì„ ë°›ìŒ</li>
</ul>
</li>
<li>Cosine Similarity<ul>
<li>$\text{cosine-similarity}(a, b) &#x3D; \frac{a \cdot b}{|a| |b|}$</li>
<li>ë°©í–¥ì„±ë§Œ ê³ ë ¤í•¨</li>
<li>ë²¡í„°ì˜ í¬ê¸° ê³ ë ¤x</li>
</ul>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">Previous</a></div><div class="pagination-next"><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">1</a></li><li><a class="pagination-link is-current" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/page/2/">2</a></li><li><a class="pagination-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">ë…¸ë ¥ ë°±ì¤Œ ì—´ì • ì²œì¤Œì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">138</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">64</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">110</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD íŒŒì´í”„ë¼ì¸</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Jenkins/"><span class="level-start"><span class="level-item">Jenkins</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/"><span class="level-start"><span class="level-item">ë²„ì „ ê´€ë¦¬</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%EC%A0%84%EB%9E%B5/"><span class="level-start"><span class="level-item">ë²„ì „ ê´€ë¦¬ ë° ë°°í¬ ì „ëµ</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/Cuda/"><span class="level-start"><span class="level-item">Cuda</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Java/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">ë‚´ ì½”ë“œê°€ ê·¸ë ‡ê²Œ ì´ìƒí•œê°€ìš”</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">í•µì‹¬ ì›ë¦¬ - ê¸°ë³¸í¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/"><span class="level-start"><span class="level-item">ê¸°íƒ€</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/"><span class="level-start"><span class="level-item">ë°ì´í„°ë² ì´ìŠ¤ &amp; ê²€ìƒ‰ì—”ì§„</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹</span></span><span class="level-end"><span class="level-item tag">47</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/"><span class="level-start"><span class="level-item">ë…¼ë¬¸ ë¦¬ë·°</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ ê°œë…</span></span><span class="level-end"><span class="level-item tag">38</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%86%B5%EA%B3%84%ED%95%99-%EB%B0%8F-%EC%88%98%ED%95%99/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ì„ ìœ„í•œ í†µê³„í•™ ë° ìˆ˜í•™</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/"><span class="level-start"><span class="level-item">ì„±ëŠ¥ê³¼ íŠœë‹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%8F-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%82%B9/"><span class="level-start"><span class="level-item">í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí‚¹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/"><span class="level-start"><span class="level-item">ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/API-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">API ì„¤ê³„ ë° ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ì›¹ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/HTTP-%EB%B0%8F-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/"><span class="level-start"><span class="level-item">HTTP ë° ë„¤íŠ¸ì›Œí¬</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Core/"><span class="level-start"><span class="level-item">Spring Core</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Data-JPA/"><span class="level-start"><span class="level-item">Spring Data JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/"><span class="level-start"><span class="level-item">ê°œë°œ í™˜ê²½ ì„¤ì •</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">ë³´ì•ˆ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">ë°ì´í„° ì•”í˜¸í™”</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%84%9C%EB%B2%84-%EB%B0%8F-%EC%9D%B8%ED%94%84%EB%9D%BC/"><span class="level-start"><span class="level-item">ì„œë²„ ë° ì¸í”„ë¼</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/"><span class="level-start"><span class="level-item">í´ë¼ìš°ë“œ ì»´í“¨íŒ…</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EB%8F%84%EC%BB%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"><span class="level-start"><span class="level-item">ë„ì»¤ &amp; ì¿ ë²„ë„¤í‹°ìŠ¤</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">31</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/Effective-Java/"><span class="level-start"><span class="level-item">Effective Java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/"><span class="level-start"><span class="level-item">Java&quot;</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B3%91%EB%A0%AC-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ë™ì‹œì„± &amp; ë³‘ë ¬ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/"><span class="level-start"><span class="level-item">ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%ED%81%B4%EB%A6%B0-%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">í´ë¦° ì½”ë“œ</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-27T14:37:53.000Z">2024-09-27</time></p><p class="title"><a href="/Jenkins-Notification-Teams-Email/">Jenkins Notification(Teams, Email)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-26T14:14:55.000Z">2024-09-26</time></p><p class="title"><a href="/Jenkins-SVM-%EC%97%B0%EB%8F%99-Multibranch-Pipeline-%EC%84%A4%EC%A0%95-%EB%B0%A9%EB%B2%95/">Jenkins - SVM ì—°ë™ &gt; Multibranch Pipeline ì„¤ì • ë°©ë²•</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-23T14:58:06.000Z">2024-09-23</time></p><p class="title"><a href="/Jenkins-SVM-%EC%97%B0%EB%8F%99-Freestyle-Project-%EC%84%A4%EC%A0%95-%EB%B0%A9%EB%B2%95/">Jenkins - SVM ì—°ë™ &gt; Freestyle Project ì„¤ì • ë°©ë²•</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-22T14:51:41.000Z">2024-09-22</time></p><p class="title"><a href="/Jenkins%EC%97%90%EC%84%9C-%EB%8B%A4%EC%96%91%ED%95%9C-%EB%B9%8C%EB%93%9C-%EC%98%B5%EC%85%98-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0-Multi-branch-Pipeline-vs-Freestyle-Project/">Jenkinsì—ì„œ ë‹¤ì–‘í•œ ë¹Œë“œ ì˜µì…˜ ì„ íƒí•˜ê¸° &gt; Multi-branch Pipeline vs Freestyle Project</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD íŒŒì´í”„ë¼ì¸</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Jenkins/">Jenkins</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-20T17:29:08.000Z">2024-09-21</time></p><p class="title"><a href="/DevOps/CICD%20%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Docker/Docker-Installation-CentOS-7/">Docker Installation - CentOS 7</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD íŒŒì´í”„ë¼ì¸</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Docker/">Docker</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1ê¸‰ ì‹œë¯¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASGI/"><span class="tag">ASGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CGI/"><span class="tag">CGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FastAPI/"><span class="tag">FastAPI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Forward-Proxy/"><span class="tag">Forward Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gunicorn/"><span class="tag">Gunicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jenkins/"><span class="tag">Jenkins</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/L4-%EC%8A%A4%EC%9C%84%EC%B9%98/"><span class="tag">L4 ìŠ¤ìœ„ì¹˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Load-Testing/"><span class="tag">Load Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OSI-7%EA%B3%84%EC%B8%B5/"><span class="tag">OSI 7ê³„ì¸µ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RPS/"><span class="tag">RPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Response-Time/"><span class="tag">Response Time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reverse-Proxy/"><span class="tag">Reverse Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Springì´ë€</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stress-Testing/"><span class="tag">Stress Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TCP-IP-4%EA%B3%84%EC%B8%B5/"><span class="tag">TCP/IP 4ê³„ì¸µ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TPS/"><span class="tag">TPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Testing-Types/"><span class="tag">Testing Types</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Throughput/"><span class="tag">Throughput</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Uvicorn/"><span class="tag">Uvicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WAS/"><span class="tag">WAS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSGI/"><span class="tag">WSGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-commit-rule/"><span class="tag">git commit rule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-flow/"><span class="tag">git flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-merge/"><span class="tag">git merge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-rebase/"><span class="tag">git rebase</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-flow/"><span class="tag">github flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gitlab-flow/"><span class="tag">gitlab flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python ì„¤ì¹˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">ê°ì²´ì§€í–¥</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">ë‹¤í˜•ì„±</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%88%84%EC%88%98/"><span class="tag">ë°ì´í„° ëˆ„ìˆ˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">ëŒë‹¤ì‹</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%8B%B1/"><span class="tag">ë¡œë“œ ë°¸ëŸ°ì‹±</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C/"><span class="tag">ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">ë²¡í„°ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%EC%A7%80%ED%91%9C/"><span class="tag">ì„±ëŠ¥ ì§€í‘œ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/"><span class="tag">ì„±ëŠ¥ í…ŒìŠ¤íŠ¸</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">ì—”íŠ¸ë¡œí”¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9B%B9-%EC%84%9C%EB%B2%84/"><span class="tag">ì›¹ ì„œë²„</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">ì •ë³´ëŸ‰</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">ì •ë³´ì´ë¡ </span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8F%AC%EC%9B%8C%EB%93%9C-%ED%94%84%EB%A1%9D%EC%8B%9C/"><span class="tag">í¬ì›Œë“œ í”„ë¡ì‹œ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">í–‰ë ¬ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>