<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: 딥러닝 - Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="차분하고 겸손하지만 확실하게!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="차분하고 겸손하지만 확실하게!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"차분하고 겸손하지만 확실하게!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">딥러닝</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-28T14:11:41.000Z" title="3/28/2023, 11:11:41 PM">2023-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:01:25.000Z" title="9/6/2024, 12:01:25 AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/">NLP</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/Text-Summarization/">Text Summarization</a></span><span class="level-item">6 minutes read (About 912 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/Text%20Summarization/Text-Summarization-%EC%9D%B4%EB%9E%80/">Text Summarization 이란</a></h1><div class="content"><h2 id="Text-Summarization-이란"><a href="#Text-Summarization-이란" class="headerlink" title="Text Summarization 이란"></a>Text Summarization 이란</h2><p>원문을 이해하기 쉬우면서도 가치있는 정보로 변환하는 작업을 말함</p>
<ul>
<li>인간은 길이가 길거나 여러 문서로 나눠져있는 텍스트 정보를 한 눈에 파악하기 어려워함</li>
<li>때로는 알지 못하는 전문 용어가 많이 사용되어 있을 수도 있음</li>
<li>이러한 텍스트를 원문을 잘 반영하면서도 간결하여 이해하기 쉬운 형태로 바꿔주는 작업은 상당히 가치있는 일</li>
</ul>
<blockquote>
<p>Text summarization is the process of <strong>distilling the most important information</strong> from a text to produce an abridged version for a particular task and user</p>
<p>텍스트 요약은 특정 작업 및 사용자에 대한 요약 버전을 생성하기 위해 텍스트에서 가장 중요한 정보를 추출하는 프로세스이다.<br><a target="_blank" rel="noopener" href="https://epubs.siam.org/doi/abs/10.1137/1037127">Berry, Dumais, &amp; O’Brien (1995)</a></p>
</blockquote>
<ul>
<li>Text Summarization 은 요약의 대상(source)이 text 로 한정이 됨<ul>
<li>Text를 image로 본다면 image captioning, video로 본다면 video summarization이 됨</li>
<li>Text, image, video 등 다양한 형태의 source를 함께 요약하는 방식을 multimodal summarization이라고 함</li>
</ul>
</li>
</ul>
<h2 id="Task-Categories"><a href="#Task-Categories" class="headerlink" title="Task Categories"></a>Task Categories</h2><p>Text summarization의 task는 크게 요약문을 생성하는 방식에 따라 extractive summarization과 abstractive summarization으로 나눌 수 있음</p>
<ol>
<li>추출적 요약(Extractive Summarization)<ul>
<li><code>원문에서 중요한 문장이나 구문을 선택</code>하여 요약문을 만드는 방법</li>
<li>원문의 문장을 그대로 사용하며, 요약문은 원문에 있는 문장들의 조합으로 이루어짐</li>
<li><code>원문의 정보를 그대로 유지하는 것이 중요한 경우에 적합</code></li>
<li>주요 알고리즘: TextRank, LSA(Latent Semantic Analysis), Luhn 알고리즘 등</li>
</ul>
</li>
<li>생성적 요약(Abstractive Summarization)<ul>
<li><code>원문의 의미를 파악한 후, 새로운 문장을 생성</code>하여 요약문을 만드는 방법</li>
<li>원문에 없는 표현이나 단어도 요약문에 포함될 수 있음</li>
<li>원문의 정보를 보다 잘 요약하고, 자연스러운 문장으로 표현할 수 있는 장점이 있음</li>
<li><code>요약문이 자연스럽고 독립적인 정보를 제공해야 하는 경우에 적합</code></li>
<li>주요 기술 : Sequence-to-Sequence, Attention, Transformer 등</li>
</ul>
</li>
</ol>
<p><img src="https://velog.velcdn.com/images%2Fjaehyeong%2Fpost%2Fa6e87a99-815a-4570-94d2-7083c0f065ac%2Fextractive-abstractive.PNG" alt="img"></p>
<p>※ 이외에도 다음과 같은 관점으로 Task를 구분할 수 있음</p>
<ul>
<li><p>keyword&#x2F;sentence summarization : 생성해내는 Text 형태에 따라 구분</p>
</li>
<li><p>knowledge-poor&#x2F;rich summarization : 요약 과정에서 원문 외 외부 정보를 얼마나 사용하는지에 따라</p>
</li>
<li><p>single&#x2F;multi document summarization : 원문의 개수에 따라 구분</p>
</li>
</ul>
<p><img src="https://github.com/uoneway/Text-Summarization-Repo/raw/main/images/Classification_of_summarization_tasks.png" alt="Figure 2.1: Classification of summarization tasks."></p>
<p>(G. Sizov(2010). <a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/Extraction-Based-Automatic-Summarization%3A-and-of-Sizov/2d27fd9af4b10cc5b54a849a3c2ad84755b3b13c">Extraction-Based Automatic Summarization: Theoretical and Empirical Investigation of Summarization Techniques</a>)Text Summarization 이란</p>
<h2 id="Text-Summarization-기초-개념"><a href="#Text-Summarization-기초-개념" class="headerlink" title="Text Summarization 기초 개념"></a>Text Summarization 기초 개념</h2><ul>
<li>Summarization 기본 용어<ul>
<li>Original text &#x3D; Source text</li>
<li>generated summary &#x3D;  모델이 생성해낸 요약문을 의미</li>
<li>reference summary &#x3D; 반면 우리가 정답으로 간주하는(보통은 사람이 직접 원문을 보고 생성한) 요약문, 또는 gold summary라고 부름<ul>
<li>보통은 두 용어를 크게 구분없이 쓰는듯 하나,  generated summary는 평가하기 위한 기준이 되는 요약문이라는 면을 강조할 때, gold summary는 우리가 찾는 진짜 요약문이라는 점을 강조할 때 주로 사용되는 듯 함</li>
</ul>
</li>
<li>Metric: Rouge, BLEU, Perplexity(PPL) 등</li>
</ul>
</li>
</ul>
<p>참고</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/uoneway/Text-Summarization-Repo">https://github.com/uoneway/Text-Summarization-Repo</a></p>
</li>
<li><p>[글] <a target="_blank" rel="noopener" href="https://github.com/icoxfog417/awesome-text-summarization">icoxfog417. awesome-text-summarization</a></p>
</li>
<li><p>[PPT] <a target="_blank" rel="noopener" href="https://www.slideshare.net/cozyhous?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview">Sang-Houn Choi. Text summarization</a></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-11-22T14:43:45.000Z" title="11/22/2022, 11:43:45 PM">2022-11-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T23:35:43.000Z" title="9/6/2024, 8:35:43 AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/">논문 리뷰</a></span><span class="level-item">a minute read (About 149 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0/Efficient-Classification-of-Long-Documents-Using-Transformers/">Efficient Classification of Long Documents Using Transformers</a></h1><div class="content"><p>업무로 KoBERT Model을 통해 Text Classification을 수행하면서 2가지의 궁금증이 있었다.</p>
<ul>
<li>BERT에서는 문서의 앞에서부터 512개의 Token들만 읽어서 처리를 수행<ul>
<li>그렇다면 입력값이 몇 천개가 들어오면 어떻게 될까</li>
</ul>
</li>
<li>BERT에서 Classification(Label, Target)의 갯수 몇 천개라면 input dense 와 hidden dense를 몇 개를 설정해야 적절할까.</li>
</ul>
<p>해당 페이지는  첫번째에 대한 궁금증 해소를 위해 리서치한 결과에 대한 요약 내용이다.</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.11258">Efficient Classification of Long Documents Using Transformers</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-11-16T14:46:11.000Z" title="11/16/2022, 11:46:11 PM">2022-11-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-11T13:25:10.978Z" title="9/11/2024, 10:25:10 PM">2024-09-11</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">딥러닝 개념</a></span><span class="level-item">22 minutes read (About 3295 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%8F%E1%85%A6%E1%84%85%E1%85%A1%E1%84%89%E1%85%B3%20%E1%84%8E%E1%85%A1%E1%86%BC%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A6%E1%84%80%E1%85%A6%20%E1%84%87%E1%85%A2%E1%84%8B%E1%85%AE%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/%EB%AA%A8%EB%8D%B8-%EC%B5%9C%EC%A0%81%ED%99%94/">모델 최적화</a></h1><div class="content"><h1 id="모델-최적화-훈련-성능과-일반화-성능의-균형"><a href="#모델-최적화-훈련-성능과-일반화-성능의-균형" class="headerlink" title="모델 최적화: 훈련 성능과 일반화 성능의 균형"></a>모델 최적화: 훈련 성능과 일반화 성능의 균형</h1><h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><ul>
<li>모델 최적화는 <strong>훈련 성능을 극대화</strong>하고, <strong>과대적합</strong>을 방지하여 <strong>일반화 성능</strong>을 유지하는 두 가지 방향에서 이루어져야함</li>
<li><strong>과대적합</strong>은 훈련 데이터에 지나치게 맞추는 현상이며, 반대로 <strong>일반화</strong>는 새로운 데이터에서도 좋은 성능을 유지하는 것을 의미합</li>
<li>이 글에서는 <strong>훈련 성능을 향상</strong>시키면서도 <strong>과대적합을 방지</strong>하는 방법들을 설명</li>
</ul>
<h2 id="1-과대적합-Overfitting-과-일반화-Generalization"><a href="#1-과대적합-Overfitting-과-일반화-Generalization" class="headerlink" title="1. 과대적합(Overfitting)과 일반화(Generalization)"></a><strong>1. 과대적합(Overfitting)과 일반화(Generalization)</strong></h2><h3 id="과대적합-Overfitting"><a href="#과대적합-Overfitting" class="headerlink" title="과대적합(Overfitting)"></a><strong>과대적합(Overfitting)</strong></h3><ul>
<li><strong>과대적합</strong>은 모델이 훈련 데이터의 <strong>세부적인 패턴</strong>에 지나치게 맞춰지면서, 훈련 데이터에서는 매우 좋은 성능을 내지만, <strong>새로운 데이터</strong>에서는 성능이 저하되는 현상을 의미</li>
<li>과대적합된 모델은 학습한 데이터에만 적합하고, 현실 세계의 데이터에 대한 <strong>예측 능력이 떨어짐</strong></li>
</ul>
<h3 id="일반화-Generalization"><a href="#일반화-Generalization" class="headerlink" title="일반화(Generalization)"></a><strong>일반화(Generalization)</strong></h3><ul>
<li><strong>일반화</strong>는 모델이 <strong>훈련 데이터 이외의 데이터</strong>에서 <strong>잘 작동하는 능력</strong>을 의미</li>
<li>딥러닝 모델의 성능을 제대로 평가하려면 <strong>훈련 데이터와는 다른 검증 데이터</strong>나 테스트 데이터에서 모델이 얼마나 잘 작동하는지 살펴보는 것이 중요</li>
<li>일반화를 달성하기 위해서는 훈련 중 <strong>과대적합을 방지</strong>하는 다양한 기법이 필요</li>
</ul>
<h2 id="2-훈련-성능-향상-과대적합-가능성-증가"><a href="#2-훈련-성능-향상-과대적합-가능성-증가" class="headerlink" title="2. 훈련 성능 향상 (과대적합 가능성 증가)"></a><strong>2. 훈련 성능 향상 (과대적합 가능성 증가)</strong></h2><ul>
<li>훈련 성능을 향상시키는 것은 모델이 훈련 데이터에서 좋은 성능을 내도록 <strong>최적화</strong>하는 과정</li>
<li>하지만 이 과정에서 <strong>과대적합의 위험</strong>이 증가할 수 있으므로 주의가 필요</li>
</ul>
<h3 id="1-경사하강법의-핵심-파라미터-튜닝"><a href="#1-경사하강법의-핵심-파라미터-튜닝" class="headerlink" title="1) 경사하강법의 핵심 파라미터 튜닝"></a><strong>1) 경사하강법의 핵심 파라미터 튜닝</strong></h3><ul>
<li><p><strong>옵티마이저 선택</strong> </p>
<ul>
<li>딥러닝 모델을 훈련할 때 <strong>Adam</strong>이나 <strong>SGD(Stochastic Gradient Descent)</strong> 같은 옵티마이저를 선택할 수 있음(Adam은 <strong>적응형 학습률</strong>을 사용하여 빠르고 안정적인 학습을 제공)</li>
</ul>
</li>
<li><p><strong>학습률(Learning rate)</strong></p>
<ul>
<li>학습률이 너무 높으면 훈련이 불안정해지고, 너무 낮으면 학습 속도가 느려짐</li>
<li><strong>적절한 학습률</strong>을 선택하는 것이 훈련 성능을 향상시키는 중요한 요소</li>
<li><strong>학습률 스케줄링</strong>(Learning rate scheduling)을 적용하면, 학습 도중에 학습률을 점진적으로 줄여 과대적합을 방지할 수 있음</li>
</ul>
</li>
<li><p><strong>배치 크기(Batch size)</strong></p>
<ul>
<li>배치 크기가 클수록 <strong>훈련의 안정성</strong>이 증가하지만, <strong>작은 배치 크기</strong>는 <strong>더 빠른 수렴</strong>과 <strong>일반화 성능 향상</strong>에 도움이 될 수 있음</li>
<li>프랑소와 숄레는 작은 배치 크기를 사용할 경우, <strong>노이즈</strong>를 통해 모델이 <strong>더 나은 일반화 성능</strong>을 가질 수 있다고 언급</li>
</ul>
</li>
</ul>
<h3 id="2-모델-구조-조정"><a href="#2-모델-구조-조정" class="headerlink" title="2) 모델 구조 조정"></a><strong>2) 모델 구조 조정</strong></h3><ul>
<li><p><strong>적합한 모델 선택</strong></p>
<ul>
<li>모델 구조는 해결하려는 문제에 맞게 설계되어야 함</li>
<li>간단한 문제를 해결할 때는 <strong>작은 모델</strong>로도 충분하지만, 복잡한 문제에서는 <strong>더 큰 네트워크</strong>가 필요</li>
<li>프랑소와 숄레는 모델 선택 시 <strong>베이스라인 모델</strong>을 먼저 구현하고, 이를 바탕으로 더 복잡한 모델을 설계하는 방법을 권장</li>
</ul>
</li>
<li><p><strong>층을 늘리기</strong></p>
<ul>
<li>딥러닝 모델의 깊이를 늘리는 것은 <strong>복잡한 패턴</strong>을 학습할 수 있도록 도와줌</li>
<li>하지만, 너무 많은 층을 사용하면 과대적합의 위험이 커질 수 있으므로 주의해야 함</li>
</ul>
</li>
</ul>
<h3 id="3-모델-용량-증가"><a href="#3-모델-용량-증가" class="headerlink" title="3) 모델 용량 증가"></a><strong>3) 모델 용량 증가</strong></h3><ul>
<li><strong>노드 수 증가</strong><ul>
<li>각 층의 **뉴런 수(노드 수)**를 늘리면 모델의 용량이 커져 <strong>더 복잡한 패턴</strong>을 학습할 수 있음</li>
<li>하지만, <strong>너무 큰 모델</strong>은 훈련 데이터에 과도하게 맞춰지면서 일반화 성능이 저하될 수 있음</li>
</ul>
</li>
</ul>
<h2 id="3-일반화-성능-향상-과대적합-방지"><a href="#3-일반화-성능-향상-과대적합-방지" class="headerlink" title="3. 일반화 성능 향상 (과대적합 방지)"></a><strong>3. 일반화 성능 향상 (과대적합 방지)</strong></h2><ul>
<li>과대적합을 방지하고 <strong>모델의 일반화 성능을 높이기 위해</strong>서는 다양한 <strong>정규화 기법</strong>과 <strong>모델 조정 방법</strong>을 적용할 수 있음</li>
<li>프랑소와 숄레는 딥러닝 모델이 데이터에 너무 맞춰지지 않도록 하기 위해 아래와 같은 기법들을 권장</li>
</ul>
<h3 id="1-데이터셋-큐레이션"><a href="#1-데이터셋-큐레이션" class="headerlink" title="1) 데이터셋 큐레이션"></a><strong>1) 데이터셋 큐레이션</strong></h3><ul>
<li><p><strong>더 많은 데이터 확보</strong></p>
<ul>
<li>더 많은 훈련 데이터를 확보하면 <strong>모델이 더 다양한 패턴을 학습</strong>할 수 있어 일반화 성능이 향상됨</li>
<li>데이터를 <strong>증가시키는 데이터 증강(data augmentation)</strong> 기법도 매우 유용</li>
</ul>
</li>
<li><p><strong>정확한 레이블 할당</strong></p>
<ul>
<li>잘못된 레이블을 포함한 데이터는 모델의 성능을 저하시키고 과대적합을 유발할 수 있음</li>
<li><strong>레이블 오류를 최소화</strong>하는 것이 중요</li>
</ul>
</li>
</ul>
<h3 id="2-더-나은-특성-feature-개발"><a href="#2-더-나은-특성-feature-개발" class="headerlink" title="2) 더 나은 특성(feature) 개발"></a><strong>2) 더 나은 특성(feature) 개발</strong></h3><ul>
<li>특성 공학은 모델이 학습할 수 있는 <strong>의미 있는 특성</strong>을 만들어내는 과정</li>
<li>프랑소와 숄레는 딥러닝에서 자동으로 <strong>특성을 추출</strong>할 수 있는 장점이 있지만, 여전히 <strong>좋은 특성 설계</strong>가 모델 성능에 중요하다고 강조</li>
</ul>
<h3 id="3-네트워크-용량-줄이기"><a href="#3-네트워크-용량-줄이기" class="headerlink" title="3) 네트워크 용량 줄이기"></a><strong>3) 네트워크 용량 줄이기</strong></h3><ul>
<li><strong>간소한 모델 설계</strong><ul>
<li>모델의 복잡성을 줄여 <strong>과대적합을 방지</strong></li>
<li>층의 수나 노드 수가 너무 많으면 훈련 데이터에 지나치게 맞춰지기 때문에, 문제에 적합한 <strong>적당한 크기의 모델</strong>을 사용하는 것이 중요</li>
</ul>
</li>
</ul>
<h3 id="4-가중치-규제-Regularization"><a href="#4-가중치-규제-Regularization" class="headerlink" title="4) 가중치 규제(Regularization)"></a><strong>4) 가중치 규제(Regularization)</strong></h3><ul>
<li><strong>L1, L2 규제</strong>: 모델의 가중치 크기를 제한하여 <strong>너무 큰 가중치 값</strong>을 방지</li>
<li>이를 통해 모델이 훈련 데이터에 너무 맞춰지지 않도록 하고, 더 <strong>일반화된 모델</strong>을 만들 수 있음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># L2 규제(가중치 감쇠)를 사용하는 Dense 층 예시</span></span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> regularizers</span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">64</span>, kernel_regularizer=regularizers.l2(<span class="number">0.01</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br></pre></td></tr></table></figure>

<h3 id="5-드롭아웃-Dropout"><a href="#5-드롭아웃-Dropout" class="headerlink" title="5) 드롭아웃(Dropout)"></a><strong>5) 드롭아웃(Dropout)</strong></h3><ul>
<li><strong>드롭아웃</strong>은 훈련 중에 <strong>무작위로 일부 뉴런을 비활성화</strong>하여 모델이 특정 뉴런에 <strong>의존하지 않도록</strong> 하는 정규화 기법입니다.</li>
<li>이를 통해 과대적합을 방지하고 <strong>더 나은 일반화 성능</strong>을 얻을 수 있음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br></pre></td></tr></table></figure>

<h3 id="6-교차-검증-Cross-validation"><a href="#6-교차-검증-Cross-validation" class="headerlink" title="6) 교차 검증(Cross-validation)"></a><strong>6) 교차 검증(Cross-validation)</strong></h3><ul>
<li><strong>교차 검증</strong>은 데이터를 여러 번 나누어 학습하고 검증하여 모델이 훈련 데이터에 과적합되지 않도록 방지하는 방법입니다. 특히 <strong>소규모 데이터셋</strong>에서 유용하며, 데이터 분할에 따른 성능 차이를 줄일 수 있습니다.</li>
</ul>
<h3 id="7-조기-종료-Early-Stopping"><a href="#7-조기-종료-Early-Stopping" class="headerlink" title="7) 조기 종료(Early Stopping)"></a><strong>7) 조기 종료(Early Stopping)</strong></h3><ul>
<li><strong>조기 종료</strong>는 검증 데이터에서 성능이 더 이상 개선되지 않을 때 훈련을 멈추는 기법</li>
<li><strong>과대적합</strong>이 일어나는 것을 방지하기 위해 **검증 손실(validation loss)**이 일정 기간 동안 향상되지 않으면 훈련을 중단할 수 있음</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">early_stopping = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, patience=<span class="number">5</span>)</span><br><span class="line">model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=<span class="number">100</span>, callbacks=[early_stopping])</span><br></pre></td></tr></table></figure>


<h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a><strong>결론</strong></h2><h2 id="결론-1"><a href="#결론-1" class="headerlink" title="결론"></a>결론</h2><ul>
<li>딥러닝 모델의 최적화는 <strong>훈련 성능을 극대화</strong>하는 것과 동시에 <strong>과대적합을 방지</strong>하여 <strong>일반화 성능을 높이는 것</strong>이 핵심</li>
<li><strong>프랑소와 숄레</strong>는 이 두 가지 목표를 균형 있게 달성하는 것이 중요하다고 강조하며, 모델이 <strong>현실 세계에서도 높은 성능</strong>을 유지하도록 다양한 <strong>정규화 기법</strong>과 <strong>훈련 기법</strong>을 적용해야 한다고 설명</li>
<li>훈련 성능을 향상시키면서도 <strong>과대적합을 방지</strong>하는 전략을 적절히 사용하면, 모델은 더 나은 <strong>일반화 성능</strong>을 유지하며, 새로운 데이터에 대해 높은 예측력을 가질 수 있음</li>
</ul>
<h2 id="부록-1-일반화-성능을-최적화하는-전략-학습-그래프-기반-접근"><a href="#부록-1-일반화-성능을-최적화하는-전략-학습-그래프-기반-접근" class="headerlink" title="부록 1. 일반화 성능을 최적화하는 전략: 학습 그래프 기반 접근"></a>부록 1. <strong>일반화 성능을 최적화하는 전략: 학습 그래프 기반 접근</strong></h2><ul>
<li>모델 학습 과정에서 **훈련 곡선(Training curve)**과 **검증 곡선(Validation curve)**을 주의 깊게 관찰하는 것은 <strong>과대적합</strong>과 <strong>과소적합</strong>을 방지하고, 모델이 <strong>일반화 성능</strong>을 갖출 수 있도록 돕는 강력한 방법</li>
<li>이를 기반으로 모델의 <strong>네트워크 크기</strong>나 <strong>하이퍼파라미터</strong>를 점진적으로 조정하여 최적의 성능을 찾는 것이 핵심</li>
</ul>
<h3 id="1-먼저-모델을-과대적합시키기"><a href="#1-먼저-모델을-과대적합시키기" class="headerlink" title="1. 먼저 모델을 과대적합시키기"></a>1. <strong>먼저 모델을 과대적합시키기</strong></h3><ul>
<li><strong>초기에는 충분한 복잡성을 가진 네트워크</strong>로 시작하여 모델이 훈련 데이터에 잘 맞도록 해야함</li>
<li>이때 <strong>훈련 데이터에서 성능이 높아지고</strong>, <strong>검증 데이터에서 성능이 떨어지는</strong> <strong>과대적합</strong>이 발생하는 시점을 확인.</li>
<li><strong>과대적합의 징후</strong>는 훈련 세트에서는 손실이 계속해서 낮아지는데, 검증 세트에서는 손실이 낮아지다가 다시 증가하는 패턴을 보임</li>
</ul>
<h3 id="2-과대적합-발생-시-네트워크-크기-줄이기"><a href="#2-과대적합-발생-시-네트워크-크기-줄이기" class="headerlink" title="2. 과대적합 발생 시 네트워크 크기 줄이기"></a>2. <strong>과대적합 발생 시 네트워크 크기 줄이기</strong></h3><ul>
<li>모델이 <strong>과대적합</strong>되기 시작하면, 네트워크의 <strong>복잡도를 줄이기</strong> 위해 <strong>층의 수</strong>나 <strong>노드 수</strong>를 줄임</li>
<li>이를 통해 모델이 더 단순해지고, 과대적합을 방지할 수 있음<ul>
<li><strong>층 수</strong> 또는 <strong>뉴런 수</strong>를 줄여서 모델이 과도하게 복잡하지 않도록 하되, <strong>훈련 데이터에 대한 성능이 여전히 유지</strong>되는지 확인</li>
</ul>
</li>
</ul>
<h3 id="3-과소적합-발견-시-네트워크-크기-증가"><a href="#3-과소적합-발견-시-네트워크-크기-증가" class="headerlink" title="3. 과소적합 발견 시 네트워크 크기 증가"></a>3. <strong>과소적합 발견 시 네트워크 크기 증가</strong></h3><ul>
<li>네트워크를 단순화한 후 <strong>과소적합</strong>이 발생할 수 있음 (과소적합은 <strong>훈련 데이터에서의 성능</strong>이 충분히 올라가지 않는 경우)<ul>
<li><strong>훈련 곡선과 검증 곡선 모두가</strong> 손실이 계속 높은 상태에 머무르는 경우 과소적합을 의미합</li>
<li>이때는 <strong>네트워크 크기를 다시 키워야</strong> 함</li>
</ul>
</li>
<li><strong>층의 수</strong>나 <strong>노드 수</strong>를 다시 늘려 모델이 충분한 표현력을 가질 수 있도록 조정</li>
</ul>
<h3 id="4-최적의-일반화-성능을-찾기"><a href="#4-최적의-일반화-성능을-찾기" class="headerlink" title="4. 최적의 일반화 성능을 찾기"></a>4. <strong>최적의 일반화 성능을 찾기</strong></h3><ul>
<li><strong>과대적합</strong>과 <strong>과소적합</strong> 사이의 <strong>균형점</strong>을 찾기 위해, 네트워크의 복잡성을 조정하면서 <strong>훈련 데이터</strong>와 <strong>검증 데이터</strong>에서 성능이 모두 향상되는 지점을 찾아야 함</li>
<li><strong>훈련 손실</strong>은 꾸준히 낮아지고, <strong>검증 손실</strong>은 더 이상 증가하지 않는 상태가 <strong>최적의 일반화 성능</strong>을 의미</li>
<li>이를 확인하기 위해서는 <strong>훈련과 검증 곡선이 비슷하게 수렴</strong>하는 지점을 찾는 것이 중요</li>
</ul>
<h2 id="학습-곡선을-통해-모델-성능-조정하기"><a href="#학습-곡선을-통해-모델-성능-조정하기" class="headerlink" title="학습 곡선을 통해 모델 성능 조정하기"></a><strong>학습 곡선을 통해 모델 성능 조정하기</strong></h2><h3 id="훈련-및-검증-손실-그래프"><a href="#훈련-및-검증-손실-그래프" class="headerlink" title="훈련 및 검증 손실 그래프"></a><strong>훈련 및 검증 손실 그래프</strong></h3><ul>
<li><p>훈련 중 **훈련 손실(Training Loss)**과 **검증 손실(Validation Loss)**의 그래프를 주의 깊게 살펴보는 것이 중요</p>
</li>
<li><p>각 손실 값의 변화 추이를 통해 과대적합 또는 과소적합 여부를 판별할 수 있음</p>
<ul>
<li><p><strong>과대적합 발생 시</strong>: 훈련 손실은 계속해서 감소하지만, 검증 손실은 증가하기 시작</p>
</li>
<li><p><strong>과소적합 발생 시</strong>: 훈련 손실과 검증 손실 모두 높은 상태로 남아있음</p>
</li>
<li><p><strong>일반화가 잘 이루어질 때</strong>: 훈련 손실과 검증 손실이 함께 낮아지며, 검증 손실이 더 이상 증가하지 않을 때가 최적의 상태</p>
</li>
</ul>
</li>
</ul>
<h3 id="훈련-및-검증-정확도-그래프"><a href="#훈련-및-검증-정확도-그래프" class="headerlink" title="훈련 및 검증 정확도 그래프"></a><strong>훈련 및 검증 정확도 그래프</strong></h3><ul>
<li><p><strong>정확도 그래프(Accuracy Curve)</strong> 또한 학습 곡선에서 중요한 지표</p>
</li>
<li><p>훈련 정확도와 검증 정확도 사이에 큰 차이가 생기면 <strong>과대적합</strong>의 가능성이 있음</p>
<ul>
<li><p><strong>과대적합</strong>: 훈련 정확도는 계속해서 높아지지만, 검증 정확도는 일정 수준에서 멈추거나 떨어짐</p>
</li>
<li><p><strong>과소적합</strong>: 훈련 정확도 자체가 낮고, 검증 정확도도 낮은 상태가 지속</p>
</li>
<li><p><strong>일반화</strong>: 훈련과 검증 정확도가 비슷한 수준에서 안정되면 모델이 <strong>일반화</strong>가 잘 되고 있다는 신호</p>
</li>
</ul>
</li>
</ul>
<h2 id="모델-학습-시의-실용적인-예시"><a href="#모델-학습-시의-실용적인-예시" class="headerlink" title="모델 학습 시의 실용적인 예시"></a><strong>모델 학습 시의 실용적인 예시</strong></h2><p>아래는 케라스를 사용해 학습 중 <strong>훈련 및 검증 손실&#x2F;정확도</strong>를 시각화하여 네트워크 크기를 조정하고 일반화 성능을 찾는 방법</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모델 정의</span></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(input_dim,)))</span><br><span class="line">model.add(Dense(<span class="number">64</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(output_dim, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 컴파일</span></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>, loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습</span></span><br><span class="line">history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=<span class="number">50</span>, batch_size=<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습 곡선 시각화</span></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;loss&#x27;</span>], label=<span class="string">&#x27;Training Loss&#x27;</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_loss&#x27;</span>], label=<span class="string">&#x27;Validation Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;accuracy&#x27;</span>], label=<span class="string">&#x27;Training Accuracy&#x27;</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">&#x27;val_accuracy&#x27;</span>], label=<span class="string">&#x27;Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Training and Validation Accuracy&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-11-16T14:45:29.000Z" title="11/16/2022, 11:45:29 PM">2022-11-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-09T13:05:15.098Z" title="9/9/2024, 10:05:15 PM">2024-09-09</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">딥러닝 개념</a></span><span class="level-item">17 minutes read (About 2514 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%20%EA%B0%9C%EB%85%90/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%8F%E1%85%A6%E1%84%85%E1%85%A1%E1%84%89%E1%85%B3%20%E1%84%8E%E1%85%A1%E1%86%BC%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A6%E1%84%80%E1%85%A6%20%E1%84%87%E1%85%A2%E1%84%8B%E1%85%AE%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%20%EC%B5%9C%EC%A0%81%ED%99%94(%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EB%88%84%EC%88%98,%20%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9%EA%B3%BC%20%EC%9D%BC%EB%B0%98%ED%99%94)/">데이터 최적화(데이터 누수, 데이터 전처리, 데이터 분할 전략)</a></h1><div class="content"><h2 id="개요"><a href="#개요" class="headerlink" title="개요"></a>개요</h2><ul>
<li><strong>데이터 최적화</strong>는 <strong>머신러닝 모델 성능</strong>을 극대화하기 위한 필수 단계</li>
<li>모델을 학습시키기 위해서는 <strong>적절한 데이터 처리</strong>와 <strong>전처리 과정</strong>이 필요하며, 이를 통해 모델이 <strong>과대적합을 방지</strong>하고 <strong>일반화 성능</strong>을 높일 수 있음</li>
<li><strong>데이터 누수 방지</strong>와 함께 <strong>데이터 전처리</strong> 및 <strong>데이터 분할 전략</strong>을 중심으로 효율적인 데이터 준비 방법에 대해 알아봄</li>
</ul>
<h2 id="1-데이터-누수-Data-Leakage-방지"><a href="#1-데이터-누수-Data-Leakage-방지" class="headerlink" title="1. 데이터 누수(Data Leakage) 방지"></a>1. <strong>데이터 누수(Data Leakage) 방지</strong></h2><ul>
<li><strong>데이터 누수</strong>는 모델이 학습하는 동안 <strong>미래 정보를 포함하거나</strong> 평가 과정에서 <strong>테스트 데이터의 일부를 사용하는</strong> 경우 발생</li>
<li>이는 모델 성능이 부풀려질 수 있지만, <strong>실제 환경</strong>에서의 성능은 크게 떨어지게 됨</li>
<li>데이터 누수는 훈련 데이터에 <strong>부정확한 정보를 제공</strong>하여 모델이 잘못 학습하게 만드는 중요한 문제</li>
</ul>
<h3 id="데이터-누수-방지-방법"><a href="#데이터-누수-방지-방법" class="headerlink" title="데이터 누수 방지 방법"></a><strong>데이터 누수 방지 방법</strong></h3><h4 id="1-미래-정보-포함-여부-확인"><a href="#1-미래-정보-포함-여부-확인" class="headerlink" title="1) 미래 정보 포함 여부 확인"></a>1) <strong>미래 정보 포함 여부 확인</strong></h4><ul>
<li><strong>미래의 데이터를 학습에 포함</strong>시키는 것은 누수의 가장 흔한 사례</li>
<li><strong>시계열 데이터</strong>나 <strong>시간 의존적인 데이터</strong>에서는 과거 데이터만 사용해야 하며, <strong>미래 데이터를 절대 포함하지 않도록</strong> 주의해야 함</li>
</ul>
<ul>
<li>금융 시장에서 주식 가격 예측 모델을 만들 때, <strong>미래의 주가 데이터</strong>가 학습에 포함되지 않도록 해야함 → 이를 방지하기 위해 <strong>시간순으로 데이터를 분할</strong>하여 과거 데이터를 학습에 사용하고, <strong>미래 데이터를 검증용</strong>으로 사용함</li>
</ul>
<h4 id="2-중복-샘플-방지"><a href="#2-중복-샘플-방지" class="headerlink" title="2) 중복 샘플 방지"></a>2) <strong>중복 샘플 방지</strong></h4><ul>
<li>같은 샘플이 훈련과 테스트 세트에 <strong>중복</strong>되어 포함되면, 모델은 이미 학습한 데이터를 기반으로 평가되어 <strong>성능이 과대평가</strong>될 수 있음</li>
<li>데이터 분할 시에는 <strong>샘플 중복을 방지</strong>하여 데이터 누수가 발생하지 않도록 해야함</li>
</ul>
<ul>
<li>예시: 고객 데이터를 기반으로 머신러닝 모델을 학습할 때, 같은 고객이 훈련과 테스트 세트에 <strong>중복</strong>으로 포함되지 않도록 주의해야 함</li>
</ul>
<h4 id="3-전처리-단계에서의-주의"><a href="#3-전처리-단계에서의-주의" class="headerlink" title="3) 전처리 단계에서의 주의"></a>3) <strong>전처리 단계에서의 주의</strong></h4><ul>
<li>전처리 과정에서 데이터를 잘못 처리하면 <strong>데이터 누수</strong>가 발생할 수 있음</li>
<li>특히 <strong>훈련 세트와 테스트 세트</strong>를 구분하지 않고 전체 데이터에 대한 <strong>통계값</strong>을 사용하여 전처리를 하면 <strong>테스트 데이터의 정보가 학습 과정에 누출</strong>될 수 있음</li>
</ul>
<ul>
<li>예시: 결측값 처리 시 전체 데이터의 <strong>평균값</strong>이나 <strong>중앙값</strong>을 사용하는 대신, <strong>훈련 데이터에서만</strong> 통계치를 계산하고 테스트 데이터에는 그 값을 적용해야 함</li>
</ul>
<h4 id="4-특징-공학-Feature-Engineering-에서의-주의"><a href="#4-특징-공학-Feature-Engineering-에서의-주의" class="headerlink" title="4) 특징 공학(Feature Engineering)에서의 주의"></a>4) <strong>특징 공학(Feature Engineering)에서의 주의</strong></h4><ul>
<li>예측할 타깃 변수와 강하게 <strong>연관된 변수</strong>를 모델 학습에 포함하면 <strong>미래 정보가 누출</strong>되어 모델이 과대평가될 수 있음</li>
</ul>
<ul>
<li>예시: 의료 데이터를 활용한 예측 모델에서, 환자의 <strong>퇴원 여부</strong>를 예측하는 경우, 이미 퇴원 여부가 포함된 변수를 학습에 포함시키면 안됨</li>
</ul>
<h4 id="5-레이블-누수-확인"><a href="#5-레이블-누수-확인" class="headerlink" title="5) 레이블 누수 확인"></a>5) <strong>레이블 누수 확인</strong></h4><ul>
<li>모델이 학습 과정에서 <strong>타깃 변수</strong>와 관련된 정보를 <strong>직접적으로 사용하는 것</strong>은 데이터 누수의 전형적인 사례입</li>
<li>타깃 변수와 <strong>직접적인 상관관계</strong>가 있는 변수를 학습에 포함시키지 않도록 해야 함</li>
</ul>
<ul>
<li>예시: 대출 승인 여부를 예측할 때, <strong>이미 승인 여부가 기록된 변수</strong>를 모델이 학습하도록 하면 안됨</li>
</ul>
<h2 id="2-데이터-분할-전략"><a href="#2-데이터-분할-전략" class="headerlink" title="2. 데이터 분할 전략"></a>2. <strong>데이터 분할 전략</strong></h2><ul>
<li><strong>데이터 분할</strong>은 모델의 성능을 제대로 평가하기 위해 필수적인 과정</li>
<li>데이터를 적절히 분할함으로써 모델의 <strong>일반화 성능</strong>을 평가하고, <strong>과대적합</strong>을 방지할 수 있음</li>
<li>프랑소와 숄레는 데이터 분할의 중요성을 강조하며, 올바른 분할이 <strong>성능 평가</strong>에 핵심적인 역할을 한다고 언급</li>
</ul>
<h3 id="데이터-분할-방법"><a href="#데이터-분할-방법" class="headerlink" title="데이터 분할 방법"></a><strong>데이터 분할 방법</strong></h3><h4 id="1-훈련-x2F-검증-x2F-테스트-데이터-분할"><a href="#1-훈련-x2F-검증-x2F-테스트-데이터-분할" class="headerlink" title="1) 훈련&#x2F;검증&#x2F;테스트 데이터 분할"></a>1) <strong>훈련&#x2F;검증&#x2F;테스트 데이터 분할</strong></h4><ul>
<li><p>일반적으로 데이터는 세 개의 세트로 나누어 사용</p>
<ul>
<li><p><strong>훈련 세트(Train)</strong>: 모델을 학습시키는 데 사용됨</p>
</li>
<li><p><strong>검증 세트(Validation)</strong>: 하이퍼파라미터 튜닝 및 모델 선택에 사용됨</p>
</li>
<li><p><strong>테스트 세트(Test)</strong>: 최종적으로 모델 성능을 평가하는 데 사용됨 테스트 세트는 <strong>한 번만 사용</strong>하고, 이후에는 모델 학습에 포함되지 않아야함</p>
</li>
</ul>
</li>
</ul>
<h4 id="2-데이터-섞기-Shuffle"><a href="#2-데이터-섞기-Shuffle" class="headerlink" title="2) 데이터 섞기(Shuffle)"></a>2) <strong>데이터 섞기(Shuffle)</strong></h4><ul>
<li>데이터는 무작위로 섞는 것이 중요, 그렇지 않으면 <strong>데이터 순서</strong>에 따라 모델이 <strong>편향된 학습</strong>을 할 수 있음</li>
<li>특히 <strong>지역별</strong>이나 <strong>시간순</strong>으로 정렬된 데이터는 <strong>무작위로 섞어야</strong> 모델이 다양한 패턴을 학습할 수 있음</li>
</ul>
<ul>
<li>단, <strong>시계열 데이터</strong>의 경우에는 데이터를 섞으면 안 되고, <strong>시간순</strong>으로 유지해야 함, 그렇지 않으면 <strong>미래 데이터를 학습</strong>에 사용하게 되어 <strong>데이터 누수</strong>가 발생할 수 있음</li>
</ul>
<h4 id="3-층화-샘플링-Stratified-Sampling"><a href="#3-층화-샘플링-Stratified-Sampling" class="headerlink" title="3) 층화 샘플링(Stratified Sampling)"></a>3) <strong>층화 샘플링(Stratified Sampling)</strong></h4><ul>
<li>데이터셋이 <strong>불균형</strong>한 경우, 데이터 분할 시 <strong>층화 샘플링</strong>을 사용하여 <strong>클래스 비율을 유지</strong>해야함</li>
<li>이를 통해 <strong>소수 클래스</strong>가 훈련 및 검증 세트에서 <strong>충분히 포함</strong>될 수 있도록 보장</li>
</ul>
<ul>
<li>예시: <code>train_test_split</code> 함수에서 <code>stratify</code> 옵션을 사용하여 <strong>불균형 데이터</strong>의 클래스 비율을 유지</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, stratify=y, random_state=<span class="number">42</span>)</span><br></pre></td></tr></table></figure>


<h2 id="3-데이터-전처리-Data-Preprocessing"><a href="#3-데이터-전처리-Data-Preprocessing" class="headerlink" title="3. 데이터 전처리(Data Preprocessing)"></a>3. <strong>데이터 전처리(Data Preprocessing)</strong></h2><ul>
<li><strong>데이터 전처리</strong>는 모델 학습에 있어서 중요한 단계</li>
<li>프랑소와 숄레는 데이터를 적절히 전처리해야만 모델이 <strong>일반화 성능</strong>을 높일 수 있다고 설명</li>
<li>이 과정에서 잘못된 전처리는 모델 성능을 저하시킬 수 있으며, 데이터 누수의 원인이 될 수도 있음</li>
</ul>
<h3 id="전처리-방법"><a href="#전처리-방법" class="headerlink" title="전처리 방법"></a><strong>전처리 방법</strong></h3><h4 id="1-결측값-처리-Missing-Data-Handling"><a href="#1-결측값-처리-Missing-Data-Handling" class="headerlink" title="1) 결측값 처리(Missing Data Handling)"></a>1) <strong>결측값 처리(Missing Data Handling)</strong></h4><ul>
<li>결측값을 처리하지 않고 모델에 포함하면 <strong>성능 저하</strong>가 발생할 수 있음</li>
<li>결측값은 <strong>평균값</strong>, <strong>중앙값</strong> 등으로 대체할 수 있으며, 때로는 특정 모델을 사용하여 결측값을 <strong>예측</strong>할 수 있음</li>
</ul>
<ul>
<li>중요한 점은, <strong>훈련 세트의 통계값만</strong> 사용하여 결측값을 처리해야 한다는 것, 테스트 데이터에는 훈련 세트에서 계산된 통계값을 사용해야 데이터 누수를 방지할 수 있음</li>
</ul>
<h4 id="2-범주형-변수-인코딩-Categorical-Encoding"><a href="#2-범주형-변수-인코딩-Categorical-Encoding" class="headerlink" title="2) 범주형 변수 인코딩(Categorical Encoding)"></a>2) <strong>범주형 변수 인코딩(Categorical Encoding)</strong></h4><ul>
<li><p>머신러닝 모델은 <strong>숫자형 데이터</strong>만 처리할 수 있기 때문에 <strong>범주형 변수</strong>는 숫자로 변환해야함</p>
<ul>
<li><p><strong>One-Hot Encoding</strong>: 범주형 변수를 이진 변수로 변환하여 처리하는 방법</p>
</li>
<li><p><strong>Label Encoding</strong>: 범주를 숫자로 변환하는 방식</p>
</li>
</ul>
</li>
</ul>
<h4 id="3-스케일링-Scaling"><a href="#3-스케일링-Scaling" class="headerlink" title="3) 스케일링(Scaling)"></a>3) <strong>스케일링(Scaling)</strong></h4><ul>
<li>변수 간 스케일이 크게 다른 경우, <strong>정규화</strong>나 <strong>표준화</strong>를 통해 스케일을 맞춰줘야함</li>
<li>이는 특히 <strong>거리 기반 알고리즘</strong>에서 매우 중요함</li>
<li>이때도 스케일링은 <strong>훈련 세트</strong>로부터 계산된 값을 사용하여 <strong>테스트 세트</strong>에 적용해야함</li>
</ul>
<h2 id="4-데이터-증강-Data-Augmentation"><a href="#4-데이터-증강-Data-Augmentation" class="headerlink" title="4. 데이터 증강(Data Augmentation)"></a>4. <strong>데이터 증강(Data Augmentation)</strong></h2><ul>
<li>데이터가 충분하지 않거나 특정 클래스의 데이터가 부족한 경우, <strong>데이터 증강</strong>을 통해 데이터를 <strong>인위적으로 늘릴 수 있음</strong></li>
<li>특히 <strong>딥러닝 모델</strong>에서는 데이터 증강이 중요한 역할을 함</li>
</ul>
<h3 id="데이터-증강-방법"><a href="#데이터-증강-방법" class="headerlink" title="데이터 증강 방법"></a><strong>데이터 증강 방법</strong></h3><h4 id="1-이미지-데이터-증강"><a href="#1-이미지-데이터-증강" class="headerlink" title="1) 이미지 데이터 증강"></a>1) <strong>이미지 데이터 증강</strong></h4><ul>
<li><strong>이미지 데이터</strong>의 경우 <strong>회전</strong>, <strong>확대</strong>, <strong>축소</strong>, <strong>뒤집기</strong> 등을 통해 <strong>다양한 훈련 데이터</strong>를 생성할 수 있음</li>
<li>이는 <strong>과대적합</strong>을 방지하고, 모델이 다양한 패턴을 학습할 수 있도록 도와줌</li>
</ul>
<h4 id="2-텍스트-데이터-증강"><a href="#2-텍스트-데이터-증강" class="headerlink" title="2) 텍스트 데이터 증강"></a>2) <strong>텍스트 데이터 증강</strong></h4><ul>
<li>텍스트 데이터에서는 <strong>문장의 순서를 변경</strong>하거나 <strong>동의어로 대체</strong>하는 방식으로 데이터를 증강할 수 있음</li>
<li>이를 통해 텍스트 데이터를 더욱 다양하게 만들 수 있음</li>
</ul>
<h4 id="3-합성-데이터-생성"><a href="#3-합성-데이터-생성" class="headerlink" title="3) 합성 데이터 생성"></a>3) <strong>합성 데이터 생성</strong></h4><ul>
<li>**GAN(생성적 적대 신경망)**이나 <strong>SMOTE</strong> 기법을 통해 <strong>소수 클래스 데이터를 생성</strong>할 수 있음</li>
<li>이 방법은 데이터가 부족하거나 <strong>불균형 데이터셋</strong>에서 사용될 수 있음</li>
</ul>
<h2 id="5-데이터-품질-유지-및-관리"><a href="#5-데이터-품질-유지-및-관리" class="headerlink" title="5. 데이터 품질 유지 및 관리"></a>5. <strong>데이터 품질 유지 및 관리</strong></h2><ul>
<li>데이터 최적화의 마지막 단계는 <strong>데이터 품질 관리</strong></li>
<li>프랑소와 숄레는 <strong>데이터 일관성</strong>과 <strong>버전 관리</strong>가 중요하다고 강조하며, 데이터가 변경될 경우 <strong>모델 성능</strong>에 미치는 영향을 추적하는 것이 필수적이라고 설명</li>
</ul>
<h3 id="데이터-품질-관리-방법"><a href="#데이터-품질-관리-방법" class="headerlink" title="데이터 품질 관리 방법"></a><strong>데이터 품질 관리 방법</strong></h3><ul>
<li><strong>데이터 버전 관리</strong>: 데이터 수집 및 처리 과정에서 <strong>버전 관리</strong>를 명시하여 추적합니다. 이를 통해 데이터 변경 시 <strong>모델에 미치는 영향</strong>을 추적할 수 있음</li>
<li><strong>데이터 소스의 일관성 유지</strong>: 여러 소스에서 데이터를 수집할 때, <strong>스키마</strong>와 <strong>포맷</strong>을 일관되게 유지해야함</li>
<li><strong>데이터 품질 모니터링</strong>: 정기적으로 <strong>데이터 품질</strong>을 모니터링하여 <strong>이상값</strong>이나 <strong>패턴</strong>을 확인하고, 잘못된 데이터가 모델에 학습되지 않도록 방지해야함</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-10-26T12:45:50.000Z" title="10/26/2022, 9:45:50 PM">2022-10-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T00:20:48.000Z" title="9/5/2024, 9:20:48 AM">2024-09-05</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%86%B5%EA%B3%84%ED%95%99-%EB%B0%8F-%EC%88%98%ED%95%99/">딥러닝을 위한 통계학 및 수학</a></span><span class="level-item">an hour read (About 7939 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%ED%86%B5%EA%B3%84%ED%95%99%20%EB%B0%8F%20%EC%88%98%ED%95%99/%EA%B8%B0%EC%88%A0%ED%86%B5%EA%B3%84/">(2) 통계학 기본 - 데이터 구성</a></h1><div class="content"><h2 id="통계분석-자료분석"><a href="#통계분석-자료분석" class="headerlink" title="통계분석 - 자료분석"></a>통계분석 - 자료분석</h2><h3 id="데이터-구성"><a href="#데이터-구성" class="headerlink" title="데이터  구성"></a>데이터  구성</h3><ul>
<li><p>데이터는 기본적으로 **관측치(행)**와 **변수(변수)**들로 구성</p>
<p><img src="/img/basic_statistics/obser.png" alt="관측치"></p>
</li>
<li><p>관측치(Observations)</p>
<ul>
<li>모집단으로부터 추출된 표본의 수</li>
</ul>
</li>
<li><p>변수(Variable)</p>
<ul>
<li><p>속성 혹은 특성이라고 함</p>
</li>
<li><p>독립변수와 종속변수</p>
<ul>
<li><p>변수들 간의 상호 관련성, 즉 인과관계가 있는지에 따라 구분</p>
<ul>
<li><p>$$<br>y&#x3D;f(x)<br>$$</p>
<ul>
<li>x를 독립변수, y를 종속변수라 한다.</li>
<li>온도에 따른 아이스크림의 판매량 상관관계를 예시로 들었을 때, 날씨가 영하일 경우 아이스크림의 판매량이 떨어지고, 날씨가 더울 경우 아이스크림 판매량이 늘어나는 것처럼 원인이 되는 변수를 독립변수 원인의 결과인 아이스크림 판매량은 독립변수라 한다.</li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>구분</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>독립 변수<br />(Qualitative variable)</td>
<td>설명변수로 원인이 되는 변수</td>
</tr>
<tr>
<td>종속 변수<br />(Quantitative variable)</td>
<td>결과변수로 독립변수에 영향을 받아서 결과가 되는 변수</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>질적&#x2F;양적 변수</p>
<ul>
<li><p>속성을 수량화 할 수 있는가에 따라 구분</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>질적 변수<br />(Qualitative variable)</td>
<td>수치로 나타낼 수 없는 변수 <br />(ex. 회사명, 직종, 혈액형 등)</td>
</tr>
<tr>
<td>양적 변수 <br />(Quantitative variable)</td>
<td>수치로 나타낼 수 있는 변수 <br />(ex. 체중, 온도, 나이, 키 등)</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>이산변수 및 종속변수</p>
<ul>
<li><p>변수가 어떠한 값이라도 가질 수 있는지 아니면 특정 수치만 가질 수 있는지에 따라 구분</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>이산 변수<br />(Discrete variable)</td>
<td>셀 수 있는 정수 값을 갖는변수<br />(ex. 학생수, 직원수 등)</td>
</tr>
<tr>
<td>연속 변수<br />(Continuous variable)</td>
<td>연속적인 모든 실수 값을 갖는 변수<br /> (ex. 길이, 무게, 온도 등)</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>명목변수와 서열변수</p>
<ul>
<li><p>구분한 범주기 서열이 존재하는지에 따라 구분</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>명목 변수<br />(Discrete variable)</td>
<td>자료를 서로 다른 범주로 구분, 각 범주에 수치를 부여<br />(ex. 남자-1 여자-2 등)</td>
</tr>
<tr>
<td>서열 변수<br />(Continuous variable)</td>
<td>자료에 서열을 부여하기 위해서 수치를 사용<br />(ex. 5는 만족 3은 보통 1은 불만족으로 구분)</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>등간변수와 비율변수</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>등간변수 <br />(Interval variable)</td>
<td>자료를 서열뿐 아니라 상대척 차이까지 제시<br />(ex. 온도 20도와 30도의 차이는 10도 이다.</td>
</tr>
<tr>
<td>비율 변수 <br />(Ratio variable)</td>
<td>자료를 분류, 서열, 차이와 함께 절대영점까지 표현 <br />(ex. 키 180cm &#x3D; 90cm * 2)</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<ul>
<li>잔차(Residual)<ul>
<li>관측값과 계산 값의 차이를 의미하며, 잔차를 바탕으로 각종 오차를 계산</li>
</ul>
</li>
</ul>
<h2 id="통계분석-표본조사-Sample"><a href="#통계분석-표본조사-Sample" class="headerlink" title="통계분석 - 표본조사(Sample)"></a>통계분석 - 표본조사(Sample)</h2><ul>
<li>표본조사란<ul>
<li>모집단의 특성을 나타내는 일부 표본을 추출하기 위해서 자료를 수집하는 행위</li>
<li>모집단은 대상이 너무에 현실적으로 모집단을 전수조사하는 것은 불가능</li>
<li>모집단을 전수조사하는 것보다 표본 조사가 오히려 오차가 적을 수 있음</li>
</ul>
</li>
<li>표본방법<ul>
<li><strong>확률표집</strong><ul>
<li>정의<ul>
<li>수학적인 지침에 의해 선정되는 표본추출법</li>
<li>표본의 오차를 계산해야 함</li>
</ul>
</li>
<li>종류<ul>
<li>단순 무작위 표집(Simple random sampling)<ul>
<li>랜덤하게 묘수에서 표본을 반복적으로 추출하는 것으로 난수표 및 체계적 표집법을 사용</li>
</ul>
</li>
<li>층화표집법(Stratified sampling)<ul>
<li>모집단을 기준에 따라서 소집단으로 분류하고, <strong>각 소집단으로부터 무작위로 표본을 추출</strong></li>
<li>모집단에 대한 특성을 이해해야 하기에, 소집단 구분에 많은 비용과 노력이 발생</li>
<li>발생비율이 낮은 소집단은 해당 표본을 찾기 어려운 문제가 있음</li>
</ul>
</li>
<li>군집표집법(Clustser sampling)<ul>
<li>모집단을 특정 군집으로 분류하고, <strong>군집 중 일부를 선택해서 군집의 모든 구성원을 전수조사</strong> 하는 방법</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><strong>비확률표집</strong><ul>
<li>정의<ul>
<li>수학적으로 계산할 수 없는 경우에 사용되는 표본추출법</li>
<li>표본의 오차를 계산할 수 없음</li>
</ul>
</li>
<li>방법<ul>
<li>할당표본추출법(Quota sampling)<ul>
<li>가장 널리 사용되는 방법으로 모집단의 특성이 잘 반영되도록 특성별로 비례해서 표본을 추출</li>
<li>사전에 정해놓은 분류기준에 의해서 집단을 <strong>소집단으로 분류</strong>하고 집단별 대상을 선정</li>
<li>마케팅 조사, 연령별, 성별 설문조사 등에 사용됨</li>
</ul>
</li>
<li>편의표본추출법(Convenience sampling)<ul>
<li>가장 간단한 형태로 임의의 선정지역, 조사시간 등을 정의해 표본을 선택하는 방법</li>
<li>표본추출 비용이 거의 발생하지 않고 조사가 아주 간단</li>
<li>추출된 표본이 모집단을 대표하지 못함</li>
<li>응답거부자의 특성이 반영되지 않음</li>
</ul>
</li>
<li>판단표본추출법(Purposive sampling)<ul>
<li>모집단의 의견을 반영할 수 있을 것이라고 판단될 때 사용하는 방법</li>
<li>조사문제에 대해서 잘 알고있을 때 사용</li>
<li>적은 비용으로 의미 있는 자료를 수집할 수 있는 장점</li>
<li>모집단의 성격을 대표하지 못할 수 있음</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="통계분석-기술통계-분석"><a href="#통계분석-기술통계-분석" class="headerlink" title="통계분석 - 기술통계 분석"></a>통계분석 - 기술통계 분석</h2><ul>
<li>통계에는 기술통계와 추리통계 2가지가 있다.<ul>
<li>기술통계 : 표 및 그래프, 객관적인 수치를 사용해 데이터를 요약</li>
<li>추리통계 : 확률을 사용해서 모수와 표본 간의 오차 범위를 예측</li>
</ul>
</li>
</ul>
<h3 id="기술통계-분석"><a href="#기술통계-분석" class="headerlink" title="기술통계 분석"></a>기술통계 분석</h3><table>
<thead>
<tr>
<th>구분</th>
<th>요약방법</th>
<th>자료 정리</th>
<th>그래프</th>
</tr>
</thead>
<tbody><tr>
<td>질적자료</td>
<td>도표<br />그래프</td>
<td>도수분포표<br />분할표</td>
<td>막대그래프(Bar Chart, 빈도)<br />막대그래프(Bar Chart, 퍼센트)<br />원 그래프(Pie Chart)</td>
</tr>
<tr>
<td>연속자료</td>
<td>수치<br />그래프</td>
<td>산술평균<br />중앙값<br />조화평균</td>
<td>히스토그램(Histogram)<br />상자그래프(Box Plot)<br />시계열(Time Series)<br />산점도(Scatter Plot)</td>
</tr>
</tbody></table>
<h4 id="질적자료-기술통계"><a href="#질적자료-기술통계" class="headerlink" title="질적자료 기술통계"></a>질적자료 기술통계</h4><ul>
<li><p>도수분포표(Frequency Table)</p>
<ul>
<li><p>수집된 자료애 대해서 적절한 등급으로 분류해서 정리한 표</p>
</li>
<li><p>각 자료에 대해서 출현 빈도를 계산하고 여러 구간으로 분료한 표</p>
</li>
<li><p>관측값을 여러 개의 그룹으로 나누고 관측값의 수를 요약 정리한 표</p>
<p><img src="/img/basic_statistics/freq.png" alt="freq"></p>
</li>
<li><p>이러한 표를 바탕으로 그래프(Bar&#x2F;Pie Graph)를 그린다</p>
</li>
</ul>
</li>
<li><p>분할표(Contingency Table)</p>
<ul>
<li><p>질적변수가 2개일 때 관측치를 몇 개의 그룹으로 분할해서 빈도수를 정리한 것</p>
</li>
<li><p>예시 - 2개의 질적 범주(성별, 플레이 유무)</p>
<p><img src="/img/basic_statistics/conti01.png" alt="cont01"></p>
<p><img src="/img/basic_statistics/conti02.png" alt="cont02"></p>
</li>
</ul>
</li>
</ul>
<h4 id="연속자료-기술통계"><a href="#연속자료-기술통계" class="headerlink" title="연속자료 기술통계"></a>연속자료 기술통계</h4><ul>
<li><p>자료의 분포 특성을 파악하기 위해서 숫자로 표현</p>
</li>
<li><p>중심위치와 산포경향을 파악하여 요약</p>
<table>
<thead>
<tr>
<th>중심위치</th>
<th>산포경향</th>
</tr>
</thead>
<tbody><tr>
<td>관측 잘가 어디에 집중되어 있는지를 분석</td>
<td>자료가 중심위치를 기준으로 어느 정도 흩어져 있는지를 분석</td>
</tr>
<tr>
<td>산술평균, 중앙값, 최빈값, 기하평균, 조화평균, 가중편균</td>
<td>범위, 편차, 표준편차</td>
</tr>
</tbody></table>
<ul>
<li><p>중심위치</p>
<ul>
<li><p>평균은 자료의 분포상 무게중심을 하지만, 평균은 데이터의 분포에 따라 역할을 제대로 하지 못할 수 있다. 아래의 예는 평균은 178.46이지만 정작 170-180의 사람은 가장 적은 것을 볼 수있음</p>
<p><img src="/img/basic_statistics/mean.png" alt="mean"></p>
</li>
<li><p>따라서 표존편차를 함께 사용한다. 표준편차는 평ㅇ균을 기준으로 데이터가 떨어져 있는 거리 값으로 표준편차가 크게 나타난다면 평균을 기준으로 데이터가 멀리 흩어져 있다는 것을 알 수 있다.</p>
</li>
<li><p>평균, 중앙값, 최빈값</p>
<table>
<thead>
<tr>
<th>구분</th>
<th>평균(Mean)</th>
<th>중앙값(Median)</th>
<th>최빈값(Mode)</th>
</tr>
</thead>
<tbody><tr>
<td>의미</td>
<td>자료의 합을 개수로 나눈 값</td>
<td>작은값부터 큰 값을 나열할 때 중앙에 있는 값</td>
<td>자료 중 빈도가 가장 많이 나타나는 값</td>
</tr>
<tr>
<td>장점</td>
<td>자료의 값을 모두 사용</td>
<td>극단적인 값이 있을 때 자료의 특성을 잘 반영</td>
<td>쉽게 계산이 가능</td>
</tr>
<tr>
<td>단점</td>
<td>극단적인 값이 있으면 자료의 특성을 잘 반영하지 못함</td>
<td>모든 자료를 사용하지 않음</td>
<td>자료의 수가 적으면 중심 경향을 잘 바영하지 못함</td>
</tr>
</tbody></table>
</li>
<li><p>가중평균(Weighted mean)</p>
<ul>
<li>자료의 중요도 및 영향 등에 따라서 가중치를 반영한 평균값</li>
</ul>
</li>
<li><p>기하평균(Geometric mean)</p>
<ul>
<li>변화량을 계산할 때 많이 사용</li>
<li>연간 경제성장률, 물가 인상률, 연간 이자율 등과 같은 곳에 사용 2010년부터 2022년까지 경제 성장률에 대한 평균, 즉 2010년의 기준에서 2022년의 경쟁률로 발전하려면 매년 몇 퍼센트가 증가해야 하는가를 의미</li>
</ul>
</li>
<li><p>조화평균(Harmonic mean)</p>
<ul>
<li><p>여러 단위가 결합될 때 평균적인 변화를 계산</p>
</li>
<li><p>상대적인 비를 계산</p>
</li>
<li><p>예시</p>
<ul>
<li><p>경기도에서 서울까지 자동차로 다녀왔는데 갈 때에는 고속도로를 이요하여 100km&#x2F;h로 갔고, 올때는 국도를 이용해서 70km.h로 돌아왔다면 왕복 평균 속도는 얼마인가?</p>
<ul>
<li>평균이라면 85이지만 조화평균의 경우 82.3km&#x2F;h이다</li>
</ul>
<p>$$<br>H&#x3D; \frac{n}{\frac{1}{a_1}+…+\frac{1}{a_n}} &#x3D; \frac{2}{\frac{1}{100}+\frac{1}{70}}&#x3D;2&#x2F;(0.0143+0.01)&#x3D;82.3<br>$$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>절단평균(Trimmed Mean)</p>
<ul>
<li>가장 큰 값과 작은 값을 잘라내고 산술평균을 구한 것</li>
</ul>
</li>
</ul>
</li>
<li><p>산포경향</p>
<ul>
<li><p>범위</p>
</li>
<li><p>분산</p>
<ul>
<li>자료가 평균을 중심으로 얼마나 븐포하고 있는가를 수치로 나타냄</li>
<li>확률변수가 기대값으로부터 얼마나 떨어진 곳에 분포하는지를 나타내는 숫자값</li>
</ul>
</li>
<li><p><strong>표준편차</strong></p>
<ul>
<li>자료의 분포와 변동에 대한 정보를 제공</li>
<li>자료에 있는 이상치를 점검</li>
<li>가설검정을 함</li>
</ul>
<blockquote>
<p><strong>체비쇼프의 정리(Chebyshev’s Theorem)</strong></p>
<ul>
<li>어떤 k에 대해서 적어도 자료의 (1-(1&#x2F;k*2)) 만큼의 비율이 k표준편차 내에 있음을 의미</li>
<li>k&#x3D;2 이면 3&#x2F;4인 75%의 자료가 2 표준편차 내에 있다는 것을 의미</li>
<li>k&#x3D; 3이라면 88.9%의 자료가 3 표준편차 내에 있다는 것을 의미</li>
</ul>
</blockquote>
</li>
<li><p><strong>변동계수(Coefficient of Variation)</strong></p>
<ul>
<li><p><strong>측정 단위가 다른 자료나 자료 값의 차이가 너무 큰 경우</strong> 사용</p>
</li>
<li><p>상대 표준편차라고도 한다, 즉 상대적인 산포를 계산한다</p>
</li>
<li><p>변동계수는 <strong>표준편차를 산술평균으로 나눈 값</strong>이다.<br>$$<br>CV&#x3D;\frac{σ}{\overset{-}{x}}<br>$$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="그래프"><a href="#그래프" class="headerlink" title="그래프"></a>그래프</h4><ul>
<li><p>히스토그램(Histogram)</p>
<ul>
<li>각 구간별 현황 및 대칭 여부를 확인하기 위해서 히스토그램을 사용할 수 있음</li>
<li>데이터의 이상값(outler) 유무를 확인할 수 있음</li>
</ul>
<p><img src="/img/basic_statistics/histogram.png" alt="histogram"></p>
</li>
<li><p>상자그림(Box Plot)</p>
<ul>
<li><p>대칭여부, 이상값, 자료의 분포, 최대값, 최소값, 중위값 등을 확인할 수 있음</p>
<p><img src="/img/basic_statistics/boxplot.png" alt="boxplot"></p>
</li>
<li><p>사분위수</p>
<table>
<thead>
<tr>
<th>사분위수</th>
<th>설명</th>
</tr>
</thead>
<tbody><tr>
<td>제1사분위수(Q1)</td>
<td>데이터의 25%가 이 값보다 작거나 같음</td>
</tr>
<tr>
<td>제2사분위수(Q2)</td>
<td>중위수 데이터의 50%가 이 값보다 작거나 같다</td>
</tr>
<tr>
<td>제3사분위수(Q3)</td>
<td>데이터의 75%가 이 값보다 작거나 같다</td>
</tr>
<tr>
<td>사분위간범위<br />(InterQuantile Range)</td>
<td>재1사분위수(Q1)과 제3사분위수(Q3) 간의 거리(Q3-Q1)이고, 데이터의 50%의 범위</td>
</tr>
</tbody></table>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/boxplot2.png" alt="boxplot2"></p>
</li>
<li><p>Boxplot의 의미</p>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/boxplot3.png" alt="boxplot3"></p>
</li>
<li><p>박스의 길이가 길면 자료가 넓게 펴져있는 것</p>
</li>
<li><p>박스의 길이가 짧으면 자료가 평균을 중심으로 모여있는 것</p>
</li>
</ul>
</li>
<li><p>시계열(TimeSeries) 분석</p>
<ul>
<li><p>시계열 분석이란</p>
<ul>
<li>시계열 데이터는 관측치가 시간적 순서를 가지고 있음</li>
<li>미래를 예측하는 것을 목적으로 함</li>
<li>시계열 데이터를 사용해서 추세(Trend)분석, 원인 예측, 전망 등을 분석</li>
<li>주가 환율, 거래량 변동, 기온, 습도 등의 데이터이다.</li>
</ul>
</li>
<li><p>시계열 데이터 구성요소</p>
<table>
<thead>
<tr>
<th>구성요소</th>
<th>설명</th>
</tr>
</thead>
<tbody><tr>
<td>추세<br />(Trend)</td>
<td>기술혁신, 인구증가, 문화의 변화 등과 같이 장기간에 걸쳐 일정한 방향으로 지속적으로 사읏ㅇ하거나 하강하는 경향이다.</td>
</tr>
<tr>
<td>계절적 변동<br />(Seasonal variation)</td>
<td>봄, 여름, 가을, 겨울에 따라서 특정 소비가 증가하거나, 감소하는 형태로 나타남</td>
</tr>
<tr>
<td>주기적 변동<br />(Cyclical variation)</td>
<td>경기동향, 실업률, 이자율과 같이 일정한 주기를 가지고 장기간에 걸쳐 변동됨</td>
</tr>
<tr>
<td>임의 변동<br />(Random variation)</td>
<td>불규칙 변동이라고 하며, 우연한 요인에 의해 발생되기 때문에 패턴을 가지고 있지 않음</td>
</tr>
</tbody></table>
</li>
<li><p>추세(Trend)분해 방법</p>
<table>
<thead>
<tr>
<th>방법</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>Lowess.Loess 회귀</td>
<td>특정 범위에 다항 회귀선을 구하여 병합하는 방법</td>
</tr>
<tr>
<td>이동평균<br />(Moving Average)</td>
<td>특정 기간 동안의 값의 평균변화를 분석</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h2 id="통계분석-추리통계"><a href="#통계분석-추리통계" class="headerlink" title="통계분석 - 추리통계"></a>통계분석 - 추리통계</h2><h3 id="1-확률"><a href="#1-확률" class="headerlink" title="1. 확률"></a>1. 확률</h3><ul>
<li>확률은 어떤 사건이 발생할 가능성으로 0과 1사이의 숫자로 표현</li>
<li>표본 자료를 사용해서 구한 통계량과 모집단의 모수를 추론</li>
</ul>
<h3 id="2-확률계산"><a href="#2-확률계산" class="headerlink" title="2. 확률계산"></a>2. 확률계산</h3><ul>
<li>표본공간(Sample space)<ul>
<li>S로 표시하며 통계적 시험에서 발생할 수 있는 경우의 수</li>
</ul>
</li>
<li>사건(Event)<ul>
<li>특정 결과가 발생하는 모임으로 A,B,C 등으로 표현<ul>
<li>P(A) : 사건 A가 일어날 확률</li>
<li>n(A) : 사건 A가 일어날 수 있는 경우의 수</li>
<li>n(S) : 전체 경우의 수</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>$$<br>확률 &#x3D; \frac{사건이 발생할 경우의 수}{전체경우의수}<br>$$</p>
<p>$$<br>P(A) &#x3D; \frac{n(A)}{n(S)}<br>$$</p>
<h3 id="3-추리통계-Inferential-Statistics-란"><a href="#3-추리통계-Inferential-Statistics-란" class="headerlink" title="3. 추리통계(Inferential Statistics)란"></a>3. 추리통계(Inferential Statistics)란</h3><p>기술통계에서 자료의 특성이 분석되면 표본을 사용하여 모집단의 특성을 추정하는 분석</p>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/inferstats.png" alt="inferstats"></p>
<ul>
<li><p>기술통계와 추리 통계의 차이점</p>
<table>
<thead>
<tr>
<th>기술통계</th>
<th>추리통계</th>
</tr>
</thead>
<tbody><tr>
<td><strong>수집한 데이터</strong>의 특성을 파악하기 위해서 <strong>요약정리</strong>하는 통계방법</td>
<td>수집한 데이터에서 <strong>표본(sample)을</strong> <strong>추출하여</strong>  <strong>모집단의 특성을 추정</strong></td>
</tr>
<tr>
<td>평균, 중위값, 최빈수, 범위, 분산, 표준편차와 같은 분석으로 데이터의 특성을 파악</td>
<td>표본을 사용해서 미래를 예측하는 것<br />차이검정 및 관계검정 등</td>
</tr>
</tbody></table>
</li>
<li><p>추리통계학 작업</p>
<ul>
<li>가설형태</li>
<li>통계적 결정오류 및 통계적 유의도</li>
<li>가설검증</li>
</ul>
</li>
<li><p>추리통계학 검증방법</p>
<ul>
<li>모수에 의한 검증<ul>
<li>T-test</li>
<li>ANOVA</li>
<li>Z 검증 방법</li>
</ul>
</li>
<li>비모수 통계 검증<ul>
<li>카이제곱 검증</li>
<li>Mann-Whitney U 검증</li>
<li>Kruskal-Wallis 검증</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="통계분석-통계적-추론"><a href="#통계분석-통계적-추론" class="headerlink" title="통계분석 - 통계적 추론"></a>통계분석 - 통계적 추론</h2><h3 id="1-확률분포"><a href="#1-확률분포" class="headerlink" title="1. 확률분포"></a>1. 확률분포</h3><ul>
<li><p>확률변수란</p>
<ul>
<li>확률변수가 특정 값을 가질 확률을 나타내는 함수</li>
<li>통계량을 분석하여 통계적 의사결정을 내릴 수 있는 기준을 제시</li>
<li>이산확률분포와 연속활률분포로 분류(어떤 종류의 값을 가지고 있는가에 따라 구분)</li>
</ul>
</li>
<li><p>확률분포의 종류</p>
<ul>
<li>이산확률분포 : 일양균등분포, 이항분포, 포아송분포, 초기하분포, 기하분포</li>
<li>연속확률분포 <ul>
<li>평균분포 : 정규분포, t-분포</li>
<li>분산분포 : 카이제곱분포, f-분포</li>
</ul>
</li>
</ul>
</li>
<li><p>확률변수와 확률분포의 관계</p>
<ul>
<li>확률변수는 모든 원소를 실수로 대응하는 함수이고</li>
<li>확률분포는 확률변수로 얻어진 실수를 확률 값으로 반환하는 함수</li>
</ul>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/prob01.png" alt="prob01"></p>
</li>
</ul>
<h2 id="2-이산확률분포"><a href="#2-이산확률분포" class="headerlink" title="2. 이산확률분포"></a>2. 이산확률분포</h2><ul>
<li><p>이산확률분포란</p>
<ul>
<li>확률변수가 0,1,2,와 같이 이산적인 형태를 이루는 분포</li>
<li>로또 1등으로 당첨될 확률, 1남 3녀가 될 확률 등을 계산하는 형태</li>
</ul>
</li>
<li><p>이산확률변수(Discreate Random Variable)</p>
<ul>
<li>특정 수치만을 가지고 확률변수로 정수로 표현된다</li>
<li>P(X) &#x3D; 180</li>
</ul>
</li>
<li><p>이항분포(Binomial Distribution) &#x3D; 베르누이분포</p>
<ul>
<li><p>베르누이 과정의 시행을 반복</p>
</li>
<li><p>베르누이 시행은 두 가지 결과 중 하나만 나타나게 시행하는 것으로 보통 “성공”, “실패”로 표현</p>
</li>
<li><p>이전의 실행 결과에 독립적이므로 영향을 주지 않는다.</p>
</li>
<li><p>각 시행의 성공 혹은 실패의 확률은 처음부터 끝까지 변하지 않음</p>
<blockquote>
<p><strong>베르누이분포(Bernoulli ditribution)</strong></p>
<ul>
<li>베르누이분포는 확률변수가 0과 1 두 가지 결과 값만을 가지고 서로 독립적으로 시행됨</li>
<li>모든 실험결과에서 결과 확률은 항상 동일</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>포아송분포(poisson distribution)</p>
<ul>
<li><p>데이터 분석자가 설정한 시간에서 사건이 발생하는 건수</p>
</li>
<li><p>주어진 시간, 거리, 공간 범위에서 발생 할 확률이 아주 낮은 사건들의 발생에 관한 이산확률 분포</p>
</li>
<li><p>시간 단위당 도착에 대한 모델에 많이 사용됨</p>
</li>
<li><p>예시</p>
<ul>
<li>주어지 기간 동안 살인 사건의 수</li>
<li>생산 공장에서 작업 중에 재해가 발생하여 사망할 건수</li>
<li>일정한 거리의 전선에서 결점 수</li>
</ul>
<blockquote>
<p><strong>지수분포(Exponential Distribution)</strong></p>
<ul>
<li>포아송분포의 반대로 도착시간에 따른 시간을 측정할 때 사용하는 연속확률분포</li>
<li>두 사건 사이에서 시간에 대한 확률을 의미</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>초기하분포(Hypergeometric distribution)</p>
<ul>
<li>주어진 횟수만큼 반복되는 경우 성공할 횟수를 예측</li>
<li>과거의 결과는 현재, 미래의 결과에 영향을 미치는 것으로 분석(이항확률분포는 연속되는 시행이 독립적)</li>
<li>시행마다 발생할 결과가 이항분포처럼 두 가지만 있지만 유한 모집단에서 비복원 추출되기 때문에 베르누이 시행조건에 만족되지 안흔ㄴ 경우 사용되는 확률분포</li>
<li>베르누이 과정을 따르지 않는다.</li>
</ul>
</li>
</ul>
<h3 id="3-연속확률분포"><a href="#3-연속확률분포" class="headerlink" title="3. 연속확률분포"></a>3. 연속확률분포</h3><ul>
<li><p>연속확률분포란</p>
<ul>
<li>연속 확률변수의 값에 대응하는 확률을 표시</li>
<li>확률밀도함수를 사용해서 분포를 표현할 수 있음</li>
<li>관측값이 연속적인 값을 가지고 있는 확률변수</li>
</ul>
</li>
<li><p>연속확률변수(Continuous Random Variable)</p>
<ul>
<li>어떤 범위에서 연속적인 값을 가질 수 있는 실수</li>
<li>연속확률변수의 자료는 각각 고유의 값을 가지고 있음</li>
<li>몸무게, 체온, 수명 등의 변수가 있음</li>
<li>P(175.0 &lt;&#x3D; X &lt;&#x3D; 185.0)</li>
</ul>
</li>
<li><p>정규분포(Normal Distribution)</p>
<ul>
<li><p>통계이론에서 중요한 확률분포로 샘플을 추출해서 모집단의 모수를 예측할 때 사용</p>
</li>
<li><p>모집단의 분포를 정규분포로 가정하고 통계분석을 수행</p>
</li>
<li><p>정규분포는 평균을 중심으로 좌우대칭 구조를 가지고 잇는 확률분포</p>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/ND.svg" alt="ND"></p>
</li>
</ul>
</li>
<li><p>표준정규분포(Stadard Normal Distribution)</p>
<ul>
<li><p>정규분포에서 확률변수를 측정단위와 관계없이 자료를 표준화시켜 측정한 확률분포</p>
</li>
<li><p>표준 확률변수(Standardized Random Variable)</p>
<ul>
<li>표준 확률변수는 측정단위와 관계없이 자료를 표준화시킴</li>
<li>평균으로부터 떨어진 거리를 계산할 수 있음</li>
</ul>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/SND.png" alt="SND"></p>
</li>
<li><p>경험적 법칙(Empirical Rule)</p>
<ul>
<li><p>k&#x3D;1, 68.26% 이상의 데이터가 μ ± 1 시그마에 있다</p>
</li>
<li><p>k&#x3D;2, 95.44% 이상의 데이터가 μ ± 2 시그마에 있다</p>
</li>
<li><p>k&#x3D;3, 99.73% 이상의 데이터가 μ ± 3 시그마에 있다</p>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/er.jpg" alt="er"></p>
</li>
<li><p>z 함수를 이요해서 평균과 표준편차로 면적을 계산할 수 있음(적분 사용 안해도됨)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="4-통계적-추론-Statistical-Inference"><a href="#4-통계적-추론-Statistical-Inference" class="headerlink" title="4. 통계적 추론(Statistical Inference)"></a>4. 통계적 추론(Statistical Inference)</h3><ul>
<li><p>통계적 추론이란 우리가 알지 못하는 대상에 대해서 통계적으로 접근하여 알아가는 과정</p>
</li>
<li><p>예시</p>
<ul>
<li>스마트폰을 가장 많이 사용하는 시간?</li>
<li>스마트폰을 남자와 여자 중에 누가 더 많이 사용할까?</li>
<li>급여수준과 사용하는 스마트폰의 종류는 관계가 있을까?</li>
</ul>
</li>
<li><p>모수적 추론(Parametric inference)</p>
<ul>
<li>어떤 대상인 모집단의 분포가 어떤 분포일 것이라고 가정하고 모수에 대해서 추론</li>
<li>모집단이 정규분포를 따른다면 분포의 모수는 평균과 분산일 것</li>
<li>따라서 모수적 추론의 가정은 최종 결론에 아주 큰 영향을 줌</li>
<li>정규분포, 이항분포, 포아송분포 등을 가정</li>
</ul>
</li>
<li><p>비모수적 추론(Non-parametric inference)</p>
<ul>
<li>모집단에 대해서 어떠한 가정도 하지 않고 추론</li>
<li>모집단을 몇개의 모수로 결정하기 어려워서 많은 모수를 사용해야 할 때 비모수적 추론을 함</li>
<li>비모수적 추론을 사용하는 경우<ul>
<li>정규분포를 따르지 않는 것이 증명</li>
<li>표본의 수가 적어서 정규분포를 가정할 수가 없음</li>
<li>모집단에 대한 아무런 정보가 없음</li>
<li>정규분포를 가정하지 않기 때문에 평균과 분산이 없고 평균값의 차이, 신뢰구간을 구할 수가 없음</li>
<li>따라서 비모수적 추론은 해석이 복잡해지고 실제 값을 사용하기 보다 부호나 순위 등의 형태를 사용하는 경우가 많음</li>
</ul>
</li>
</ul>
</li>
<li><p>베이지안 추론(Bayesian Inference)</p>
<ul>
<li><p>베이지안 확률을 사용해서 추론하는 방법으로 모수적 추론에서 가정한 분포의 모수로 추론</p>
</li>
<li><p>실험을 통해서 정보를 획득하고 베이즈 정리를 사용하여 가설 확률을 수정하는 통계적 추정방법</p>
</li>
<li><p>인공지능에서 사전 데이터로부터 학습된 지식을 추가 데이터로 업데이트할 때 사용됨<br>$$<br>P(H|E) &#x3D; \frac{P(E|H)P(H)}{P(E)}<br>$$</p>
<blockquote>
<p><strong>베이즈 정리(Bayes’ theorm)</strong></p>
<ul>
<li>A와 B는 모두 독립사건이고, A에 대해서 B의 조건부 확률 P(A|B)와 B에 대한 A의 조건부확률(B|A)는 일반적으로 같지 않음 <ul>
<li>A와 B의 사전확률(Prior probability)인 P(A)와 P(B)가 같지 않기 때문</li>
</ul>
</li>
<li>결론적으로 베이즈 정리는 P(A|B), P(B|A) 사이의 연관규칙이 존재하며 해당 규칙의 관계를 설명</li>
</ul>
</blockquote>
<blockquote>
<p>$$<br>P(A|B) &#x3D; \frac{P(B|A)P(A)}{P(B)}<br>$$</p>
<ul>
<li>A와 B는 모두 독립사건이고 B가 발생활 확률 P(B)가 0 이 아님</li>
<li>사건 A가 일어날 확률 P(A)와 사건 B가 일어날 확률 P(B)에서 B에 대한 사건 A의 조건부확률(P(B|A))를 알고 있으면 A에 대한 B가 일어날 확률을 알지 못해도 추정이 가능하다는 것</li>
</ul>
</blockquote>
<ul>
<li><p>베이즈 정리를 사용한 베이지안 추론</p>
<ul>
<li><p>사전 경험과 현재 데이터를 사용해서 어떤 사건의 확률을 베이즈 정리를 사용해서 추론한 것</p>
</li>
<li><p>P(A)는 사전확률이고 “사건A가 발생한다”라는 명제에 대한 확률값으로 정의됨</p>
</li>
<li><p>P(B)는 증거로 측정을 통해서 얻어진 B가 발생할 확률</p>
</li>
<li><p>P(B|A)는 가능도(Likelihood)로 “사건 A가 발생할 때 명제 B가 발생할 조건부확률”</p>
</li>
<li><p>P(B|A)와 P(A), P(B)를 통해서 P(A|B)를 얻을 수 있으며, P(A|B)는 사후확률로 B라는 증거가 관찰된 후의 명제에 대한 확률</p>
<blockquote>
<p><strong>베이지안 추론</strong><br>$$<br>P(H|E) &#x3D; \frac{P(E|H)P(H)}{P(E)}<br>$$</p>
<ul>
<li>사건 A가 발생한다라는 명제를 H로 정의하고 믿음의 정도는 P(H)로 나타냄</li>
<li>증거B를 E로 나타냄</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>통계적 추론 방법에 따른 분류</p>
<ul>
<li>통계적 추론<ul>
<li>추정(Estimation)<ul>
<li>점추정(Point Estimation)<ul>
<li>미지의 모수에 대해 표본의 통계량을 사용해서 어떤 값으로 추정하는 과정</li>
<li>모집단의 특성을 단일값으로 추정하는 방법</li>
<li>모집단의 평균이 표본평균과 일치하는 세타를 찾는 방법을 적률방법(Moment Method)라고 함</li>
<li>예<ul>
<li>표본평균</li>
<li>표본분산</li>
</ul>
</li>
</ul>
</li>
<li>구간추정(Interval Estimation)<ul>
<li>모수의 값이 포함될 것이라 생각되는 범위를 통해서 모수를 추정</li>
<li>모수의 구간 값을 계산해서 모수가 특정 구간에 포함될 것을 확률로 분석</li>
<li>신뢰수준으로 85%, 97% 등으로 확률로 나타냄</li>
<li>신뢰구간(Confidnece interval)<ul>
<li>P(L ≤ θ ≤ U) - 1 - α</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>가설검정(Testing hypothesis)<ul>
<li>모수에 대한 가설을 세우고 해당 가설의 옳고 그름을 판단</li>
<li>가설에 대한 검정을 통해서 기각할 것인지 채택할 것인지 결정</li>
<li>검정 통계량(Test statsitic)은 귀무가설을 기각하고 대립가설을  채택할지 아니면 귀무가설을 채택하고 대립가설을 기각할 것인지에 대한 통계량</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="통계분석-5-가설"><a href="#통계분석-5-가설" class="headerlink" title="통계분석 - 5.가설"></a>통계분석 - 5.가설</h2><h3 id="가설검증"><a href="#가설검증" class="headerlink" title="가설검증"></a>가설검증</h3><ul>
<li><p>가설검증(hypothesis test)이란</p>
<ul>
<li>표본 데이터를 기반으로 모집단에 대한 새로운 주장의 옳고 그름을 추론하는 과정</li>
<li>가설의 진설여부를 증명하는 것</li>
<li>통계적 유의성을 검정하는 것으로, 유의적 검정(Significance Test)라고도 함</li>
<li>모수에서 표본을 사용하여 진실여부를 True, False로 판단</li>
<li>귀무가설(H0)이 사실이라고 가정하고 검증</li>
<li>통계적 검정(statstical test) 라고도 함</li>
</ul>
</li>
<li><p>귀무가설(Null, Hypothesis ,H0)</p>
<ul>
<li>기존의 주장 또는 기존에 알려진 사실(일반적으로 진실이라고 믿고 있는 것)</li>
<li>통계적 검정 대상이 됨<ul>
<li>제네시스는 연비가 10km 이다</li>
</ul>
</li>
</ul>
</li>
<li><p>대립가설(Alternative Hypothesis, H1)</p>
<ul>
<li>모집단에 대한 새로운 주장 (모집단과 표본의 평균은 다르다.)</li>
<li>귀무가설과 대립하는 가설로 새로운 사실을 입증</li>
<li>연구가설이라고도 함</li>
<li>모수의 표본을 사용해서 검증<ul>
<li>제네시스는 연비가 10km가 아니다.</li>
</ul>
</li>
</ul>
</li>
<li><p>가설검정(귀무가설을 채택할 것인지 기각할 것인지 검증)의 종류</p>
<ul>
<li>우측 검정(Right-sided Test)<ul>
<li>오른쪽 5% 내에 있는지를 확인</li>
<li>95% 구간을 벗어나면 귀무가설을 기각됨</li>
</ul>
</li>
<li>좌측 검정(Left-sided Test)<ul>
<li>좌측 5%로 검정하여 귀무가설을 채택할지 기각할지 결정</li>
</ul>
</li>
<li>양측 검정(Two-sided Test)<ul>
<li>우측과 좌측 2.5% 구간을 기준으로 귀무가설을 채택할지 기각할지 결정</li>
</ul>
</li>
</ul>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/hypo_test.png" alt="hypo_test"></p>
</li>
</ul>
<h2 id="통계분석-7-통계분석-기법"><a href="#통계분석-7-통계분석-기법" class="headerlink" title="통계분석 - 7. 통계분석 기법"></a>통계분석 - 7. 통계분석 기법</h2><ul>
<li><p>통계분석이란</p>
<ul>
<li>특정집단을 대상으로 자료를 수집하여 대상집단의 정보를 구체적 통계분석 기법으로 통계적 추론을 하는 일련의 과정을 의미</li>
</ul>
<p><img src="D:/NaverCloud/md/git/blog/matte/source/_posts/통계학/기본/img/basic_statistics/stats_anal.jpg" alt="stats_anal"></p>
</li>
</ul>
<h3 id="평균차이검정"><a href="#평균차이검정" class="headerlink" title="평균차이검정"></a>평균차이검정</h3><ul>
<li><p>평균차이검정</p>
<ul>
<li><p>평균검정(T-test)</p>
<ul>
<li><p>분석해야하는 집단의 수가 2개 미만일 때 사용하는 방법</p>
</li>
<li><p>집단 간에 평균 값을 비교하는 분석기법</p>
</li>
<li><p>3개의 집단에 대해서 평균분석을 하면 1종 오류가 발생할 확률이 높아짐</p>
</li>
<li><p>평균검정은 집단이 1,2,3 이면 1:2, 2:3, 1:3 처럼 3번 평균을 비교하지만 분산분석(ANOVA)은 한번에 평균을 비교</p>
</li>
<li><p>종류</p>
<table>
<thead>
<tr>
<th>종류</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>One Sample T-test</td>
<td>하나의 집단에 평균이 얼마인지를 검사하는 방법</td>
</tr>
<tr>
<td>Independent Samples T-test</td>
<td>독립된 두 집단 간에 평균의 차이를 검사하는 방법</td>
</tr>
<tr>
<td>Paired Samples T-test</td>
<td>하나의 집단을 처리 전과 처리 후로 나누어 분석하는 방법</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
<li><p>분산분석(ANOVA, Analysis of Variance)</p>
<ul>
<li><p>ANOVA는 전체분산을 여러 개로 분할하여 분석하는 것으로 어떤 요인(factor)의 영향이 유의한지를 검정</p>
</li>
<li><p>집단이 3개 이상인 경우 사용</p>
</li>
<li><p>두개 이상의 집단을 비교할 때 사용하며 각 집단의 평균 차이에 의해서 발생되는 집단 간의 분산을 비교</p>
</li>
<li><p>F-분포(F-distribution, 연속확률분포)를 사용해서 가설을 검증하는 방법</p>
</li>
<li><p>종류 </p>
<table>
<thead>
<tr>
<th>기법</th>
<th>내용</th>
</tr>
</thead>
<tbody><tr>
<td>One way ANOVA</td>
<td>하나의 집단구분 변수를 사용</td>
</tr>
<tr>
<td>Two way ANOVA</td>
<td>동시에 두 집단의 집단구분 변수를 사용<br />평균 반응 프로파일(두 변수 간의 상호작용을 확인하여 변화량을 확인)을 사용하여 두 개의 벼누 간에 상호작용(변화)를 확인</td>
</tr>
<tr>
<td>Repeated Measured ANOVA</td>
<td>집단이 3개이고 반복적으로 측정<br />반복해서 측정하여 변화된 것을 비교하는 방법</td>
</tr>
<tr>
<td>Two way Repeated Measured ANOVA</td>
<td>시점 데이터와 집단 데이터를 사용해서 분석하는 형태</td>
</tr>
</tbody></table>
<blockquote>
<p><strong>F값의 의미</strong></p>
<ul>
<li>F값 &#x3D; 집단 간의 변량 &#x2F; 집단 내의 변량</li>
<li>F값이 클수록 집단 간 변량이 집단 내 변량보다 커진다는 것을 의미</li>
<li>독립변수의 설명력이 크다는 것은 집단 간의 변량이 크다는 것을 의미하기에 독립변수의 설명력이 커질수록 F값이 커진다</li>
<li>변량은 변수나 분산의 뜻으로 사용됨</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li><p>관계검정</p>
<ul>
<li>차이검정은 그룹 간의 차이를 분석(평균, 분산)하는 것이고 관계검정은 벼누솨 변수의 관계(연관성)울 검정</li>
<li>종류<ul>
<li>상관분석(Correlation)<ul>
<li>연속변수와 연속변수를 분석</li>
<li>두 개의 변수 간에 관계를 통계적 기법으로 분석</li>
<li>인과관계가 명확하지 않을 때 분석</li>
<li>선형관계를 전제</li>
<li>두 개의 변수는 균등한 관계<ul>
<li>ex. 키와 몸무게 -&gt; 어떤 변수가 원인이고 어떤 변수가 결과인지 알 수 없을 때 변수는 균등관계</li>
</ul>
</li>
<li>종류<ul>
<li>공분산(Covariance)</li>
<li>상관계수(Correlation Coefficient)</li>
<li>Pearson 상관계수</li>
<li>Spearman 상관계수</li>
</ul>
</li>
</ul>
</li>
<li>회귀분석(Regression)<ul>
<li>연속변수와 연속변수를 분석</li>
<li>변수 간의 인과관계를 분석</li>
<li>상관관계에서는 두가지 변수는 변수간에 원인과 결과가 없는 균등한 변수이고 회귀분석은 변수 간에 원인과 결과가 있는 변수</li>
<li>상관분석은 1:1의 관계이지만, 회귀분석은 1:N의 관계에서 데이터를 분석</li>
<li>인과 분석(원인 결과 분석)으로 독립변수의 변화가 종속변수의 변화를 어떻게 유발하는지 분석<ul>
<li>독립변수 : 독립변수의 변화가 종속변수에 여향을 주는 변수 x1, x2, …</li>
<li>종속변수 : 독깁변수에 영향을 받는 변수</li>
</ul>
</li>
<li>목적<ul>
<li>예측<ul>
<li>원인변수에 영향을 받는 기울기(회귀계수)를 찾아 y를 예측</li>
<li>변수를 비표준화하여 사용</li>
</ul>
</li>
</ul>
</li>
<li>종류<ul>
<li>Multiple Linear Regression</li>
<li>Logistic Regression</li>
</ul>
</li>
</ul>
</li>
<li>교차분석(Cross-tabulation)<ul>
<li>질적변수와 질적변수를 분석</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-10-22T14:36:41.000Z" title="10/22/2022, 11:36:41 PM">2022-10-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T00:20:52.000Z" title="9/5/2024, 9:20:52 AM">2024-09-05</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%86%B5%EA%B3%84%ED%95%99-%EB%B0%8F-%EC%88%98%ED%95%99/">딥러닝을 위한 통계학 및 수학</a></span><span class="level-item">10 minutes read (About 1498 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84%20%EC%9C%84%ED%95%9C%20%ED%86%B5%EA%B3%84%ED%95%99%20%EB%B0%8F%20%EC%88%98%ED%95%99/01.%20%ED%86%B5%EA%B3%84%ED%95%99%EC%9D%B4%EB%9E%80/">(1) 통계학 기본 - 통계학이란</a></h1><div class="content"><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>전공으로 통계를 공부하지 않았기 때문에 머신러닝에 대한 대학 원서나 확률과 통계에 대한 개념을 접할 때 간혹 전문용어 등이 나타날 때 갸우뚱하는 경우가 있었다. 그래서 용어에 대한 개념체계를 명백히 하면서 자격증이 남을 수 있는  ADsP 를 준비하게 되었다.<br>따라서 전반적으로 엔지니어로써의 관점보다는, <strong>원론적인 내용</strong>에 대해 알아두면 언젠가는 도움이 되지 않을까라는 지적 호기심의 관점으로  작성하였다.<br>(대부분의 내용은 이기적 ADsP 책을 기본으로 하였습니다.)</p>
<h2 id="통계학-Statistics-이란"><a href="#통계학-Statistics-이란" class="headerlink" title="통계학(Statistics)이란"></a>통계학(Statistics)이란</h2><ul>
<li><p>관심 대상인 <strong>모집단의 특성</strong>을 파악하기 위해</p>
<ul>
<li>문제 : 모집단을 조사하기란 매우 어려움, 현실세계에서 99%이상은 표본추출로 실행할 것임</li>
</ul>
</li>
<li><p>모집단으로부터 관련된 일부 자료인 <strong>표본을 수집</strong>하고</p>
<ul>
<li>표본추출(sampling)</li>
</ul>
</li>
<li><p>수집된 표본의 자료를 <strong>요약</strong>하여 표본의 특성을 파악하고</p>
<ul>
<li>기술통계학(Descriptive Statistics)</li>
</ul>
</li>
<li><p>표본의 자료를 이용하여 모집단의 특성에 대해 <strong>확률을 이용해 추론</strong>(95% 신뢰도로, σ&#x3D;1.96)하는 학문</p>
<ul>
<li>추론통계학(Inferential Statistics)</li>
</ul>
<p><img src="/img/basic_statistics/popu_sample.png" alt="core_statistics">)</p>
</li>
</ul>
<h3 id="기술통계학-Descriptive-Statistics"><a href="#기술통계학-Descriptive-Statistics" class="headerlink" title="기술통계학(Descriptive Statistics)"></a>기술통계학(Descriptive Statistics)</h3><ul>
<li>조사 및 측정된 자료를 통해 그 자료가 가지고 있는 특징을 수치, 표, 그래프로 <strong>정리</strong>하는 과정<ul>
<li>수치 <ul>
<li>중심위치<ul>
<li>평균(산술평균, 기하평균, 조화평균, 가중평균)</li>
<li>중앙값</li>
<li>최빈값</li>
</ul>
</li>
<li>산포경향<ul>
<li>범위</li>
<li>편차</li>
<li>표준편차</li>
<li>변동계수(Coefficient of Variation)</li>
</ul>
</li>
</ul>
</li>
<li>표</li>
<li>그래프</li>
</ul>
</li>
</ul>
<h4 id="추론통계학-Inferential-Statistics"><a href="#추론통계학-Inferential-Statistics" class="headerlink" title="추론통계학(Inferential Statistics)"></a>추론통계학(Inferential Statistics)</h4><ul>
<li>모집단으로부터  플을 추출 및 분석하여 그 결과로부터 전체 모집단에 대한 특성을 <strong>예측</strong>하는 과정</li>
<li>추리통계학 작업<ul>
<li>가설형태</li>
<li>통계적 결정오류 및 통계적 유의도</li>
<li>가설검증</li>
</ul>
</li>
<li>추리통계학 검증방법<ul>
<li>모수에 의한 검증<ul>
<li>T-test</li>
<li>ANOVA</li>
<li>Z 검증 방법</li>
</ul>
</li>
<li>비모수 통계 검증<ul>
<li>카이제곱 검증</li>
<li>Mann-Whitney U 검증</li>
<li>Kruskal-Wallis 검증</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="기본-용어-정리"><a href="#기본-용어-정리" class="headerlink" title="기본 용어 정리"></a>기본 용어 정리</h4><ol>
<li><p><strong>모집단과 표본</strong></p>
<ul>
<li><p>모집단(Population)</p>
<ul>
<li>관심 있는 연구대상 전체의 집합</li>
<li>무한모집단: 모집단의 크기가 무한한 경우(전 세계인구, 축구를 좋아하는 사람들의 수)</li>
<li>유한모집단: 모집단의 크기가 유한한 경우(A 대학교 재학생의 수)</li>
</ul>
</li>
<li><p>전수조사(Census)</p>
<ul>
<li>관심있는 모집단 전체를 조사하는 경우로서 주로 모집단의 규모가 작을 경우에 실시</li>
<li>전수조사의 어려움<ul>
<li>조사 불가능 (모집단 전체를 대상으로 조사자체가 불가능)</li>
<li>엄청난 시간과 비용 소모</li>
</ul>
</li>
<li>해결책<ul>
<li>전수조사 -&gt; 표본조사</li>
</ul>
</li>
</ul>
</li>
<li><p>표본(Sample)</p>
<ul>
<li>실제로 조사 및 측정되는 모집단의 일부</li>
</ul>
</li>
<li><p>조사하기 위해 추출한 모집단의 일부 원소들</p>
</li>
<li><p>표본조사</p>
<ul>
<li>모집단에서 추출된 일부분인 표본을 가지고하는 조사</li>
<li>수집방법<ul>
<li>실험(Eperiment)</li>
<li>조사(Survey)</li>
<li>출판 자료(Published data)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>모수(Parameter) 와 통계량(Statistic)</strong></p>
<ul>
<li><p>모수(Parameter)</p>
<ul>
<li><p>통계적 관점에서의 의미</p>
<ul>
<li>모집단에 대한 수치 특성값</li>
<li>모집단의 특성을 나타내는 양적인 측도로서 주어진 모집단을 따르는 고유의 상수(상수&#x3D;모집단은 진실된 하나의 값임)</li>
<li>모집단의 특성(모평균(𝜇), 모분산(𝜎)  등)을 나타내는 값으로 모집단을 전수조사해야만 알 수 있는 값</li>
<li>실제로는 모집단의 크기와 범위가 너무 방대하기에 전수조사를 실시하지 않고 표본 조사를 하는데, 표본평균, 표본분산 등으로 모평균, 모분산등을 추정할 수 있음</li>
<li>표본 관측으로 구하고자 하는 모집단에 대한 정보</li>
<li>예시</li>
<li>서울시 송파구 소재의 고등학교 사교육비 평균</li>
</ul>
</li>
<li><p>확률적 관점에서의 의미</p>
<ul>
<li>정규 분포(Normal Distribution)의 경우<ul>
<li>모수: 평균 (μ, Mean), 분산(σ², Variance)</li>
</ul>
</li>
</ul>
</li>
<li><p>수학적 관점에서의 의미<br>$$<br>f(x) &#x3D; ax^2+bx+c<br>$$</p>
<ul>
<li>모수는 a,b,c를 뜻함, x는 함수의 인수(the function’s argument)</li>
<li>특정 시스템을 정의하거나 분류하는데 도움이 되는 특성</li>
<li>함수의 특정한 성질을 나타내는 변수를 의미</li>
<li>일반적으로 θ로 표현</li>
</ul>
</li>
</ul>
</li>
<li><p>통계량(Statistic)</p>
<ul>
<li>표본에서 얻은 수치 특성값</li>
<li>표본의 특성을 나타내는 양적인 측도로서 모집단의 분포를 따르는 확률변수<ul>
<li>확률변수 &#x3D; 표본에 따라 값이 변함을 의미</li>
</ul>
</li>
<li>표본평균(x̅), 표본표준편차(𝑠)</li>
<li>예시<ul>
<li>우리나라 고등학교 1학년 중에서 1000명만 뽑아 조사하여 얻은 평균 사 교육비</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>표본오차와 통계적 추론</strong></p>
<ul>
<li><p>표본오차(Sampling Error)</p>
<ul>
<li>모집단에서 표본을 추출해서 조사하기 때문에, 모수와 표본 통계량 사이에 생기는 오차</li>
<li>표본의 크기를 크게함으로써 표본 오차를 감소 -&gt; 통계학에서 표본의 크기를 크게 하라는 이유</li>
<li>표본오차는 아무리 표본을 크게 해도 전수조사를 하지 않는 이상 존재</li>
<li><strong>표본오차의 허용범위를 확률로 구하는 것이 통계의 목적</strong></li>
</ul>
</li>
<li><p>통계적추론</p>
<ul>
<li>우리가 실제로 알고 싶은 것은 표본의 값(통계량: statistic)이 아니고 모집단의 값(모수:parameter)</li>
<li>통계학의 목적 : 추론(Inference) -&gt; 표본에서 구한 값을 이용해 우리가 구하고자하는 모집단의 값도 어떠할 것이다 추론</li>
</ul>
</li>
</ul>
</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2022-08-04T00:39:12.000Z" title="8/4/2022, 9:39:12 AM">2022-08-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:00:20.000Z" title="9/6/2024, 12:00:20 AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</a><span> / </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/">NLP</a></span><span class="level-item">6 minutes read (About 904 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/KoNLPy%20%EC%84%A4%EC%B9%98(Ubuntu)/">KoNLPy 설치(Ubuntu)</a></h1><div class="content"><h3 id="배경"><a href="#배경" class="headerlink" title="배경"></a>배경</h3><p>한국어를 위한 Text Classification을 수행하기 위해 형태소 분석기(Mecab)를 사용할 필요가 있었음<br>이를 위해 하지만 <a target="_blank" rel="noopener" href="https://konlpy.org/ko/v0.5.2/install/">konlpy 공식 홈페이지</a> 의 설명대로 수행하였으나 잘 설치가 되지 않아 결국 수동으로 직접 설치 수행</p>
<ul>
<li>서버 : Ubuntu 16.04</li>
<li>Python Version :  3.8.13</li>
<li>JDK Versuib:  openjdk 1.8.0_292<ul>
<li>Mecab은 Java로 구현된 모듈이기에 필요</li>
</ul>
</li>
<li>KoNLPy Version : 0.60 (0.52 에서도 정상 동작 확인)</li>
<li>설치 날짜 : 22.08.03</li>
</ul>
<h3 id="설치"><a href="#설치" class="headerlink" title="설치"></a>설치</h3><ul>
<li><p>Install KoNLPy Package </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 -m pip install konlpy </span><br></pre></td></tr></table></figure>
</li>
<li><p>ubuntu dependency 설치</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install g++ openjdk-8-jdk python3-dev python3-pip curl</span><br></pre></td></tr></table></figure>

<p>※ openjdk-8-jdk : 필자는 기존에 JDK가 설치가 되어져 있었음, JDK가  설치 되어있지 않다면 해당 작업 외에 JDK를 bash에서 사용할 수 있도록 추가 작업 필요!</p>
</li>
<li><p>mecab-ko 설치</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/util <span class="comment"># util 파일 위치 지정(/tmp, /usr/local/share/util 등)</span></span><br><span class="line">sudo wget https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz</span><br><span class="line">sudo tar xvf mecab-0.996-ko-0.9.2.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> mecab-0.996-ko-0.9.2</span><br><span class="line">sudo ./configure</span><br><span class="line">sudo make check</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>
</li>
<li><p>mecab-dic 설치</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/util</span><br><span class="line">wget https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz</span><br><span class="line">tar zxvf mecab-ko-dic-2.1.1-20180720.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> mecab-ko-dic-2.1.1-20180720</span><br><span class="line">sudo ./autogen.sh</span><br><span class="line">sudo ./configure</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<p>※ 아래와 같은 오류 발생 시 sudo apt-get install automake libtool 수행</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">(pytorch_p38) shchoice@dq-mls-01:~/util/mecab-ko-dic-2.1.1-20180720$ sh autogen.sh </span><br><span class="line">Looking <span class="keyword">in</span> current directory <span class="keyword">for</span> macros.</span><br><span class="line">autogen.sh: 11: autogen.sh: aclocal: not found</span><br><span class="line">autogen.sh: 14: autogen.sh: autoconf: not found</span><br><span class="line">autogen.sh: 15: autogen.sh: automake: not found</span><br></pre></td></tr></table></figure>
</li>
<li><p>mecab-python 설치</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ~/util</span><br><span class="line">git <span class="built_in">clone</span> https://bitbucket.org/eunjeon/mecab-python-0.996.git</span><br><span class="line"><span class="built_in">cd</span> mecab-python-0.996</span><br><span class="line">python3 setup.py build</span><br><span class="line">python3 setup.py install</span><br></pre></td></tr></table></figure>
</li>
<li><p>mecab 정상 동작 확인</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line">Python <span class="number">3.8</span><span class="number">.13</span> (default, Mar <span class="number">28</span> <span class="number">2022</span>, <span class="number">11</span>:<span class="number">38</span>:<span class="number">47</span>) </span><br><span class="line">[GCC <span class="number">7.5</span><span class="number">.0</span>] :: Anaconda, Inc. on linux</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Mecab</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mecab = Mecab()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>sentence = <span class="string">&quot;안녕하세요~ KoNLPy 설치 후 테스트를 위한 문장입니다.&quot;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mecab.morphs(sentence)</span><br><span class="line">[<span class="string">&#x27;안녕&#x27;</span>, <span class="string">&#x27;하&#x27;</span>, <span class="string">&#x27;세요&#x27;</span>, <span class="string">&#x27;~&#x27;</span>, <span class="string">&#x27;KoNLPy&#x27;</span>, <span class="string">&#x27;설치&#x27;</span>, <span class="string">&#x27;후&#x27;</span>, <span class="string">&#x27;테스트&#x27;</span>, <span class="string">&#x27;를&#x27;</span>, <span class="string">&#x27;위한&#x27;</span>, <span class="string">&#x27;문장&#x27;</span>, <span class="string">&#x27;입니다&#x27;</span>, <span class="string">&#x27;.&#x27;</span>]</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="참고-공식-홈페이지를-통한-설치-시-오류-내용"><a href="#참고-공식-홈페이지를-통한-설치-시-오류-내용" class="headerlink" title="[참고] 공식 홈페이지를 통한 설치 시 오류 내용"></a>[참고] 공식 홈페이지를 통한 설치 시 오류 내용</h3><ul>
<li><p>mecab.sh 스크립트 사용 중 오류</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">bash &lt;(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)</span><br><span class="line"></span><br><span class="line">기존:34 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease                                                                                  </span><br><span class="line">기존:35 http://ppa.launchpad.net/webupd8team/y-ppa-manager/ubuntu xenial InRelease                                                                         </span><br><span class="line">기존:36 http://mariadb.mirror.liquidtelecom.com/repo/10.4/ubuntu xenial InRelease                                                                </span><br><span class="line">내려받기 72.2 k바이트, 소요시간 2초 (25.8 k바이트/초)</span><br><span class="line">패키지 목록을 읽는 중입니다... 완료</span><br><span class="line">E: 설치 방법 드라이버 /usr/lib/apt/methods/&lt;https을(를) 찾을 수 없습니다.</span><br><span class="line">E: 설치 방법 드라이버 /usr/lib/apt/methods/&lt;https을(를) 찾을 수 없습니다.</span><br><span class="line">E: 설치 방법 드라이버 /usr/lib/apt/methods/oops을(를) 찾을 수 없습니다.</span><br><span class="line">W: GPG 오류: http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease: 다음 서명들은 공개키가 없기 때문에 인증할 수 없습니다: NO_PUBKEY A4B469963BF863CC</span><br><span class="line">W: The repository <span class="string">&#x27;http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64  InRelease&#x27;</span> is not signed.</span><br><span class="line">N: Data from such a repository can<span class="string">&#x27;t be authenticated and is therefore potentially dangerous to use.</span></span><br><span class="line"><span class="string">N: See apt-secure(8) manpage for repository creation and user configuration details.</span></span><br><span class="line"><span class="string">E: &lt;https://dl.bintray.com/rabbitmq-erlang/debian&gt;/dists/xenial/InRelease 파일을 받는데 실패했습니다  </span></span><br><span class="line"><span class="string">E: &lt;https://dl.bintray.com/rabbitmq/debian&gt;/dists/xenial/InRelease 파일을 받는데 실패했습니다  </span></span><br><span class="line"><span class="string">E: oops://ubuntu.com/dists/foo/InRelease 파일을 받는데 실패했습니다  </span></span><br><span class="line"><span class="string">E: Some index files failed to download. They have been ignored, or old ones used instead.</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>pip3 install konlpy 설치는 완료했지만 위의 스크립트 파일 실행 오류로 tagger를 읽어오지 못하는 오류 발생</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">Python <span class="number">3.8</span><span class="number">.13</span> (default, Mar <span class="number">28</span> <span class="number">2022</span>, <span class="number">11</span>:<span class="number">38</span>:<span class="number">47</span>) </span><br><span class="line">[GCC <span class="number">7.5</span><span class="number">.0</span>] :: Anaconda, Inc. on linux</span><br><span class="line"><span class="type">Type</span> <span class="string">&quot;help&quot;</span>, <span class="string">&quot;copyright&quot;</span>, <span class="string">&quot;credits&quot;</span> <span class="keyword">or</span> <span class="string">&quot;license&quot;</span> <span class="keyword">for</span> more information.</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> konlpy.tag <span class="keyword">import</span> Mecab</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mecab = Mecab()</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;/home/shchoice/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/konlpy/tag/_mecab.py&quot;</span>, line <span class="number">77</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    self.tagger = Tagger(<span class="string">&#x27;-d %s&#x27;</span> % dicpath)</span><br><span class="line">NameError: name <span class="string">&#x27;Tagger&#x27;</span> <span class="keyword">is</span> <span class="keyword">not</span> defined</span><br><span class="line"></span><br><span class="line">During handling of the above exception, another exception occurred:</span><br><span class="line"></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">&quot;&lt;stdin&gt;&quot;</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">&quot;/home/shchoice/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/konlpy/tag/_mecab.py&quot;</span>, line <span class="number">82</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&#x27;Install MeCab in order to use it: http://konlpy.org/en/latest/install/&#x27;</span>)</span><br><span class="line">Exception: Install MeCab <span class="keyword">in</span> order to use it: http://konlpy.org/en/latest/install/</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="느낀점"><a href="#느낀점" class="headerlink" title="느낀점"></a>느낀점</h3><p>KoNLPy를 설치를 3번째 해보는데, 매번 오래된? 관리가 잘되지 않은? ubuntu 환경에서 사용해서인지 홈페이지 가이드 대로 설치를 수행하다 불필요하게 시간을 소모했다. 따라서 KoNLPy 설치할 때에는 그냥 처음부터 수동으로 설치를 하자</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/page/4/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/page/6/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/page/4/">4</a></li><li><a class="pagination-link is-current" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">노력 백줌 열정 천줌의 소프트웨어 개발자</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">139</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">64</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">110</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD 파이프라인</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Jenkins/"><span class="level-start"><span class="level-item">Jenkins</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/"><span class="level-start"><span class="level-item">버전 관리</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC-%EB%B0%8F-%EB%B0%B0%ED%8F%AC-%EC%A0%84%EB%9E%B5/"><span class="level-start"><span class="level-item">버전 관리 및 배포 전략</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/Cuda/"><span class="level-start"><span class="level-item">Cuda</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Java/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">내 코드가 그렇게 이상한가요</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">핵심 원리 - 기본편</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/"><span class="level-start"><span class="level-item">기타</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/"><span class="level-start"><span class="level-item">데이터베이스 &amp; 검색엔진</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">47</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/"><span class="level-start"><span class="level-item">논문 리뷰</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">딥러닝 개념</span></span><span class="level-end"><span class="level-item tag">38</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">딥러닝 기본 개념</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">딥러닝을 활용한 자연어 처리(NLP) 개념</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%86%B5%EA%B3%84%ED%95%99-%EB%B0%8F-%EC%88%98%ED%95%99/"><span class="level-start"><span class="level-item">딥러닝을 위한 통계학 및 수학</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/"><span class="level-start"><span class="level-item">성능과 튜닝</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%8F-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%82%B9/"><span class="level-start"><span class="level-item">테스트 및 벤치마킹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/"><span class="level-start"><span class="level-item">소프트웨어 공학</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">소프트웨어 아키텍처</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/API-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">API 설계 및 아키텍처</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">마이크로서비스 아키텍처</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">웹 프로그래밍</span></span><span class="level-end"><span class="level-item tag">17</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/HTTP-%EB%B0%8F-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC/"><span class="level-start"><span class="level-item">HTTP 및 네트워크</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Core/"><span class="level-start"><span class="level-item">Spring Core</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Data-JPA/"><span class="level-start"><span class="level-item">Spring Data JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EA%B0%9C%EB%B0%9C-%ED%99%98%EA%B2%BD-%EC%84%A4%EC%A0%95/"><span class="level-start"><span class="level-item">개발 환경 설정</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">보안</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">데이터 암호화</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%84%9C%EB%B2%84-%EB%B0%8F-%EC%9D%B8%ED%94%84%EB%9D%BC/"><span class="level-start"><span class="level-item">서버 및 인프라</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/"><span class="level-start"><span class="level-item">클라우드 컴퓨팅</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EB%8F%84%EC%BB%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"><span class="level-start"><span class="level-item">도커 &amp; 쿠버네티스</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">서버리스 아키텍처</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">프로그래밍</span></span><span class="level-end"><span class="level-item tag">31</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/Effective-Java/"><span class="level-start"><span class="level-item">Effective Java</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">함수형 프로그래밍</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/"><span class="level-start"><span class="level-item">Java&quot;</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B3%91%EB%A0%AC-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">동시성 &amp; 병렬 프로그래밍</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/"><span class="level-start"><span class="level-item">소프트웨어 공학</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%ED%81%B4%EB%A6%B0-%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">클린 코드</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-10-15T15:01:29.000Z">2024-10-16</time></p><p class="title"><a href="/Jenkins-SVM-%EC%97%B0%EB%8F%99-Jenkinsfile-%EC%9E%91%EC%84%B1/">Jenkins - SVM 연동 &gt; Jenkinsfile 작성</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-27T14:37:53.000Z">2024-09-27</time></p><p class="title"><a href="/Jenkins-Notification-Teams-Email/">Jenkins Notification(Teams, Email)</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-26T14:14:55.000Z">2024-09-26</time></p><p class="title"><a href="/Jenkins-SVM-%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%83%E1%85%A9%E1%86%BC-Multibranch-Pipeline-%E1%84%89%E1%85%A5%E1%86%AF%E1%84%8C%E1%85%A5%E1%86%BC-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8/">Jenkins - SVM 연동 &gt; Multibranch Pipeline 설정 방법</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-23T14:58:06.000Z">2024-09-23</time></p><p class="title"><a href="/Jenkins-SVM-%EC%97%B0%EB%8F%99-Freestyle-Project-%EC%84%A4%EC%A0%95-%EB%B0%A9%EB%B2%95/">Jenkins - SVM 연동 &gt; Freestyle Project 설정 방법</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-22T14:51:41.000Z">2024-09-22</time></p><p class="title"><a href="/Jenkins%EC%97%90%EC%84%9C-%EB%8B%A4%EC%96%91%ED%95%9C-%EB%B9%8C%EB%93%9C-%EC%98%B5%EC%85%98-%EC%84%A0%ED%83%9D%ED%95%98%EA%B8%B0-Multi-branch-Pipeline-vs-Freestyle-Project/">Jenkins에서 다양한 빌드 옵션 선택하기 &gt; Multi-branch Pipeline vs Freestyle Project</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD 파이프라인</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/Jenkins/">Jenkins</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item">October 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">18</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1급 시민</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASGI/"><span class="tag">ASGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CGI/"><span class="tag">CGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FastAPI/"><span class="tag">FastAPI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Forward-Proxy/"><span class="tag">Forward Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gunicorn/"><span class="tag">Gunicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Jenkins/"><span class="tag">Jenkins</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/L4-%EC%8A%A4%EC%9C%84%EC%B9%98/"><span class="tag">L4 스위치</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Load-Testing/"><span class="tag">Load Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OSI-7%EA%B3%84%EC%B8%B5/"><span class="tag">OSI 7계층</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RPS/"><span class="tag">RPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Response-Time/"><span class="tag">Response Time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reverse-Proxy/"><span class="tag">Reverse Proxy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Spring이란</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stress-Testing/"><span class="tag">Stress Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TCP-IP-4%EA%B3%84%EC%B8%B5/"><span class="tag">TCP/IP 4계층</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TPS/"><span class="tag">TPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Testing-Types/"><span class="tag">Testing Types</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Throughput/"><span class="tag">Throughput</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Uvicorn/"><span class="tag">Uvicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WAS/"><span class="tag">WAS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSGI/"><span class="tag">WSGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-commit-rule/"><span class="tag">git commit rule</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-flow/"><span class="tag">git flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-merge/"><span class="tag">git merge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git-rebase/"><span class="tag">git rebase</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/github-flow/"><span class="tag">github flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/gitlab-flow/"><span class="tag">gitlab flow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python 설치</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">객체지향</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">다형성</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EB%88%84%EC%88%98/"><span class="tag">데이터 누수</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">람다식</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%A1%9C%EB%93%9C-%EB%B0%B8%EB%9F%B0%EC%8B%B1/"><span class="tag">로드 밸런싱</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C/"><span class="tag">리버스 프록시</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">벡터의 곱셈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%EC%A7%80%ED%91%9C/"><span class="tag">성능 지표</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/"><span class="tag">성능 테스트</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">엔트로피</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%9B%B9-%EC%84%9C%EB%B2%84/"><span class="tag">웹 서버</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">정보량</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">정보이론</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">클래스 다이어그램</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8F%AC%EC%9B%8C%EB%93%9C-%ED%94%84%EB%A1%9D%EC%8B%9C/"><span class="tag">포워드 프록시</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">함수형 인터페이스</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">함수형 프로그래밍</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">행렬의 곱셈</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>