<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Deep Learning - Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Deep Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-20T14:21:57.000Z" title="7/20/2023, 11:21:57â€¯PM">2023-07-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:53.000Z" title="12/21/2023, 12:32:53â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">21 minutes read (About 3218 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/7%EC%9E%A5-%EA%B8%B0%EC%B4%88-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%A9%EB%B2%95-Gradient-Descent-%ED%8E%B8%EB%AF%B8%EB%B6%84/">7ì¥. ê¸°ì´ˆ ìµœì í™” ë°©ë²• Gradient Descent - í¸ë¯¸ë¶„</a></h1><div class="content"><h2 id="í¸ë¯¸ë¶„"><a href="#í¸ë¯¸ë¶„" class="headerlink" title="í¸ë¯¸ë¶„"></a>í¸ë¯¸ë¶„</h2><h3 id="ë‹¤ë³€ìˆ˜-í•¨ìˆ˜-Multivariation-Function"><a href="#ë‹¤ë³€ìˆ˜-í•¨ìˆ˜-Multivariation-Function" class="headerlink" title="ë‹¤ë³€ìˆ˜ í•¨ìˆ˜(Multivariation Function)"></a>ë‹¤ë³€ìˆ˜ í•¨ìˆ˜(Multivariation Function)</h3><ul>
<li>ì—¬ëŸ¬ ê°œì˜ ë³€ìˆ˜(multivariate)ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” í•¨ìˆ˜<ul>
<li>$z &#x3D; f(x,y)$</li>
<li>$y &#x3D; f(x_1, x_2)$</li>
<li>$x &#x3D; \begin{bmatrix} x_1 \ x_2 \end{bmatrix}$</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2" alt="MultivariateFunction"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2">https://github.com/shchoice/shchoice.github.io/assets/100276387/b827a50c-a2cb-452a-852b-28242a4154f2</a></p>
<h3 id="í¸ë¯¸ë¶„-1"><a href="#í¸ë¯¸ë¶„-1" class="headerlink" title="í¸ë¯¸ë¶„"></a>í¸ë¯¸ë¶„</h3><ul>
<li><p>ë‹¤ë³€ìˆ˜ xì™€ yë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” í•¨ìˆ˜ fë¥¼ xë¡œ ë¯¸ë¶„í•  ê²½ìš°</p>
<ul>
<li>í•˜ë‚˜ì˜ ë³€ìˆ˜ë§Œ ë‚¨ê²¨ ë†“ê³  ë‚˜ë¨¸ì§€ë¥¼ ìƒìˆ˜ ì·¨ê¸‰í•˜ëŠ” ë¯¸ë¶„ ë°©ë²•</li>
</ul>
</li>
<li><p>í•¨ìˆ˜ fë¥¼ xë³€ìˆ˜(xì¶•)ìœ¼ë¡œ ë¯¸ë¶„</p>
<ul>
<li>í¸ë¯¸ë¶„ ê¸°í˜¸ ğœ• (round í˜¹ì€ partial ë¼ê³  ë¶€ë¦„)</li>
</ul>
<p>$\frac{\partial f}{\partial x} &#x3D; \lim_{h \to 0} \frac{f(x+h,y) - f(x,y)}{(x+h) - x}$</p>
</li>
<li><p>Yê°’ì— ëŒ€í•´ ëš ì˜ëì„ ë•Œ xì¶•ì— ëŒ€í•œ ê¸°ìš¸ê¸°</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61" alt="GradientDescent01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61">https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61</a></p>
</li>
</ul>
<h3 id="í•¨ìˆ˜ì˜-ì…ì¶œë ¥-í˜•íƒœ"><a href="#í•¨ìˆ˜ì˜-ì…ì¶œë ¥-í˜•íƒœ" class="headerlink" title="í•¨ìˆ˜ì˜ ì…ì¶œë ¥ í˜•íƒœ"></a>í•¨ìˆ˜ì˜ ì…ì¶œë ¥ í˜•íƒœ</h3><ul>
<li><p>í•¨ìˆ˜ì˜ ì…ë ¥ì´ ë²¡í„°ì¸ ê²½ìš°</p>
<p>$y&#x3D;f(\begin{bmatrix} x_1 \â¦™\x_n \end{bmatrix})&#x3D;f(x), \text{ where } x \in \mathbb{R}^n$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì¶œë ¥ì´ ë²¡í„°ì¸ ê²½ìš° $y&#x3D;f(\begin{bmatrix} y_1 \â¦™\y_n \end{bmatrix})&#x3D;f(x)&#x3D;\begin{bmatrix} f_1(x) \â¦™\f_n(x) \end{bmatrix}, \text{ where } y \in \mathbb{R}^n$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì…ë ¥ì´ í–‰ë ¬ì¸ ê²½ìš°</p>
<p>$y&#x3D;f(\begin{bmatrix} x_{1,1} â‹¯ x_{1,m} \â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ x_{n,1} â‹¯ x_{n,m} \end{bmatrix})&#x3D;f(X), \text{ where } X \in \mathbb{R}^{n \times m}$</p>
</li>
<li><p>í•¨ìˆ˜ì˜ ì¶œë ¥ì´ í–‰ë ¬ì¸ ê²½ìš° $Y&#x3D;f(\begin{bmatrix} y_{1,1} â‹¯ y_{1,m} \â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ y_{n,1} â‹¯ y_{n,m} \end{bmatrix})&#x3D;f(x), \text{ where } Y \in \mathbb{R}^{n \times m}$</p>
</li>
<li><p>ì…ë ¥ê³¼ ì¶œë ¥ì´ ë²¡í„°ì¸ í•¨ìˆ˜</p>
<p>$y&#x3D;f(\begin{bmatrix} y_1 \â¦™\y_n \end{bmatrix})&#x3D;f(x)&#x3D; f(\begin{bmatrix} x_1 \â¦™\x_n \end{bmatrix}), \text{ where } f: \mathbb{R}^n \rightarrow \mathbb{R}^m$</p>
</li>
</ul>
<h3 id="ìŠ¤ì¹¼ë¼ë¥¼-ë²¡í„°ë¡œ-ìŠ¤ì¹¼ë¼ë¥¼-í–‰ë ¬ë¡œ-ë¯¸ë¶„"><a href="#ìŠ¤ì¹¼ë¼ë¥¼-ë²¡í„°ë¡œ-ìŠ¤ì¹¼ë¼ë¥¼-í–‰ë ¬ë¡œ-ë¯¸ë¶„" class="headerlink" title="ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ, ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„"></a>ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ, ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„</h3><ul>
<li>ë¯¸ë¶„ ê²°ê³¼ëŠ” gradient ë²¡í„°ê°€ ë˜ì–´ ë°©í–¥ê³¼ í¬ê¸°ë¥¼ ëª¨ë‘ ë‚˜íƒ€ëƒ„</li>
</ul>
<ol>
<li><p>ìŠ¤ì¹¼ë¼ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</p>
<ul>
<li><p>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„í•œë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸</p>
</li>
<li><p>ê²°ê³¼ëŠ” ë²¡í„°ê°€ ë¨</p>
</li>
<li><p>ê° ë²¡í„°ì˜ ìš”ì†ŒëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í•´ë‹¹ ë°©í–¥ì„ ë¯¸ë¶„í•œ ê²°ê³¼ë¥¼ ë‚˜íƒ€ëƒ„, ì´ê²ƒì„ gradientë¼ê³  ë¶€ë¥´ë©°, í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ ë‚˜íƒ€ë‚˜ëŠ”ë° ì‚¬ìš©</p>
</li>
<li><p>$\frac{\partial f}{\partial x} &#x3D; \nabla_x f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_1} \ â¦™\ \frac{\partial f}{\partial x_n} \end{bmatrix}, \text {where }x \in \mathbb{R}^n$</p>
</li>
<li><p>ì˜ˆì œ</p>
<ul>
<li><p>$f(x,y)&#x3D;3x2+2xy+y2$ ë¼ëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ì™€ ë²¡í„° ë³€ìˆ˜ $x$ ì™€ $y$ ê°€ ìˆìŒ</p>
<ul>
<li><p>ì´ í•¨ìˆ˜ë¥¼ ê° ë³€ìˆ˜ì— ëŒ€í•´ í¸ë¯¸ë¶„ í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŒ</p>
<p>$\frac{\partial f}{\partial x} &#x3D; 6x + 2y$</p>
<p>$\frac{\partial f}{\partial y} &#x3D; 2x + 2y$</p>
</li>
<li><p>ë”°ë¼ì„œ í•¨ìˆ˜ $f(x,y)$ ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ</p>
<p>$\nabla f &#x3D; \left[\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}\right] &#x3D; [6x + 2y, 2x + 2y]$</p>
</li>
<li><p>ì´ ê·¸ë˜ë””ì–¸íŠ¸ ë²¡í„°ëŠ” ê° ì $(x,y)$ì—ì„œ í•¨ìˆ˜ì˜ ê°’ì´ ê°€ì¥ í¬ê²Œ ì¦ê°€í•˜ëŠ” ë°©í–¥ì„ ê°€ë¦¬í‚´, ë”°ë¼ì„œ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” ìµœì í™” ë¬¸ì œì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì—­í• ì„ í•¨ (ìµœì í™” ì•Œê³ ë¦¬ì¦˜ì€ ì¼ë°˜ì ìœ¼ë¡œ ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™í•˜ì—¬ í•¨ìˆ˜ì˜ ìµœì†Œê°’ì„ ì°¾ìŠµë‹ˆë‹¤. ì´ê²ƒì´ ê·¸ë˜ë””ì–¸íŠ¸ ë””ì„¼íŠ¸ ë°©ë²•ì˜ ê¸°ë³¸ ê°œë…)</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ì½”ë“œë¡œ í™•ì¸í•´ë³´ê¸°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sympy <span class="keyword">import</span> symbols, diff</span><br><span class="line"></span><br><span class="line">x, y = symbols(<span class="string">&#x27;x y&#x27;</span>)</span><br><span class="line">f = <span class="number">3</span>*x**<span class="number">2</span> + <span class="number">2</span>*x*y + y**<span class="number">2</span></span><br><span class="line"></span><br><span class="line">df_dx = diff(f, x)  <span class="comment"># xì— ëŒ€í•œ í¸ë¯¸ë¶„</span></span><br><span class="line">df_dy = diff(f, y)  <span class="comment"># yì— ëŒ€í•œ í¸ë¯¸ë¶„</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;df/dx: <span class="subst">&#123;df_dx&#125;</span>&#x27;</span>)    <span class="comment"># df/dx: 6*x + 2*y</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;df/dy: <span class="subst">&#123;df_dy&#125;</span>&#x27;</span>)    <span class="comment"># df/dy: 2*x + 2*y</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì„ì˜ì˜ ì‹œì‘ì </span></span><br><span class="line">x_value = <span class="number">1.0</span></span><br><span class="line">y_value = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># í•™ìŠµë¥ </span></span><br><span class="line">eta = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):  <span class="comment"># 100ë²ˆ ë°˜ë³µ</span></span><br><span class="line">    gradient_x = df_dx.evalf(subs=&#123;x: x_value, y: y_value&#125;)  <span class="comment"># x ìœ„ì¹˜ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</span></span><br><span class="line">    gradient_y = df_dy.evalf(subs=&#123;x: x_value, y: y_value&#125;)  <span class="comment"># y ìœ„ì¹˜ì—ì„œì˜ ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚°</span></span><br><span class="line"></span><br><span class="line">    x_value -= eta * gradient_x     <span class="comment"># ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™</span></span><br><span class="line">    y_value -= eta * gradient_y     <span class="comment"># ê·¸ë˜ë””ì–¸íŠ¸ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì´ë™</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Optimized x: <span class="subst">&#123;x_value&#125;</span>&#x27;</span>)    <span class="comment"># Optimized x: -0.0627121858146143</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;Optimized y: <span class="subst">&#123;y_value&#125;</span>&#x27;</span>)    <span class="comment"># Optimized y: 0.154295508359253</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>ìŠ¤ì¹¼ë¼ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„</p>
<ul>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ ë³€ìˆ˜ì— ëŒ€í•´ ë¯¸ë¶„í•˜ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ„</li>
<li>ê²°ê³¼ëŠ” í–‰ë ¬ì´ ë¨</li>
<li>ì´ í–‰ë ¬ì˜ ê° ìš”ì†ŒëŠ” í•´ë‹¹ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ì˜ í•´ë‹¹ ìš”ì†Œë¡œ í¸ë¯¸ë¶„í•œ ê°’, ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ë¥¼ í–‰ë ¬ë¡œ ë¯¸ë¶„í•œ ê²°ê³¼ëŠ” ìì½”ë¹„ì•ˆ í–‰ë ¬ì´ë¼ê³  ë¶€ë¥´ë©°, ì´ëŠ” í•¨ìˆ˜ì˜ ì§€ì—­ì  ë³€í™”ìœ¨ì„ ë‚˜íƒ€ëƒ„</li>
<li>$\frac{\partial f}{\partial x} &#x3D; \nabla_x f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_{1,1}  } â‹¯ \frac{\partial f}{\partial x_{1,m}} \ â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ \frac{\partial f}{\partial x_{n,1}  } â‹¯ \frac{\partial f}{\partial x_{n,m}} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n \times m}$</li>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ fê°€ í–‰ë ¬ Xì— ì˜ì¡´í•œë‹¤ê³  í•˜ë©´, ì´ í•¨ìˆ˜ë¥¼ í–‰ë ¬ Xì— ëŒ€í•´ ë¯¸ë¶„í•œ ê²°ê³¼ëŠ” í–‰ë ¬ì´ ë¨<ul>
<li>ì´ í–‰ë ¬ì˜ (i, j)ë²ˆì§¸ ìš”ì†ŒëŠ” fë¥¼ Xì˜ (i, j)ë²ˆì§¸ ìš”ì†Œì— ëŒ€í•´ í¸ë¯¸ë¶„í•œ ê°’</li>
<li>ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ fë¥¼ í–‰ë ¬ $X &#x3D; \begin{bmatrix} x_{11} &amp; x_{12} \ x_{21} &amp; x_{22} \end{bmatrix}$ì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í˜•íƒœì˜ í–‰ë ¬ì´ ë‚˜ì˜´<ul>
<li>$\nabla_X f &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_{11}} &amp; \frac{\partial f}{\partial x_{12}} \ \frac{\partial f}{\partial x_{21}} &amp; \frac{\partial f}{\partial x_{22}} \end{bmatrix}$</li>
<li>ì´ë•Œ $\frac{\partial f}{\partial x_{ij}}$ëŠ” í•¨ìˆ˜ fë¥¼ í–‰ë ¬ Xì˜ (i,j)ë²ˆì§¸ ìš”ì†Œì— ëŒ€í•´ í¸ë¯¸ë¶„í•œ ê²ƒìœ¼ë¡œ, ì´ë ‡ê²Œ êµ¬í•´ì§„ í–‰ë ¬ì„ ìì½”ë¹„ì•ˆ í–‰ë ¬(Jacobian matrix) ì´ë¼ê³  í•¨</li>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬ì˜ ê° ìš”ì†ŒëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ê°€ ê° ë³€ìˆ˜ë¥¼ ì¡°ê¸ˆì”© ë³€í™”ì‹œí‚¬ ë•Œ, í•¨ìˆ˜ì˜ ì¶œë ¥ì´ ì–¼ë§ˆë‚˜ ë³€í™”í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ëƒ„, ë”°ë¼ì„œ ìì½”ë¹„ì•ˆ í–‰ë ¬ì€ í•¨ìˆ˜ì˜ ì§€ì—­ì ì¸ ë³€í™”ìœ¨ì„ ì„¤ëª…í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
</li>
<li>ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ì€ ë”¥ëŸ¬ë‹ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ê°œë…<ul>
<li>ì‹ ê²½ë§ì˜ <strong>ê°€ì¤‘ì¹˜ëŠ” ì¼ë°˜ì ìœ¼ë¡œ í–‰ë ¬ í˜•íƒœ</strong>ë¥¼ ê°€ì§€ë©°, ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸(ë¯¸ë¶„ê°’)ë¥¼ ê³„ì‚°í•´ì•¼ í•¨. ì´ ë•Œ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ë°”ë¡œ ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ìœ¼ë¡œ, ì˜¤ì°¨ í•¨ìˆ˜(ìŠ¤ì¹¼ë¼ í•¨ìˆ˜)ë¥¼ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</li>
</ul>
</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>ìŠ¤ì¹¼ë¼, ë²¡í„°, í–‰ë ¬</strong></p>
<ul>
<li><strong>ìŠ¤ì¹¼ë¼</strong>ëŠ” ë‹¨ì¼í•œ ìˆ˜ì¹˜ ê°’ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, 10ì´ë‚˜ 2.5ì™€ ê°™ì€ ë‹¨ì¼ ìˆ«ìë¥¼ ìŠ¤ì¹¼ë¼ë¼ê³  í•©ë‹ˆë‹¤.</li>
<li><strong>ë²¡í„°</strong>ëŠ” ìˆ«ìë“¤ì˜ ë°°ì—´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [1, 2]ì™€ ê°™ì€ 1ì°¨ì› ë°°ì—´ì´ ë²¡í„°ì…ë‹ˆë‹¤.</li>
<li><strong>í–‰ë ¬</strong>ì€ ìˆ«ìë“¤ì˜ 2ì°¨ì› ë°°ì—´ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, [[1, 2], [3, 4]]ì™€ ê°™ì€ 2ì°¨ì› ë°°ì—´ì´ í–‰ë ¬ì…ë‹ˆë‹¤.</li>
</ul>
</blockquote>
<blockquote>
<p><strong>ìì½”ë¹„ì•ˆ í–‰ë ¬, í—¤ì‹œì•ˆ í–‰ë ¬</strong></p>
<ul>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬(Jacobian matrix)<ul>
<li>ìì½”ë¹„ì•ˆ í–‰ë ¬ì€ ë²¡í„° ê°’ì„ ê°€ì§„ í•¨ìˆ˜ë¥¼ ë²¡í„° ë³€ìˆ˜ì— ëŒ€í•´ ë¯¸ë¶„í•  ë•Œ ì‚¬ìš©</li>
<li>í•¨ìˆ˜ì˜ ì…ë ¥ê³¼ ì¶œë ¥ì´ ëª¨ë‘ ë²¡í„°ì¼ ë•Œ, ê° ì…ë ¥ ë³€ìˆ˜ì— ëŒ€í•œ ê° ì¶œë ¥ ë³€ìˆ˜ì˜ í¸ë¯¸ë¶„ì„ í–‰ë ¬ í˜•íƒœë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì´ ìì½”ë¹„ì•ˆ í–‰ë ¬</li>
<li>ì¦‰, ë‹¤ë³€ìˆ˜ ë²¡í„° í•¨ìˆ˜ì˜ ì²« ë²ˆì§¸ ë„í•¨ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.</li>
</ul>
</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬(Hessian matrix)<ul>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì€ ìŠ¤ì¹¼ë¼ ê°’ì„ ê°€ì§„ í•¨ìˆ˜ë¥¼ í–‰ë ¬ ë³€ìˆ˜ì— ëŒ€í•´ ë‘ ë²ˆ ë¯¸ë¶„í•  ë•Œ ì‚¬ìš©</li>
<li>ì¦‰, í•¨ìˆ˜ì˜ ë‘ ë²ˆì§¸ ë„í•¨ìˆ˜(2ì°¨ ë¯¸ë¶„)ë¥¼ ë‚˜íƒ€ëƒ„</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì˜ ê° ì„±ë¶„ì€ ì›ë˜ í•¨ìˆ˜ì˜ ë‘ ë³€ìˆ˜ì— ëŒ€í•œ ë‘ ë²ˆì§¸ í¸ë¯¸ë¶„</li>
<li>í—¤ì‹œì•ˆ í–‰ë ¬ì€ ì£¼ë¡œ í•¨ìˆ˜ì˜ ê³¡ë¥ , ì¦‰ ìµœì†Ÿê°’, ìµœëŒ“ê°’, ë˜ëŠ” ì•ˆì¥ì (saddle point) ë“±ì„ íŒë³„í•˜ëŠ” ë° ì‚¬ìš©ë¨</li>
</ul>
</li>
</ul>
<p>ë”°ë¼ì„œ, ìì½”ë¹„ì•ˆì€ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°(1ì°¨ ë„í•¨ìˆ˜)ë¥¼, í—¤ì‹œì•ˆì€ ê³¡ë¥ (2ì°¨ ë„í•¨ìˆ˜)ì„ ë‚˜íƒ€ë‚´ë©°, ë‘ í–‰ë ¬ ëª¨ë‘ í•¨ìˆ˜ì˜ ì§€ì—­ì ì¸ ë™ì‘ì„ ì´í•´í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•¨</p>
</blockquote>
<h3 id="Gradient"><a href="#Gradient" class="headerlink" title="Gradient"></a>Gradient</h3><ul>
<li><p>ìƒë¯¸ë¶„ê³¼ ë‹¬ë¦¬ ë¯¸ë¶„ ê²°ê³¼ê°€ ë²¡í„°</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61" alt="GradientDescent01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61">https://github.com/shchoice/shchoice.github.io/assets/100276387/858207a4-1764-44d8-aff9-b66fb1d7ed61</a></p>
<p>$\nabla f(x,y) &#x3D; \begin{bmatrix} 2x+y \ x+3y^2 +10y\end{bmatrix} &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x} \ \frac{\partial f}{\partial y} \end{bmatrix}$</p>
</li>
</ul>
<h3 id="ë²¡í„°ë¥¼-ìŠ¤ì¹¼ë¼ë¡œ-ë²¡í„°ë¥¼-ë²¡í„°ë¡œ-ë¯¸ë¶„"><a href="#ë²¡í„°ë¥¼-ìŠ¤ì¹¼ë¼ë¡œ-ë²¡í„°ë¥¼-ë²¡í„°ë¡œ-ë¯¸ë¶„" class="headerlink" title="ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ, ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„"></a>ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ, ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</h3><ol>
<li><p>ë²¡í„°ë¥¼ ìŠ¤ì¹¼ë¼ë¡œ ë¯¸ë¶„</p>
<p>$\frac{\partial f}{\partial x} &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x}, â€¦ \text { }, \frac{\partial f_n}{\partial x} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n}$</p>
</li>
<li><p>ë²¡í„°ë¥¼ ë²¡í„°ë¡œ ë¯¸ë¶„</p>
<p>$\frac{\partial f}{\partial x} &#x3D; \begin{bmatrix} \frac{\partial f}{\partial x_1} \ â¦™ \ \frac{\partial f}{\partial x_n} \end{bmatrix} &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x}, â€¦ \text { }, \frac{\partial f_m}{\partial x} \end{bmatrix}  &#x3D; \begin{bmatrix} \frac{\partial f_1}{\partial x_{1}  } â‹¯ \frac{\partial f_m}{\partial x_{1}} \ â¦™ \text{ }\text{ }  â‹± \text{ }\text{ } â¦™ \ \frac{\partial f_1}{\partial x_{n}  } â‹¯ \frac{\partial f_m}{\partial x_{n}} \end{bmatrix}, \text {where }x \in \mathbb{R}^{n}\text{ } and\text{ } f(x) \in \mathbb{R}^m$</p>
</li>
</ol>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•˜ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•˜ê¸°</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>]]).requires_grad_(<span class="literal">True</span>)</span><br><span class="line">x1 = x + <span class="number">2</span></span><br><span class="line">x2 = x - <span class="number">2</span></span><br><span class="line">x3 = x1 * x2</span><br><span class="line">y = x3.<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x1)</span><br><span class="line"><span class="comment">#tensor([[3., 4.],</span></span><br><span class="line"><span class="comment">#       [5., 6.]], grad_fn=&lt;AddBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x2)</span><br><span class="line"><span class="comment"># tensor([[-1.,  0.],</span></span><br><span class="line"><span class="comment">#         [ 1.,  2.]], grad_fn=&lt;SubBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(x3)</span><br><span class="line"><span class="comment"># tensor([[-3.,  0.],</span></span><br><span class="line"><span class="comment">#        [ 5., 12.]], grad_fn=&lt;MulBackward0&gt;)</span></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"><span class="comment"># tensor(14., grad_fn=&lt;SumBackward0&gt;)</span></span><br><span class="line"></span><br><span class="line">y.backward() <span class="comment"># ìŠ¤ì¹¼ë¼ì—¬ì•¼ë§Œ ë¯¸ë¶„ ê°€ëŠ¥í•˜ë‹¤. ìŠ¤ì¹¼ë¼ ì•„ë‹ˆë©´ ì—ëŸ¬ ë°˜í™˜ # grequired_grad_(True) ëŠ” ë‹¤ ë¯¸ë¶„</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">.backward() ë©”ì„œë“œëŠ” PyTorchì—ì„œ ì œê³µí•˜ëŠ” ìë™ ë¯¸ë¶„ ê¸°ëŠ¥ìœ¼ë¡œ, ì‹¤ì œë¡œëŠ” ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ì— ëŒ€í•œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ë©°</span></span><br><span class="line"><span class="string">íŒŒì´í† ì¹˜ì˜ ê³„ì‚° ê·¸ë˜í”„(computation graph)ì˜ íŠ¹ì„±ì—ì„œ ë¹„ë¡¯ë¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ë˜ì„œ y.backward()ì—ì„œ yëŠ” ë³´í†µ ìŠ¤ì¹¼ë¼(scalar)ê°€ ë¨</span></span><br><span class="line"><span class="string">ê·¸ ì´ìœ ëŠ” ìš°ë¦¬ê°€ ê´€ì‹¬ì„ ê°–ëŠ” ëŒ€ìƒì´ ë³´í†µ ì†ì‹¤ í•¨ìˆ˜(loss function)ì´ê¸° ë•Œë¬¸ì´ê³ , ì´ëŠ” ìŠ¤ì¹¼ë¼ ê°’ì„ ë°˜í™˜</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ°ë° ë§Œì•½ yê°€ ë²¡í„°ë‚˜ í–‰ë ¬ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ í…ì„œë¼ë©´? </span></span><br><span class="line"><span class="string">ì´ ê²½ìš°ì—ë„ .backward() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ì´ë¥¼ ìœ„í•´ì„œëŠ” ì¸ìë¡œ ë²¡í„°ë¥¼ ì œê³µí•´ì•¼ í•¨ </span></span><br><span class="line"><span class="string">ì´ ë²¡í„°ëŠ” yì˜ ê° ìš”ì†Œì— ëŒ€í•œ ê°€ì¤‘ì¹˜ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì´ë¥¼ í†µí•´ ìŠ¤ì¹¼ë¼ ê°’ì„ ì–»ì„ ìˆ˜ ìˆìŒ</span></span><br><span class="line"><span class="string">ì˜ˆì‹œ) v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)  # ê°€ì¤‘ì¹˜ ë²¡í„°, y.backward(v)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ì´ëŸ° ë³µì¡ì„± ë•Œë¬¸ì— ëŒ€ë¶€ë¶„ì˜ ê²½ìš°, .backward()ëŠ” ì†ì‹¤ ê°’ê³¼ ê°™ì€ ìŠ¤ì¹¼ë¼ í…ì„œì— ëŒ€í•´ì„œë§Œ í˜¸ì¶œë˜ë©°, </span></span><br><span class="line"><span class="string">ì´ëŠ” ê° íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚° </span></span><br><span class="line"><span class="string">ì´ ê·¸ë˜ë””ì–¸íŠ¸ëŠ” íŒŒë¼ë¯¸í„°ì˜ .grad ì†ì„±ì— ì €ì¥ë˜ë©°, ì´ë¥¼ ì‚¬ìš©í•´ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.grad)</span><br><span class="line"><span class="comment"># tensor([[2., 4.],</span></span><br><span class="line"><span class="comment">#        [6., 8.]])</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">print(x3.numpy())</span></span><br><span class="line"><span class="string"># RuntimeError: Can&#x27;t call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.</span></span><br><span class="line"><span class="string">print(x3.detach_().numpy())</span></span><br><span class="line"><span class="string"># array([[-3.,  0.],</span></span><br><span class="line"><span class="string">#       [ 5., 12.]], dtype=float32)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">PyTorchì—ì„œ í…ì„œëŠ” ê¸°ë³¸ì ìœ¼ë¡œ requires_grad ì†ì„±ì´ Falseë¡œ ì„¤ì •ë˜ë‚˜, </span></span><br><span class="line"><span class="string">ì´ ì†ì„±ì´ Trueë¡œ ì„¤ì •ë˜ë©´, </span></span><br><span class="line"><span class="string">í•´ë‹¹ í…ì„œì— ì—°ì‚°ì´ ìˆ˜í–‰ë  ë•Œë§ˆë‹¤ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•˜ëŠ” ê³„ì‚° ê·¸ë˜í”„ì— ì´ ì •ë³´ê°€ ì¶”ê°€ë¨</span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—­ì „íŒŒ(backpropagation) ë‹¨ê³„ì—ì„œ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆê²Œë¨.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ê·¸ëŸ¬ë‚˜ requires_gradê°€ Trueì¸ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ì§ì ‘ ë³€í™˜í•  ìˆ˜ ì—†ìŒ. </span></span><br><span class="line"><span class="string">ì´ëŠ” PyTorchì˜ ê³„ì‚° ê·¸ë˜í”„ì™€ Numpyê°€ ì„œë¡œ í˜¸í™˜ë˜ì§€ ì•Šê¸° ë•Œë¬¸. </span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ requires_gradê°€ Trueì¸ í…ì„œë¥¼ Numpy ë°°ì—´ë¡œ ë³€í™˜í•˜ë ¤ë©´ ë¨¼ì € detach() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬</span></span><br><span class="line"><span class="string"> ê³„ì‚° ê·¸ë˜í”„ì—ì„œ í•´ë‹¹ í…ì„œë¥¼ ë¶„ë¦¬í•œ í›„ ë³€í™˜í•´ì•¼ í•¨</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">ë”°ë¼ì„œ ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ì œì•ˆí•˜ëŠ” ê²ƒì²˜ëŸ¼, x3.detach().numpy()ë¥¼ ì‚¬ìš©í•˜ë©´ x3ë¥¼ Numpy ë°°ì—´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜í•  ìˆ˜ ìˆìŒ. </span></span><br><span class="line"><span class="string">ì´ë ‡ê²Œ í•˜ë©´ x3ì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ í•„ìš”í•˜ì§€ ì•Šì€ ìƒˆë¡œìš´ í…ì„œê°€ ìƒì„±ë˜ê³ , ì´ í…ì„œëŠ” Numpy ë°°ì—´ë¡œ ë³€í™˜ë  ìˆ˜ ìˆìŒ.</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="Why-we-laern-this"><a href="#Why-we-laern-this" class="headerlink" title="Why we laern this?"></a>Why we laern this?</h3><ul>
<li><p>Loss í•¨ìˆ˜ ê²°ê³¼ê°’ì¸ ìŠ¤ì¹¼ë¼ í˜ìˆ˜ë¥¼ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ë¡œ ë¯¸ë¶„í•´ì•¼ í•œë‹¤ë©´?</p>
</li>
<li><p>DNNì˜ ì¤‘ê°„ ê²°ê³¼ë¬¼ ë²¡í„°(â„)ë¥¼ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ë¡œ ë¯¸ë¶„í•´ì•¼ í•œë‹¤ë©´?</p>
<p>ë”¥ëŸ¬ë‹ì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜(íŒŒë¼ë¯¸í„°)ê°€ í–‰ë ¬ í˜•íƒœë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ì´ëŸ¬í•œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ê·¸ë˜ë””ì–¸íŠ¸(ë¯¸ë¶„ê°’)ë¥¼ ê³„ì‚°í•´ì•¼ í•©ë‹ˆë‹¤. ì´ ë•Œ ì‚¬ìš©ë˜ëŠ” ê²ƒì´ ë°”ë¡œ ìŠ¤ì¹¼ë¼-í–‰ë ¬ ë¯¸ë¶„ìœ¼ë¡œ, ì†ì‹¤ í•¨ìˆ˜(ìŠ¤ì¹¼ë¼ í•¨ìˆ˜)ë¥¼ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë˜í•œ, DNNì—ì„œëŠ” ê° ë ˆì´ì–´ì˜ ì…ë ¥(ì¤‘ê°„ ê²°ê³¼ ê°’)ì„ ê°€ì¤‘ì¹˜ í–‰ë ¬ì— ëŒ€í•´ ë¯¸ë¶„í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ëŸ¬í•œ ë¯¸ë¶„ ê°œë…ì„ ì´í•´í•˜ëŠ” ê²ƒì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ ì´í•´í•˜ê³  ìµœì í™”í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, ì´ëŸ¬í•œ ì´ìœ ë“¤ë¡œ ì¸í•´ íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ì— ëŒ€í•œ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜, ì¦‰ ì†ì‹¤ í•¨ìˆ˜ì˜ ê²°ê³¼ ê°’ì„ ë¯¸ë¶„í•˜ê±°ë‚˜, íŒŒë¼ë¯¸í„° í–‰ë ¬(ğœƒ)ì— ëŒ€í•œ ì¤‘ê°„ ê²°ê³¼ ê°’ ë²¡í„° (â„)ë¥¼ ë¯¸ë¶„í•˜ëŠ” ê°œë…ì„ ë°°ìš°ëŠ” ê²ƒì´ ë”¥ëŸ¬ë‹ì—ì„œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-19T14:56:59.000Z" title="7/19/2023, 11:56:59â€¯PM">2023-07-19</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:43.000Z" title="12/21/2023, 12:32:43â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">5 minutes read (About 713 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/6%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%B4-%EC%9E%98-%ED%95%99%EC%8A%B5%EB%90%98%EB%8A%94%EC%A7%80-%ED%8C%90%EB%8B%A8%ED%95%98%EA%B8%B0-Loss-Function/">6ì¥. ì‹ ê²½ë§ì´ ì˜ í•™ìŠµë˜ëŠ”ì§€ íŒë‹¨í•˜ê¸° - Loss Function</a></h1><div class="content"><h2 id="Again-Our-object-is"><a href="#Again-Our-object-is" class="headerlink" title="Again, Our object is"></a>Again, Our object is</h2><ul>
<li>ë°ì´í„°ë¥¼ ë„£ì—ˆì„ ë•Œ ì¶œë ¥ì„ ë°˜í™˜í•˜ëŠ” ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ëŠ” ê²ƒ</li>
<li>Linear Layer í•¨ìˆ˜ë¥¼ í†µí•´ ì›í•˜ëŠ” í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•´ë³´ì<ul>
<li>Linear Layer í•¨ìˆ˜ê°€ ì–¼ë§ˆë‚˜ ì›í•˜ëŠ” ë§Œí¼ ë™ì‘í•˜ëŠ”ì§€ ì¸¡ì •í•´ ë³´ì</li>
<li>ì–¼ë§ˆë‚˜ ì˜ ë™ì‘í•˜ëŠ”ì§€, ì ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ë³´ì</li>
</ul>
</li>
</ul>
<h2 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h2><ul>
<li>Loss(ì†ì‹¤ê°’): ì›í•˜ëŠ” ì¶œë ¥ê°’(target,ğ‘¦)ê°€ ì‹¤ì œ ì¶œë ¥ê°’(output, $\hat{y}$)ì˜ ì°¨ì´ì˜ í•©<ul>
<li>$\text{Loss} &#x3D; \sum_{i&#x3D;1}^{N} | y_i - \hat{y}<em>i | &#x3D; \sum</em>{i&#x3D;1}^{N} | y_i - f(x_i) |$</li>
</ul>
</li>
<li>ê·¸ëŸ¬ë¯€ë¡œ ìš°ë¦¬ëŠ” Lossê°€ ì‘ì„ìˆ˜ë¡ ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ì˜ ëª¨ì‚¬í•˜ê³  ìˆë‹¤ê³  í•  ìˆ˜ ìˆìŒ</li>
<li>Lossê°€ ì‘ì€ Linear Layerë¥¼ ì„ íƒí•˜ë©´ ë¨</li>
</ul>
<h2 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h2><ul>
<li><p>Linear Layerì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°”ê¿€ ë•Œë§ˆë‹¤ Lossë¥¼ ê³„ì‚°</p>
</li>
<li><p>Loss Function</p>
<ul>
<li>ì…ë ¥ : Linear Layerì˜ íŒŒë¼ë¯¸í„°(ğœƒ, ì¦‰, ğ‘Š,ğ‘ê°€ íŒŒë¼ë¯¸í„°)</li>
<li>ì¶œë ¥ : Looss<ul>
<li>ğ¿(ğœƒ)&#x3D;$\sum_{i&#x3D;1}^{n} | y_i - f_{\theta}(x_j) |, \text{ where } \theta &#x3D; {W, b}$</li>
</ul>
</li>
</ul>
</li>
<li><p>ì¢…ë¥˜</p>
<ul>
<li><p>Euclidean Distance</p>
<ul>
<li><p>$| y - \hat{y} |_2 (L2) &#x3D; \sqrt{(y_1 - \hat{y}_1)^2 + \ldots + (y_n - \hat{y}</p>
<p>n)^2} &#x3D; \sqrt{\sum</p>
<p>{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2}, \text{ where } y \in \mathbb{R}^n \text{ and } \hat{y} \in \mathbb{R}^n$</p>
<ul>
<li><strong>ë”¥ëŸ¬ë‹ì€ ì°¨ì›ì œì•½ì´ ì—†ì–´ì„œ ê³ ì°¨ì›ìœ¼ë¡œ ê°€ë©´ ì°¨ì´ê°€ êµ‰ì¥íˆ ì»¤ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— RMSE ê°€ ë“±ì¥</strong></li>
<li>cf) $| y - \hat{y} | : L1$, ì ˆëŒ€ê°’</li>
</ul>
</li>
</ul>
</li>
<li><p>RMSE(Root Mean Square Error)</p>
<ul>
<li>Euclidean Distanceì™€ ë¹„ìŠ·í•œ ê°œë…</li>
<li>$\text{RMSE}(y, \hat{y}) &#x3D; \sqrt{\frac{1}{n} \sum_{i&#x3D;1}^{n} (y_i - \hat{y}_i)^2}$</li>
</ul>
</li>
<li><p>&#96;&#96;&#96;<br>MSE</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">    (Mean Square Error)</span><br><span class="line"></span><br><span class="line">    - $\text&#123;MSE&#125;(y, \hat&#123;y&#125;) = \frac&#123;1&#125;&#123;n&#125; \sum_&#123;i=1&#125;^&#123;n&#125; (y_i - \hat&#123;y&#125;_i)^2 = \frac&#123;1&#125;&#123;n&#125;(\| y - \hat&#123;y&#125; \|_2)^2 = \frac&#123;1&#125;&#123;n&#125;\| y - \hat&#123;y&#125; \|_2^2 âˆ \| y - \hat&#123;y&#125; \|_2^2$</span><br><span class="line">    - Rootì™€ ìƒìˆ˜ë¥¼ ëºì§€ë§Œ í¬ê¸° ì°¨ì´ë¡œ ì¸í•œ ìˆœì„œ ê²°ê³¼ëŠ” ë°”ë€Œì§€ ì•ŠìŒ</span><br><span class="line">    - **ì†ì‹¤í•¨ìˆ˜ë¡œ ê°€ì¥ ë§ì´ ì‚¬ìš©**</span><br><span class="line"></span><br><span class="line">## ì½”ë“œ êµ¬í˜„í•˜ê¸°</span><br><span class="line"></span><br><span class="line">- Loss Function ì˜ˆì œ (1) â€“ ì§ì ‘ êµ¬í˜„í•˜ê¸°</span><br><span class="line"></span><br><span class="line">  ```python</span><br><span class="line">  import torch</span><br><span class="line">  import torch.nn as nn</span><br><span class="line">  </span><br><span class="line">  def mse(x_hat, x):</span><br><span class="line">      # |x_hat| = (batch_size, dim)</span><br><span class="line">      # |x| = (batch_size, dim)</span><br><span class="line">      y = ((x - x_hat)**2).mean()</span><br><span class="line">      </span><br><span class="line">      return y</span><br><span class="line">  </span><br><span class="line">  x = torch.FloatTensor([[1, 1],</span><br><span class="line">                         [2, 2]])</span><br><span class="line">  x_hat = torch.FloatTensor([[0, 0],</span><br><span class="line">                             [0, 0]])</span><br><span class="line">  </span><br><span class="line">  print(x.size(), x_hat.size()) # torch.Size([2, 2]) torch.Size([2, 2])</span><br><span class="line">  mse(x_hat, x) # tensor(2.5000)</span><br></pre></td></tr></table></figure></li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83" alt="LossFunction"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83">https://github.com/shchoice/shchoice.github.io/assets/100276387/c6689fb1-d9b7-4b33-a090-3474b05d1c83</a></p>
</li>
<li><p>Loss Function ì˜ˆì œ (2) â€“ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>]])</span><br><span class="line">x_hat = torch.FloatTensor([[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">                           [<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(x.size(), x_hat.size()) <span class="comment"># torch.Size([2, 2]) torch.Size([2, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x)) <span class="comment"># tensor(2.5000)</span></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x, reduction=<span class="string">&#x27;sum&#x27;</span>)) <span class="comment"># tensor(10.)</span></span><br><span class="line"><span class="built_in">print</span>(F.mse_loss(x_hat, x, reduction=<span class="string">&#x27;none&#x27;</span>)) <span class="comment"># tensor([[1., 1.], [4., 4.]])</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Loss Function ì˜ˆì œ (3) â€“ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">mse_loss = nn.MSELoss()</span><br><span class="line"><span class="built_in">print</span>(mse_loss(x_hat, x)) <span class="comment"># tensor(2.5000)</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h2><ul>
<li>ìš°ë¦¬ëŠ” ëª©í‘œë¡œ í•˜ëŠ” í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ê¸° ìœ„í•´<ul>
<li>í•™ìŠµìš© ì…ë ¥ ë°ì´í„°ë“¤ì„ Linear Layerì— ë„£ì–´ ì¶œë ¥ ê°’ë“¤ì„ êµ¬í•˜ê³ </li>
<li>ì¶œë ¥ê°’($\hat{y}$)ë“¤ê³¼ ëª©í‘œê°’(${y}$)ë“¤ì˜ ì°¨ì´ì˜ í•©(Loss)ë¥¼ ìµœì†Œí™” í•´ì•¼í•¨</li>
</ul>
</li>
<li>ê²°êµ­, Linear Layer íŒŒë¼ë¯¸í„°(ğœƒ)ë¥¼ ë°”ê¾¸ë©´ì„œ lossë¥¼ ìµœì†Œí™” í•´ì•¼í•¨</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-18T14:54:12.000Z" title="7/18/2023, 11:54:12â€¯PM">2023-07-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:43.000Z" title="12/21/2023, 12:32:43â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">10 minutes read (About 1494 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/5%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-Linear-Layer-1/">5ì¥. ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì‚´í´ë³´ê¸° - Linear Layer</a></h1><div class="content"><h2 id="ëª©í‘œ"><a href="#ëª©í‘œ" class="headerlink" title="ëª©í‘œ"></a>ëª©í‘œ</h2><p>ìš°ë¦¬ëŠ” ë‹¤ìŒì˜ ì´ë¯¸ì§€ë¥¼ í†µí•´ 3ì´ë¼ê³  ë¨¸ë¦¬ê°€ ì¸ì‹í•˜ì§€ë§Œ, ì»´í“¨í„°ê°€ ì–´ë–»ê²Œ ì´ ì´ë¯¸ì§€ë¥¼ 3ìœ¼ë¡œ ê·¼ì‚¬í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì•¼í•œë‹¤</p>
<p>ìš°ë¦¬ëŠ” $f^*$(f optimal)ì„ ëª¨ì‚¬í•˜ëŠ” ìµœì ì˜ $\hat{f}$ (f hat)ì„ ì°¾ì•„ì•¼í•œë‹¤</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d" alt="DigitMnist"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d">https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d</a></p>
<h3 id="Linear-Layer-ë€"><a href="#Linear-Layer-ë€" class="headerlink" title="Linear Layer ë€"></a>Linear Layer ë€</h3><ul>
<li><code>ì‹ ê²½ë§ì˜ ê°€ì¥ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ</code>, ë”¥ëŸ¬ë‹ì„ í†µí•´ ëª¨ì‚¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ë•Œ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ê²ƒì´ Linear Layer</li>
<li>Fully-connected(FC) Layer ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•¨<ul>
<li>ì…ë ¥ì˜ ëª¨ë“  ë…¸ë“œëŠ” ì¶œë ¥ì˜ ëª¨ë“  ë…¸ë“œì™€ ì»¨ë„¥ì…˜ì´ ìˆìŒ</li>
<li>Dense Layer ë¼ê³ ë„ ë¶ˆë¦¬ê¸°ë„ í•¨</li>
</ul>
</li>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜<ul>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì°¾ì•„ë‚´ë©´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì¶œë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942">https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942</a></p>
<h3 id="Linear-Layer-ë™ì‘ë°©ì‹"><a href="#Linear-Layer-ë™ì‘ë°©ì‹" class="headerlink" title="Linear Layer ë™ì‘ë°©ì‹"></a>Linear Layer ë™ì‘ë°©ì‹</h3><ul>
<li>ê° ì…ë ¥ ë…¸ë“œë“¤ì— weight(ê°€ì¤‘ì¹˜)ë¥¼ ê³±í•˜ê³  ëª¨ë‘ í•©ì¹œ ë’¤, bias(í¸í–¥)ì„ ë”í•¨</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ed702032-9ad9-491c-b1cd-481a7a412907" alt="FCLayer02"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/ed702032-9ad9-491c-b1cd-481a7a412907">https://github.com/shchoice/shchoice.github.io/assets/100276387/ed702032-9ad9-491c-b1cd-481a7a412907</a></p>
<ul>
<li>|ğœƒ|&#x3D;(18,) , &#x2F;&#x2F; 18ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆìŒ! ğ‘Š &#x3D; 5x3 &#x3D;15, ğ‘ &#x3D; 3</li>
</ul>
<h3 id="Linear-Layer-Equations"><a href="#Linear-Layer-Equations" class="headerlink" title="Linear Layer Equations"></a>Linear Layer Equations</h3><ul>
<li><p><strong>í–‰ë ¬ ê³±ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥</strong></p>
</li>
<li><p>nì°¨ì›ì—ì„œ mì°¨ì›ìœ¼ë¡œì˜ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ì„ í˜• ë³€í™˜ í•¨ìˆ˜</span><br></pre></td></tr></table></figure>

<ul>
<li>$x \in R^{k \times n}, w \in R^{n \times m} \rightarrow y \in R^{k \times m}$</li>
<li>$y &#x3D; f(k) &#x3D; x \cdot w + b$</li>
</ul>
</li>
<li><p>ê°™ì€ í‘œí˜„</p>
<ul>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ì— ê´€ê³„ì—†ì´ ë‹¨ìˆœíˆ ë²¡í„°ë¡œ ë³¼ ê²½ìš° : (m,n) x (n,1) &#x3D; (m,1)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; W^T \cdot x + b$</p>
<p>$\text{ where } x \in \mathbb{R}^n, W^T \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m \text{ and } y \in \mathbb{R}^m$</p>
</li>
</ul>
</li>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜(Nê°œ) í…ì„œë¡œ í‘œí˜„í•  ê²½ìš° : (N,n) x (n,m) &#x3D; (N,m)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; x \cdot W + b$</p>
<p>$\text{ where } x \in \mathbb{R}^{k \times n}, W \in \mathbb{R}^{n \times m}, b \in \mathbb{R}^{n \times m} \text{ and } y \in \mathbb{R}^{n \times m}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942">https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942</a></p>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°</h3><ul>
<li><p>parameter ì •ë³´ í™•ì¸ ì˜ˆì œ</p>
<ul>
<li>gradientì— ê´€í•´ì„œëŠ” ë‹¤ìŒ gradient descent íŒŒíŠ¸ì—ì„œ ë‹¤ë£¸</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># ê°„ë‹¨í•œ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì •ì˜</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)  <span class="comment"># 10ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 5ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">5</span>, <span class="number">1</span>)  <span class="comment"># 5ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 1ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ ê°ì²´ë¥¼ ìƒì„±</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì…ë ¥ ë°ì´í„°</span></span><br><span class="line">input_data = torch.FloatTensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>, <span class="number">10.0</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;input_data : <span class="subst">&#123;input_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># input_data : tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ì„ í†µí•´ ì…ë ¥ ë°ì´í„°ë¥¼ ì „ë‹¬</span></span><br><span class="line">output_data = model(input_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;output: <span class="subst">&#123;output_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># output: tensor([[2.3264]], grad_fn=&lt;AddmmBackward&gt;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.data: <span class="subst">&#123;param.data&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.data: tensor([[-0.2895, -0.1230,  0.1624,  0.0381,  0.2252,  0.2265, -0.1498,  0.0806, -0.1704,  0.2421],</span></span><br><span class="line"><span class="string">        [-0.1162,  0.0786, -0.1140,  0.0178,  0.0470,  0.2920,  0.2933,  0.2919, 0.0493, -0.0025],</span></span><br><span class="line"><span class="string">        [ 0.0196,  0.0492, -0.2049,  0.1628, -0.1038,  0.1221,  0.0516, -0.1309, -0.2128, -0.3086],</span></span><br><span class="line"><span class="string">        [ 0.0129,  0.1872, -0.1641,  0.0406,  0.1779,  0.1346, -0.1623,  0.1618, 0.0410, -0.1538],</span></span><br><span class="line"><span class="string">        [ 0.1166, -0.0591,  0.0349, -0.0866,  0.2066, -0.0777,  0.3119, -0.1021, -0.2297,  0.2657]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.data: tensor([ 0.0787, -0.0037, -0.2033,  0.0398, -0.1233])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.data: tensor([[0.0168, 0.2259, 0.2410, 0.0145, 0.2553]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.data: tensor([0.2295])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Gradient ê³„ì‚°ì„ ìœ„í•œ ëœë¤ íƒ€ê¹ƒ ê°’ ìƒì„±</span></span><br><span class="line">target = torch.FloatTensor([<span class="number">0.5</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;target <span class="subst">&#123;target&#125;</span>&quot;</span>) <span class="comment"># target tensor([[0.5000]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ í•¨ìˆ˜ë¡œ í‰ê·  ì œê³± ì˜¤ì°¨ë¥¼ ì‚¬ìš©</span></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ ê³„ì‚°</span></span><br><span class="line">loss = loss_fn(output_data, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•˜ì—¬ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì˜ ê·¸ë¼ë””ì–¸íŠ¸ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.grad: <span class="subst">&#123;param.grad&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.grad: tensor([[0.0614, 0.1229, 0.1843, 0.2458, 0.3072, 0.3687, 0.4301, 0.4915, 0.5530, 0.6144],</span></span><br><span class="line"><span class="string">        [0.8253, 1.6507, 2.4760, 3.3013, 4.1267, 4.9520, 5.7774, 6.6027, 7.4280, 8.2534],</span></span><br><span class="line"><span class="string">        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">        [0.0529, 0.1057, 0.1586, 0.2114, 0.2643, 0.3171, 0.3700, 0.4228, 0.4757, 0.5285],</span></span><br><span class="line"><span class="string">        [0.9324, 1.8648, 2.7972, 3.7296, 4.6621, 5.5945, 6.5269, 7.4593, 8.3917, 9.3241]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.grad: tensor([0.0614, 0.8253, 0.0000, 0.0529, 0.9324])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.grad: tensor([[11.5118, 23.9645,  0.0000,  2.8603,  7.8742]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.grad: tensor([3.6528])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (1) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">W = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">b = torch.FloatTensor([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(W.size()) <span class="comment"># torch.Size([3, 2])</span></span><br><span class="line"><span class="built_in">print</span>(b.size()) <span class="comment"># torch.Size([2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear</span>(<span class="params">x, W, b</span>):</span><br><span class="line">    y = torch.matmul(x, W) + b</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x, W, b)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (2) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))</span><br><span class="line">        self.b = nn.Parameter(torch.FloatTensor(output_dim))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = torch.matmul(x, self.W) + self.b</span><br><span class="line">        <span class="comment"># |y| = (batch_size, input_dim) * (input_dim, output_dim)</span></span><br><span class="line">        <span class="comment">#     = (batch_size, output_dim)        </span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-3.7895e+32,  7.2868e-43],</span></span><br><span class="line"><span class="string">        [ 2.8026e-45,  0.0000e+00],</span></span><br><span class="line"><span class="string">        [-3.7896e+32,  7.2868e-43]], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (3) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">linear = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.4061,  0.0483,  0.0804],</span></span><br><span class="line"><span class="string">        [ 0.0581,  0.0730,  0.4323]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.4551, 0.4209], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (4) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.linear = nn.Linear(input_dim, output_dim)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="comment"># |y| = (batch_size, output_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.1267,  0.0563,  0.3951],</span></span><br><span class="line"><span class="string">        [ 0.2291,  0.3214,  0.2595]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.3659, 0.4013], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Linear Layer ëŠ” ì„ í˜• í•¨ìˆ˜</li>
<li>ë‚´ë¶€ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°(weight parameter) ğ‘Šì™€ ğ‘ì— ì˜í•´ ì •ì˜ë¨</li>
<li>ìš°ë¦° ì´ í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì¡°ì ˆí•˜ë©´, ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ì›í•˜ëŠ” ì¶œë ¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-16T15:05:57.000Z" title="7/17/2023, 12:05:57â€¯AM">2023-07-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:43.000Z" title="12/21/2023, 12:32:43â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">10 minutes read (About 1436 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/5%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-Linear-Layer/">5ì¥. ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì‚´í´ë³´ê¸° - Linear Layer</a></h1><div class="content"><h2 id="ëª©í‘œ"><a href="#ëª©í‘œ" class="headerlink" title="ëª©í‘œ"></a>ëª©í‘œ</h2><p>ìš°ë¦¬ëŠ” ë‹¤ìŒì˜ ì´ë¯¸ì§€ë¥¼ í†µí•´ 3ì´ë¼ê³  ë¨¸ë¦¬ê°€ ì¸ì‹í•˜ì§€ë§Œ, ì»´í“¨í„°ê°€ ì–´ë–»ê²Œ ì´ ì´ë¯¸ì§€ë¥¼ 3ìœ¼ë¡œ ê·¼ì‚¬í•˜ë„ë¡ í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì•¼í•œë‹¤</p>
<p>ìš°ë¦¬ëŠ” $f^*$(f optimal)ì„ ëª¨ì‚¬í•˜ëŠ” ìµœì ì˜ $\hat{f}$ (f hat)ì„ ì°¾ì•„ì•¼í•œë‹¤</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d" alt="DigitMnist"></p>
<h3 id="Linear-Layer-ë€"><a href="#Linear-Layer-ë€" class="headerlink" title="Linear Layer ë€"></a>Linear Layer ë€</h3><ul>
<li><code>ì‹ ê²½ë§ì˜ ê°€ì¥ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ</code>, ë”¥ëŸ¬ë‹ì„ í†µí•´ ëª¨ì‚¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ë•Œ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ê²ƒì´ Linear Layer</li>
<li>Fully-connected(FC) Layer ë¼ê³  ë¶ˆë¦¬ê¸°ë„ í•¨<ul>
<li>ì…ë ¥ì˜ ëª¨ë“  ë…¸ë“œëŠ” ì¶œë ¥ì˜ ëª¨ë“  ë…¸ë“œì™€ ì»¨ë„¥ì…˜ì´ ìˆìŒ</li>
<li>Dense Layer ë¼ê³ ë„ ë¶ˆë¦¬ê¸°ë„ í•¨</li>
</ul>
</li>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì„ í˜• ë³€í™˜ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜<ul>
<li>ë‚´ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì°¾ì•„ë‚´ë©´ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì¶œë ¥ì„ ì–»ì„ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<h3 id="Linear-Layer-ë™ì‘ë°©ì‹"><a href="#Linear-Layer-ë™ì‘ë°©ì‹" class="headerlink" title="Linear Layer ë™ì‘ë°©ì‹"></a>Linear Layer ë™ì‘ë°©ì‹</h3><ul>
<li>ê° ì…ë ¥ ë…¸ë“œë“¤ì— weight(ê°€ì¤‘ì¹˜)ë¥¼ ê³±í•˜ê³  ëª¨ë‘ í•©ì¹œ ë’¤, bias(í¸í–¥)ì„ ë”í•¨</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ed702032-9ad9-491c-b1cd-481a7a412907" alt="FCLayer02"></p>
<ul>
<li>|ğœƒ|&#x3D;(18,) , &#x2F;&#x2F; 18ê°œì˜ íŒŒë¼ë¯¸í„°ê°€ ìˆìŒ! ğ‘Š &#x3D; 5x3 &#x3D;15, ğ‘ &#x3D; 3</li>
</ul>
<h3 id="Linear-Layer-Equations"><a href="#Linear-Layer-Equations" class="headerlink" title="Linear Layer Equations"></a>Linear Layer Equations</h3><ul>
<li><p><strong>í–‰ë ¬ ê³±ìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥</strong></p>
</li>
<li><p>nì°¨ì›ì—ì„œ mì°¨ì›ìœ¼ë¡œì˜ <code>ì„ í˜• ë³€í™˜ í•¨ìˆ˜</code></p>
<ul>
<li>$x \in R^{k \times n}, w \in R^{n \times m} \rightarrow y \in R^{k \times m}$</li>
<li>$y &#x3D; f(k) &#x3D; x \cdot w + b$</li>
</ul>
</li>
<li><p>ê°™ì€ í‘œí˜„</p>
<ul>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜ì— ê´€ê³„ì—†ì´ ë‹¨ìˆœíˆ ë²¡í„°ë¡œ ë³¼ ê²½ìš° : (m,n) x (n,1) &#x3D; (m,1)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; W^T \cdot x + b$</p>
<p>$\text{ where } x \in \mathbb{R}^n, W^T \in \mathbb{R}^{m \times n}, b \in \mathbb{R}^m \text{ and } y \in \mathbb{R}^m$</p>
</li>
</ul>
</li>
<li><p>ğ‘¥ë¥¼ ë¯¸ë‹ˆë°°ì¹˜(Nê°œ) í…ì„œë¡œ í‘œí˜„í•  ê²½ìš° : (N,n) x (n,m) &#x3D; (N,m)</p>
<ul>
<li><p>$y &#x3D; f(k) &#x3D; x \cdot W + b$</p>
<p>$\text{ where } x \in \mathbb{R}^{k \times n}, W \in \mathbb{R}^{n \times m}, b \in \mathbb{R}^{n \times m} \text{ and } y \in \mathbb{R}^{n \times m}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/704a682c-5897-48ba-bd4c-971327678942" alt="FCLayer01"></p>
<h3 id="ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°"><a href="#ì½”ë“œë¡œ-êµ¬í˜„í•´ë³´ê¸°" class="headerlink" title="ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°"></a>ì½”ë“œë¡œ êµ¬í˜„í•´ë³´ê¸°</h3><ul>
<li><p>parameter ì •ë³´ í™•ì¸ ì˜ˆì œ</p>
<ul>
<li>gradientì— ê´€í•´ì„œëŠ” ë‹¤ìŒ gradient descent íŒŒíŠ¸ì—ì„œ ë‹¤ë£¸</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># ê°„ë‹¨í•œ ì‹ ê²½ë§ êµ¬ì¡°ë¥¼ ì •ì˜</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SimpleNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SimpleNet, self).__init__()</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">10</span>, <span class="number">5</span>)  <span class="comment"># 10ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 5ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">5</span>, <span class="number">1</span>)  <span class="comment"># 5ê°œì˜ ì…ë ¥ì„ ë°›ì•„ 1ê°œì˜ ì¶œë ¥ì„ ë‚´ëŠ” ì„ í˜• ê³„ì¸µ</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = torch.relu(self.fc1(x))</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ ê°ì²´ë¥¼ ìƒì„±</span></span><br><span class="line">model = SimpleNet()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì…ë ¥ ë°ì´í„°</span></span><br><span class="line">input_data = torch.FloatTensor([<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">8.0</span>, <span class="number">9.0</span>, <span class="number">10.0</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;input_data : <span class="subst">&#123;input_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># input_data : tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì‹ ê²½ë§ì„ í†µí•´ ì…ë ¥ ë°ì´í„°ë¥¼ ì „ë‹¬</span></span><br><span class="line">output_data = model(input_data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;output: <span class="subst">&#123;output_data&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># output: tensor([[2.3264]], grad_fn=&lt;AddmmBackward&gt;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì— ëŒ€í•œ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.data: <span class="subst">&#123;param.data&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.data: tensor([[-0.2895, -0.1230,  0.1624,  0.0381,  0.2252,  0.2265, -0.1498,  0.0806, -0.1704,  0.2421],</span></span><br><span class="line"><span class="string">        [-0.1162,  0.0786, -0.1140,  0.0178,  0.0470,  0.2920,  0.2933,  0.2919, 0.0493, -0.0025],</span></span><br><span class="line"><span class="string">        [ 0.0196,  0.0492, -0.2049,  0.1628, -0.1038,  0.1221,  0.0516, -0.1309, -0.2128, -0.3086],</span></span><br><span class="line"><span class="string">        [ 0.0129,  0.1872, -0.1641,  0.0406,  0.1779,  0.1346, -0.1623,  0.1618, 0.0410, -0.1538],</span></span><br><span class="line"><span class="string">        [ 0.1166, -0.0591,  0.0349, -0.0866,  0.2066, -0.0777,  0.3119, -0.1021, -0.2297,  0.2657]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.data: tensor([ 0.0787, -0.0037, -0.2033,  0.0398, -0.1233])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.data: tensor([[0.0168, 0.2259, 0.2410, 0.0145, 0.2553]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.data: tensor([0.2295])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># Gradient ê³„ì‚°ì„ ìœ„í•œ ëœë¤ íƒ€ê¹ƒ ê°’ ìƒì„±</span></span><br><span class="line">target = torch.FloatTensor([<span class="number">0.5</span>]).unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;target <span class="subst">&#123;target&#125;</span>&quot;</span>) <span class="comment"># target tensor([[0.5000]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ í•¨ìˆ˜ë¡œ í‰ê·  ì œê³± ì˜¤ì°¨ë¥¼ ì‚¬ìš©</span></span><br><span class="line">loss_fn = nn.MSELoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì†ì‹¤ ê³„ì‚°</span></span><br><span class="line">loss = loss_fn(output_data, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì—­ì „íŒŒë¥¼ ìˆ˜í–‰í•˜ì—¬ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ê³„ì‚°</span></span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># íŒŒë¼ë¯¸í„°ë“¤ì˜ ê·¸ë¼ë””ì–¸íŠ¸ ì •ë³´ë¥¼ ì¶œë ¥</span></span><br><span class="line"><span class="keyword">for</span> name, param <span class="keyword">in</span> model.named_parameters():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;name: <span class="subst">&#123;name&#125;</span>, param.grad: <span class="subst">&#123;param.grad&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    name: fc1.weight, param.grad: tensor([[0.0614, 0.1229, 0.1843, 0.2458, 0.3072, 0.3687, 0.4301, 0.4915, 0.5530, 0.6144],</span></span><br><span class="line"><span class="string">        [0.8253, 1.6507, 2.4760, 3.3013, 4.1267, 4.9520, 5.7774, 6.6027, 7.4280, 8.2534],</span></span><br><span class="line"><span class="string">        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],</span></span><br><span class="line"><span class="string">        [0.0529, 0.1057, 0.1586, 0.2114, 0.2643, 0.3171, 0.3700, 0.4228, 0.4757, 0.5285],</span></span><br><span class="line"><span class="string">        [0.9324, 1.8648, 2.7972, 3.7296, 4.6621, 5.5945, 6.5269, 7.4593, 8.3917, 9.3241]])</span></span><br><span class="line"><span class="string">    name: fc1.bias, param.grad: tensor([0.0614, 0.8253, 0.0000, 0.0529, 0.9324])</span></span><br><span class="line"><span class="string">    name: fc2.weight, param.grad: tensor([[11.5118, 23.9645,  0.0000,  2.8603,  7.8742]])</span></span><br><span class="line"><span class="string">    name: fc2.bias, param.grad: tensor([3.6528])</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (1) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">W = torch.FloatTensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">                       [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">b = torch.FloatTensor([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(W.size()) <span class="comment"># torch.Size([3, 2])</span></span><br><span class="line"><span class="built_in">print</span>(b.size()) <span class="comment"># torch.Size([2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linear</span>(<span class="params">x, W, b</span>):</span><br><span class="line">    y = torch.matmul(x, W) + b</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x, W, b)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (2) â€“ nn.Module ì¶”ìƒ í´ë˜ìŠ¤ë¥¼ í™œìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))</span><br><span class="line">        self.b = nn.Parameter(torch.FloatTensor(output_dim))</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = torch.matmul(x, self.W) + self.b</span><br><span class="line">        <span class="comment"># |y| = (batch_size, input_dim) * (input_dim, output_dim)</span></span><br><span class="line">        <span class="comment">#     = (batch_size, output_dim)        </span></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-3.7895e+32,  7.2868e-43],</span></span><br><span class="line"><span class="string">        [ 2.8026e-45,  0.0000e+00],</span></span><br><span class="line"><span class="string">        [-3.7896e+32,  7.2868e-43]], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (3) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">linear = nn.Linear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.4061,  0.0483,  0.0804],</span></span><br><span class="line"><span class="string">        [ 0.0581,  0.0730,  0.4323]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.4551, 0.4209], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Raw Linear Layer ì˜ˆì œ (4) â€“ nn.Linear ì´ìš©</p>
<ul>
<li><p>$f(x) &#x3D; y &#x3D; x \cdot W + b, \text{ where } x \in \mathbb{R}^{N \times n}, y \in \mathbb{R}^{N \times m}, \text{ Thus, } W \in \mathbb{R}^{n \times m} \text{ and } b \in \mathbb{R}^{m}$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch </span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyLinear</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_dim=<span class="number">3</span>, output_dim=<span class="number">2</span></span>):</span><br><span class="line">        self.input_dim = input_dim</span><br><span class="line">        self.output_dim = output_dim</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        </span><br><span class="line">        self.linear = nn.Linear(input_dim, output_dim)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># |x| = (batch_size, input_dim)</span></span><br><span class="line">        y = self.linear(x)</span><br><span class="line">        <span class="comment"># |y| = (batch_size, output_dim)</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">x = torch.FloatTensor([[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">                       [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">                       [<span class="number">3</span>, <span class="number">3</span>, <span class="number">3</span>],</span><br><span class="line">                       [<span class="number">4</span>, <span class="number">4</span>, <span class="number">4</span>]])</span><br><span class="line"><span class="built_in">print</span>(x.size()) <span class="comment"># torch.Size([4, 3])</span></span><br><span class="line"></span><br><span class="line">linear = MyLinear(<span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">y = linear(x)</span><br><span class="line"><span class="built_in">print</span>(y.size()) <span class="comment"># torch.Size([4, 2])</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> linear.parameters():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([[-0.1267,  0.0563,  0.3951],</span></span><br><span class="line"><span class="string">        [ 0.2291,  0.3214,  0.2595]], requires_grad=True)</span></span><br><span class="line"><span class="string">Parameter containing:</span></span><br><span class="line"><span class="string">tensor([0.3659, 0.4013], requires_grad=True)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>Linear Layer ëŠ” ì„ í˜• í•¨ìˆ˜</li>
<li>ë‚´ë¶€ ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°(weight parameter) ğ‘Šì™€ ğ‘ì— ì˜í•´ ì •ì˜ë¨</li>
<li>ìš°ë¦° ì´ í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì˜ ì¡°ì ˆí•˜ë©´, ì£¼ì–´ì§„ ì…ë ¥ì— ëŒ€í•´ ì›í•˜ëŠ” ì¶œë ¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŒ</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-16T14:58:32.000Z" title="7/16/2023, 11:58:32â€¯PM">2023-07-16</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:43.000Z" title="12/21/2023, 12:32:43â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">4 minutes read (About 591 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/5%EC%9E%A5-%EC%8B%A0%EA%B2%BD%EB%A7%9D%EC%9D%98-%EA%B8%B0%EB%B3%B8-%EA%B5%AC%EC%84%B1%EC%9A%94%EC%86%8C-%EC%82%B4%ED%8E%B4%EB%B3%B4%EA%B8%B0-%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88%EA%B3%BC-%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/">5ì¥. ì‹ ê²½ë§ì˜ ê¸°ë³¸ êµ¬ì„±ìš”ì†Œ ì‚´í´ë³´ê¸° - í–‰ë ¬ì˜ ê³±ì…ˆê³¼ ë²¡í„°ì˜ ê³±ì…ˆ</a></h1><div class="content"><h2 id="í–‰ë ¬ì˜-ê³±ì…ˆ-Matrix-Multiplication"><a href="#í–‰ë ¬ì˜-ê³±ì…ˆ-Matrix-Multiplication" class="headerlink" title="í–‰ë ¬ì˜ ê³±ì…ˆ(Matrix Multiplication)"></a>í–‰ë ¬ì˜ ê³±ì…ˆ(Matrix Multiplication)</h2><ul>
<li><p>í–‰ë ¬ì˜ ê³±ì…ˆ</p>
<ul>
<li>2ê°œì˜ í–‰ë ¬ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ <code>ìƒˆë¡œìš´ í–‰ë ¬</code>ì„ ìƒì„±</li>
<li>ì²« ë²ˆì§¸ í–‰ë ¬ì˜ ê° í–‰ê³¼ ë‘ ë²ˆì§¸ í–‰ë ¬ì˜ ê° ì—´ ì‚¬ì´ì˜ ë‚´ì ì„ ìš”ì†Œë¡œ ê°€ì§€ëŠ” ìƒˆë¡œìš´ í–‰ë ¬ì„ ë§Œë“¬</li>
<li>í–‰ë ¬ ê³±ì…ˆì€ ë‚´ì ì˜ ì´í•©ì„ ì‚¬ìš©í•˜ì§€ë§Œ ìì²´ì ìœ¼ë¡œëŠ” ë‹¤ë¥¸ ì—°ì‚°</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># í–‰ë ¬ ê³±ì…ˆ</span></span><br><span class="line">M = torch.tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">N = torch.tensor([[<span class="number">7</span>, <span class="number">8</span>], [<span class="number">9</span>, <span class="number">10</span>], [<span class="number">11</span>, <span class="number">12</span>]])</span><br><span class="line">matrix_product = torch.mm(M, N) <span class="comment"># ë‘ í…ì„œê°€ ëª¨ë‘ 2ì°¨ì› ì´ìƒì¸ ê²½ìš°, &#x27;@&#x27;ëŠ” í–‰ë ¬ê³±(matrix multiplication)ì„ ê³„ì‚°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Matrix Product:\\n <span class="subst">&#123;matrix_product&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Matrix Product:</span></span><br><span class="line"><span class="comment">#  tensor([[ 58,  64],</span></span><br><span class="line"><span class="comment">#         [139, 154]])</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="1-Matrix-Multiplication-í–‰ë ¬-ê³±"><a href="#1-Matrix-Multiplication-í–‰ë ¬-ê³±" class="headerlink" title="1. Matrix Multiplication(í–‰ë ¬ ê³±)"></a>1. Matrix Multiplication(í–‰ë ¬ ê³±)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/29973390-4e07-4bf5-a650-be12868b240b" alt="MatrixMultiplication"></p>
<h3 id="2-Vector-Matrix-Multiplication-ë²¡í„°ì™€-í–‰ë ¬ì˜-ê³±"><a href="#2-Vector-Matrix-Multiplication-ë²¡í„°ì™€-í–‰ë ¬ì˜-ê³±" class="headerlink" title="2. Vector Matrix Multiplication (ë²¡í„°ì™€ í–‰ë ¬ì˜ ê³±)"></a>2. Vector Matrix Multiplication (ë²¡í„°ì™€ í–‰ë ¬ì˜ ê³±)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/321590d0-9da0-44bf-945f-90d828b4f084" alt="VectorMatrixMultiplication01"></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4e1cd1aa-2d96-4e75-bb3e-6db31d46b176" alt="VectorMatrixMultiplication02"></p>
<h3 id="3-Batch-Matrix-Multiplication"><a href="#3-Batch-Matrix-Multiplication" class="headerlink" title="3. Batch Matrix Multiplication"></a>3. Batch Matrix Multiplication</h3><ul>
<li>ê°™ì€ ê°¯ìˆ˜ì˜ í–‰ë ¬ ìŒë“¤ì— ëŒ€í•´ì„œ ë³‘ë ¬ë¡œ í–‰ë ¬ ê³± ì‹¤í–‰</li>
<li>ë§Œì•½ 4ì°¨ì› í…ì„œë¼ë©´ (N1, N2, n, h) X (N1, N2, h, m) ì´ ë¨</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4baa6300-8ffc-4ee4-bee2-81c14936e11c" alt="BatchMatrixMultiplication"></p>
<h2 id="ë²¡í„°ì˜-ê³±ì…ˆ-Vector-Multiplication"><a href="#ë²¡í„°ì˜-ê³±ì…ˆ-Vector-Multiplication" class="headerlink" title="ë²¡í„°ì˜ ê³±ì…ˆ(Vector Multiplication)"></a>ë²¡í„°ì˜ ê³±ì…ˆ(Vector Multiplication)</h2><p>ë²¡í„°ì˜ ê³±ì…ˆì—ëŠ” ì£¼ë¡œ 2ê°€ì§€ì˜ í˜•íƒœë¡œ ìˆìŒ</p>
<ul>
<li><p>ë‚´ì  (Dot Product, Inner Product, ì ê³±)</p>
<ul>
<li>ë‘ ê°œì˜ ë²¡í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ <code>ìŠ¤ì¹¼ë¼</code>(ë‹¨ì¼ ìˆ˜ì¹˜) ê°’ì„ ì¶œë ¥</li>
<li>ë²¡í„°ì˜ ë‚´ì ì€ ê°™ì€ ìœ„ì¹˜ì— ìˆëŠ” ìš”ì†Œë“¤ë¼ë¦¬ ê³±í•œ í›„, ê·¸ ê²°ê³¼ë¥¼ ëª¨ë‘ ë”í•´ì„œ í•˜ë‚˜ì˜ ìˆ«ìë¥¼ ì–»ìŒ</li>
<li>ë‚´ì ì€ ë²¡í„°ë“¤ ì‚¬ì´ì˜ <code>ìœ ì‚¬ì„±</code>ì„ ì¸¡ì •í•˜ëŠ” ë° ì‚¬ìš©</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ë²¡í„° ë‚´ì </span></span><br><span class="line">A = torch.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">B = torch.tensor([<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>])</span><br><span class="line">dot_product = torch.mm(A, B) <span class="comment"># ë‘ í…ì„œê°€ ëª¨ë‘ 1ì°¨ì›ì¸ ê²½ìš°, &#x27;@&#x27;ëŠ” ë²¡í„° ë‚´ì (dot product)ì„ ê³„ì‚°</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Dot Product: <span class="subst">&#123;dot_product&#125;</span>&quot;</span>)</span><br><span class="line"><span class="comment"># Dot Product: 32</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>ì™¸ì  (Cross Product)</p>
<ul>
<li>3ì°¨ì› ë²¡í„°ì— í•œì •í•˜ë©°, ë‘ ë²¡í„°ì˜ ì™¸ì ì€ ìƒˆë¡œìš´ ë²¡í„°ë¥¼ ìƒì„±</li>
<li>ìƒˆë¡œìš´ ë²¡í„°ëŠ” ë‘ ì…ë ¥ ë²¡í„°ì— ìˆ˜ì§ì¸ ë°©í–¥ì„ ê°€ì§€ë©°, ê·¸ í¬ê¸°ëŠ” ë‘ ì…ë ¥ ë²¡í„° ì‚¬ì´ì˜ ê°ë„ì— ë”°ë¼ ë‹¬ë¼ì§</li>
<li>ë¬¼ë¦¬í•™ì—ì„œ í˜ì˜ ë°©í–¥ ê³„ì‚° ë“±ì— ì‚¬ìš©</li>
</ul>
</li>
</ul>
<h2 id="ë²¡í„°ì˜-ë‚´ì -vs-ì½”ì‚¬ì¸-ìœ ì‚¬ë„"><a href="#ë²¡í„°ì˜-ë‚´ì -vs-ì½”ì‚¬ì¸-ìœ ì‚¬ë„" class="headerlink" title="ë²¡í„°ì˜ ë‚´ì  vs ì½”ì‚¬ì¸ ìœ ì‚¬ë„"></a>ë²¡í„°ì˜ ë‚´ì  vs ì½”ì‚¬ì¸ ìœ ì‚¬ë„</h2><ul>
<li>Dot Product<ul>
<li>$a \cdot b &#x3D; |a| |b| \cos \theta$</li>
<li>ì–¼ë§ˆë‚˜ ê°™ì€ ë°©í–¥ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ì •ë³´ë¥¼ ë‹´ìœ¼ë©°,</li>
<li>ë²¡í„°ì˜ í¬ê¸°ì—ë„ ì˜í–¥ì„ ë°›ìŒ</li>
</ul>
</li>
<li>Cosine Similarity<ul>
<li>$\text{cosine-similarity}(a, b) &#x3D; \frac{a \cdot b}{|a| |b|}$</li>
<li>ë°©í–¥ì„±ë§Œ ê³ ë ¤í•¨</li>
<li>ë²¡í„°ì˜ í¬ê¸° ê³ ë ¤x</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-15T14:58:24.000Z" title="7/15/2023, 11:58:24â€¯PM">2023-07-15</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:42.000Z" title="12/21/2023, 12:32:42â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">2 minutes read (About 333 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/4%EC%9E%A5-PyTorch-Tutorials-Tensor/">4ì¥. PyTorch Tutorials - Tensor</a></h1><div class="content"><h2 id="Tensor"><a href="#Tensor" class="headerlink" title="Tensor"></a>Tensor</h2><h3 id="Tensorë€-ë¬´ì—‡ì¸ê°€"><a href="#Tensorë€-ë¬´ì—‡ì¸ê°€" class="headerlink" title="Tensorë€ ë¬´ì—‡ì¸ê°€"></a>Tensorë€ ë¬´ì—‡ì¸ê°€</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/5b8d117f-0487-4131-b90b-261a8d54914d" alt="Tensor"></p>
<ul>
<li>Scalar : ì </li>
<li>Vector : 1ì°¨ì› ë°°ì—´</li>
<li>Matrix : 2ì°¨ì› ë°°ì—´</li>
<li>Tensor : 3ì°¨ì› ì´ìƒì˜ ë°°ì—´</li>
</ul>
<h3 id="Tensor-Shape"><a href="#Tensor-Shape" class="headerlink" title="Tensor Shape"></a>Tensor Shape</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/1873595c-eae5-4056-b07f-ed0a4158ea28" alt="Tensor Shape"></p>
<p>â€‹	$x \in \mathbb{R}^{k \times n \times m} \rightarrow |x|&#x3D;(k,n,m)$</p>
<h3 id="Matrix-Shape"><a href="#Matrix-Shape" class="headerlink" title="Matrix Shape"></a>Matrix Shape</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/fe5c94b3-57fe-4bd4-832b-cce05c96b097" alt="Matrix Shape"></p>
<ul>
<li>$x \in \mathbb{R}^{k \times n} \rightarrow |x|&#x3D;(k,n)$</li>
</ul>
<h3 id="Typical-Tensor-Shape-Tabular-Dataset"><a href="#Typical-Tensor-Shape-Tabular-Dataset" class="headerlink" title="Typical Tensor Shape : Tabular Dataset"></a>Typical Tensor Shape : Tabular Dataset</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/088e479a-0a60-4b2e-bde5-95873c2bcc55" alt="Tabular Shape"></p>
<ul>
<li>$|x|&#x3D;(n,) \Rightarrow x \in \mathbb{R}^n \text{ (vector)}$</li>
</ul>
<h3 id="Mini-batch-Consider-Parallel-Operations"><a href="#Mini-batch-Consider-Parallel-Operations" class="headerlink" title="Mini batch: Consider Parallel Operations"></a>Mini batch: Consider Parallel Operations</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/3f3b8ada-ec71-404a-9357-782900187dfa" alt="MiniBatch"></p>
<ul>
<li>$|x|&#x3D;(k,n) \Rightarrow x \in \mathbb{R}^{k \times n}$</li>
</ul>
<h3 id="Typical-Tensor-Shape-NLP"><a href="#Typical-Tensor-Shape-NLP" class="headerlink" title="Typical Tensor Shape : NLP"></a>Typical Tensor Shape : NLP</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/b90beaa4-dfd0-464d-a463-abb9e9f18353" alt="NLP_Tensor_Shape"></p>
<ul>
<li>$x \in \mathbb{R}^{k \times n \times m} \rightarrow |x|&#x3D;(k,n,m)$</li>
<li>|ğ‘¥|&#x3D;(#ğ’”,#ğ°,#ğ’‡)</li>
<li>$|x_{(i,j)}|$&#x3D;(#ğ‘“, )</li>
<li>$|x_i|$&#x3D;(#ğ‘¤, #ğ‘“, )</li>
</ul>
<h3 id="Typical-Tensor-Shape-Computer-Vision-GrayScale"><a href="#Typical-Tensor-Shape-Computer-Vision-GrayScale" class="headerlink" title="Typical Tensor Shape : Computer Vision(GrayScale)"></a>Typical Tensor Shape : Computer Vision(GrayScale)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/802d848b-a788-4bbb-8753-210de6260e4c" alt="CV_GrayScale_Tensor_Shape"></p>
<ul>
<li>|ğ‘¥|&#x3D;(#ğ¢ğ¦ğ , ğ¡, ğ’˜)</li>
</ul>
<h3 id="Typical-Tensor-Shape-Computer-Vision-Color"><a href="#Typical-Tensor-Shape-Computer-Vision-Color" class="headerlink" title="Typical Tensor Shape : Computer Vision(Color)"></a>Typical Tensor Shape : Computer Vision(Color)</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/b287b7a4-88de-4dc2-83cb-a58d5da8e751" alt="CV_Color_Tensor_Shape"></p>
<ul>
<li>|ğ‘¥|&#x3D;(#ğ¢ğ¦ğ , #ğœğ¡ğšğ§ğ§ğğ¥, ğ¡, ğ’˜) (4ì°¨ì›ì´ ë¨)</li>
<li>$|x_i|$&#x3D;(#ğ‘â„, â„, ğ‘¤)</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-13T14:51:23.000Z" title="7/13/2023, 11:51:23â€¯PM">2023-07-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:42.000Z" title="12/21/2023, 12:32:42â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">4 minutes read (About 598 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/3%EC%9E%A5-%EB%94%A5%EB%9F%AC%EB%8B%9D-Overview-Working-Process/">3ì¥. ë”¥ëŸ¬ë‹ Overview - Working Process</a></h1><div class="content"><h3 id="ìš°ë¦¬ì˜-ëª©í‘œ"><a href="#ìš°ë¦¬ì˜-ëª©í‘œ" class="headerlink" title="ìš°ë¦¬ì˜ ëª©í‘œ!"></a>ìš°ë¦¬ì˜ ëª©í‘œ!</h3><p>ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•´ì„œ ê²°ê³¼ë¥¼ ë‚´ëŠ” ê°€ìƒì˜ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“œëŠ” ê²ƒ</p>
<ul>
<li><p>ì˜ˆì‹œ</p>
<ul>
<li><p>ì£¼ì–´ì§„ ìˆ«ì ê·¸ë¦¼ì„ ë³´ê³  ë§ì¶”ê¸°!</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d" alt="DigitMnist"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d">https://github.com/shchoice/shchoice.github.io/assets/100276387/6098ece2-fe64-461f-a8fd-1a516e978c0d</a></p>
</li>
</ul>
</li>
</ul>
<h3 id="Working-Process"><a href="#Working-Process" class="headerlink" title="Working Process"></a>Working Process</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/bf6feb46-8811-4897-86a1-9097e688f0f3" alt="WorkingProcess"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/bf6feb46-8811-4897-86a1-9097e688f0f3">https://github.com/shchoice/shchoice.github.io/assets/100276387/bf6feb46-8811-4897-86a1-9097e688f0f3</a></p>
<ul>
<li>ë¬¸ì œ ì •ì˜<ul>
<li>ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„</li>
<li>í’€ê³ ì í•˜ëŠ” ë¬¸ì œë¥¼ ë‹¨ê³„ë¼ë¡œ ë‚˜ëˆ„ê³  simplify í•˜ì—¬ì•¼ í•œë‹¤.</li>
<li>ì‹ ê²½ë§ì´ë¼ëŠ” í•¨ìˆ˜ì— ë„£ê¸° ìœ„í•œ xì™€ ê²°ê³¼ê°’ yê°€ ì •ì˜ë˜ì–´ì•¼ í•œë‹¤.<ul>
<li>ğ‘¦&#x3D;ğ‘“(ğ‘¥) : ë¼ë©´ ë“ëŠ” ì´ë¯¸ì§€ë¥¼ ë„£ìœ¼ë©´ ë¬¼ì˜ ì˜¨ë„ê°€ ë‚˜ì˜¨ë‹¤ ë“±</li>
</ul>
</li>
</ul>
</li>
<li>ë°ì´í„° ìˆ˜ì§‘<ul>
<li>ë¬¸ì œ ì •ì˜ì— ë”°ë¼ ì •í•´ì§„ ğ‘¥ì™€ ğ‘¦</li>
<li>í’€ê³ ì í•˜ëŠ” ë¬¸ì œì˜ ì˜ì—­ì— ë”°ë¼ ìˆ˜ì§‘ ë°©ë²•ì´ ë‹¤ë¦„<ul>
<li>NLP, CV : crawling</li>
<li>ë°ì´í„°ë¶„ì„ : ì‹¤ì œ ìˆ˜ì§‘í•œ ë°ì´í„°</li>
</ul>
</li>
<li>í•„ìš”ì— ë”°ë¼ ë ˆì´ë¸”ë§(labeling) ì‘ì—…ì„ ìˆ˜í–‰<ul>
<li>ìë™ì ìœ¼ë¡œ labelì´ yë¡œ ì£¼ì–´ì§ˆ ìˆ˜ë„ ìˆì§€ë§Œ, ëŒ€ë¶€ë¶„ ë ˆì´ë¸”ì´ ë”°ë¡œ í•„ìš”í•¨, ë¹„ì§€ë„í•™ìŠµ ê¸°ëŒ€í•˜ì§€ ë§ì</li>
</ul>
</li>
</ul>
</li>
<li>ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„ì„<ul>
<li>ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì‹ ê²½ë§ì— ë„£ì–´ì£¼ê¸° ìœ„í•œ í˜•íƒœë¡œ ê°€ê³µí•˜ëŠ” ê³¼ì •<ul>
<li>ì…ì¶œë ¥ ê°’ì„ ì •ì œ(Cleansing &amp; normalization)</li>
</ul>
</li>
<li>ì´ ê³¼ì •ì—ì„œ íƒí—˜ì  ë¶„ì„(EDA)ì´ í•„ìš”<ul>
<li>ë°ì´í„° ì•Œë§ì€ ì•Œê³ ë¦¬ì¦˜ ì°¾ê¸° ìœ„í•¨(NLP, CV ìƒëµë˜ê¸°ë„)</li>
</ul>
</li>
<li>CVì˜ ê²½ìš° ë°ì´í„° ì¦ê°•(augmentation)ì´ ìˆ˜í–‰ë¨<ul>
<li>rotation, flipping, shifting ë“±ì˜ ì—°ì‚°</li>
</ul>
</li>
</ul>
</li>
<li>ì•Œê³ ë¦¬ì¦˜ ì ìš©<ul>
<li>ë°ì´í„°ì— ëŒ€í•´ ê°€ì„¤ì„ ì„¸ìš°ê³ , í•´ë‹¹ ê°€ì„¤ì„ ìœ„í•œ ì•Œê³ ë¦¬ì¦˜(ëª¨ë¸)ì„ ì ìš©</li>
</ul>
</li>
<li>í‰ê°€<ul>
<li>ë¬¸ì œ ì •ì˜ì— ë”°ë¥¸ ê³µì •í•˜ê³  ì˜¬ë°”ë¥¸ í‰ê°€ ë°©ë²• í•„ìš” (ê°€ì„¤ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ì‹¤í—˜ ì„¤ê³„)</li>
<li>í…ŒìŠ¤íŠ¸ ì…‹ êµ¬ì„±</li>
<li>ë„ˆë¬´ ì‰½ê±°ë‚˜ ì–´ë µë‹¤ë©´ íŒë³„ë ¥ì´ ë–¨ì–´ì§, ì‹¤ì œ ë°ì´í„°ì™€ ê°€ì¥ ê°€ê¹ê²Œ êµ¬ì„±ë˜ì•¼í•¨</li>
<li>ì •ì„±ì  í‰ê°€(extrinsic evaluation)ì™€ ì •ì„±ì  í‰ê°€(intrinsic evaluation)ë¡œ ë‚˜ë‰¨</li>
</ul>
</li>
<li>ë°°í¬<ul>
<li>í•™ìŠµê³¼ í‰ê°€ê°€ ì™„ë£Œëœ ëª¨ë¸ weights íŒŒì¼ì„ ë°°í¬í•¨</li>
<li>RESTful API ë“±ì„ í†µí•´ wrapping í›„ ë°°í¬</li>
<li>ë°ì´í„° ë¶„í¬ì˜ ë³€í™”ì— ë”°ë¥¸ ëª¨ë¸ ì—…ë°ì´íŠ¸ ë° ìœ ì§€ë³´ìˆ˜ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-12T14:53:08.000Z" title="7/12/2023, 11:53:08â€¯PM">2023-07-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:42.000Z" title="12/21/2023, 12:32:42â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">2 minutes read (About 363 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/3%EC%9E%A5-%EB%94%A5%EB%9F%AC%EB%8B%9D-Overview-%EC%A2%8B%EC%9D%80-%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5%EC%9D%B4%EB%9E%80/">3ì¥. ë”¥ëŸ¬ë‹ Overview - ì¢‹ì€ ì¸ê³µì§€ëŠ¥ì´ë€</a></h1><div class="content"><h2 id="ì¢‹ì€-ì¸ê³µì§€ëŠ¥ì´ë€"><a href="#ì¢‹ì€-ì¸ê³µì§€ëŠ¥ì´ë€" class="headerlink" title="ì¢‹ì€ ì¸ê³µì§€ëŠ¥ì´ë€"></a>ì¢‹ì€ ì¸ê³µì§€ëŠ¥ì´ë€</h2><h3 id="ì¸ê³µì§€ëŠ¥-ëª¨ë¸ì´ë€"><a href="#ì¸ê³µì§€ëŠ¥-ëª¨ë¸ì´ë€" class="headerlink" title="ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ë€?"></a>ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ë€?</h3><ul>
<li>ğ‘¥ ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ğ‘¦ ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜<ul>
<li>ğ‘¦&#x3D;ğ‘“(ğ‘¥)</li>
</ul>
</li>
<li>íŒŒë¼ë¯¸í„°(weight parameter, ğœƒ)ë€<ul>
<li>ğ‘“ê°€ ë™ì‘í•˜ëŠ” ë°©ì‹(ğ‘¥ ê°€ ë“¤ì–´ì™”ì„ ë•Œ, ì–´ë–¤ ğ‘¦ ë¥¼ ë±‰ì–´ë‚¼ ê²ƒì¸ê°€?)ë¥¼ ê²°ì •</li>
</ul>
</li>
<li>í•™ìŠµì´ë€<ul>
<li>ğ‘¥ì™€ ğ‘¦ì˜ ìŒìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ğ‘¥ë¡œë¶€í„° ğ‘¦ë¡œ ê°€ëŠ” ê´€ê³„ë¥¼ ë°°ìš°ëŠ” ê²ƒ</li>
<li><code>ğ‘¥ì™€ ğ‘¦ë¥¼ í†µí•´ ì ì ˆí•œ íŒŒë¼ë¯¸í„°(ğœƒ)ë¥¼ ì°¾ì•„ë‚´ëŠ” ê²ƒ</code></li>
</ul>
</li>
<li>ëª¨ë¸ì´ë€<ul>
<li>ìƒí™©ì— ë”°ë¼ <code>ì•Œê³ ë¦¬ì¦˜ ìì²´</code>ë¥¼ ì´ë¥´ê±°ë‚˜ <code>íŒŒë¼ë¯¸í„°</code>ë¥¼ ì´ë¦„</li>
</ul>
</li>
</ul>
<h3 id="ì¢‹ì€-ì¸ê³µì§€ëŠ¥-ëª¨ë¸ì´ë€"><a href="#ì¢‹ì€-ì¸ê³µì§€ëŠ¥-ëª¨ë¸ì´ë€" class="headerlink" title="ì¢‹ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ë€?"></a>ì¢‹ì€ ì¸ê³µì§€ëŠ¥ ëª¨ë¸ì´ë€?</h3><ul>
<li><code>ì¼ë°˜í™”(Generalization)</code>ë¥¼ ì˜ í•˜ëŠ” ëª¨ë¸</li>
<li>ë³´ì§€ ëª»í•œ(unseen) ë°ì´í„°ì— ëŒ€í•´ì„œ ì¢‹ì€ ì˜ˆì¸¡(prediction)ì„ í•˜ëŠ” ëª¨ë¸<ul>
<li>ìš°ë¦¬ëŠ” ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•´ì„œ ë°ì´í„°ë¥¼ ëª¨ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸</li>
<li>ë³´ì§€ ëª»í•œ ê²½ìš°ì— ëŒ€í•´ì„œ, ëª¨ë¸ì€ ì¢‹ì€ íŒë‹¨ì„ ë‚´ë¦´ ìˆ˜ ìˆì–´ì•¼ í•¨</li>
</ul>
</li>
</ul>
<h3 id="ê¸°ì¡´-ë¨¸ì‹ ëŸ¬ë‹ì˜-í•œê³„"><a href="#ê¸°ì¡´-ë¨¸ì‹ ëŸ¬ë‹ì˜-í•œê³„" class="headerlink" title="ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œê³„"></a>ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œê³„</h3><ul>
<li>ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì€ ì£¼ë¡œ ì„ í˜• ë˜ëŠ” ë‚®ì€ ì°¨ì›ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŒ</li>
<li>Kernel ë“±ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ì„ í˜• ë°ì´í„°ë¥¼ ë‹¤ë£° ìˆ˜ ìˆì§€ë§Œ í•œê³„ê°€ ëª…í™•í•¨<ul>
<li>ì´ë¯¸ì§€, í…ìŠ¤íŠ¸, ìŒì„±ê³¼ ê°™ì€ í›¨ì”¬ ë” ë†’ì€ ì°¨ì›ì˜ ë°ì´í„°ë“¤ì— ëŒ€í•´ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì„</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-11T14:44:26.000Z" title="7/11/2023, 11:44:26â€¯PM">2023-07-11</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:42.000Z" title="12/21/2023, 12:32:42â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ê¸°ë³¸ ê°œë…</a></span><span class="level-item">5 minutes read (About 750 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/3%EC%9E%A5-%EB%94%A5%EB%9F%AC%EB%8B%9D-Overview-%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%B4%EB%9E%80/">3ì¥. ë”¥ëŸ¬ë‹ Overview - ë”¥ëŸ¬ë‹ì´ë€</a></h1><div class="content"><h2 id="ë”¥ëŸ¬ë‹-ê°œìš”"><a href="#ë”¥ëŸ¬ë‹-ê°œìš”" class="headerlink" title="ë”¥ëŸ¬ë‹ ê°œìš”"></a>ë”¥ëŸ¬ë‹ ê°œìš”</h2><h3 id="ë”¥ëŸ¬ë‹ì´ë€"><a href="#ë”¥ëŸ¬ë‹ì´ë€" class="headerlink" title="ë”¥ëŸ¬ë‹ì´ë€?"></a>ë”¥ëŸ¬ë‹ì´ë€?</h3><ul>
<li>Deep Neural Network(D NN)ì„ í•™ìŠµì‹œì¼œ ë¬¸ì œë¥¼ í•´ê²°</li>
<li>ì¸ê²½ì‹ ê²½ë§(Artificial Neural Networks)ì˜ ì í†µì„ ì´ì–´ë°›ìŒ<ul>
<li>neuron ë“¤ë¡œ êµ¬ì„±ëœ ì‹ ê²½ë§ì„ í•™ìŠµí•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²¨í•˜ë„ë¡ ë™ì‘í•˜ëŠ” í•¨ìˆ˜<ul>
<li>ë”¥ëŸ¬ë‹ì€ ì¸ê³µì‹ ê²½ë§ì˜ ë¶€ë¶„ì§‘í•©</li>
<li>ì°¨ì´ì ì´ë¼ë©´ ANNì€ ì–‡ê²Œ, DNNì€ ê¹Šê²Œ ìŒ“ìŒ</li>
</ul>
</li>
</ul>
</li>
<li>ê¸°ì¡´ ì‹ ê²½ë§ì— ë¹„í•˜ì—¬ ë” ê¹Šì€ êµ¬ì¡°ë¥¼ ê°–ëŠ” ê²ƒì´ íŠ¹ì§•<ul>
<li>ì´ìœ  1. GPUë¥¼ í™œìš©í•œ ë³‘ë ¬ ì—°ì‚° ë°©ë²•ì´ ëŒ€ì¤‘í™”ë˜ë©°, ì‹ ê²½ë§ì˜ í•™ìŠµ&#x2F;ì¶”ë¡  ì†ë„ì˜ ë¹„ì•½ì  ì¦ê°€</li>
<li>ì´ìœ  2. ì¸í„°ë„·ì˜ ë°œë‹¬ë¡œ ë¹…ë°ì´í„°ê°€ ë„ë¦¬ í™œìš©ë˜ê³  ì´ë¥¼ í†µí•´ ê¹Šì€ ì‹ ê²½ë§ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆê²Œ ë¨</li>
</ul>
</li>
</ul>
<h3 id="ì™œ-ë”¥ëŸ¬ë‹ì¸ê°€"><a href="#ì™œ-ë”¥ëŸ¬ë‹ì¸ê°€" class="headerlink" title="ì™œ ë”¥ëŸ¬ë‹ì¸ê°€?"></a>ì™œ ë”¥ëŸ¬ë‹ì¸ê°€?</h3><ul>
<li>ë¹„ì„ í˜• í•¨ìˆ˜ë¡œ ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ì— ë¹„í•´ íŒ¨í„´ ì¸ì‹ ëŠ¥ë ¥ì´ ì›”ë“±í•¨ â€» ì´ ì„¸ìƒ ì–´ë– í•œ ìœ í˜•ì˜ í•¨ìˆ˜ë“  ëª¨ì‚¬í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì´ ìˆë‹¤ëŠ” ê²ƒì´ ìˆ˜í•™ì ìœ¼ë¡œ ì¦ëª…ë¨, UAT(Universal Approach Theorem)</li>
<li>ì´ë¯¸ì§€ë‚˜ í…ìŠ¤íŠ¸, ìŒì„±ê³¼ ê°™ì€ ë¶„ì•¼ë“¤ì—ì„œ ë¹„ì•½ì ì¸ ì„±ëŠ¥ ê°œì„ ì„ ë§Œë“¬<ul>
<li>ê¸°ì¡´ ë¨¸ì‹ ëŸ¬ë‹ê³¼ ë‹¬ë¦¬ hand-crafted featureê°€ í•„ìš”ì—†ìŒ</li>
<li>ë‹¨ìˆœíˆ rawê°’ì„ ë„£ëŠ” ê²ƒìœ¼ë¡œ, ìë™ìœ¼ë¡œ íŠ¹ì§•(feature)ì„ í•™ìŠµí•¨</li>
</ul>
</li>
</ul>
<h3 id="ë”¥ëŸ¬ë‹ì˜-ì£¼ìš”ì—­ì‚¬"><a href="#ë”¥ëŸ¬ë‹ì˜-ì£¼ìš”ì—­ì‚¬" class="headerlink" title="ë”¥ëŸ¬ë‹ì˜ ì£¼ìš”ì—­ì‚¬"></a>ë”¥ëŸ¬ë‹ì˜ ì£¼ìš”ì—­ì‚¬</h3><ul>
<li><p>1980ë…„ëŒ€ ì—­ì „íŒŒ(Back-propagation) ì•Œê³ ë¦¬ì¦˜ì˜ ê°œë°œë¡œ ì¸í•œ ì¤‘í¥ê¸°</p>
</li>
<li><p>í•˜ì§€ë§Œ ëª¨ë¸ì„ ê¹Šì„¸ ìŒ“ì§€ ëª»í•¨ìœ¼ë¡œì¨ ì ˆë§ê°</p>
</li>
<li><p>2010ë…„ ì´ˆ ImageNet ìš°ìŠ¹ê³¼ ìŒì„± ì¸ì‹(Speech Recognition)ì˜ ìƒìš©í™”</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/80f13ae3-fc0f-408b-a6ff-37deb09e19ac" alt="ImageNet"></p>
</li>
<li><p>2015ë…„ ê¸°ê³„ë²ˆì—­(Machine Translation)ì˜ ìƒìš©í™” <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/f3fc9ae0-7502-4424-9c1a-3b107a67599c" alt="Machine Translation"></p>
<ul>
<li>ìì—°ì–´ ì²˜ë¦¬(SequenceToSequence, seq2seq)ì˜ ì‹œì‘</li>
</ul>
</li>
<li><p>2017ë…„ ì•ŒíŒŒê³ ì˜ ìŠ¹ë¦¬</p>
</li>
<li><p>2018ë…„ GANì„ í†µí•œ ì´ë¯¸ì§€ í•©ì„±ì˜ ë°œì „<br> <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/80646f7d-686d-4132-afa1-295c966f776c" alt="GAN"></p>
</li>
</ul>
<h3 id="ë”¥ëŸ¬ë‹-íŒ¨ëŸ¬ë‹¤ì„ì˜-ë³€í™”"><a href="#ë”¥ëŸ¬ë‹-íŒ¨ëŸ¬ë‹¤ì„ì˜-ë³€í™”" class="headerlink" title="ë”¥ëŸ¬ë‹ íŒ¨ëŸ¬ë‹¤ì„ì˜ ë³€í™”"></a>ë”¥ëŸ¬ë‹ íŒ¨ëŸ¬ë‹¤ì„ì˜ ë³€í™”</h3><ul>
<li><p>ê¸°ì¡´ íŒ¨ëŸ¬ë‹¤ì„</p>
<ul>
<li><p>Hand-Crafted Featureë¥¼ ì¶”ì¶œí•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì— ë„£ê³  í•™ìŠµ</p>
<p>â€» Hand-Crafted Feature : ì–¼êµ´ì€ ë‘¥ê·¸ë ‡ê²Œ ë˜ì–´ì ¸ ìˆìœ¼ë©°, ëˆˆ ì½” ì…ì˜ ìœ„ì¹˜ê°€ ìˆë‹¤ë¼ëŠ” ê°€ì •ë“¤ì„ ë„£ëŠ” ê²ƒ ì¦‰, ì—¬ëŸ¬ sub-ëª¨ë“ˆ</p>
</li>
<li><p>ì—¬ëŸ¬ ë‹¨ê³„ì˜ sub-moduleë¡œ ì´ë£¨ì–´ì ¸ ìˆì—ˆìŒ</p>
<ul>
<li>ì—¬ëŸ¬ sub-moduleë¡œ êµ¬ì„±ë˜ì–´ì ¸ ìˆì–´ì„œ ì‹œìŠ¤í…œì´ ë¬´ê±°ì› ìœ¼ë©°, ì—¬ëŸ¬ ì‚¬ëŒì´ ì‘ì—…ì„ í•´ì•¼í–ˆìŒ</li>
</ul>
</li>
<li><p>ê°€ì •ì´ ë“¤ì–´ê°, í•˜ì§€ë§Œ ì‚¬ëŒì˜ ê°€ì •ì´ í‹€ë¦´ ìˆ˜ë„ ìˆëŠ” ë¬¸ì œì ì´ ìˆìŒ</p>
</li>
</ul>
</li>
<li><p>ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„</p>
<ul>
<li><p>Raw ê°’ì„ ì‹ ê²½ë§ì— ë„£ìœ¼ë©´ ìë™ìœ¼ë¡œ íŠ¹ì§•(Feature)ì„ í•™ìŠµ</p>
<ul>
<li>í•˜ì§€ë§Œ, ì‚¬ëŒì´ í•´ì„í•˜ê¸°ê°€ ì–´ë ¤ì›€, ì–¼êµ´ ì¸ì‹ì´ ì•ˆë˜ë©´ ì™œ ì•ˆë˜ëŠ”ì§€ ì•Œê¸° ì–´ë ¤ì›€(ë¸”ë™ë°•ìŠ¤)</li>
</ul>
</li>
<li><p>í•˜ë‚˜ì˜ taskì— ëŒ€í•´ì„œ, </p>
<ul>
<li>í•˜ë‚˜ì˜ ì‹ ê²½ë§ ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ” end-to-end ë°©ì‹</li>
</ul>
<ul>
<li>í›¨ì”¬ ê°€ë³ê³  í˜¼ìì„œë„ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì¶©ë¶„íˆ ì‘ì—…ì´ ê°€ëŠ¥í•¨</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-03-28T14:11:41.000Z" title="3/28/2023, 11:11:41â€¯PM">2023-03-28</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:45:16.000Z" title="12/21/2023, 12:45:16â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/Text-Summarization/">Text Summarization</a></span><span class="level-item">6 minutes read (About 912 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/Text%20Summarization/Text-Summarization-%E1%84%8B%E1%85%B5%E1%84%85%E1%85%A1%E1%86%AB/">Text Summarization ì´ë€</a></h1><div class="content"><h2 id="Text-Summarization-ì´ë€"><a href="#Text-Summarization-ì´ë€" class="headerlink" title="Text Summarization ì´ë€"></a>Text Summarization ì´ë€</h2><p>ì›ë¬¸ì„ ì´í•´í•˜ê¸° ì‰¬ìš°ë©´ì„œë„ ê°€ì¹˜ìˆëŠ” ì •ë³´ë¡œ ë³€í™˜í•˜ëŠ” ì‘ì—…ì„ ë§í•¨</p>
<ul>
<li>ì¸ê°„ì€ ê¸¸ì´ê°€ ê¸¸ê±°ë‚˜ ì—¬ëŸ¬ ë¬¸ì„œë¡œ ë‚˜ëˆ ì ¸ìˆëŠ” í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ í•œ ëˆˆì— íŒŒì•…í•˜ê¸° ì–´ë ¤ì›Œí•¨</li>
<li>ë•Œë¡œëŠ” ì•Œì§€ ëª»í•˜ëŠ” ì „ë¬¸ ìš©ì–´ê°€ ë§ì´ ì‚¬ìš©ë˜ì–´ ìˆì„ ìˆ˜ë„ ìˆìŒ</li>
<li>ì´ëŸ¬í•œ í…ìŠ¤íŠ¸ë¥¼ ì›ë¬¸ì„ ì˜ ë°˜ì˜í•˜ë©´ì„œë„ ê°„ê²°í•˜ì—¬ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë°”ê¿”ì£¼ëŠ” ì‘ì—…ì€ ìƒë‹¹íˆ ê°€ì¹˜ìˆëŠ” ì¼</li>
</ul>
<blockquote>
<p>Text summarization is the process of <strong>distilling the most important information</strong> from a text to produce an abridged version for a particular task and user</p>
<p>í…ìŠ¤íŠ¸ ìš”ì•½ì€ íŠ¹ì • ì‘ì—… ë° ì‚¬ìš©ìì— ëŒ€í•œ ìš”ì•½ ë²„ì „ì„ ìƒì„±í•˜ê¸° ìœ„í•´ í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì´ë‹¤.<br><a target="_blank" rel="noopener" href="https://epubs.siam.org/doi/abs/10.1137/1037127">Berry, Dumais, &amp; Oâ€™Brien (1995)</a></p>
</blockquote>
<ul>
<li>Text Summarization ì€ ìš”ì•½ì˜ ëŒ€ìƒ(source)ì´ text ë¡œ í•œì •ì´ ë¨<ul>
<li>Textë¥¼ imageë¡œ ë³¸ë‹¤ë©´ image captioning, videoë¡œ ë³¸ë‹¤ë©´ video summarizationì´ ë¨</li>
<li>Text, image, video ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ sourceë¥¼ í•¨ê»˜ ìš”ì•½í•˜ëŠ” ë°©ì‹ì„ multimodal summarizationì´ë¼ê³  í•¨</li>
</ul>
</li>
</ul>
<h2 id="Task-Categories"><a href="#Task-Categories" class="headerlink" title="Task Categories"></a>Task Categories</h2><p>Text summarizationì˜ taskëŠ” í¬ê²Œ ìš”ì•½ë¬¸ì„ ìƒì„±í•˜ëŠ” ë°©ì‹ì— ë”°ë¼ extractive summarizationê³¼ abstractive summarizationìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŒ</p>
<ol>
<li>ì¶”ì¶œì  ìš”ì•½(Extractive Summarization)<ul>
<li><code>ì›ë¬¸ì—ì„œ ì¤‘ìš”í•œ ë¬¸ì¥ì´ë‚˜ êµ¬ë¬¸ì„ ì„ íƒ</code>í•˜ì—¬ ìš”ì•½ë¬¸ì„ ë§Œë“œëŠ” ë°©ë²•</li>
<li>ì›ë¬¸ì˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©°, ìš”ì•½ë¬¸ì€ ì›ë¬¸ì— ìˆëŠ” ë¬¸ì¥ë“¤ì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§</li>
<li><code>ì›ë¬¸ì˜ ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•œ ê²½ìš°ì— ì í•©</code></li>
<li>ì£¼ìš” ì•Œê³ ë¦¬ì¦˜: TextRank, LSA(Latent Semantic Analysis), Luhn ì•Œê³ ë¦¬ì¦˜ ë“±</li>
</ul>
</li>
<li>ìƒì„±ì  ìš”ì•½(Abstractive Summarization)<ul>
<li><code>ì›ë¬¸ì˜ ì˜ë¯¸ë¥¼ íŒŒì•…í•œ í›„, ìƒˆë¡œìš´ ë¬¸ì¥ì„ ìƒì„±</code>í•˜ì—¬ ìš”ì•½ë¬¸ì„ ë§Œë“œëŠ” ë°©ë²•</li>
<li>ì›ë¬¸ì— ì—†ëŠ” í‘œí˜„ì´ë‚˜ ë‹¨ì–´ë„ ìš”ì•½ë¬¸ì— í¬í•¨ë  ìˆ˜ ìˆìŒ</li>
<li>ì›ë¬¸ì˜ ì •ë³´ë¥¼ ë³´ë‹¤ ì˜ ìš”ì•½í•˜ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ìˆëŠ” ì¥ì ì´ ìˆìŒ</li>
<li><code>ìš”ì•½ë¬¸ì´ ìì—°ìŠ¤ëŸ½ê³  ë…ë¦½ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì•¼ í•˜ëŠ” ê²½ìš°ì— ì í•©</code></li>
<li>ì£¼ìš” ê¸°ìˆ  : Sequence-to-Sequence, Attention, Transformer ë“±</li>
</ul>
</li>
</ol>
<p><img src="https://velog.velcdn.com/images%2Fjaehyeong%2Fpost%2Fa6e87a99-815a-4570-94d2-7083c0f065ac%2Fextractive-abstractive.PNG" alt="img"></p>
<p>â€» ì´ì™¸ì—ë„ ë‹¤ìŒê³¼ ê°™ì€ ê´€ì ìœ¼ë¡œ Taskë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆìŒ</p>
<ul>
<li><p>keyword&#x2F;sentence summarization : ìƒì„±í•´ë‚´ëŠ” Text í˜•íƒœì— ë”°ë¼ êµ¬ë¶„</p>
</li>
<li><p>knowledge-poor&#x2F;rich summarization : ìš”ì•½ ê³¼ì •ì—ì„œ ì›ë¬¸ ì™¸ ì™¸ë¶€ ì •ë³´ë¥¼ ì–¼ë§ˆë‚˜ ì‚¬ìš©í•˜ëŠ”ì§€ì— ë”°ë¼</p>
</li>
<li><p>single&#x2F;multi document summarization : ì›ë¬¸ì˜ ê°œìˆ˜ì— ë”°ë¼ êµ¬ë¶„</p>
</li>
</ul>
<p><img src="https://github.com/uoneway/Text-Summarization-Repo/raw/main/images/Classification_of_summarization_tasks.png" alt="Figure 2.1: Classification of summarization tasks."></p>
<p>(G. Sizov(2010). <a target="_blank" rel="noopener" href="https://www.semanticscholar.org/paper/Extraction-Based-Automatic-Summarization%3A-and-of-Sizov/2d27fd9af4b10cc5b54a849a3c2ad84755b3b13c">Extraction-Based Automatic Summarization: Theoretical and Empirical Investigation of Summarization Techniques</a>)Text Summarization ì´ë€</p>
<h2 id="Text-Summarization-ê¸°ì´ˆ-ê°œë…"><a href="#Text-Summarization-ê¸°ì´ˆ-ê°œë…" class="headerlink" title="Text Summarization ê¸°ì´ˆ ê°œë…"></a>Text Summarization ê¸°ì´ˆ ê°œë…</h2><ul>
<li>Summarization ê¸°ë³¸ ìš©ì–´<ul>
<li>Original text &#x3D; Source text</li>
<li>generated summary &#x3D;  ëª¨ë¸ì´ ìƒì„±í•´ë‚¸ ìš”ì•½ë¬¸ì„ ì˜ë¯¸</li>
<li>reference summary &#x3D; ë°˜ë©´ ìš°ë¦¬ê°€ ì •ë‹µìœ¼ë¡œ ê°„ì£¼í•˜ëŠ”(ë³´í†µì€ ì‚¬ëŒì´ ì§ì ‘ ì›ë¬¸ì„ ë³´ê³  ìƒì„±í•œ) ìš”ì•½ë¬¸, ë˜ëŠ” gold summaryë¼ê³  ë¶€ë¦„<ul>
<li>ë³´í†µì€ ë‘ ìš©ì–´ë¥¼ í¬ê²Œ êµ¬ë¶„ì—†ì´ ì“°ëŠ”ë“¯ í•˜ë‚˜,  generated summaryëŠ” í‰ê°€í•˜ê¸° ìœ„í•œ ê¸°ì¤€ì´ ë˜ëŠ” ìš”ì•½ë¬¸ì´ë¼ëŠ” ë©´ì„ ê°•ì¡°í•  ë•Œ, gold summaryëŠ” ìš°ë¦¬ê°€ ì°¾ëŠ” ì§„ì§œ ìš”ì•½ë¬¸ì´ë¼ëŠ” ì ì„ ê°•ì¡°í•  ë•Œ ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë“¯ í•¨</li>
</ul>
</li>
<li>Metric: Rouge, BLEU, Perplexity(PPL) ë“±</li>
</ul>
</li>
</ul>
<p>ì°¸ê³ </p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/uoneway/Text-Summarization-Repo">https://github.com/uoneway/Text-Summarization-Repo</a></p>
</li>
<li><p>[ê¸€] <a target="_blank" rel="noopener" href="https://github.com/icoxfog417/awesome-text-summarization">icoxfog417. awesome-text-summarization</a></p>
</li>
<li><p>[PPT] <a target="_blank" rel="noopener" href="https://www.slideshare.net/cozyhous?utm_campaign=profiletracking&utm_medium=sssite&utm_source=ssslideview">Sang-Houn Choi. Text summarization</a></p>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/Deep-Learning/page/3/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/Deep-Learning/page/5/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/Deep-Learning/">1</a></li><li><a class="pagination-link" href="/categories/Deep-Learning/page/2/">2</a></li><li><a class="pagination-link" href="/categories/Deep-Learning/page/3/">3</a></li><li><a class="pagination-link is-current" href="/categories/Deep-Learning/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">ë…¸ë ¥ ë°±ì¤Œ ì—´ì • ì²œì¤Œì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">134</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">67</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">78</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê¸°ë³¸ ê°œë…</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ìì—°ì–´ìƒì„± ê°œë…</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ì¤‘ê¸‰ ê°œë…</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD íŒŒì´í”„ë¼ì¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ElasticSearch/"><span class="level-start"><span class="level-item">ElasticSearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/JPA/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/JPA/Basic/"><span class="level-start"><span class="level-item">Basic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%81%B4%EB%A6%B0%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">í´ë¦°ì½”ë“œ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Kotlin/"><span class="level-start"><span class="level-item">Kotlin</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/Kotlin/WebFlux/"><span class="level-start"><span class="level-item">WebFlux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Kotlin/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/OPS/"><span class="level-start"><span class="level-item">OPS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/%EC%84%A4%EC%B9%98/"><span class="level-start"><span class="level-item">ì„¤ì¹˜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/%ED%95%A8%EA%BB%98%EC%9E%90%EB%A6%AC%EA%B8%B0/"><span class="level-start"><span class="level-item">í•¨ê»˜ìë¦¬ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/Clean-Code/"><span class="level-start"><span class="level-item">Clean Code</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/TDD/"><span class="level-start"><span class="level-item">TDD</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">ë‚´ ì½”ë“œê°€ ê·¸ë ‡ê²Œ ì´ìƒí•œê°€ìš”</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Advanced-Concept/"><span class="level-start"><span class="level-item">Advanced Concept</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B0%8F-%EB%B9%84%EB%8F%99%EA%B8%B0/"><span class="level-start"><span class="level-item">ë™ì‹œì„± ë° ë¹„ë™ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">ë¬¸ë²•</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/REST/"><span class="level-start"><span class="level-item">REST</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/Spring-Framework/"><span class="level-start"><span class="level-item">Spring Framework</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">í•µì‹¬ ì›ë¦¬ - ê¸°ë³¸í¸</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/TIL/1%EB%A7%8C-%EC%8B%9C%EA%B0%84%EC%9D%98-%EB%B2%95%EC%B9%99/"><span class="level-start"><span class="level-item">1ë§Œ ì‹œê°„ì˜ ë²•ì¹™</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/"><span class="level-start"><span class="level-item">HTTP í”„ë¡œí† ì½œ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">ë°ì´í„° ì•”í˜¸í™”</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"><span class="level-start"><span class="level-item">ì¸ê³µì§€ëŠ¥</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC/"><span class="level-start"><span class="level-item">ê°œë… ì •ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EC%98%A4%EC%BC%80%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%85%98/"><span class="level-start"><span class="level-item">ì»¨í…Œì´ë„ˆ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EC%98%A4%EC%BC%80%EC%8A%A4%ED%8A%B8%EB%A0%88%EC%9D%B4%EC%85%98/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/"><span class="level-start"><span class="level-item">í†µê³„í•™</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/%EA%B8%B0%EB%B3%B8/"><span class="level-start"><span class="level-item">ê¸°ë³¸</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"><span class="level-start"><span class="level-item">íŒŒì´ì¬</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-03T13:08:34.000Z">2024-09-03</time></p><p class="title"><a href="/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD íŒŒì´í”„ë¼ì¸</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD íŒŒì´í”„ë¼ì¸</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T15:59:18.000Z">2024-09-02</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/AES-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA%E1%84%8B%E1%85%AA-RSA-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/">AES ì•”í˜¸í™”ì™€ RSA ì•”í˜¸í™”</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/">ë°ì´í„° ì•”í˜¸í™”</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-30T14:54:04.000Z">2024-08-30</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/HTTP%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%90%E1%85%A9%E1%84%8F%E1%85%A9%E1%86%AF/CORS/">CORS</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/">HTTP í”„ë¡œí† ì½œ</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-26T14:52:30.000Z">2024-08-26</time></p><p class="title"><a href="/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/">ëª¨ë‹ˆí„°ë§</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-19T14:22:16.000Z">2024-08-19</time></p><p class="title"><a href="/%EB%8F%99%EC%8B%9C%EC%84%B1-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-vs-%EB%B3%91%EB%A0%AC-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/">ë™ì‹œì„± í”„ë¡œê·¸ë˜ë° vs ë³‘ë ¬ í”„ë¡œê·¸ë˜ë°</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1ê¸‰ ì‹œë¯¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Springì´ë€</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python ì„¤ì¹˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">ê°ì²´ì§€í–¥</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">ë‹¤í˜•ì„±</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">ëŒë‹¤ì‹</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">ë²¡í„°ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">ì—”íŠ¸ë¡œí”¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">ì •ë³´ëŸ‰</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">ì •ë³´ì´ë¡ </span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/"><span class="tag">íŒŒë¼ë¯¸í„°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">í–‰ë ¬ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>