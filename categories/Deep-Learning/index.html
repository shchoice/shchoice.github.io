<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>Category: Deep Learning - Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">Deep Learning</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-01-22T14:51:21.000Z" title="1/22/2024, 11:51:21â€¯PM">2024-01-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-22T14:54:37.000Z" title="1/22/2024, 11:54:37â€¯PM">2024-01-22</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/Paper/">Paper</a></span><span class="level-item">9 minutes read (About 1304 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Finetuned-Language-Models-are-Zero-Shot-Learners/">Finetuned Language Models are Zero-Shot Learners</a></h1><div class="content"><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><ul>
<li>ì´ ë…¼ë¬¸ì€ LMì˜ zero-shot learning ëŠ¥ë ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ Instruction tuning ì´ë¼ëŠ” ê°„ë‹¨í•œ ë°©ë²•ì„ ì œì•ˆí•¨</li>
<li>137Bì˜ Pretrained LLMì¸ FLAN ë° instruction í…œí”Œë¦¿ë“¤ë¡œ êµ¬ì„±ëœ 60ê°œ ì´ìƒì˜ NLP ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•¨</li>
<li>FLANì€ Zero-shot ì„±ëŠ¥ì´ 175Bì˜ GPT-3 ëª¨ë¸ë³´ë‹¤ ì„±ëŠ¥ì´ ì¢‹ì•˜ìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/5dc6e601-56ec-4333-9984-da67501dd269" alt="FLAN 01"></p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><ul>
<li><p>GPT3ì™€ ê°™ì´ í° ê·œëª¨ì˜ LM ëª¨ë¸ë“¤ì—ì„œ few-shot learning ì˜ ì„±ëŠ¥ì€ ì¢‹ì•˜ìœ¼ë‚˜ zero-shot learningì—ì„œëŠ” ëœ ì„±ê³µì ì´ì—ˆë‹¤.</p>
</li>
<li><p>ìš°ë¦¬ëŠ” LLM ì—ì„œ zero-shot ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³ ì ê°„ë‹¨í•œ ë°©ë²•ì¸  Instruction Tuningì„ ì†Œê°œí•˜ë©° ë‹¤ìŒê³¼ ê°™ì€ í™˜ê²½ì—ì„œ ë…¼ë¬¸ì„ ì‘ì„±í•˜ì˜€ìŒ</p>
<ul>
<li>ëª¨ë¸ : FLAN(Fine-tuned LAnguage Net) ëª¨ë¸, 137Bì˜ Pretrained LLMì„ë° Instruction Tuningì„ ì‚¬ìš©</li>
<li>ë°ì´í„°ì…‹ : instruction í…œí”Œë¦¿ë“¤ë¡œ êµ¬ì„±ëœ 60ê°œ ì´ìƒì˜ NLP ë°ì´í„°ì…‹ì„ ì‚¬ìš©</li>
</ul>
</li>
<li><p>Instruction tuning ë°©ë²•ì€ pretrain-finetuneê³¼ prompt-based ë°©ë²•ë“¤ì˜ ì¥ì ë“¤ì„ ëª¨ë‘ ê°€ì§€ê³  ìˆìœ¼ë©° finetuningì„ í†µí•´ ì–¸ì–´ ëª¨ë¸ì˜ ì¶”ë¡  ë‹¨ê³„ì—ì„œ text ìƒí˜¸ì‘ìš©ë¥´ í–¥ìƒ ì‹œí‚´</p>
</li>
<li><p>ë³´ì§€ëª»í•œ tasksì— ëŒ€í•˜ì—¬ Zero-shot ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ ì NLP ë°ì´í„°ì…‹ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§ í•˜ì˜€ê³  ê° í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•´ hold-out evalutationì„ ìˆ˜í–‰</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/38005e2f-28a6-45ba-8dbc-d7da92984ff7" alt="FLAN 02"></p>
</li>
</ul>
<h2 id="2-FLAN-Instruction-Tuning-Imporves-Zero-SHot-Learning"><a href="#2-FLAN-Instruction-Tuning-Imporves-Zero-SHot-Learning" class="headerlink" title="2. FLAN : Instruction Tuning Imporves Zero-SHot Learning"></a>2. FLAN : Instruction Tuning Imporves Zero-SHot Learning</h2><h3 id="2-1-Tasks-amp-Templates"><a href="#2-1-Tasks-amp-Templates" class="headerlink" title="2.1 Tasks &amp; Templates"></a>2.1 Tasks &amp; Templates</h3><ul>
<li><p>62ê°œì˜ Text Datasetë“¤ì„ 12ê°œì˜ Task clusterë“¤ë¡œ ë¶„ë¥˜í•¨</p>
<ul>
<li>ìì—°ì–´ ì´í•´ TaskëŠ” íŒŒë€ìƒ‰ (ì§€ë¬¸ì„ ì½ê³  ë¬¸ì œë¥¼ ë§ì¶”ëŠ” ìœ í˜• ë“±ì´ ìˆìŒ)</li>
<li>ìì—°ì–´ ìƒì„± taskëŠ” ë¯¼íŠ¸ìƒ‰ (ëŒ€í‘œì ìœ¼ë¡œ ìš”ì•½ê³¼ ë²ˆì—­ì´ ìˆìŒ)</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8755111f-e080-4393-ab58-72505a5e014e" alt="FLAN 03"></p>
</li>
<li><p>ê°ê°ì˜ ë°ì´í„°ì…‹ì— ëŒ€í•œ Taskë¥¼ ì‘ì„±í•˜ê¸° ìœ„í•´ 10ê°œì˜ Templateë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬ì„±í•˜ì˜€ìŒ</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/be1bd4ef-82ee-43e0-bd1f-8d1e0e2f3fae" alt="FLAN 04"></p>
</li>
</ul>
<h3 id="2-4-Training-Detatils"><a href="#2-4-Training-Detatils" class="headerlink" title="2.4 Training Detatils"></a>2.4 Training Detatils</h3><ul>
<li>Model Architecture and pretraining<ul>
<li>137B íŒŒë¼ë¯¸í„°ì˜ Decoder-only Transformer LMì¸ LaMDA-PT ì— instruction tuningì„ ì‚¬ìš©í•˜ì˜€ìŒ</li>
</ul>
</li>
<li>Instruction tuning ì ˆì°¨</li>
</ul>
<h2 id="3-Results"><a href="#3-Results" class="headerlink" title="3. Results"></a>3. Results</h2><ul>
<li>NLI, Reading comprehension, closed-book QA , translation, commonsense reasoning, coreference resolution, struct-to-text ë“±ì˜ Taskë“¤ì— ëŒ€í•´ FLANì„ í‰ê°€í•˜ì˜€ê³  ë‹¤ìŒê³¼ ê°™ì€ ê²°ê³¼ë¥¼ ì–»ìŒ</li>
<li>Instruction Tuningì€ NLI, QA, translation, struct-to-text ë“±ì˜ Taskë“¤ì— ëŒ€í•´ì„œëŠ” ë§¤ìš° íš¨ê³¼ì ì´ì—ˆìŒ</li>
<li>ë‹¤ë§Œ commonsense reasoning, coreference resolution task ë“¤ ì²˜ëŸ¼ instructionì´ ë§¤ìš° ì¤‘ë³µë˜ê³  ì–¸ì–´ëª¨ë¸ë§ìœ¼ë¡œ í˜•ì‹í™”ëœ í…ŒìŠ¤í¬ì— ëŒ€í•´ì„œëŠ” ëœ íš¨ê³¼ì </li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/cf7fd74d-4824-45bc-9404-e9972b82e6b0" alt="FLAN 05"></p>
<h2 id="4-Ablation-Studies-amp-Further-Analysis"><a href="#4-Ablation-Studies-amp-Further-Analysis" class="headerlink" title="4. Ablation Studies &amp; Further Analysis"></a>4. Ablation Studies &amp; Further Analysis</h2><p>Instruction Tuningì´ ëª¨ë¸ì˜ Zero-shot ì„±ëŠ¥ì„ ì˜¬ë ¸ëŠ”ì§€ ì•Œì•„ë³´ê¸° ìœ„í•´ ablationì„ ì‚´í´ë³´ì</p>
<h3 id="4-1-Number-of-instruction-tuning-clusters"><a href="#4-1-Number-of-instruction-tuning-clusters" class="headerlink" title="4.1 Number of instruction tuning clusters"></a>4.1 Number of instruction tuning clusters</h3><ul>
<li>Cluster ì¦‰ taskë“¤ì´ ë§ì•„ì§ˆìˆ˜ë¡ ì œë¡œìƒ· ì„±ëŠ¥ì´ ëŠ˜ì–´ë‚¨ì„ í™•ì¸í•  ìˆ˜ ìˆìŒ</li>
<li>ë‹¨, ì´ ì‹¤í—˜ì€ ì–´ë–¤ instruction tuning êµ°ì§‘ì´ ê° í‰ê°€ êµ°ì§‘ì— ê°€ì¥ ë§ì€ ê¸°ì—¬ë¥¼ í•˜ëŠ”ì§€ ê²°ë¡ ì„ ë‚´ë¦´ ìˆ˜ ì—†ìœ¼ë©°, ê°ì • ë¶„ì„ êµ°ì§‘ìœ¼ë¡œëŠ” ì„±ëŠ¥ í–¥ìƒì´ ê±°ì˜ ì—†ë‹¤ëŠ” í•œê³„ê°€ ìˆì—ˆìŒ.</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/61324062-a997-45c7-b46d-e8d30f13f15e" alt="FLAN 06"></p>
<h3 id="4-2-Scaling-Laws"><a href="#4-2-Scaling-Laws" class="headerlink" title="4.2 Scaling Laws"></a>4.2 Scaling Laws</h3><p>ëª¨ë¸ì˜ í¬ê¸°ê°€ Instriction Tuningì— ì–´ë– í•œ ì˜í–¥ì„ ë¼ì³¤ëŠ”ê°€</p>
<ul>
<li>í‰ê°€ë¥¼ ìœ„í•´ ëª¨ë¸ Size:  422M, 2B, 8B, 68B, 137B ëª¨ë¸ë“¤ì„ ì‹¤í—˜êµ°ìœ¼ë¡œ ì‚¬ìš©</li>
<li>100B ì´ìƒì˜ ëª¨ë¸ì—ì„œëŠ” Instruction Modelì´ Untuned Modelì— ë¹„í•´ ìƒë‹¹íˆ ì„±ëŠ¥ì´ í–¥ìƒë¨</li>
<li>í•˜ì§€ë§Œ 8Bì´í•˜ì˜ ëª¨ë¸ì—ì„œëŠ” untuned ëª¨ë¸ì— ë¹„í•´ ì„±ëŠ¥ì´ ë–¨ì–´ì§<ul>
<li>ê·¸ ì´ìœ ëŠ” instruction ì´ ì¶”ê°€ëœ 40ì—¬ê°œì˜ tasksë“¤ì„ í•™ìŠµí•˜ëŠ” ë°ì— ëª¨ë¸ì˜ í¬ê¸°ê°€ ì‘ì•„ì„œ ê·¸ëŸ´ ê²ƒìœ¼ë¡œ  ì¶”ì •ë¨</li>
</ul>
</li>
</ul>
<h3 id="4-3-Role-of-Instructions"><a href="#4-3-Role-of-Instructions" class="headerlink" title="4.3 Role of Instructions"></a>4.3 Role of Instructions</h3><ul>
<li>ë‹¤ìŒì˜ ìƒí™©ë“¤ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰</li>
<li>No Instrction : inputê³¼ output ë§Œ ë„£ìŒ(Templateì´ ì—†ëŠ” ìƒíƒœ) (ex. ë²ˆì—­)<ul>
<li>input : â€œThe dog runs.â€</li>
<li>output :  â€œLe chien court</li>
</ul>
</li>
<li>Dataset ì´ë¦„ë§Œ ì ìŒ:<ul>
<li>input : â€œ[Translation: WMTâ€™14 to French] The dog runs.â€</li>
</ul>
</li>
<li>FLANì˜ Finetuning ë°©ë²•(Instruction Tuning)<ul>
<li>input : â€œPlease translate this sentence to French: â€˜The dog runs.â€</li>
</ul>
</li>
<li>ê·¸ ê²°ê³¼ FLANì˜ Instructionsê°€ zero-shot ì„±ëŠ¥ì—ì„œ ê°€ì¥ ìš°ìˆ˜í–ˆìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/a96b16ab-04d9-4741-9a8f-3bb0c4390127" alt="FLAN 07"></p>
<h3 id="4-4-Instructions-with-Few-shot-exemplars"><a href="#4-4-Instructions-with-Few-shot-exemplars" class="headerlink" title="4.4 Instructions with Few-shot exemplars"></a>4.4 Instructions with Few-shot exemplars</h3><ul>
<li>ì´ì „ê¹Œì§€ëŠ” instruction tuningì—ì„œ zero-shot settingì— ëŒ€í•´ì„œ ì•Œì•„ë³´ì•˜ê³  ì—¬ê¸°ì„œëŠ” few-shots ìƒí™©ì—ì„œ instructionì´ ì–´ë–»ê²Œ ì‚¬ìš©ë ì§€ì— ëŒ€í•´ì„œ ë§í•¨</li>
<li>few-shot instruction ì˜ˆì œë“¤ì€ ëª¨ë“  task clusterì—ì„œ zero-shot instruction ë³´ë‹¤ ë›°ì–´ë‚¬ìŒ</li>
<li>íŠ¹íˆ struct to text, translation closed-book QAì™€ ê°™ì´ í¬ê³  ë³µì¡í•œ ì¶œë ¥ì„ ê°–ëŠ” ì˜ˆì œì—ì„œ ì„±ëŠ¥ì´ ë” ì¢‹ì•˜ìŒ, exemplarsë¡œ ì¸í•´ ëª¨ë¸ì´ ë” ì˜ ì´í•´í–ˆê¸° ë•Œë¬¸</li>
<li>ë˜í•œ í‘œì¤€í¸ì°¨ê°€ few-shot FLAN ì—ì„œ ë” ë‚®ì•˜ìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ce7cb0f9-8e1e-4c5a-88e2-2325098bf104" alt="FLAN 07"></p>
<h3 id="4-5-Intruction-Tuning-Facilitates-Prompt-Tuning"><a href="#4-5-Intruction-Tuning-Facilitates-Prompt-Tuning" class="headerlink" title="4.5 Intruction Tuning Facilitates Prompt Tuning"></a>4.5 Intruction Tuning Facilitates Prompt Tuning</h3><ul>
<li>FLAN ëª¨ë¸ì´ Soft Promptë¡œ ì¶”ë¡ ì„ í•  ë•Œì—ë„ Untuned model ë³´ë‹¤ ì„±ëŠ¥ì´ í›¨ì”¬ ë†’ìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8f2b472b-de79-45d0-af7c-edc24785fd2e" alt="FLAN 08"></p>
<h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h2><ul>
<li>Intruction tuning ë°©ë²•ì„ í†µí•´ ê·œëª¨ìˆëŠ” LMì—ì„œ zero-shot taskë“¤ì— ëŒ€í•´ ì„±ëŠ¥ì„ ë†’ì˜€ê³  ê·¸ ê²°ê³¼ FLANì€ GPT-3 ë³´ë‹¤ ì„±ëŠ¥ì´ ë†’ì•˜ìœ¼ë©° ì–¸ì–´ëª¨ë¸ì´ instrcionì„ ë”°ë¥¼ ìˆ˜ ìˆëŠ” ì ì¬ì ì¸ ëŠ¥ë ¥ì„ í™•ì¸í•˜ì˜€ìŒ</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2024-01-10T14:46:29.000Z" title="1/10/2024, 11:46:29â€¯PM">2024-01-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-01-10T14:56:19.000Z" title="1/10/2024, 11:56:19â€¯PM">2024-01-10</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/Transformers/">Transformers</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/Transformers/TainingArugments/">TainingArugments</a></span><span class="level-item">16 minutes read (About 2443 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/TrainingArguments-padding%EA%B3%BC-max-length/">TrainingArguments - paddingê³¼ max_length</a></h1><div class="content"><p>Transformersì˜ Tokenizer ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ í•™ìŠµì„ í• ë•Œ paddingê³¼ max_length ì„¤ì •ì„ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ?</p>
<ol>
<li><p><strong>ëª¨ë¸ ì•„í‚¤í…ì²˜ê°€ ì–´ë–¤ ê²ƒì¸ì§€ í™•ì¸í•´ë³´ê¸°</strong></p>
<p>í¬ê²Œ GPT ê³„ì—´ì˜ ëª¨ë¸ê³¼ BERT ëª¨ë¸ì˜ ê³„ì—´ë¡œ ë‚˜ëˆ„ì–´ì„œ ìƒê°í•´ë³´ì.</p>
<ul>
<li><p>GPT ê³„ì—´ ëª¨ë¸</p>
<ul>
<li><p>GPTê³„ì—´ì˜ LLMì€ ê¸°ë³¸ì ìœ¼ë¡œ pad_tokenì„ ê°€ì§€ê³  ìˆì§€ ì•Šê³ , eos_tokenì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ëì„ ë‚˜íƒ€ëƒ„</p>
</li>
<li><p>ë”°ë¼ì„œ transformersë¡œ Tokenizerë¡œ í•™ìŠµì„ í•˜ë ¤ë©´ ë°˜ë“œì‹œ tokenizer.pad_token &#x3D; tokenizer.eos_token ì„ ì„¤ì •í•´ì•¼í•œë‹¤.</p>
</li>
<li><p>GPT ëª¨ë¸ì˜ íŠ¹ì„±</p>
<ul>
<li>PT ê³„ì—´ì˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(Large Language Models, LLM)ì€ ê¸°ë³¸ì ìœ¼ë¡œ **<code>pad_token</code>**ì„ í¬í•¨í•˜ì§€ ì•ŠìŒ</li>
<li>ëŒ€ì‹ , ì´ ëª¨ë¸ë“¤ì€ **<code>eos_token</code>**ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ëì„ ë‚˜íƒ€ëƒ„</li>
<li>ì´ëŠ” ì‹œí€€ìŠ¤ ìƒì„± ê³¼ì •ì—ì„œ ëª¨ë¸ì´ ì–¸ì œ ë¬¸ì¥ì´ ëë‚¬ëŠ”ì§€ë¥¼ ì¸ì‹í•˜ëŠ” ë° ì¤‘ìš”í•œ ì—­í• ì„ í•¨</li>
</ul>
</li>
<li><p>Tokenizer ì„¤ì •</p>
<ul>
<li><p>GPT ê³„ì—´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„ ì§„í–‰í•  ë•Œ, <strong><code>Transformers</code></strong> ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ **<code>Tokenizer</code>**ë¥¼ ì ì ˆíˆ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ **<code>tokenizer.pad_token = tokenizer.eos_token</code>**ìœ¼ë¡œ ì„¤ì •í•´ì•¼ í•¨(í•„ìˆ˜?)</p>
</li>
<li><p>ì´ë ‡ê²Œ ì„¤ì •í•¨ìœ¼ë¡œì¨, ëª¨ë¸ì€ íŒ¨ë”©ëœ ë¶€ë¶„ì„ ì‹œí€€ìŠ¤ì˜ ëìœ¼ë¡œ ì¸ì‹í•˜ê³ , í•´ë‹¹ ë¶€ë¶„ì„ ë¬´ì‹œí•  ìˆ˜ ìˆê²Œ ë¨</p>
</li>
<li><p>special_tokens_map.json ì„ ë³´ë©´ ë‹¤ìŒ ì„¸ê°€ì§€ ë°–ì— ì¡´ì¬í•˜ì§€ ì•ŠëŠ”ë‹¤.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="string">&quot;bos_token&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&lt;s&gt;&quot;</span>,</span><br><span class="line">    <span class="string">&quot;lstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;normalized&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;rstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;single_word&quot;</span>: false</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;eos_token&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&lt;/s&gt;&quot;</span>,</span><br><span class="line">    <span class="string">&quot;lstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;normalized&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;rstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;single_word&quot;</span>: false</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">&quot;unk_token&quot;</span>: &#123;</span><br><span class="line">    <span class="string">&quot;content&quot;</span>: <span class="string">&quot;&lt;unk&gt;&quot;</span>,</span><br><span class="line">    <span class="string">&quot;lstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;normalized&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;rstrip&quot;</span>: false,</span><br><span class="line">    <span class="string">&quot;single_word&quot;</span>: false</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
</li>
<li><p>BERT ê³„ì—´ ëª¨ë¸</p>
<ul>
<li>BERT ê³„ì—´ ëª¨ë¸ì˜ íŠ¹ì„±<ul>
<li>BERT ê³„ì—´ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ <strong><code>pad_token</code>*<em>ì´ ì •ì˜ë˜ì–´ ìˆìœ¼ë©°, ì‹œí€€ìŠ¤ì˜ ì‹œì‘(*</em><code>[CLS]</code>**)ê³¼ ë(</strong><code>[SEP]</code>**)ì„ ë‚˜íƒ€ë‚´ëŠ” íŠ¹ë³„í•œ í† í°ì„ ì‚¬ìš©</li>
</ul>
</li>
<li>Tokenizer ì„¤ì •<ul>
<li>BERT ëª¨ë¸ì˜ ê²½ìš°, **<code>padding=&quot;max_length&quot;</code>**ë¡œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì </li>
<li>ì´ëŠ” ëª¨ë“  ì‹œí€€ìŠ¤ê°€ ë™ì¼í•œ ìµœëŒ€ ê¸¸ì´ë¥¼ ê°–ë„ë¡ í•¨</li>
<li>ì´ ë°©ì‹ì€ ëª¨ë¸ì´ ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ í•˜ë©°, íŠ¹íˆ BERTì™€ ê°™ì€ ëª¨ë¸ì´ ë¬¸ì¥ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ë° ìœ ìš©</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>padding ë° max_length ì˜µì…˜ì— ëŒ€í•´ ì´í•´ë¥¼ í•´ë³´ì</strong></p>
<p><strong>Padding ì˜µì…˜</strong></p>
<ol>
<li>True: ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ê¸¸ì´ì— ë§ì¶”ì–´ ë‹¤ë¥¸ ëª¨ë“  ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©,ì´ëŠ” ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ìœ ìš©</li>
<li>False ë˜ëŠ” None: íŒ¨ë”©ì„ ìˆ˜í–‰í•˜ì§€ ì•ŠìŒ. ëª¨ë“  ì‹œí€€ìŠ¤ëŠ” ì›ë˜ì˜ ê¸¸ì´ë¥¼ ìœ ì§€</li>
<li>â€œmax_lengthâ€: ëª¨ë“  ì‹œí€€ìŠ¤ë¥¼ max_lengthì— ì§€ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”©í•©ë‹ˆë‹¤. ì´ëŠ” ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë° ì í•©</li>
<li>â€œlongestâ€: Trueì™€ ìœ ì‚¬í•˜ê²Œ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ì— ë§ì¶”ì–´ ë‚˜ë¨¸ì§€ ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ì˜µì…˜ì€ ëª…ì‹œì ìœ¼ë¡œ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ëŠ” ê²ƒì„ ê°•ì¡°</li>
</ol>
<p><strong>Max_length ì˜µì…˜</strong></p>
<ul>
<li>max_length ê°’ ì„¤ì •: max_lengthëŠ” ëª¨ë¸ì´ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì§€ì •, ê¸´ ì…ë ¥ì„ ì ì ˆí•œ í¬ê¸°ë¡œ ì˜ë¼ë‚´ëŠ” ë° ì‚¬ìš©ë˜ë©°, ë©”ëª¨ë¦¬ ì œí•œì´ë‚˜ ëª¨ë¸ ì•„í‚¤í…ì²˜ì˜ ì œí•œì„ ê³ ë ¤í•  ë•Œ ì¤‘ìš”</li>
<li>integer ê°’ìœ¼ë¡œ ì„¤ì •ì„ í•´ë„ ë¨</li>
</ul>
<p><strong>ì¶”ê°€ ì˜µì…˜</strong></p>
<ul>
<li>truncation:<ul>
<li>Trueë¡œ ì„¤ì •í•˜ë©´, max_lengthë³´ë‹¤ ê¸´ ì‹œí€€ìŠ¤ëŠ” ì˜ë ¤ë‚˜ê°€ì„œ max_length ê¸¸ì´ì— ë§ì¶°ì§</li>
<li><strong><code>False</code></strong> ë˜ëŠ” Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´, ì…ë ¥ ì‹œí€€ìŠ¤ê°€ max_lengthë¥¼ ì´ˆê³¼í•´ë„ ì˜ë¦¬ì§€ ì•ŠìŒ</li>
</ul>
</li>
<li>return_tensors:<ul>
<li>ì¶œë ¥ ë°ì´í„° íƒ€ì…ì„ ì§€ì •í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ptëŠ” PyTorch í…ì„œ, tfëŠ” TensorFlow í…ì„œ, npëŠ” NumPy ë°°ì—´ì„ ë°˜í™˜</li>
</ul>
</li>
<li>return_attention_mask:<ul>
<li>Trueë¡œ ì„¤ì •í•˜ë©´, ëª¨ë¸ì´ ì–´ë–¤ ë¶€ë¶„ì´ ì‹¤ì œ ë°ì´í„°ì´ê³  ì–´ë–¤ ë¶€ë¶„ì´ íŒ¨ë”©ì¸ì§€ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆëŠ” attention maskë¥¼ ë°˜í™˜</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Padding ë° max_legnth ë¥¼ ì„¤ì •í•˜ê¸°</strong></p>
<ul>
<li><p>GPT ëª¨ë¸ì¼ ê²½ìš°</p>
<ul>
<li><p><strong>ê°œë³„ì ì´ê±°ë‚˜ ìì—°ìŠ¤ëŸ¬ìš´ í…ìŠ¤íŠ¸ ìƒì„±ì„ ì¤‘ì‹œí•˜ëŠ” ê²½ìš°ì—ëŠ” <code>padding=False</code>ê°€ ë” í•©ë¦¬ì </strong>ì¼ ìˆ˜ ìˆìŒ (ê°œì¸ ìƒê°: ì¼ë°˜ì ìœ¼ë¡œëŠ” Falseê°€ ê°€ì¥ í•©ë¦¬ì ì¼ ê²ƒ ê°™ìŒ)</p>
</li>
<li><p><strong>ë°°ì¹˜ ì²˜ë¦¬ì˜ í•„ìš”ì„±ì´ ë†’ê³ , ëª¨ë“  ì…ë ¥ì„ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§ì¶°ì•¼ í•˜ëŠ” ê²½ìš°ì—ëŠ” <code>padding=True</code>ê°€ ì í•©</strong>í•  ìˆ˜ ìˆìŒ (ê°œì¸ìƒê°: **<code>max_length</code>**ì™€ <strong><code>longest</code></strong> ì˜µì…˜ì€ ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ ì²˜ë¦¬ì— ì í•©í•˜ì§€ë§Œ, GPTì™€ ê°™ì€ ìƒì„± ëª¨ë¸ì—ëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŒ)</p>
</li>
<li><p>ì¢€ë” ìì„¸íˆ ì•Œì•„ë³´ì</p>
<ul>
<li><p>Paddingì„ <strong><em>*Falseë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°*</em>:</strong></p>
<ol>
<li><strong>ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±</strong>: GPT ê³„ì—´ ëª¨ë¸ì€ ì£¼ë¡œ í…ìŠ¤íŠ¸ ìƒì„±ì— ì‚¬ìš©ë˜ê¸°ì—. padding&#x3D;Falseë¥¼ ì„¤ì •í•˜ë©´, ëª¨ë¸ì€ ê° ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ë©°, ì´ëŠ” ë³´ë‹¤ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ ìƒì„±ì— ë„ì›€ì´ ë  ìˆ˜ ìˆìŒ</li>
<li><strong>ë¶ˆí•„ìš”í•œ íŒ¨ë”© ë°©ì§€</strong>: íŠ¹íˆ ë‹¨ì¼ ì…ë ¥ì„ ì²˜ë¦¬í•  ë•Œ, ë¶ˆí•„ìš”í•œ íŒ¨ë”©ì„ ì¶”ê°€í•˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ ë” íš¨ìœ¨ì ìœ¼ë¡œ ì‘ë™í•˜ë„ë¡ í•˜ë©°, íŠ¹íˆ ì‘ì€ ë°ì´í„°ì…‹ì—ì„œ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ol>
<p>(ê°œì¸ ìƒê° : . GPT ëª¨ë¸ì€ ì—°ì†ì ì¸ í…ìŠ¤íŠ¸ ìƒì„±ì— ìµœì í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, íŒ¨ë”© ì—†ì´ ì‹¤ì œ ë°ì´í„°ì˜ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì´ ë” ìì—°ìŠ¤ëŸ¬ìš´ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ìˆì„ ê²ƒ)</p>
</li>
<li><p>Paddingì„ Trueë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°**:**</p>
<ol>
<li><strong>ë°°ì¹˜ ì²˜ë¦¬ì— ìœ ë¦¬</strong>: ì—¬ëŸ¬ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•´ì•¼ í•˜ëŠ” ê²½ìš°, padding&#x3D;TrueëŠ” ëª¨ë“  ì‹œí€€ìŠ¤ê°€ ê°™ì€ ê¸¸ì´ë¥¼ ê°–ë„ë¡ ë³´ì¥, ì´ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì—ì„œ ì¤‘ìš”í•˜ë©°, íŠ¹íˆ GPUë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì—°ì‚° íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŒ</li>
<li><strong>ë™ì  ê¸¸ì´ì˜ ì…ë ¥ ì²˜ë¦¬</strong>: ëª¨ë“  ì…ë ¥ì´ ë™ì¼í•œ ê¸¸ì´ë¥¼ ê°€ì§ìœ¼ë¡œì¨ ëª¨ë¸ì´ ë” ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ í•™ìŠµê³¼ ì¶”ë¡  ì„±ëŠ¥ì— ê¸ì •ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ol>
<p>(ê°œì¸ ìƒê° : , GPTì˜ ê²½ìš° ì¼ë°˜ì ìœ¼ë¡œ ìƒì„± ì‘ì—…ì— ì‚¬ìš©ë˜ê³  ë°°ì¹˜ ì²˜ë¦¬ê°€ ì¤‘ìš”í•˜ì§€ ì•Šê¸°ì— Falseê°€ ìœ ë¦¬í•  ê²ƒ ê°™ìŒ)</p>
</li>
<li><p>Paddingì„ max_lengthë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš° ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ ì²˜ë¦¬, Paddingì„ longestë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš° ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ê¸°ì¤€ì˜ íŒ¨ë”©ìœ¼ë¡œ Trueì™€ ê°™ì´ ì¢€ ë” ì ì ˆí•˜ì§€ ì•Šì•„ ë³´ì„</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>BERT ëª¨ë¸ì˜ ê²½ìš°</p>
<ul>
<li><p>ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì¼ê´€ëœ ê¸¸ì´ê°€ í•„ìš”í•˜ë‹¤ë©´ <strong><code>max_length</code></strong> ë˜ëŠ” **<code>longest</code>**ê°€ ì í•©í•  ìˆ˜ ìˆê³ </p>
</li>
<li><p>ê° ì‹œí€€ìŠ¤ì˜ ì›ë˜ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ë ¤ë©´ **<code>False</code>**ê°€ ì í•©í•  ìˆ˜ ìˆìŒ</p>
</li>
<li><p>ì¢€ë” ìì„¸íˆ ì•Œì•„ë³´ì</p>
<ul>
<li><p>Paddingì„ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True</span><br></pre></td></tr></table></figure>

<p>ë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°:</p>
<ul>
<li><strong>ë™ì  ê¸¸ì´ì˜ ì…ë ¥ ì²˜ë¦¬</strong>: <strong>True</strong>ë¡œ ì„¤ì •í•˜ë©´ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ì— ë§ì¶”ì–´ ë‚˜ë¨¸ì§€ ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©í•©ë‹ˆë‹¤. ì´ëŠ” ë™ì  ê¸¸ì´ì˜ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” ë° ìœ ìš©í•˜ë©°, íŠ¹íˆ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ ë¬¸ì¥ë“¤ì´ ì„ì—¬ ìˆëŠ” ë°ì´í„°ì…‹ì— ì í•©í•©ë‹ˆë‹¤.</li>
<li><strong>ë°°ì¹˜ ì²˜ë¦¬ì— íš¨ìœ¨ì </strong>: ì—¬ëŸ¬ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•  ë•Œ, ëª¨ë“  ì‹œí€€ìŠ¤ê°€ ê°™ì€ ê¸¸ì´ë¥¼ ê°–ë„ë¡ í•˜ì—¬ GPU ë“±ì˜ ìì›ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ul>
</li>
<li><p>Paddingì„ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">False</span><br></pre></td></tr></table></figure>

<p>ë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°:</p>
<ul>
<li><strong>íŒ¨ë”© ì—†ìŒ</strong>: ì‹œí€€ìŠ¤ì˜ ì‹¤ì œ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ë©°, íŒ¨ë”©ì„ ì¶”ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì´ëŠ” ê° ë¬¸ì¥ì˜ ì›ë˜ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ê³ ì í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.</li>
<li><strong>ê°œë³„ ì‹œí€€ìŠ¤ ì²˜ë¦¬ì— ì í•©</strong>: ë‹¨ì¼ ë¬¸ì¥ ë¶„ë¥˜ë‚˜ íŠ¹ì • ì‘ì—…ì—ì„œ ê° ë¬¸ì¥ì˜ ì‹¤ì œ ê¸¸ì´ë¥¼ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ul>
</li>
<li><p>Paddingì„ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">max_length</span><br></pre></td></tr></table></figure>

<p>ë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°:</p>
<ul>
<li><strong>ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ ì²˜ë¦¬</strong>: ëª¨ë“  ì‹œí€€ìŠ¤ë¥¼ <strong>max_length</strong>ì— ì§€ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”©í•©ë‹ˆë‹¤. ì´ëŠ” íŠ¹íˆ ëª¨ë¸ì´ ê³ ì •ëœ ê¸¸ì´ì˜ ì…ë ¥ì„ ìš”êµ¬í•˜ëŠ” ê²½ìš°ì— ì í•©í•©ë‹ˆë‹¤.</li>
<li><strong>ì¼ê´€ëœ ì…ë ¥ ê¸¸ì´</strong>: í›ˆë ¨ê³¼ ì¶”ë¡  ì‹œ ì¼ê´€ëœ ê¸¸ì´ì˜ ì…ë ¥ì„ ì œê³µí•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</li>
</ul>
</li>
<li><p>Paddingì„ </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">longest</span><br></pre></td></tr></table></figure>

<p>ë¡œ ì„¤ì •í•˜ëŠ” ê²½ìš°:</p>
<ul>
<li><strong>ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ ê¸°ì¤€ì˜ íŒ¨ë”©</strong>: ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ì— ë§ì¶”ì–´ ë‚˜ë¨¸ì§€ ì‹œí€€ìŠ¤ë¥¼ íŒ¨ë”©í•©ë‹ˆë‹¤. ì´ëŠ” <strong>True</strong>ì™€ ìœ ì‚¬í•˜ì§€ë§Œ, ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ìŠµë‹ˆë‹¤.</li>
<li><strong>ë°°ì¹˜ ì²˜ë¦¬ì— ì í•©</strong>: ì—¬ëŸ¬ ì‹œí€€ìŠ¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ì— ì í•©í•˜ë©°, ê° ë°°ì¹˜ ë‚´ì—ì„œ ê°€ì¥ ê¸´ ì‹œí€€ìŠ¤ì— ë§ì¶”ì–´ íŒ¨ë”©ì„ ì§„í–‰í•©ë‹ˆë‹¤.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>paddingê³¼ max_length ì— ë”°ë¥¸ í† í¬ë‚˜ì´ì¦ˆ ê²°ê³¼ë¥¼ í™•ì¸í•´ë³´ì</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig</span><br><span class="line"><span class="keyword">from</span> peft <span class="keyword">import</span> (</span><br><span class="line">    prepare_model_for_kbit_training,</span><br><span class="line">    LoraConfig,</span><br><span class="line">    get_peft_model</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model_id = <span class="string">&quot;huggyllama/llama-7b&quot;</span></span><br><span class="line"></span><br><span class="line">bnb_config = BitsAndBytesConfig(</span><br><span class="line">    load_in_4bit=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_use_double_quant=<span class="literal">True</span>,</span><br><span class="line">    bnb_4bit_quant_type=<span class="string">&quot;nf4&quot;</span>,</span><br><span class="line">    bnb_4bit_compute_dtype=torch.bfloat16</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model = AutoModelForCausalLM.from_pretrained(</span><br><span class="line">    model_id,</span><br><span class="line">    quantization_config=bnb_config</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
</li>
<li><p>Case 01: padding&#x3D;False, max_length&#x3D;16</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=<span class="literal">True</span>, add_eos_token=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;right&#x27;</span></span><br><span class="line"></span><br><span class="line">sample_sentence = [<span class="string">&quot;Hello, world!&quot;</span>, <span class="string">&quot;Hello, Alpaca world!&quot;</span>]</span><br><span class="line">context_length = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">tokenized_output = tokenizer(</span><br><span class="line">    sample_sentence,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">    max_length = context_length,</span><br><span class="line">    return_overflowing_tokens=<span class="literal">False</span>,</span><br><span class="line">    return_length=<span class="literal">True</span>,</span><br><span class="line">    padding=<span class="literal">False</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenized_output)</span><br><span class="line"><span class="comment"># &#123;&#x27;input_ids&#x27;: [[1, 15043, 29892, 3186, 29991, 2], [1, 15043, 29892, 838, 29886, 11989, 3186, 29991, 2]], &#x27;attention_mask&#x27;: [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]], &#x27;length&#x27;: [6, 9]&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Case 02: padding&#x3D;Ture, max_length&#x3D;16</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=<span class="literal">True</span>, add_eos_token=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;right&#x27;</span></span><br><span class="line"></span><br><span class="line">sample_sentence = [<span class="string">&quot;Hello, world!&quot;</span>, <span class="string">&quot;Hello, Alpaca world!&quot;</span>]</span><br><span class="line">context_length = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">tokenized_output = tokenizer(</span><br><span class="line">    sample_sentence,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">    max_length = context_length,</span><br><span class="line">    return_overflowing_tokens=<span class="literal">False</span>,</span><br><span class="line">    return_length=<span class="literal">True</span>,</span><br><span class="line">    padding=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenized_output)</span><br><span class="line"><span class="comment"># &#123;&#x27;input_ids&#x27;: [[1, 15043, 29892, 3186, 29991, 2, 2, 2, 2], [1, 15043, 29892, 838, 29886, 11989, 3186, 29991, 2]], &#x27;attention_mask&#x27;: [[1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1]], &#x27;length&#x27;: [9, 9]&#125;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>Case 03: padding&#x3D;â€™max_lengthâ€™, max_length&#x3D;16</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=<span class="literal">True</span>, add_eos_token=<span class="literal">True</span>)</span><br><span class="line">tokenizer.pad_token = tokenizer.eos_token</span><br><span class="line">tokenizer.padding_side = <span class="string">&#x27;right&#x27;</span></span><br><span class="line"></span><br><span class="line">sample_sentence = [<span class="string">&quot;Hello, world!&quot;</span>, <span class="string">&quot;Hello, Alpaca world!&quot;</span>]</span><br><span class="line">context_length = <span class="number">16</span></span><br><span class="line"></span><br><span class="line">tokenized_output = tokenizer(</span><br><span class="line">    sample_sentence,</span><br><span class="line">    truncation=<span class="literal">True</span>,</span><br><span class="line">    max_length = context_length,</span><br><span class="line">    return_overflowing_tokens=<span class="literal">False</span>,</span><br><span class="line">    return_length=<span class="literal">True</span>,</span><br><span class="line">    padding=<span class="string">&#x27;max_length&#x27;</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tokenized_output)</span><br><span class="line"><span class="comment"># &#123;&#x27;input_ids&#x27;: [[1, 15043, 29892, 3186, 29991, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], [1, 15043, 29892, 838, 29886, 11989, 3186, 29991, 2, 2, 2, 2, 2, 2, 2, 2]], &#x27;attention_mask&#x27;: [[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]], &#x27;length&#x27;: [16, 16]&#125;</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-10-02T14:59:13.000Z" title="10/2/2023, 11:59:13â€¯PM">2023-10-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:59.000Z" title="12/21/2023, 12:40:59â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">3 minutes read (About 445 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/4%E1%84%8C%E1%85%A1%E1%86%BC-Sequence2Sequence-AMP-Automatic-Mixed-Precision/">4ì¥. Sequence2Sequence - AMP(Automatic Mixed Precision)</a></h1><div class="content"><h2 id="Motivations"><a href="#Motivations" class="headerlink" title="Motivations"></a>Motivations</h2><ul>
<li>GPUì˜ í•œê³„ë¡œ ì¸í•œ í•™ìŠµì˜ ë¹„íš¨ìœ¨ì„±ì„ í•´ì†Œí•  ìˆ˜ ìˆìœ¼ë©´ ì¢‹ì„ ê²ƒ<ul>
<li>ë©”ëª¨ë¦¬ : ë” í° ëª¨ë¸ë¡œ ë” í° ë°°ì¹˜ ì‚¬ì´ì¦ˆë¡œ í•™ìŠµ</li>
<li>ì—°ì‚° ì†ë„ : Float Point16(half-precision)<ul>
<li>Double 64 bits, Float 32 Bits (ì‘ì€ ì‹¤ìˆ˜ í‘œí˜„ ë°ì´í„° íƒ€ì…ì„ ì‚¬ìš©í•˜ë©´ ì—°ì‚° ì†ë„ê°€ ë” ë¹¨ë¼ì§)</li>
</ul>
</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ FP16ì˜ ê²½ìš° í‘œí˜„ ë²”ìœ„ì˜ í•œê³„ê°€ ìˆì–´, ë„ˆë¬´ ì‘ì€ ê°’ì˜ ê²½ìš° 0ìœ¼ë¡œ í‘œí˜„ë¨<ul>
<li>ë„ˆë¬´ ì‘ì€ ê°’ìœ¼ë¡œ ë‚˜ëˆŒ ê²½ìš° NaNìœ¼ë¡œ ê°’ì´ ë°˜í™˜ë¨(underflow)</li>
<li>ë§ˆì°¬ê°€ì§€ë¡œ ë„ˆë¬´ í° ê°’ì˜ ê²½ìš°ì—ëŠ” infë¡œ í‘œí˜„ë¨(overflow)</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/28f6b73f-0b5d-4e06-a54e-0c08feb8aa05" alt="AutomaticMixedPrecision01"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/28f6b73f-0b5d-4e06-a54e-0c08feb8aa05">https://github.com/shchoice/shchoice.github.io/assets/100276387/28f6b73f-0b5d-4e06-a54e-0c08feb8aa05</a></p>
<h2 id="Mixec-Precision-Training-Narang-and-Micikevicius-et-al-2018"><a href="#Mixec-Precision-Training-Narang-and-Micikevicius-et-al-2018" class="headerlink" title="Mixec Precision Training [Narang and Micikevicius et al., 2018]"></a>Mixec Precision Training <strong>[Narang and Micikevicius et al., 2018]</strong></h2><ul>
<li><p>í•„ìš”ì— ë”°ë¼ scalingì„ í†µí•´ FP16ì— í‘œí˜„ ê°€ëŠ¥í•œ ë²”ìœ„ ë‚´ì—ì„œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9aab579f-9ed7-41a0-930d-bc13a1c3f4b9" alt="AutomaticMixedPrecision02"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/9aab579f-9ed7-41a0-930d-bc13a1c3f4b9">https://github.com/shchoice/shchoice.github.io/assets/100276387/9aab579f-9ed7-41a0-930d-bc13a1c3f4b9</a></p>
</li>
<li><p>ì†ë„ëŠ” ë” ë¹ ë¥´ë©´ì„œ, ì„±ëŠ¥ì€ ë¹„ìŠ·í•˜ê±°ë‚˜ ë›°ì–´ë‚œ íš¨ê³¼</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/fe094e01-7e0f-4585-ae8f-2d9e3b29a87f" alt="AutomaticMixedPrecision03"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/fe094e01-7e0f-4585-ae8f-2d9e3b29a87f">https://github.com/shchoice/shchoice.github.io/assets/100276387/fe094e01-7e0f-4585-ae8f-2d9e3b29a87f</a></p>
</li>
<li><p>PyTorchì—ì„œì˜ AMP</p>
<ul>
<li><p>ì°¸ê³  : <a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/amp_examples.html">https://pytorch.org/docs/stable/notes/amp_examples.html</a> <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4e222c6b-48b9-46f9-937c-be0aebf64e98" alt="AutomaticMixedPrecision04"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/4e222c6b-48b9-46f9-937c-be0aebf64e98">https://github.com/shchoice/shchoice.github.io/assets/100276387/4e222c6b-48b9-46f9-937c-be0aebf64e98</a></p>
</li>
</ul>
</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul>
<li>AMPë¥¼ í†µí•´ FP16ìœ¼ë¡œ ì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ<ul>
<li>ì´ë¥¼ í†µí•´ ì†ë„ ì¦ê°€ì™€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŒ</li>
<li>ëª‡ ê°€ì§€ ì¶”ê°€ì ì¸ ì˜ˆì™¸ ì²˜ë¦¬(e.g. NaN, Inf ì²˜ë¦¬ ë° CPU ì—°ì‚°ì²˜ë¦¬)ê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-09-29T14:37:14.000Z" title="9/29/2023, 11:37:14â€¯PM">2023-09-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:41:01.000Z" title="12/21/2023, 12:41:01â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">3 minutes read (About 392 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/4%E1%84%8C%E1%85%A1%E1%86%BC-Sequence2Sequence-Gradient-Accumlations/">4ì¥. Sequence2Sequence - Gradient Accumlations</a></h1><div class="content"><h2 id="Batch-Size"><a href="#Batch-Size" class="headerlink" title="Batch Size"></a>Batch Size</h2><ul>
<li>í° ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” epoch ë‚´ì˜ forward &amp; backward íšŸìˆ˜ë¥¼ ì¤„ì—¬ì£¼ì–´ í•™ìŠµì˜ ì†ë„ë¥¼ ë†’ì—¬ì¤Œ<ul>
<li>í•œ epoch ë‚´ì—ì„œ íŒŒë¼ë¯¸í„°ì˜ update íšŸìˆ˜, ì¦‰ iterationì´ ì¤„ì–´ë“¤ìŒ</li>
</ul>
</li>
<li>ë˜í•œ ë°°ì¹˜ ì‚¬ì´ì¦ˆì— ë”°ë¼ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë°”ë€” ìˆ˜ ìˆìŒ<ul>
<li>ì‘ì€ ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” local minimaë¥¼ íƒˆì¶œ í•  ìˆ˜ ìˆë‹¤ê³  ì•Œë ¤ì ¸ ìˆìœ¼ë‚˜</li>
<li>í° ë°ì´í„°ì…‹ì—ì„œëŠ” ë°°ì¹˜ì‚¬ì´ì¦ˆê°€ í´ìˆ˜ë¡ ì˜¤íˆë ¤ ì„±ëŠ¥ì´ ë†’ì•„ì§€ê¸°ë„ í•¨</li>
</ul>
</li>
<li>ë”°ë¼ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë–¨ì–´ì§€ì§€ ì•ŠëŠ” í•œë„ ë‚´ì—ì„œ, ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ìµœëŒ€ë¡œ í•˜ì—¬ í•™ìŠµì„ ë¹ ë¥´ê²Œ ì§„í–‰í•  ìˆ˜ ìˆìŒ<ul>
<li>ê¸°ë³¸ì ìœ¼ë¡œ SGDë¥¼ ì‚¬ìš©í•  ê²½ìš°, LRê³¼ ë°°ì¹˜ ì‚¬ì´ì¦ˆëŠ” ë¹„ë¡€ ê´€ê³„ë¥¼ ê°–ê²Œë¨</li>
<li>í•˜ì§€ë§Œ Adamì„ ì‚¬ìš©í•  ê²½ìš°, LRì— í¬ê²Œ ì‹ ê²½ ì“¸ í•„ìš” ì—†ìŒ</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ GPU ë©”ëª¨ë¦¬ê°€ í—ˆë½í•˜ì§€ ì•ŠìŒ</li>
</ul>
<h2 id="Gradient-Accumulation"><a href="#Gradient-Accumulation" class="headerlink" title="Gradient Accumulation"></a>Gradient Accumulation</h2><ul>
<li><p>Forward &amp; Backwardë¥¼ í•  ë•Œë§ˆë‹¤ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸(optimizer.step())ë¥¼ í•˜ëŠ” ëŒ€ì‹ , gradientë¥¼ ëˆ„ì í•´ì„œ ë‚˜ì¤‘ì— í•œë²ˆì— ì—…ë°ì´íŠ¸ í•˜ëŠ” ë°©ë²•</p>
<ul>
<li>ë§ˆì¹˜ ëˆ„ì  íšŸìˆ˜ ë§Œí¼ì˜ ë°°ì¹˜ì‚¬ì´ì¦ˆê°€ ì¦ê°€ëœ íš¨ê³¼</li>
<li>ex) kë²ˆ accumlation &#x3D; k * batch_size $\theta \leftarrow \theta + \Delta_\theta \sum_{i&#x3D;1}^{N} y_i \log f_\theta (x_i)$</li>
</ul>
</li>
<li><p>ì†ë„ ìƒì˜ ì´ì ì€ ì—†ìŒ (í•˜ì§€ë§Œ batch_sizeê°€ ì»¤ì§€ëŠ” ê²ƒê³¼ ê°™ì€ íš¨ê³¼)</p>
</li>
<li><p>Seq2Seqì—ì„  Adam optimizer ê¸°ì¤€ batch_size 256ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥</p>
<ul>
<li>iteration_per_update íŒŒë¼ë¯¸í„°ë¡œ ì¡°ì ˆ(k&#x3D;4 * batch_size&#x3D;64 &#x3D; 256 íš¨ê³¼)</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/d5b8e647-1b29-450d-a51b-cd775e2cf7c1" alt="GradientAccumlation"></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-26T14:51:03.000Z" title="8/26/2023, 11:51:03â€¯PM">2023-08-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:41:19.000Z" title="12/21/2023, 12:41:19â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">23 minutes read (About 3468 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/4%E1%84%8C%E1%85%A1%E1%86%BC-Sequence2Sequence-Machine-Translation-%E1%84%89%E1%85%A9%E1%84%80%E1%85%A2/">4ì¥.  Sequence2Sequence - Machine Translation ì†Œê°œ</a></h1><div class="content"><h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2><ul>
<li><p>Objective</p>
<ul>
<li><p>$\hat{y} &#x3D; \text{argmax}</p>
<p>{y \in Y} P</p>
<p>{x \to y}(y|x)$</p>
<ul>
<li>xì—ì„œ yë¡œ ë³€ì—­ì„ í•˜ëŠ” task</li>
<li>ë²ˆì—­ì„ í•œë‹¤ëŠ” ê²ƒì€ ì–´ë–¤ xê°€ ì£¼ì–´ì¡Œì„ ë•Œ yê°€ ê°€ëŠ¥í•œ ë¬¸ì¥ì˜ ì§‘í•© ì¤‘ ìµœëŒ€ë¡œ í•˜ëŠ” ë¬¸ì¥ì„ ê³ ë¦„ì„ ì˜ë¯¸</li>
</ul>
</li>
</ul>
</li>
<li><p>History</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/81a1c036-206c-402d-9fe8-83466f5758e5" alt="MTHistory"></p>
</li>
<li><p>NMT ê¸°ë°˜ ê¸°ê³„ë²ˆì—­ì— ì‚¬ìš©ë˜ëŠ” ì´ìœ </p>
<ul>
<li>End-to-End ëª¨ë¸<ul>
<li>SMT ë°©ì‹ì€ ì—¬ëŸ¬ sub-moduleë“¤ì´ ì§„í–‰ë ìˆ˜ë¡ errorê°€ ê°€ì¤‘ë¨</li>
</ul>
</li>
<li>Better generalization<ul>
<li>Discreteí•œ ë‹¨ì–´ë¥¼ Continuousí•œ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ê³„ì‚°<ul>
<li>Word embedding</li>
<li>Context embedding</li>
</ul>
</li>
</ul>
</li>
<li>LSTMê³¼ Attentionì˜ ì ìš©<ul>
<li>Sequenceì˜ ê¸¸ì´ì— êµ¬ì• ë°›ì§€ ì•Šê³  ë²ˆì—­</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Sequence-to-Sequence"><a href="#Sequence-to-Sequence" class="headerlink" title="Sequence-to-Sequence"></a>Sequence-to-Sequence</h2><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/605eca16-dfaf-4916-931e-0a889cddfb29" alt="seq2seq"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/605eca16-dfaf-4916-931e-0a889cddfb29">https://github.com/shchoice/shchoice.github.io/assets/100276387/605eca16-dfaf-4916-931e-0a889cddfb29</a></p>
<ul>
<li><p>Given dataset</p>
<ul>
<li><p>$D&#x3D;{x^i, y^i}_{i&#x3D;1}^{N}$  &#x2F;&#x2F; ğ‘¥ ~ ğ‘ƒ(ğ‘¥) y ~ ğ‘ƒ(ğ‘¥) ğ‘¥ì—ì„œ yë¡œ ì¦‰ í•œê¸€ì„ ì˜ì–´ë¡œ ë²ˆì—­.</p>
<p>$x^i &#x3D; {x_1^i, \ldots, x_m^i} \text{ } y^i &#x3D; {y_0^i, y_1^i, \ldots, y_n^i}$</p>
<p>where $y_0&#x3D;$<BOS>, $y_n&#x3D;$<EOS></p>
</li>
</ul>
</li>
<li><p>Find parameter that maximize likelihood,</p>
<ul>
<li><p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(y^i|x^{i}; \theta)$ &#x2F;&#x2F; ë°ì´í„°ì— ëŒ€í•´ log-likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì</p>
<p>$&#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(y_{j}^{i}|x^i, y_{&lt;j}^i; \theta)$ &#x2F;&#x2F; by chain-rule</p>
</li>
</ul>
</li>
<li><p>Minimize loss function by upgrading parameter with gradient descent.</p>
<ul>
<li><p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(y_{j}^{i},|x^i,y_{&lt;j}^i; \theta)$</p>
<p>$\theta \leftarrow \theta - \eta\nabla_\theta L(\theta)$</p>
<p>$\log P(x_t | x_{&lt;t}; \theta) &#x3D; x_t^T \cdot \log f_\theta(x_{t-1}, h_{t-1})$ &#x2F;&#x2F; softmax layerë¥¼ í†µê³¼í•˜ëŠ” ê²½ìš°,<br>                                            &#x2F;&#x2F; $x_t^T$ : GT (One-hot vector, ì‹¤ì œ ì˜ˆì¸¡ ë‹¨ì–´)<br>                                           &#x2F;&#x2F; $\log f_\theta(x_{t-1}, h_{t-1})$ : LM(softmax layerì— log ì”Œìš´ í™•ë¥ ê°’)<br><br>$\text{where } x_t \text{ is one- hot vector, and }f_Î¸ \text{ is model with parameter Î¸.}$</p>
</li>
</ul>
</li>
<li><p>Applications</p>
<table>
<thead>
<tr>
<th>Seq2Seq Applications</th>
<th>Task(From-To)</th>
</tr>
</thead>
<tbody><tr>
<td>Neutal Machine Translation(NMT)</td>
<td>íŠ¹ì • ì–¸ì–´ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ë‹¤ë¥¸ ì–¸ì–´ì˜ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥</td>
</tr>
<tr>
<td>Chatbot</td>
<td>ì‚¬ìš©ìì˜ ë¬¸ì¥ì„ ì…ë ¥ ë°›ì•„ ëŒ€ë‹µì„ ì¶œë ¥</td>
</tr>
<tr>
<td>Summarization</td>
<td>ê¸´ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê°™ì€ ì–¸ì–´ì˜ ìš”ì•½ëœ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥</td>
</tr>
<tr>
<td>Automatic Speech Recognition(ASR)</td>
<td>ì‚¬ìš©ìì˜ ë¬¸ì¥ ì…ë ¥ì„ ë°›ì•„ í”„ë¡œê·¸ë˜ë° ì½”ë“œë¡œ ì¶œë ¥</td>
</tr>
<tr>
<td>extract summê³¼ abstactive summ 2ê°€ì§€ í˜•íƒœë¡œ ìˆìŒ</td>
<td></td>
</tr>
<tr>
<td>Lip Reading</td>
<td>ìŒì„±ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í•´ë‹¹ ì–¸ì–´ì˜ ë¬¸ìì—´(ë¬¸ì¥)ìœ¼ë¡œ ì¶œë ¥</td>
</tr>
<tr>
<td>Image Captioning</td>
<td>ì…ìˆ  ì›€ì§ì„ì˜ ë™ì˜ìƒì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í•´ë‹¹ ì–¸ì–´ì˜ ë¬¸ì¥ìœ¼ë¡œ ì¶œë ¥</td>
</tr>
<tr>
<td>other NLP Task</td>
<td>ë³€í˜•ëœ seq2seqë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ê·¸ë¦¼ì„ ì„¤ëª…í•˜ëŠ” ë¬¸ì¥ì„ ì¶œë ¥</td>
</tr>
</tbody></table>
</li>
</ul>
<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><ul>
<li>EncoderëŠ” source ë¬¸ì¥ì„ conext vectorë¡œ ì••ì¶•í•˜ê³  decoderì—ê²Œ ë„˜ê²¨ì¤Œ</li>
<li>EncoderëŠ” train&#x2F;test ì‹œì— í•­ìƒ ë¬¸ì¥ ì „ì²´ë¥¼ ë°›ìŒ<ul>
<li>Encoder ìì²´ë§Œ ë†“ê³  ë³´ë©´ non-auto-regressive task</li>
<li>ë”°ë¼ì„œ bi-directional RNN ì‚¬ìš© ê°€ëŠ¥</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6f7e2e7b-d18d-4299-9866-775c122e931c" alt="Encoder01"></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/36f665ec-5d54-4f30-817f-ad6c1ce2cf67" alt="Encoder02"></p>
<ul>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>Given dataset</p>
<ul>
<li><p>$D&#x3D;{x^i, y^i}_{i&#x3D;1}^{N}$</p>
<ul>
<li>&#x2F;&#x2F; ğ‘¥ ~ ğ‘ƒ(ğ‘¥) y ~ ğ‘ƒ(ğ‘¥) ğ‘¥ì—ì„œ yë¡œ ì¦‰ í•œê¸€ì„ ì˜ì–´ë¡œ ë²ˆì—­.</li>
</ul>
<p>$x^i &#x3D; {x_1^i, \ldots, x_m^i} \text{ } y^i &#x3D; {y_0^i, y_1^i, \ldots, y_n^i}$</p>
<ul>
<li>|$x^i$| &#x3D; (bs, m, |$v_{soure}$|)</li>
<li>|$y^i$|&#x3D;(bs,n,|$v_{target}$|)</li>
</ul>
<p>where $y_0&#x3D;$<BOS>, $y_n&#x3D;$<EOS></p>
</li>
</ul>
</li>
<li><p>Get hidden states of encoder</p>
<ul>
<li><p>$h_{t}^{enc} &#x3D; RNN_{enc}(emb_{enc}(x_t), h_{t-1}^{enc}) \text{ where    } h_0^{enc} &#x3D; 0$</p>
<ul>
<li>$h_{t}^{enc}$&#x3D;(ğ‘ğ‘ , 1,â„ğ‘ )</li>
<li>|$x_t$|&#x3D;(ğ‘ğ‘ , 1, |$v_s$|) -&gt; emb layer í†µê³¼ í›„ (bs,1,ws(wordembedding_vector_size))</li>
</ul>
<p>$h_{1:m}^{enc} &#x3D; [h_{1}^{i}; \ldots; h_{m}^{enc}]$</p>
<ul>
<li>;ëŠ” concatì„ ì˜ë¯¸, $h_{1:m}^{enc}$&#x3D;(bs,m,hs)</li>
</ul>
<p>$\text{where } h_{t}^{enc} \in \mathbb{R}^{batchsize \times 1 \times hiddensize}$, $h_{1:m}^{enc} \in \mathbb{R}^{batchsize \times m \times hiddensize}$</p>
</li>
</ul>
</li>
<li><p>if we use bi-directional RNN</p>
<ul>
<li>$h_{t}^{enc} \in \mathbb{R}^{batchsize \times 1 \times (2 \times hiddensize)}$, $h_{1:m}^{enc} \in \mathbb{R}^{batchsize \times m \times (2 \times hiddensize)}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><ul>
<li><p>Decoder(One-to-Many)ëŠ” conditional language modelì´ë¼ê³  ë³¼ ìˆ˜ ìˆìŒ</p>
<ul>
<li><p>ì¸ì½”ë”ë¡œë¶€í„° ë¬¸ì¥ì„ ì••ì¶•í•œ context vectorë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì¥ì„ ìƒì„±</p>
<ul>
<li><p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(y^i|x^{i}; \theta)$</p>
<p>$&#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(y_{j}^{i}|x^i, y_{&lt;j}^i; \theta)$</p>
<ul>
<li>ì´ì „ì—ëŠ” xì˜ ë¬¸ì¥ì— ëŒ€í•´ $\log{P(x^i_j,x^i_{&lt;j};\theta)}$ì˜  ğ‘™ğ‘–ğ‘˜ğ‘’ğ‘™ğ‘–â„ğ‘œğ‘œğ‘‘ë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í–ˆì§€ë§Œ(xì— ëŒ€í•œ language model) yë¼ëŠ” sequenceë¥¼ ìƒì„±í•˜ëŠ” LMìœ¼ë¡œ ëª©í‘œë¥¼ ë°”ê¿ˆ!</li>
<li>$x^i, y_{&lt;j}^i$ëŠ” ì¡°ê±´ ìœ¼ë¡œ conditional language modelì´ë¼ê³  í•¨</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Auto-regressive taskì— ì†í•˜ë¯€ë¡œ, <strong>uni-directional RNN</strong>ì„ ì‚¬ìš©</p>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/517946d4-d882-43b1-9706-d40651da8e03" alt="Decoder01"></p>
<ul>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>Given dataset</p>
<ul>
<li><p>$D&#x3D;{x^i, y^i}_{i&#x3D;1}^{N}$  &#x2F;&#x2F; ğ‘¥ ~ ğ‘ƒ(ğ‘¥) y ~ ğ‘ƒ(ğ‘¥) ğ‘¥ì—ì„œ yë¡œ ì¦‰ í•œê¸€ì„ ì˜ì–´ë¡œ ë²ˆì—­.</p>
<p>$x^i &#x3D; {x_1^i, \ldots, x_m^i} \text{ } y^i &#x3D; {y_0^i, y_1^i, \ldots, y_n^i}$  &#x2F;&#x2F; $|y^i|&#x3D;(bs,n,|v_t|)$</p>
<p>where $y_0&#x3D;$<BOS>, $y_n&#x3D;$<EOS></p>
</li>
</ul>
</li>
<li><p>We can get hidden state of decoder</p>
<ul>
<li><p>$h_{t}^{dec} &#x3D; RNN_{dec}(emb_{dec}(\hat{y}<em>{t-1}), h</em>{t-1}^{dec})$ &#x2F;&#x2F;$|\hat{y}_{t-1}|&#x3D;(bs,1,|v_t|)$  emb í†µê³¼ í›„ (bs, 1, ws)</p>
<p>$\text{where } h_0^{dec} &#x3D; h_m^{dec}$</p>
<p>$h_{1:n}^{dec} &#x3D; [h_{1}^{i}; \ldots; h_{n}^{dec}]$  &#x2F;&#x2F; $h_{1:n}^{dec} &#x3D; (bs,n,hs)$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Generator"><a href="#Generator" class="headerlink" title="Generator"></a>Generator</h3><ul>
<li><p>GeneratorëŠ” ë””ì½”ë”ì˜ hidden stateë¥¼ ë°›ì•„ í˜„ì¬ time-stepì˜ ì¶œë ¥ tokenì— ëŒ€í•œ í™•ë¥  ë¶„í¬(multinoulli distribution) ë°˜í™˜</p>
</li>
<li><p>ë‹¨ì–´ë¥¼ ì„ íƒí•˜ëŠ” ë¬¸ì œì´ë¯€ë¡œ <strong>cross entropy lossë¥¼ í†µí•´ ìµœì í™”</strong> ê°€ëŠ¥</p>
<ul>
<li>GT ë¶„í¬ì™€ ëª¨ë¸ ë¶„í¬ ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™” í•˜ê¸° ìœ„í•¨</li>
<li>ì¡°ê±´ë¶€ ì–¸ì–´ëª¨ë¸ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, <strong>PPLë¡œ ì¹˜í™˜</strong> ê°€ëŠ¥</li>
</ul>
</li>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>Given dataset</p>
<ul>
<li><p>$D&#x3D;{x^i, y^i}_{i&#x3D;1}^{N}$  &#x2F;&#x2F; ğ‘¥ ~ ğ‘ƒ(ğ‘¥) y ~ ğ‘ƒ(ğ‘¥) ğ‘¥ì—ì„œ yë¡œ ì¦‰ í•œê¸€ì„ ì˜ì–´ë¡œ ë²ˆì—­.</p>
<p>$x^i &#x3D; {x_1^i, \ldots, x_m^i} \text{ } y^i &#x3D; {y_0^i, y_1^i, \ldots, y_n^i}$  &#x2F;&#x2F; $|y^i|&#x3D;(bs,n,|v_t|)$</p>
<p>where $y_0&#x3D;$<BOS>, $y_n&#x3D;$<EOS></p>
</li>
</ul>
</li>
<li><p>Hidden states from decoder can be calculated like as below</p>
<ul>
<li>$h_{t}^{dec} &#x3D; RNN_{dec}(emb_{dec}(\hat{y}<em>{t-1}), h</em>{t-1}^{dec}), \text{ where } h_0^{dec} &#x3D; h_m^{dec}$</li>
</ul>
</li>
<li><p>Generator return a probability distribution of current output token</p>
<ul>
<li><p>$\hat{y}<em>{t} &#x3D; \text{softmax}(h</em>{t}^{dec} \cdot W_{gen}),$ &#x2F;&#x2F; í˜„ì¬ time-stepì˜ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡(ê° ë‹¨ì–´ë³„ í™•ë¥ ê°’ì´ ë“¤ì–´ìˆìŒ)</p>
<ul>
<li>$|\hat{y}_t|$&#x3D;(bs,1,$|v_t|$)&#x3D;(bs,1,hs)</li>
</ul>
<p>$\text{where } h_{t}^{dec} \in \mathbb{R}^{batchsize \times 1 \times hiddensize}, W_{gen} \in \mathbb{R}^{hiddensize \times |V|}$  &#x2F;&#x2F; WëŠ” Linear Layer</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Loss Function</p>
<ul>
<li><p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N} \log P(y^i|x^{i}; \theta)$</p>
<p>$&#x3D; -\sum_{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(y_{j}^{i},|x^i,y_{&lt;j}^i; \theta)$</p>
</li>
<li><p>Log likelihood can be calculated like as below</p>
<ul>
<li><p>$\log P(x_t | x_{&lt;t}; \theta) &#x3D; x_t^T \cdot \log {\hat{y}_t}$</p>
<p>$\text{where } x_t \text{ is one-hot vector, and }\hat{y}_t \text{ is a probaility distriution from softmax}$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><BOS> and <EOS></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8505ed90-b4a4-446b-81f3-78e801867ddc" alt="Generator01"></p>
</li>
</ul>
<h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/adac6483-47a6-4f8e-b95d-1aeca53d164f" alt="WithoutAttention"></p>
<ul>
<li>hidden stateì— ì •ë³´ë¥¼ ì €ì¥í•˜ì§€ë§Œ í•œê³„ ìš©ëŸ‰ì´ ìˆìŒ<ul>
<li>time-stepì´ mì´ê³ , mì´ ë§¤ìš°í¬ë‹¤ë©´, ë§ì€ ì •ë³´ë“¤ì„ encoderì— ë°€ì–´ë„£ì–´ì•¼ í•¨, ì´ë•Œ,  m&#x3D;hidden stateê°€ ëª¨ë“  ì •ë³´ë¥¼ ë‹´ê¸° ì–´ë ¤ì›€</li>
<li>mì´ ì»¤ì§ˆìˆ˜ë¡ ë²ˆì—­ê¸°, s2sì˜ ì„±ëŠ¥ì´ ë‚®ì•„ì§ˆ ìˆ˜ ë°–ì— ì—†ìŒ(capacity í•œê³„)</li>
<li>ë˜í•œ Encoderì˜ Hidden stateë¥¼ Decoderì˜ Hidden stateë¡œ ë„˜ê¸°ëŠ”ë° hidden stateì˜ ë²¡í„°ê°€ 1024ì°¨ì›ì´ë¼ê³  í•œë‹¤ë©´ í•œê³„ ìš©ëŸ‰ì´ ìˆê²Œë¨</li>
</ul>
</li>
<li>ë”°ë¼ì„œ Attention!!</li>
</ul>
<h3 id="What-is-Attention"><a href="#What-is-Attention" class="headerlink" title="What is Attention?"></a>What is Attention?</h3><ul>
<li>Differentiable(ë¯¸ë¶„ê°€ëŠ¥í•œ) Key-Value Function</li>
<li>ê¸°ì¡´ì˜ Key-Value í•¨ìˆ˜ì™€ ë‹¬ë¦¬, Queryì™€ Keyì˜ ìœ ì‚¬ë„ì— ë”°ë¼ Valueë¥¼ ë°˜í™˜<ul>
<li>dictionary &#x3D; {k:v, k:v â€¦ }, ì™„ë²½í•˜ê²Œ keyì™€ ì¼ì¹˜í•´ì•¼ vë¥¼ ê°€ì ¸ì˜¤ëŠ” ê²ƒê³¼ ë‹¬ë¦¬ ì—¬ê¸°ì„œëŠ” ìœ ì‚¬ë„ ë°”íƒ•ìœ¼ë¡œ ê°€ì ¸ì˜´.</li>
</ul>
</li>
<li>Decoder RNN(LSTM)ì˜ hidden stateì˜ í•œê³„ë¡œ ì¸í•´ ë¶€ì¡±í•œ ì •ë³´ë¥¼ <strong>ì§ì ‘ encoderì— ì¡°íšŒ</strong>í•˜ì—¬ ì˜ˆì¸¡ì— í•„ìš”í•œ ì •ë³´ë¥¼ ì–»ì–´ì˜¤ëŠ” ê³¼ì •(ì¦‰, encoderì— Queryë¥¼ ì˜ ë‚ ë¦¬ê³  Queryë¥¼ ì˜ ë§Œë“¤ì–´ì•¼..)</li>
<li>ì •ë³´ë¥¼ ì˜ ì–»ì–´ì˜¤ê¸° ìœ„í•´ Queryë¥¼ ì˜ ë§Œë“¤ì–´ë‚´ëŠ” ê³¼ì •ì„ í•™ìŠµ</li>
<li>ëª¨ë¸ì€ ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì • ë¶€ë¶„ì— â€œì£¼ì˜â€ë¥¼ ê¸°ìš¸ì´ê³ , ì…ë ¥ ê°„ì˜ ë³µì¡í•œ ìƒí˜¸ ê´€ê³„ë¥¼ íŒŒì•…í•˜ê³ , ì¤‘ìš”í•œ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì¶”ì¶œí•  ìˆ˜ ìˆìŒ</li>
</ul>
<h3 id="Attention-in-Seq2Seq"><a href="#Attention-in-Seq2Seq" class="headerlink" title="Attention in Seq2Seq"></a>Attention in Seq2Seq</h3><ul>
<li>Query<ul>
<li>í˜„ì¬ì— ì´ˆì ì„ ë§ì¶˜ ë¬¸ë§¥ì„ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°</li>
<li>í˜„ì¬ time-stepì˜ decoder output</li>
</ul>
</li>
<li>Keys<ul>
<li>ë‹¤ë¥¸ ëª¨ë“  ìœ„ì¹˜ì™€ í˜„ì¬ ìœ„ì¹˜ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë²¡í„°</li>
<li>ì…ë ¥ ë°ì´í„° ë‚´ì˜ ê° ìœ„ì¹˜ë¥¼ í‘œí˜„í•˜ëŠ” ë²¡í„°ë¡œ, Queryì™€ ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ë¥¼ ê²°ì •í•˜ëŠ” ë° ì‚¬ìš©ë¨</li>
<li>ê° time-step ë³„ encoder output</li>
</ul>
</li>
<li>Values<ul>
<li>ì‹¤ì§ˆì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë²¡í„°ë¡œ, Queryì™€ Keyì˜ ë§¤ì¹­ ì •ë„ì— ë”°ë¼ ê°€ì¤‘ì¹˜ê°€ ì ìš©ë¨</li>
<li>time-stepë³„ encoder output</li>
</ul>
</li>
</ul>
<h3 id="Intuitive-Explanations"><a href="#Intuitive-Explanations" class="headerlink" title="Intuitive Explanations"></a>Intuitive Explanations</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/72bdc510-8ea1-4cbc-878a-66fbe50be534" alt="Attention02"></p>
<ul>
<li>ì²˜ìŒì—ëŠ” â€˜ë‚˜ëŠ”â€™ì´ ë‚˜ì™”ë‹¤ê³  ê°€ì •</li>
<li>Decoderê°€ â€˜í•™êµì—â€™ë¥¼ ì˜ˆì¸¡ì„ í–ˆì„ ë•Œ, ì¤‘í•™êµì— ì¸ì§€, ê³ ë“±í•™êµì— ì¸ì§€, í•™êµì— ì¸ì§€ í—·ê°ˆë ¤í•¨, ê·¸ë˜ì„œ Encoderì˜ ëª¨ë“  time-stepì— Queryë¥¼ ë‚ ë ¤ì„œ ìœ ì‚¬ë„(Similarity)ë¥¼ êµ¬í•¨</li>
<li>0ì´ ì•„ë‹Œ ë¶€ë¶„ì— ëŒ€í•´ (ì—¬ê¸°ì—ì„œëŠ” to, school) Key(&#x3D;Value)ì˜ hidden stateì™€ ìœ ì‚¬ë„ë¥¼ ê³±í•¨</li>
<li>ì´ë¥¼ ë‹¤ ë”í•˜ë©´ Context Vectorê°€ ë¨</li>
<li>Query ì™€ Context Vectorë¥¼ concatí•˜ì—¬ ìƒˆë¡œìš´ hidden stateë¥¼ ë§Œë“¤ê³  softmaxë¡œ í™•ë¥  ê°’ì„ ì–»ìŒ</li>
<li>Linear Transformationì€ Queryì™€ Keyê°’ì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ Linear Layerë¥¼ í†µê³¼ì‹œì¼œ ì ì ˆíˆ ë³€í™”í•˜ê³  ìœ ì‚¬ë„ë¥¼ êµ¬í•¨, ê·¸ë˜ì„œ Linear Transformì´ í•™ìŠµì´ ì˜ ë˜ì–´ì•¼í•¨</li>
</ul>
<h3 id="Linear-Transformation"><a href="#Linear-Transformation" class="headerlink" title="Linear Transformation"></a>Linear Transformation</h3><ul>
<li>Attention mechanismì—ì„œì˜ Linear Transformationì€ ê¸°ë³¸ì ìœ¼ë¡œ, ì…ë ¥ ë²¡í„°ë¥¼ ë‹¤ë¥¸ ì°¨ì›ì˜ ê³µê°„ìœ¼ë¡œ ë§¤í•‘í•˜ëŠ” ìˆ˜í•™ì  ì—°ì‚°<ul>
<li>ì£¼ë¡œ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì…ë ¥ ë²¡í„°ì— ê³±í•˜ì—¬ ìˆ˜í–‰</li>
</ul>
</li>
<li>Attention ë©”ì»¤ë‹ˆì¦˜ì—ì„œëŠ” ì£¼ë¡œ ì„¸ ê°€ì§€ ìš”ì†Œ, ì¦‰ Query(Q), Key(K), ê·¸ë¦¬ê³  Value(V)ì˜ ìƒì„±ì— ì‚¬ìš©ë¨</li>
<li>Q,K,VëŠ” ëª¨ë‘ ì›ë³¸ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ ê°ê° ë‹¤ë¥¸ Linear Transformationì„ ìˆ˜í–‰í•¨ìœ¼ë¡œì¨ ë§Œë“¤ì–´ì§</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/bb6d51fb-e7b9-401b-bfd2-cce32b4c4e8f" alt="LinearTransformation01"></p>
<ul>
<li>Lineaer Transformationì„ í†µí•´ ì•„ë˜ì™€ ê°™ì€ íš¨ê³¼ë¥¼ ì–»ìŒ<ul>
<li>êµ¬ê¸€ ê²€ìƒ‰ì„ í• ë•Œ ì–´ë–»ê²Œ ì‘ì„±í•˜ë©´ ë” ì¢‹ì€ ì •ë³´ë¥¼ ì–»ìœ¼ë ¤ë©´ ì–´ë–»ê²Œ ì¿¼ë¦¬ë¥¼ ë‚ ë¦¬ë©´ ì•Œë“¯ì´ Linear Transformationì´ ê·¸ ì—­í• ì„ í•´ì¤Œ</li>
<li>ê²°êµ­ Attentionì€ ì¿¼ë¦¬ë¥¼ ì˜ ë§Œë“¤ê¸° ìœ„í•¨</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/10919e0c-7e4f-4546-8e05-922cc1ed6e0b" alt="LinearTransformation02"></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/84967a95-75be-44bf-9eb6-d3ee7ab24073" alt="Attention"></p>
<ul>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>With entire encoderâ€™s hidden states and current decoderâ€™s hidden state</p>
<ul>
<li><p>$w &#x3D; \text{softmax}(h_{t}^{dec} \cdot W_{a} \cdot h_{1:m}^{enc^T}))$</p>
<ul>
<li>$|h_{t}^{dec}|$: (bs,1,hs)</li>
<li>$|h_{1:m}^{enc^T}|$: (bs,m,hs$)^T$&#x3D;(bs,hs,m)</li>
<li>$|W_\alpha|$: (hs, hs)</li>
<li>$|w|$ : (bs,1,m), mini-batch ë‚´ ê° ë¬¸ì¥ë³„ í•´ë‹¹ time-stepì˜ encoderì˜ ê° time-stepì˜ ê°€ì¤‘ì¹˜(ìœ ì‚¬ë„)ê°€ ë“¤ì–´ìˆìŒ, dot-productì´ê¸°ì—  cosine similarityì™€ ìœ ì‚¬í•˜ê¸° ë•Œë¬¸<ul>
<li>cf ) Dot Product(ë‚´ì ) :$a \cdot b &#x3D; |a| |b| \cos \theta$ &#x2F;&#x2F; ì–¼ë§ˆë‚˜ ê°™ì€ ë°©í–¥ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ì •ë³´ë¥¼ ë‹´ìœ¼ë©°, ë²¡í„°ì˜ í¬ê¸°ì—ë„ ì˜í–¥ì„ ë°›ìŒ</li>
<li>cf) Cosine Similarity :  $\text{cosine-similarity}(a, b) &#x3D; \frac{a \cdot b}{|a| |b|}$, ë°©í–¥ì„±ë§Œ ê³ ë ¤í•¨, ë²¡í„°ì˜ í¬ê¸° ê³ ë ¤x</li>
</ul>
</li>
</ul>
<p>$c&#x3D;w \cdot h_{1:m}^{enc},$</p>
<ul>
<li>$|c| &#x3D; w \times h_{1:m}^{enc} &#x3D; (bs,1,m) * (bs,m,hs) &#x3D;(bs,1,hs)$</li>
</ul>
<p>$\text{where } c \in \mathbb{R}^{batchsize \times 1 \times hiddensize}$ is a context vector, and $W_a \in \mathbb{R}^{batchsize \times hiddensize}$</p>
</li>
</ul>
</li>
<li><p>Redefine  decoderâ€™s hidden state, and feed into generator</p>
<ul>
<li><p>$\tilde{h}<em>t^{dec} &#x3D; \tanh([(h_t^{dec}; c)] \cdot W</em>{concat})$</p>
<ul>
<li>$[(h_t^{dec}; c)]$ : $â„_ğ‘¡^{ğ‘‘ğ‘’ğ‘}$ ê³¼ cë¥¼ concatí•˜ë©´ (bs, 1, hs*2)</li>
<li>$W_{concat}$ì€ hs*2ë¥¼ hsë¡œ ì¤„ì—¬ì£¼ëŠ” layer (ì°¨ì› ì¶•ì†Œ)</li>
</ul>
<p>$\hat{y}_t &#x3D; \text{softmax}(\tilde{h}<em>t^{dec} \cdot W</em>{gen})$</p>
<ul>
<li>$|\hat{y}_t|$&#x3D;(bs,1,hs)*(hs, |V|) &#x3D; (bs,1,|V|)</li>
</ul>
<p>$\text{where } W_{concat} \in \mathbb{R}^{(2 \times hiddensize) \times hiddensize} \text{ and } W_{gen} \in \mathbb{R}^{hiddensize \times |V|}$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Evaluation</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4481d6ae-8c5b-4173-a2c2-4267ab2ed8ba" alt="AttentionEval"></p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Attentionì€ ë¯¸ë¶„ ê°€ëŠ¥í•œ Key-Value Function ì´ë‹¤.<ul>
<li>Attention í•¨ìˆ˜ì˜ ì…ë ¥ì€ Query, Key, Value</li>
</ul>
</li>
<li>ì •ë³´ë¥¼ ì˜ ì–»ê¸° ìœ„í•œ <strong>Queryë¥¼ ë³€í™˜í•˜ëŠ” ë°©ë²•</strong>ì„ ë°°ìš°ëŠ” ê³¼ì •</li>
<li>Attentionì„ í†µí•´ RNNì˜ hidden stateì˜ í•œê³„ë¥¼ ê·¹ë³µ ê°€ëŠ¥<ul>
<li>LSTMì„ ì“°ë”ë¼ë„ context vectorì— ëª¨ë“  ì •ë³´ë¥¼ ë‹´ê¸°ì—ëŠ” í•œê³„ê°€ ìˆìŒ</li>
<li>ë” ê¸´ ê¸¸ì´ì˜ ì…ë ¥&#x2F;ì¶œë ¥ì—ë„ ëŒ€ì²˜í•  ìˆ˜ ìˆê²Œ ë¨</li>
</ul>
</li>
</ul>
<h2 id="Masking-on-Attention"><a href="#Masking-on-Attention" class="headerlink" title="Masking on Attention"></a>Masking on Attention</h2><ul>
<li><p>Motivation</p>
<ul>
<li><p>ìš°ë¦¬ëŠ” í•­ìƒ ë¯¸ë‹ˆ ë°°ì¹˜ë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ìˆ˜í–‰ì„ í•˜ê²Œ ë¨(We always mini-batch parallelized operations)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4c415185-198e-448e-aff1-2bf52588d768" alt="MaskingAttention01"></p>
</li>
<li><p>ê·¸ë¡œì¸í•´ ì¶”ë¡ í•  ë•Œ (ìƒìš©í™” ìˆ˜ì¤€ì—ì„œ) ë¬¸ì œë¥¼ ì•¼ê¸°í•  ìˆ˜ ìˆìŒ</p>
<ul>
<li><p><PAD>ì—ë„ attention ì—°ì‚°ì´ ë“¤ì–´ê°€ê¸° ë•Œë¬¸</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/d88c7832-b20a-4d8b-846e-25c1df6a0ad4" alt="MaskingAttention02"></p>
<ul>
<li><PAD> ìœ„ì¹˜ì—ëŠ” attention weightê°€ ë“¤ì–´ê°€ì§€ ì•Šê²Œ í•´ì•¼í•¨(ì—”ì§€ë‹ˆì–´ì ìœ¼ë¡œ ì•ˆì „ì¥ì¹˜ë¥¼ ë§Œë“¤ì!)</li>
<li><PAD>ì˜ ê°œìˆ˜ê°€ 2ê°œ, ì–´ë–¤ ì„¤ì •ìœ¼ë¡œëŠ” 6ê°œë©´, ë²ˆì—­ê²°ê³¼ê°€ ë§ˆì´ë„ˆí•˜ê²Œ ë°”ë€œ. (ì‚¬ìš©ì ì…ì¥ì—ì„œconsistí•˜ì§€ ì•Šì€ ê²°ê³¼ê°€ ë‚˜ì˜´, ì‚¬ë‘í•´ìš”,ì‚¬ë‘í•´ìš§.)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Solution</p>
<ul>
<li>ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ âˆ’âˆìœ¼ë¡œ í• ë‹¹í•˜ì, ê·¸ëŸ¬ë©´ softmaxì˜ ê²°ê³¼ë¡œ 0ì´ ë‚˜ì˜´</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ab7fc949-c480-4edb-8847-f52242afc732" alt="MaskingAttention03"></p>
</li>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>After dot-products, before softmax.</p>
<ul>
<li><p>$w &#x3D; \text{softmax}(h_{t}^{dec} \cdot W_{a} \cdot h_{1:m}^{enc^T}))$</p>
<ul>
<li>$h_{t}^{dec} \cdot W_{a}$ : Q</li>
<li>$h_{1:m}^{enc^T}$ : $K^T$</li>
<li>|Q|&#x3D;(bs,1,hs), |K|&#x3D;(bs,hs,m), |Qâˆ™K|&#x3D;(bs,1,m)</li>
</ul>
</li>
<li><p>$c&#x3D;w \cdot h_{1:m}^{enc},$</p>
<p>$\text{where } c \in \mathbb{R}^{batchsize \times 1 \times hiddensize}$ is a context vector, and $W_a \in \mathbb{R}^{batchsize \times hiddensize}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½-1"><a href="#ìš”ì•½-1" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Mini-batch ë‚´ì˜ ë¬¸ì¥ êµ¬ì„±ì— ë”°ë¼, <pad>ê°€ ë™ì ìœ¼ë¡œ ìƒì„±ë¨<ul>
<li><pad>ì˜ hidden stateì—ëŠ” attention weightê°€ í• ë‹¹ë˜ë©´ ì•ˆë¨</li>
</ul>
</li>
<li>ë”°ë¼ì„œ Keyì™€ Queryì˜ dot product ì´í›„ì— (softmax ì´ì „ì—), maskingì„ í†µí•´ <pad> ìœ„ì¹˜ì˜ ê°’ì„ ìŒì˜ ë¬´í•œëŒ€ë¡œ ë³€ê²½<ul>
<li>softmax ê²°ê³¼ <pad>ì—ëŠ” 0ì´ í• ë‹¹ë¨</li>
</ul>
</li>
<li>ì´ ê¸°ë²•ì€ ì´í›„ Transformerì—ì„œë„ ìœ ìš©í•˜ê²Œ ì“°ì¼ ê²ƒ</li>
</ul>
<h2 id="Input-Feeding"><a href="#Input-Feeding" class="headerlink" title="Input Feeding"></a>Input Feeding</h2><ul>
<li>ì´ì „ ì‹œì ì˜ ë””ì½”ë”ì˜ ì¶œë ¥ì´ ë‹¤ìŒ ì‹œì ì˜ ë””ì½”ë”ì˜ ì…ë ¥ìœ¼ë¡œ ë‹¤ì‹œ ë“¤ì–´ê°€ëŠ” ë°©ì‹</li>
<li>ì´ë¥¼ í†µí•´ ì‹œí€€ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ ëª¨ë¸ì´ ì´ì „ì— ë§Œë“  ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ì—¬ ë³´ë‹¤ ì¼ê´€ì„±ìˆê³  ì—°ê´€ì„± ë†’ì€ ì¶œë ¥ì„ ìƒì„±í•˜ëŠ” ë° ë„ì›€ì´ ë¨</li>
<li>ë²ˆì—­, ëŒ€í™” ìƒì„±, ìš”ì•½ ë“±ê³¼ ê°™ì€ ë¬¸ì œì—ì„œ ì¤‘ìš”í•œ ì—­í• </li>
<li>Sampling ê³¼ì •ì—ì„œ ì†ì‹¤ëœ ì •ë³´ë¥¼ word embeddingì— concatenate</li>
<li>concatenateì„ í•˜ëŠ” ì´ìœ <ul>
<li>$\hat{y}_1$ì´ í—·ê°ˆë¦¬ëŠ”ì§€ ì•„ë‹Œì§€ ì •ë³´ ì†ì‹¤ë°©ì§€ìš©, ë”°ë¼ì„œ $\tilde{h}_t$ ë‹¤ìŒ time-stepì—ì„œ concat ë¨</li>
<li>teacher-forcing ìœ¼ë¡œ í•™ìŠµí•  ë•Œ, $y_1$ë§Œ ë“¤ì–´ê°€ê³  $\hat{y}_1$ì´ ë“¤ì–´ê°€ì§€ ì•ŠìŒ, ì´ë¡œì¸í•´ ì´ì „ time-stepì˜ ì¶”ë¡ ê°’ì„ ë³´ê³  ì¶”ê°€ì ìœ¼ë¡œ ì •ë‹µë„ ë³´ê¸°ì— ì •ë³´ ì†ì‹¤ ë°©ì§€</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/baf5abd4-0880-49b4-8266-3bfd5e0296ac" alt="InputFeeding"></p>
<ul>
<li><p>By Input Feeding,</p>
<ul>
<li>Sampling ê³¼ì •ì—ì„œ (&#x3D;argmax ê³¼ì •ì—ì„œ) ì†ì‹¤ë˜ëŠ” ì •ë³´ë¥¼ ìµœì†Œí™”</li>
<li>Teacher Forcingìœ¼ë¡œ ì¸í•œ í•™ìŠµ&#x2F;ì¶”ë¡  ì‚¬ì´ì˜ ê´´ë¦¬ë¥¼ ìµœì†Œí™”</li>
</ul>
</li>
<li><p>By Input Feeding,</p>
<ul>
<li>Sampling ê³¼ì •ì—ì„œ (&#x3D;argmax ê³¼ì •ì—ì„œ) ì†ì‹¤ë˜ëŠ” ì •ë³´ë¥¼ ìµœì†Œí™”</li>
<li>Teacher Forcingìœ¼ë¡œ ì¸í•œ í•™ìŠµ&#x2F;ì¶”ë¡  ì‚¬ì´ì˜ ê´´ë¦¬ë¥¼ ìµœì†Œí™”</li>
</ul>
</li>
<li><p>ìˆ˜ì‹</p>
<ul>
<li><p>$D&#x3D;{x^i, y^i}<em>{i&#x3D;1}^{N}$   &#x2F;&#x2F; $y&#x3D;f(x)$ $|x^i|&#x3D;(bs,m,|v|)$ $|y^i|&#x3D;(bs,n,|v|)&#x3D;y</em>{1:n}^i$</p>
<p>$x^i &#x3D; {x_1^i, \ldots, x_m^i} \text{ } y^i &#x3D; {y_0^i, y_1^i, \ldots, y_n^i}$  &#x2F;&#x2F; $|y^i|&#x3D;(bs,n,|v_t|)$</p>
<p>where $y_0&#x3D;$<BOS>, $y_n&#x3D;$<EOS></p>
</li>
<li><p>$h_{1:m}^{enc} &#x3D; RNN_{enc}(emb_{enc}(x_{1:m}), h_{0}^{enc}) \text{ where    } h_0^{enc} &#x3D; 0$</p>
<ul>
<li>$h_{1:m}^{enc}$&#x3D;(ğ‘ğ‘ , m,â„ğ‘ )</li>
<li>|$emb_{enc}(x_{1:m}), h_0^{enc}$|&#x3D;(ğ‘ğ‘ , m, ws)</li>
</ul>
</li>
<li><p>$h_{t}^{dec} &#x3D; RNN_{dec}([emb_{dec}(\hat{y}<em>{t-1}); \tilde{h}</em>{t-1}^{dec}], h_{t-1}^{dec})$$h_{t}^{dec} &#x3D; RNN_{dec}([emb_{dec}(\hat{y}<em>{t-1}), \tilde{h}</em>{t-1}^{dec}], h_{t-1}^{dec})$,  $\text{where } h_0^{dec} &#x3D; h_m^{enc}$</p>
<ul>
<li>$\tilde{h}_{t-1}^{dec}$: input feedingìœ¼ë¡œ concat â†’ (bs, 1, ws+hs)</li>
<li>$h_{t-1}^{dec}$: ì´ì „ time-steopì˜ decoderì˜ hidden state ê°’ &#x3D; (bs,1,hs)</li>
<li>$|y_{t-1}|&#x3D;(bs,1,|v|)$  : dec</li>
</ul>
</li>
<li><p>$w &#x3D; \text{softmax}(h_{t}^{dec} \cdot W_{a} \cdot h_{1:m}^{enc^T}))$</p>
<ul>
<li>$h_{t}^{dec} \cdot W_{a}$ : Q</li>
<li>$h_{1:m}^{enc^T}$ : $K^T$</li>
<li>|Q|&#x3D;(bs,1,hs), |K|&#x3D;(bs,hs,m), |Qâˆ™K|&#x3D;(bs,1,m)</li>
</ul>
<p>$c&#x3D;w \cdot h_{1:m}^{enc},$</p>
<p>$\text{where } c \in \mathbb{R}^{batchsize \times 1 \times hiddensize}$ is a context vector, and $W_a \in \mathbb{R}^{batchsize \times hiddensize}$</p>
</li>
<li><p>$\tilde{h}<em>t^{dec} &#x3D; \tanh([(h_t^{dec}; c)] \cdot W</em>{concat})$</p>
<ul>
<li>$[(h_t^{dec}; c)]$ : $â„_ğ‘¡^{ğ‘‘ğ‘’ğ‘}$ ê³¼ cë¥¼ concatí•˜ë©´ (bs, 1, hs*2)</li>
</ul>
<p>$\hat{y}_t &#x3D; \text{softmax}(\tilde{h}<em>t^{dec} \cdot W</em>{gen})$</p>
<ul>
<li>$|\hat{y}_t|$&#x3D;(bs,1,hs)*(hs, |V|) &#x3D; (bs,1,|V|)</li>
</ul>
<p>$\text{where } W_{concat} \in \mathbb{R}^{(2 \times hiddensize) \times hiddensize} \text{ and } W_{gen} \in \mathbb{R}^{hiddensize \times |V|}$</p>
</li>
<li><p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N}\sum_{t&#x3D;1}^{n} \log P(y_{j}^{i},|x^i,y_{&lt;t}^i; \theta)$<br>$\log P(x_t | x_{&lt;t}; \theta) &#x3D; y_t^{iT} \cdot \log{\hat{y}<em>{t}^i})$ &#x2F;&#x2F; softmax layerë¥¼ í†µê³¼í•˜ëŠ” ê²½ìš°,<br>&#x2F;&#x2F; $|y_t^{iT}|$$y_t^{iT}$ : (bs,1,|v|)<br>&#x2F;&#x2F; $|\log{\hat{y}</em>{t}^i}|$$\log{\hat{y}_{t}^i}$ : (bs,|v|,1)<br>$\text{where } x_t \text{ is one- hot vector, and }f_Î¸ \text{ is model with parameter Î¸.}$<br>$\theta \leftarrow \theta - \eta\nabla_\theta L(\theta)$</p>
</li>
</ul>
</li>
</ul>
<h2 id="Wrap-up"><a href="#Wrap-up" class="headerlink" title="Wrap-up"></a>Wrap-up</h2><ul>
<li>Encoder<ul>
<li>ë¬¸ì¥ì„ ë°›ì•„ context vectorë¡œ ì••ì¶•</li>
<li>Bi-directional RNNì„ í†µí•´ êµ¬í˜„</li>
</ul>
</li>
<li>Decoder &amp; Generator<ul>
<li>Conditional Language Model<ul>
<li>Encoderë¡œë¶€í„° ì •ë³´ë¥¼ ë°›ì•„ ë¬¸ì¥ì„ ìƒì„±</li>
</ul>
</li>
<li>Cross Entropy(PPL)ì„ í†µí•´ ìµœì í™”</li>
</ul>
</li>
<li>Attention<ul>
<li>Key-Value í•¨ìˆ˜</li>
<li>ë””ì½”ë”ì˜ hidden stateë¥¼ ì¸ì½”ë”ì˜ ê° hidden stateì— ìœ ì‚¬ë„ ë¹„êµ</li>
<li>ì¢‹ì€ queryë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê³¼ì •ì„ í•™ìŠµ<ul>
<li>decoderì˜ hidden stateê°€ queryê°€ ë¨</li>
</ul>
</li>
</ul>
</li>
<li>Input Feeding<ul>
<li>Sampling ê³¼ì •ì—ì„œ ì†ì‹¤ëœ ì •ë³´ë¥¼ word embeddingì— concatenate</li>
</ul>
</li>
</ul>
<h2 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher Forcing"></a>Teacher Forcing</h2><h3 id="Auto-regressive"><a href="#Auto-regressive" class="headerlink" title="Auto-regressive"></a>Auto-regressive</h3><ul>
<li><p>Inference</p>
<ul>
<li>$\hat{x}<em>t &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_t | \hat{x}{&lt;t}; \theta)$</li>
</ul>
</li>
<li><p>Auto-regressive</p>
<ul>
<li><p>ê³¼ê±° ìì‹ ì˜ ìƒíƒœë¥¼ ì°¸ì¡°í•˜ì—¬ í˜„ì¬ ìì‹ ì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸</p>
<ul>
<li><p>$\hat{x}<em>{t&#x3D;1} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;1} | x_0; \theta)$  $\text{ where } x_0 &#x3D;$ <BOS></p>
<p>$\hat{x}<em>{t&#x3D;2} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;2} | x_0,\hat{x}_1; \theta)$</p>
<p>$\hat{x}<em>{t&#x3D;3} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;3} | x_0,\hat{x}_1, \hat{x}_2; \theta)$</p>
<p>â€¦</p>
<p>$\hat{x}<em>{t} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t} | x_0,\hat{x}_{x&lt;t}; \theta)$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Training-vs-Inference"><a href="#Training-vs-Inference" class="headerlink" title="Training vs Inference"></a>Training vs Inference</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/d8941761-8ee2-4f5a-91fe-c419bdfd379a" alt="TeacherForcing"></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a><strong>Summary</strong></h3><ul>
<li>Auto-regressive taskë¥¼ feed-forwardí•  ë•ŒëŠ” ë³´í†µ ì´ì „ time-stepì˜ ì¶œë ¥ì´ í˜„ì¬ time-stepì˜ ì…ë ¥ì´ ë¨</li>
<li>Teacher Forcingì„ í†µí•´ Auto-regressive taskì— ëŒ€í•œ sequential modelingì„ í•  ìˆ˜ ìˆìŒ<ul>
<li>í•˜ì§€ë§Œ training modeì™€ inference modeì˜ ê´´ë¦¬(discrepancy)ê°€ ìƒê¹€</li>
</ul>
</li>
<li>RLì„ í†µí•´ ì´ëŸ¬í•œ ê´´ë¦¬ë¥¼ ì—†ì• ê³  ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŒ<ul>
<li>ì´ì™¸ì—ë„ ë‹¤ì–‘í•œ ë°©ë²•(e.g. professor forcing)ë“¤ì´ ì œì•ˆë¨</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-25T14:56:56.000Z" title="8/25/2023, 11:56:56â€¯PM">2023-08-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:50.000Z" title="12/21/2023, 12:40:50â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">4 minutes read (About 549 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/3%E1%84%8C%E1%85%A1%E1%86%BC-Data-Preparation/">3ì¥. Data Preparation</a></h1><div class="content"><h3 id="NLP-Project-Workflow"><a href="#NLP-Project-Workflow" class="headerlink" title="NLP Project Workflow"></a>NLP Project Workflow</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ab4e691c-23c6-4c4a-bdfa-b1b0fb895eba" alt="NLPProjectWorlflow"></p>
<h3 id="Preprocessing-Workflow"><a href="#Preprocessing-Workflow" class="headerlink" title="Preprocessing Workflow"></a>Preprocessing Workflow</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/93fccf0c-13e9-42ac-81a3-1e877a07bc41" alt="PreprocessingWorkflow"></p>
<ul>
<li><p>Cleaning</p>
<ul>
<li>ê¸°ê³„ì ì¸ ë…¸ì´ì¦ˆ ì œê±°(ë¬´ì¡°ê±´ì ìœ¼ë¡œ ì œê±°, Tableì— ë”°ë¼)<ul>
<li>ì „ê°ë¬¸ì ë³€í™˜</li>
<li>Taskì— ë”°ë¥¸ (ì „í˜•ì ì¸) ë…¸ì´ì¦ˆ ì œê±°<ul>
<li>ìŒì„± ì¸ì‹ì˜ ê²½ìš°, â€œë‚˜ëŠ” (ë§¤ìš°) ê¸°ë¶„ì´ ë‚˜ì˜ë‹¤â™¡â€<ul>
<li>(ë§¤ìš°) ë‚ ë¦¬ê¸°</li>
<li>í•˜íŠ¸ ë‚ ë¦¬ê¸°</li>
</ul>
</li>
<li>ê¸°ê³„ ë²ˆì—­ì˜ ê²½ìš°, â€œë‚˜ëŠ” (ë§¤ìš°) ê¸°ë¶„ì´ ë‚˜ì˜ë‹¤â™¡â€<ul>
<li>Iâ€™m (very) upset â™¡ (ë‚ ë¦´ê²Œ ì—†ë‹¤)</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ ì´ëª¨í‹°ì½˜ì˜ ê²½ìš°ëŠ” ë§¤ìš° ì¤‘ìš”</li>
</ul>
</li>
</ul>
</li>
<li>Interactive ë…¸ì´ì¦ˆ ì œê±°<ul>
<li>ì½”í¼ìŠ¤ì˜ íŠ¹ì„±(í¬ë¡¤ë§ í•œê³³ë§ˆë‹¤, ì™¸ì£¼ ë§ˆë‹¤ ë‹¤ë¥´ë‹¤)ì— ë”°ë¥¸ ë…¸ì´ì¦ˆ ì œê±°</li>
<li>ì‘ì—…ìê°€ ìƒí™©ì„ í™•ì¸í•˜ë©° ì‘ì—… ìˆ˜í–‰</li>
</ul>
</li>
<li>Therefore<ul>
<li>ì „ì²˜ë¦¬ ê³¼ì •ì€ Taskì™€ ì–¸ì–´, ë„ë©”ì¸ê³¼ ì½”í¼ìŠ¤ì˜ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥´ë‹¤.</li>
<li>ì‹œê°„ê³¼ í’ˆì§ˆ ì‚¬ì´ì˜ Trade-off</li>
<li>ë”°ë¼ì„œ ì „ì²˜ë¦¬ ì¤‘ì—ì„œë„ íŠ¹íˆ ë°ì´í„° ë…¸ì´ì¦ˆ ì œê±°ì˜ ê²½ìš°, ë§ì€ ë…¸í•˜ìš°ê°€ í•„ìš”</li>
</ul>
</li>
</ul>
</li>
<li><p>Tokenization</p>
<ul>
<li>í•œêµ­ì–´ì˜ ê²½ìš°<ul>
<li>ì ‘ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ í¬ì†Œì„±ì„ ë‚®ì¶”ê³ ,</li>
<li>ë„ì–´ì“°ê¸°ë¥¼ í†µì¼í•˜ê¸° ìœ„í•´ tokenizationì„ ìˆ˜í–‰</li>
</ul>
</li>
<li>êµ‰ì¥íˆ ë§ì€ POS Taggerê°€ ì¡´ì¬í•˜ëŠ”ë°,<ul>
<li>ì „í˜•ì ì¸ ì‰¬ìš´ ë¬¸ì¥(í‘œì¤€ ë¬¸ë²•ì„ ë”°ë¥´ë©°, êµ¬ì¡°ê°€ ëª…í™•í•œ ë¬¸ì¥)ì˜ ê²½ìš°, ì„±ëŠ¥ì´ ë¹„ìŠ·í•¨</li>
<li>í•˜ì§€ë§Œ ì‹ ì¡°ì–´ë‚˜ ê³ ìœ ëª…ì‚¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì´ ë‹¤ë¦„</li>
<li>ë”°ë¼ì„œ, ì£¼ì–´ì§„ ë¬¸ì œì— ë§ëŠ” ì •ì±…ì„ ê°€ì§„ taggerë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•´ì•¼í•¨</li>
</ul>
</li>
</ul>
</li>
<li><p>Subword Segmentation</p>
<ul>
<li>BPE ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ í†µê³„ì ìœ¼ë¡œ ë” ì‘ì€ ì˜ë¯¸ ë‹¨ìœ„(subword)ë¡œ ë¶„ì ˆ ìˆ˜í–‰</li>
<li>BPEë¥¼ í†µí•´ OoVë¥¼ ì—†ì•¨ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì„±ëŠ¥ìƒ ë§¤ìš° í° ì´ì ìœ¼ë¡œ ì‘ìš©</li>
<li>í•œêµ­ì–´ì˜ ê²½ìš°<ul>
<li>ë„ì–´ì“°ê¸°ê°€ ì œë©‹ëŒ€ë¡œì¸ ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, normalization ì—†ì´ ë°”ë¡œ subword segmentationì„ ì ìš©í•˜ëŠ” ê²ƒì€ ìœ„í—˜</li>
<li>ë”°ë¼ì„œ í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ í†µí•œ tokenizationì„ ì§„í–‰í•œ ì´í›„ subword segmentationì„ ì ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥</li>
</ul>
</li>
</ul>
</li>
<li><p>Batchify</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9ea340d3-cd00-4f17-b825-fb0671c4ce69" alt="Batchify"></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-24T14:49:45.000Z" title="8/24/2023, 11:49:45â€¯PM">2023-08-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:46.000Z" title="12/21/2023, 12:40:46â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">3 minutes read (About 491 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Language-Modeling-Wrap-up/">2ì¥ Language Modeling - Wrap up</a></h1><div class="content"><h3 id="Language-Model-ì´ë€"><a href="#Language-Model-ì´ë€" class="headerlink" title="Language Model ì´ë€"></a>Language Model ì´ë€</h3><ul>
<li><p>ì‹¤ì œ ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” (or íƒ€ê¹ƒ ë„ë©”ì¸) ì–¸ì–´ì˜ ë¶„í¬ë¥¼ í™•ë¥  ëª¨ë¸ë¡œ ëª¨ë¸ë§í•œ ê²ƒ</p>
<ul>
<li><p>Chain Ruleì— ì˜í•´ì„œ ë¬¸ì¥ì˜ í™•ë¥ ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ë‹¨ì–´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒê³¼ ê°™ìŒ</p>
<ul>
<li><p>$P(x_{1:n}) &#x3D; P(x_1, \ldots, x_n)$</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$= P(x_n | x_&#123;1&#125;, \\ldots, x_&#123;n-1&#125;) \\ldots P(x_2| x_1)P(x_1)$. </span><br><span class="line">      </span><br><span class="line">$= \\prod_&#123;i=1&#125;^n P(x_i | x_&#123;&lt;i&#125;)$</span><br></pre></td></tr></table></figure>

<p>$\log P(x_{1:n}) &#x3D; \sum_{i&#x3D;1}^N \log P(x_i | x_{&lt;i})$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>ì–¸ì–´ ëª¨ë¸ì„ í†µí•´ ìš°ë¦¬ëŠ” ì•„ë˜ì˜ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ</strong></p>
<ul>
<li>ì£¼ì–´ì§„ ë¬¸ì¥ë“¤ ì¤‘ì—ì„œ ê°€ì¥ fluentí•œ ë¬¸ì¥ì„ ê³¨ë¼ë‚¼ ìˆ˜ ìˆìŒ</li>
<li>ë‹¨ì–´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ë¥¼ í™•ë¥ ì ìœ¼ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h3><ul>
<li>ë§¤ time-step ë§ˆë‹¤ ëª¨ë¸ì´ ë™ë“±í•˜ê²Œ í—·ê°ˆë¦¬ê³  ìˆëŠ” í‰ê·  ë‹¨ì–´ ìˆ˜<ul>
<li>í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ê°€ ì ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
</ul>
</li>
<li>ë¬¸ì¥ì˜ í™•ë¥ ì˜ ì—­ìˆ˜ì— ë‹¨ì–´ ìˆ˜ ë§Œí¼ ê¸°í•˜ í‰ê· ì„ ì·¨í•œ ê²ƒ (10ì´ë©´ 10ê°œ ë‹¨ì–´ë¥¼ í—·ê°ˆë¦¬ëŠ” ê²ƒ, 6:4 ìˆ˜ì¤€ì´ ì•„ë‹ˆë¼ 5:5 ìˆ˜ì¤€ìœ¼ë¡œ ì°ê¸° ìˆ˜ì¤€ìœ¼ë¡œ í—·ê°ˆë¦¬ëŠ” ê²ƒ. 100ê°œë©´ 100ë¶„ì˜ 1 í™•ë¥ )<ul>
<li>ë¬¸ì¥ì˜ likelihoodê°€ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
</ul>
</li>
<li>Cross Entropyì— exponentialì„ ì·¨í•œ ê²ƒ (&#x3D;perplexityì— logë¥¼ ì·¨í•œ ê²ƒ!)<ul>
<li>GT ë¶„í¬ì™€ ëª¨ë¸ì˜ ë¶„í¬ê°€ ë¹„ìŠ·í• ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
<li>ì¦‰ ìš°ë¦¬ëŠ” perplexityë¥¼ minimizeí•´ì•¼í•˜ëŠ”ë°, CEë¥¼ minimizeí•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤!(CEê°€ ë‚®ìœ¼ë©´ PPLë„ ë‚®ìŒ)</li>
</ul>
</li>
</ul>
<h3 id="n-gram-and-Neural-Network-Language-Model"><a href="#n-gram-and-Neural-Network-Language-Model" class="headerlink" title="n-gram and Neural Network Language Model"></a><strong>n-gram and Neural Network Language Model</strong></h3><ul>
<li>n-gram<ul>
<li>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ì¸ì‹<ul>
<li>Exact Matchingì— ëŒ€í•´ì„œë§Œ count</li>
</ul>
</li>
<li>í•™ìŠµ ì½”í¼ìŠ¤ì— word sequenceê°€ ì¡´ì¬í•´ì•¼ë§Œ í™•ë¥  ê°’ì„ ì¶”ì • ê°€ëŠ¥<ul>
<li>Markov Assumption ë„ì…</li>
</ul>
</li>
<li>ì‰½ê³  ì§ê´€ì ì¸ êµ¬í˜„<ul>
<li>í•™ìŠµ(counting) í›„, ì¶”ë¡ (table look-up)</li>
<li>Scalable í•˜ë©°, ì €ë ´í•œ ê³„ì‚° ë¹„ìš©ã…œ</li>
</ul>
</li>
</ul>
</li>
<li>NNLM<ul>
<li>ë‹¨ì–´ë¥¼ continuous vectorë¡œ ë³€í™˜<ul>
<li>unseen word sequenceì— ëŒ€ì²˜ ê°€ëŠ¥</li>
<li>Generalizationì— ê°•ì </li>
</ul>
</li>
<li>ë¹„ì‹¸ê³  ëŠë¦° ì—°ì‚° ì¶”ë¡  ê³¼ì •</li>
<li>Generation taskì— êµ‰ì¥íˆ ê°•í•¨</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-21T14:48:34.000Z" title="8/21/2023, 11:48:34â€¯PM">2023-08-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:31.000Z" title="12/21/2023, 12:40:31â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">3 minutes read (About 508 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Language-Modeling-Auto-regressive-Teacher-Forcing/">2ì¥. Language Modeling - Auto-regressive &amp; Teacher Forcing</a></h1><div class="content"><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/1d84b7d5-81d2-468d-99a3-b0034e0045f8" alt="seq2seqApplication"></p>
<h3 id="Two-Approaches"><a href="#Two-Approaches" class="headerlink" title="Two Approaches"></a>Two Approaches</h3><ul>
<li>Non-autoregressive (Non-generative)<ul>
<li>í˜„ì¬ ìƒíƒœê°€ ì•&#x2F;ë’¤ ìƒíƒœë¥¼ í†µí•´ ì •í•´ì§€ëŠ” ê²½ìš° (sequenceì˜ ëª¨ë“  timestampë¥¼ ë³´ê³  ì •í•´ì§)<ul>
<li>e.g. Part of Speech(POS) Tagging, Text Classification</li>
</ul>
</li>
<li>Bidirectional RNN ì‚¬ìš© ê¶Œì¥</li>
</ul>
</li>
<li>Autoregressive (Generative)<ul>
<li>í˜„ì¬ ìƒíƒœê°€ ê³¼ê±° ìƒíƒœì— ì˜ì¡´í•˜ì—¬ ì •í•´ì§€ëŠ” ê²½ìš° (ê³¼ê±°ì—ì„œ í˜„ì¬ë¡œ ë°©í–¥ì„±ì´ ìˆìŒ)<ul>
<li>e.g. Natural Language Generation, Machine Translation</li>
</ul>
</li>
<li>One-to-Many case í•´ë‹¹</li>
<li>Bidirectional RNN ì‚¬ìš© ë¶ˆê°€!(ë°©í–¥ì„±ì´ ìˆìœ¼ë‹ˆê¹Œ! ì•-&gt; ë’¤ í˜¹ì€ ë’¤-&gt; ì• í•˜ë‚˜ë§Œ ì‚¬ìš© ê°€ëŠ¥)</li>
</ul>
</li>
</ul>
<h3 id="Auto-regressive"><a href="#Auto-regressive" class="headerlink" title="Auto-regressive"></a><strong>Auto-regressive</strong></h3><ul>
<li><p>Inference</p>
<ul>
<li>$\hat{x}<em>t &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_t | \hat{x}{&lt;t}; \theta)$</li>
</ul>
</li>
<li><p>Auto-regressive</p>
<ul>
<li><p>ê³¼ê±° ìì‹ ì˜ ìƒíƒœë¥¼ ì°¸ì¡°í•˜ì—¬ í˜„ì¬ ìì‹ ì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸</p>
<ul>
<li><p>$\hat{x}<em>{t&#x3D;1} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;1} | x_0; \theta)$  $\text{ where } x_0 &#x3D;$ <BOS></p>
<p>$\hat{x}<em>{t&#x3D;2} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;2} | x_0,\hat{x}_1; \theta)$</p>
<p>$\hat{x}<em>{t&#x3D;3} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;3} | x_0,\hat{x}_1, \hat{x}_2; \theta)$</p>
<p>â€¦</p>
<p>$\hat{x}<em>{t} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t} | x_0,\hat{x}_{x&lt;t}; \theta)$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher-Forcing"></a>Teacher-Forcing</h3><ul>
<li><p>MLEì˜ ìˆ˜ì‹ìƒ, ì •ë‹µ $x_{t-1}$ì„ RNNì˜ ì—½ë ¥ìœ¼ë¡œ ë„£ì–´ì¤˜ì•¼ í•¨</p>
<ul>
<li><p>$D&#x3D;{x^i }_{i&#x3D;1}^N$ .         &#x2F;&#x2F; $x^i \sim P(x)$ : $P(x)$ë¼ëŠ” ë¶„í¬ì—ì„œ ë¬¸ì¥ì„ ìƒ˜í”Œë§ í•¨($x^i$)</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$ &#x2F;&#x2F; log-likelihoodë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” $\theta$ë¥¼ ì°¾ìŒ</p>
<p>   $&#x3D; \text{argmax}<em>{\theta \in \heta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i}|x_{&lt;j}^i; \theta)$ &#x2F;&#x2F; by chain-rule, ê·¼ë° ë¬¸ì œëŠ” hatì´ ì—†ìŒ</p>
<p>â€‹       $\text{where } x_{1:n} &#x3D; {x_1, â€¦, x_n}$</p>
</li>
</ul>
</li>
</ul>
<h3 id="Auto-regressive-amp-Teacher-Forcing"><a href="#Auto-regressive-amp-Teacher-Forcing" class="headerlink" title="Auto-regressive &amp; Teacher Forcing"></a><strong>Auto-regressive &amp; Teacher Forcing</strong></h3><ul>
<li><p>Inference Mode</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0" alt="InferenceMode"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0">https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0</a></p>
<ul>
<li>í•™ìŠµì€ ì´ë ‡ê²Œ ëª»í•œë‹¤. ì™œëƒí•˜ë©´ lossë¥¼ êµ¬í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ë‹¤ìŒí˜ì´ì§€ì™€ ë¹„êµ! ê·¸ë˜ì„œ ë‚˜ì˜¨ ê²ƒì´ Teacher forcing,ì¦‰ Auto-regressive ì†ì„±ì„ ê°€ì§„ sequentialí•œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•</li>
</ul>
</li>
<li><p>Training Mode</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9bc7ee8b-c8fb-4e75-a9e3-e6b05a446de6" alt="TrainingMode"></p>
<ul>
<li>ë§Œì•½ì— hatì´ ë“¤ì–´ê°€ë©´ <EOS>ê°€ ë“¤ì–´ê°ˆ ë•Œê¹Œì§€ì˜ ê°¯ìˆ˜ ì´ê¸°ì—, 5ë‹¨ì–´ë¥¼ ë„£ì–´ë„ 5ê°œì´ìƒì˜ ë‹¨ì–´ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ë¬¸ì œ ë°œìƒ</li>
</ul>
</li>
</ul>
<h3 id="ê³ í†µì˜-ì‹œì‘-NLG-is-Auto-regressive-Task"><a href="#ê³ í†µì˜-ì‹œì‘-NLG-is-Auto-regressive-Task" class="headerlink" title="ê³ í†µì˜ ì‹œì‘ : NLG is Auto-regressive Task"></a><strong>ê³ í†µì˜ ì‹œì‘ : NLG is Auto-regressive Task</strong></h3><ul>
<li>Auto-regressive taskì—ì„œëŠ” ë³´í†µ ì´ì „ time-stepì˜ ëª¨ë¸ì„ ì¶œë ¥(x Ì‚_(t-1))ì„ ë‹¤ìŒ time-stepì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì¤Œ<ul>
<li>ì´ì „ time-stepì˜ ì¶œë ¥ì— ë”°ë¼ í˜„ì¬ ëª¨ë¸ì˜ stateê°€ ë°”ë€Œê²Œ ë  ê²ƒ</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ ì ì ˆí•œ í•™ìŠµì„ ìœ„í•´ì„œëŠ” í•™ìŠµ ì‹œì—ëŠ” ì´ì „ time-stepì˜ ì¶œë ¥ ê°’ì´ ì•„ë‹Œ**, ì‹¤ì œ ì •ë‹µì„ ë„£ì–´ì¤Œ**</li>
<li>ë”°ë¼ì„œ í•™ìŠµê³¼ ì¶”ë¡ ì„ ìœ„í•œ ë°©ë²•ì´ ë‹¤ë¥´ê²Œ ë˜ì–´ ì—¬ëŸ¬ê°€ì§€ ë¬¸ì œê°€ ë°œìƒ<ul>
<li>í•™ìŠµì„ ìœ„í•œ ì½”ë“œì™€ ì¶”ë¡ ì„ ìœ„í•œ ì½”ë“œë¥¼ ë”°ë¡œ ì§œì•¼ í•¨</li>
<li>í•™ìŠµê³¼ ì¶”ë¡  ë°©ë²•ì˜ ê´´ë¦¬(discrepancy)ê°€ ë°œìƒí•˜ì—¬ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŒ<ul>
<li>ì™œëƒí•˜ë©´ trainì¼ë•ŒëŠ” ì •ë‹µ xê°€ time-stampë§ˆë‹¤ ë“¤ì–´ì™€ì„œ hidden stateì—ì„œ ë„˜ê²¨ì£¼ëŠ” ê°’ë³´ë‹¤ ì •ë‹µì„ ë” ì¤‘ìš”ì‹œ í•  ìˆ˜ ìˆì–´ ì´ì „ stateë¥¼ ì¤‘ì‹œ ì•ˆí•¨ í•˜ì§€ë§Œ inference ì‹œì—ëŠ” ì •ë‹µì´ ì•„ë‹ˆë¼ ì •ë‹µ ì˜ˆì¸¡ê°’ì´ ë„˜ì–´ì˜¤ê¸°ì— ê´´ë¦¬ê°€ ë°œìƒ..</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-20T14:36:24.000Z" title="8/20/2023, 11:36:24â€¯PM">2023-08-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:27.000Z" title="12/21/2023, 12:40:27â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">4 minutes read (About 669 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Language-Modeling-%E2%80%93-RNN%E1%84%8B%E1%85%B3%E1%86%AF-%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB-LM/">2ì¥. Language Modeling â€“ RNNì„ í™œìš©í•œ LM</a></h1><div class="content"><h2 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h2><h3 id="Neural-Language-Model"><a href="#Neural-Language-Model" class="headerlink" title="Neural Language Model"></a>Neural Language Model</h3><ul>
<li><p>Resolve Sparsity</p>
<ul>
<li>Training Set<ul>
<li>ê³ ì–‘ì´ëŠ” ì¢‹ì€ ë°˜ë ¤ë™ë¬¼ ì…ë‹ˆë‹¤.</li>
</ul>
</li>
<li>Test set<ul>
<li>ê°•ì•„ì§€ëŠ” í›Œë¥­í•œ ì• ì™„ë™ë¬¼ ì…ë‹ˆë‹¤. (Unseen word sequenceë¼ ê°€ì •í•˜ì)</li>
</ul>
</li>
</ul>
</li>
<li><p>Because we know (and we can </p>
<p>approximate</p>
<p> that)</p>
<ul>
<li>ê³ ì–‘ì´ â‰ˆ ê°•ì•„ì§€</li>
<li>ì¢‹ì€ â‰ˆ í›Œë¥­í•œ</li>
<li>ë°˜ë ¤ë™ë¬¼ â‰ˆ ì• ì™„ë™ë¬¼</li>
</ul>
</li>
<li><p>But n-gram <strong>CANNOT</strong>, because words are <strong>discrete</strong> symbols</p>
</li>
</ul>
<h3 id="Neural-Language-Model-1"><a href="#Neural-Language-Model-1" class="headerlink" title="Neural Language Model"></a>Neural Language Model</h3><ul>
<li><p>Find parameter that maximize likelihood for given training corpus</p>
<ul>
<li><p>$D&#x3D;{x^i }_{i&#x3D;1}^N$ .</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$ &#x2F;&#x2F; ë°ì´í„°ì— ëŒ€í•´ log-likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì</p>
<p>$&#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i}|x_{&lt;j}^i; \theta)$<br>&#x2F;&#x2F; by chain-rule<br>$\text{where } x_{1:n} &#x3D; {x_1, â€¦, x_n}$</p>
</li>
</ul>
</li>
<li><p>Take a step of gradient descent to minimize negative log-likelihood</p>
<ul>
<li><p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i},|P(x_{&lt;j}^i; \theta)$</p>
<p>$\theta \leftarrow \theta - \eta\nabla_\theta L(\theta)$<br>$\log P(x_t | x_{&lt;t}; \theta) &#x3D; x_t^T \cdot \log f_\theta(x_{t-1}, h_{t-1})$ &#x2F;&#x2F; softmax layerë¥¼ í†µê³¼í•˜ëŠ” ê²½ìš°,<br>                                            &#x2F;&#x2F; $x_t^T$ : GT (One-hot vector, ì‹¤ì œ ì˜ˆì¸¡ ë‹¨ì–´)<br>                                           &#x2F;&#x2F; $\log f_\theta(x_{t-1}, h_{t-1})$ : LM(softmax layerì— log ì”Œìš´ í™•ë¥ ê°’)</p>
</li>
</ul>
<p>$\text{where } x_t \text{ is one-hot vector, and }f_Î¸ \text{ is model with parameter Î¸.}$</p>
<ul>
<li><p>ë” ì„¸ë¶€ì ìœ¼ë¡œ ë³´ë©´.</p>
<ul>
<li><p>$f(x_{t-1}, h_{t-1}) &#x3D; \text{softmax}(RNN(\text{emb}(x_{t-1}), h_{t-1}) \cdot W)$ $\text{, where W} \in \mathbb{R}^{hidden-size \times |V|}$   &#x2F;&#x2F; WëŠ” softmax ì „ì— ìƒëµëœ linear layer<br>$&#x3D;\text{softmax}(h_t \cdot W)\text{, where } W \in \mathbb{R}^{hidden-size \times |V|}$</p>
<p>$&#x3D;\hat{x_t}$</p>
<p>$\text{where } \hat{x_t} \text{ is a probability distribution that } P(\cdot|x_{&lt;t};\theta)$</p>
<ul>
<li>$\hat{ğ‘¥_ğ‘¡}$ : mini-batch ë‚´ ë¬¸ì¥ë³„ ë‹¨ì–´ë³„ í™•ë¥ ê°’, ì´ì „ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì„¸íƒ€ì—ì„œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì€ í™•ë¥  ë¶„í¬</li>
</ul>
<ul>
<li><p>|w| &#x3D; (hs, |V|)</p>
</li>
<li><p>|$h_t$|&#x3D;(ğ‘ğ‘ , â„ğ‘ ) &#x3D; (bs,1, hs)</p>
</li>
<li><p>|$\hat{x_t}$| &#x3D; (bs,1,hs) x (hs, |V|) &#x3D; (bs, |V|)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6eb9dd73-dda7-401c-b574-3c6acbc1a5f3" alt="NeuralLanguageMode"></p>
<ul>
<li>softmaxëŠ” ë‹¤ìŒ time-stepì— ë‚˜ì˜¬ ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ„ ì¦‰, softmax layerì˜ ê° elementëŠ” ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ê°’(ë¶„í¬)(discrete multinomial distribution)</li>
</ul>
<h3 id="Loss-Function-of-NNLM"><a href="#Loss-Function-of-NNLM" class="headerlink" title="Loss Function of NNLM"></a>Loss Function of NNLM</h3><ul>
<li>Find theta that minimize negative log-likelihood.</li>
<li>Find theta that minimize cross entropy with ground-truth probability distribution.<ul>
<li><strong>softmaxë¥¼ ì‚¬ìš©í•˜ë©´ loss functionìœ¼ë¡œ CrossEntropyë¥¼ ì‚¬ìš©í•˜ê³ </strong></li>
<li><strong>log-softmaxë¥¼ ì‚¬ìš©í•˜ë©´ NLLì„ ì‚¬ìš©í•˜ì—¬ë¼(log-likelihoodë¥¼ maximzieí•˜ë©´ NLL ì‚¬ìš©)</strong></li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>n-gram  (previous method)<ul>
<li>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ì·¨ê¸‰<ul>
<li>exact matchinì— ëŒ€í•´ì„œë§Œ count</li>
</ul>
</li>
<li>ë”°ë¼ì„œ generalization issue ë°œìƒ<ul>
<li>Markov Assumption ë„ì…(n-gram)</li>
<li>Smoothing &amp; Discounting</li>
<li>Interpolation &amp; Back-off</li>
<li>Unseen sequenceì— ëŒ€í•œ ëŒ€ì²˜ ë¯¸í¡</li>
</ul>
</li>
<li>ë¹ ë¥¸ ì—°ì‚° &amp; ì‰½ê³  ì§ê´€ì <ul>
<li>ë‹¨ìˆœí•œ look-up table ë°©ì‹</li>
<li>ë¬¸ì¥ fluency ë¹„êµ taskì—ì„œëŠ” ê´œì°®ìŒ</li>
</ul>
</li>
</ul>
</li>
<li>Neural Network Language Model<ul>
<li>Word Embeddingì„ í†µí•´, unseen sequenceì— ëŒ€í•´ ëŒ€ì²˜ ê°€ëŠ¥</li>
<li>Generation taskì—ì„œ íŠ¹íˆ ê°•ì </li>
<li>ì—°ì‚°ëŸ‰ ë§ìŒ(feed forward ì—°ì‚°)<ul>
<li>í•´ì„(XAI) ë‚œì´ë„ ì¦ê°€</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-18T14:56:21.000Z" title="8/18/2023, 11:56:21â€¯PM">2023-08-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:40:35.000Z" title="12/21/2023, 12:40:35â€¯AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span>Â /Â </span><a class="link-muted" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/">ìì—°ì–´ìƒì„± ê°œë…</a></span><span class="level-item">10 minutes read (About 1455 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%E1%84%89%E1%85%A2%E1%86%BC%E1%84%89%E1%85%A5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Language-Modeling-How-to-evaluate-LM-Perplexity/">2ì¥. Language Modeling - How to evaluate LM(Perplexity)</a></h1><div class="content"><h2 id="How-to-evaluate-LM-Perplexity"><a href="#How-to-evaluate-LM-Perplexity" class="headerlink" title="How to evaluate LM - Perplexity"></a>How to evaluate LM - Perplexity</h2><h3 id="How-to-Evaluate"><a href="#How-to-Evaluate" class="headerlink" title="How to Evaluate"></a>How to Evaluate</h3><ul>
<li>Test set<ol>
<li>ë‚˜ëŠ” í•™êµì— ê°‘ë‹ˆë‹¤</li>
<li>ë‚˜ëŠ” í•™êµë¥¼ ê°‘ë‹ˆë‹¤.</li>
</ol>
</li>
<li>Intrinsic evaluation(ì •ì„± í‰ê°€)<ul>
<li>ì •í™•í•¨</li>
<li>ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“¤ì–´ê°</li>
</ul>
</li>
<li>Extrinsic evaluation(ì •ëŸ‰ í‰ê°€)<ul>
<li>ì‹œê°„ê³¼ ë¹„ìš©ì„ ì•„ë‚„ ìˆ˜ ìˆìŒ</li>
<li><strong>Intrinsic evaluation</strong>ê³¼ ë¹„ìŠ·í• ìˆ˜ë¡ ì¢‹ì€ ë°©ë²•!</li>
</ul>
</li>
</ul>
<h3 id="What-is-Good-Language-Model"><a href="#What-is-Good-Language-Model" class="headerlink" title="What is Good Language Model?"></a>What is Good Language Model?</h3><ul>
<li>ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ì˜ ë¶„í¬ë¥¼ ê°€ì¥ ì˜ ê·¼ì‚¬í•œ ëª¨ë¸<ul>
<li>ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ â†’ í…ŒìŠ¤íŠ¸ ì‹œì˜ ì…ë ¥ ë¬¸ì¥ë“¤</li>
<li>ë¶„í¬ë¥¼ ì˜ ê·¼ì‚¬ â†’ ë¬¸ì¥ì˜ likelihoodê°€ ë†’ì„ ê²ƒ</li>
</ul>
</li>
<li>ì˜ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ì…‹ì˜ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë†’ì€ í™•ë¥ ì„ ë°˜í™˜í•˜ëŠ” ì–¸ì–´ëª¨ë¸ì´ ì¢‹ì€ ëª¨ë¸!</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><ul>
<li><p>Perplexity (PPL) ë€</p>
<ul>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•´ì„œ ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ í™•ë¥ (likelihood)ì„ êµ¬í•˜ê³ </p>
</li>
<li><p>PPL ìˆ˜ì‹ì— ë„£ì–´ ì–¸ì–´ëª¨ë¸ì˜ ì„±ëŠ¥ ì¸¡ì •</p>
<ul>
<li><p>ë¬¸ì¥ì˜ í™•ë¥ ì„ ê¸¸ì´ì— ëŒ€í•´ì„œ normalization (ê¸°í•˜í‰ê· )</p>
<ul>
<li><p>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D; \sqrt[n]{ \frac{1}{P(x_1, \ldots, x_n; \theta)}}$</p>
<ul>
<li>ë‹¨ì–´ë“¤ì˜ Chain Rule ì´ê¸°ì— ë¬¸ì¥ì´ ê¸¸ìˆ˜ë¡ í™•ë¥ ê³±ìœ¼ë¡œ ê°’ì´ ì‘ì•„ì§(1ë³´ë‹¤ ì‘ì€ ê°’ì´ê¸° ë•Œë¬¸)</li>
<li>ì§§ì€ ë¬¸ì¥ì— ë¹„í•´ ê¸´ ë¬¸ì¥ì€ í™•ë¥ ì´ ì‘ì•„ì§€ê³  ê¸¸ì´ì— ë”°ë¥¸ ê¸°í•˜í‰ê· ì„ í•˜ê¸°ì—(-1&#x2F;n) ê¸¸ì´ì— ìƒê´€ì—†ì´ normalizeí•  ìˆ˜ ìˆìŒ</li>
<li>í™•ë¥ ì— ì—­ìˆ˜ë¥¼ ì·¨í–ˆìœ¼ë¯€ë¡œ PPLì€ ì‘ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ìŒì„ ì˜ë¯¸</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Chain Ruleì— ì˜í•´ì„œ</p>
<ul>
<li>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D;\sqrt[n]{\frac{1}{P(x_1, \ldots, x_n; \theta)}} &#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}}$</li>
</ul>
</li>
<li><p>Markov assumptionì´ ì ìš© ë  ê²½ìš°</p>
<ul>
<li>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D; \sqrt[n]{ \frac{1}{P(x_1, \ldots, x_n; \theta)}} &#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}} \approx \sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{i-1}, \ldots, x_{i-k}; \theta)}}$</li>
</ul>
</li>
<li><p>Perplexity</p>
<ul>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•´ì„œ <strong>í™•ë¥ ì„ ë†’ê²Œ ë°˜í™˜í• ìˆ˜ë¡</strong> ì¢‹ì€ ì–¸ì–´ëª¨ë¸</p>
</li>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•œ <strong>PPLì´ ì‘ì„ìˆ˜ë¡</strong> ì¢‹ì€ ì–¸ì–´ëª¨ë¸</p>
</li>
<li><p>ì˜ˆì œ</p>
<ul>
<li><p>ì£¼ì‚¬ìœ„ë¥¼ ë˜ì ¸ë´…ì‹œë‹¤.</p>
<ul>
<li>1ë¶€í„° 6ê¹Œì§€ì˜ 6ê°œì˜ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ìˆ˜ì—´</li>
<li>1ë¶€í„° 6ê¹Œì§€ 6ê°œì˜ ìˆ«ìì˜ ì¶œí˜„ í™•ë¥ ì€ ëª¨ë‘ ê°™ìŒ</li>
</ul>
</li>
<li><p>uniform distribution</p>
<ul>
<li><p>$D&#x3D;{x^i}_{i&#x3D;1}^{N} \text{, where } x_i \sim P(x) \text{ and } \forall x \in {1, 2, 3, 4, 5, 6}$</p>
<p>$PPL(x_1, \ldots, x_n; \theta) &#x3D;\sqrt[n]{\frac{1}{P(x_1, \ldots, x_n; \theta)}}&#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i)}}$    &#x2F;&#x2F; ë…ë¦½ì‹œí–‰ì´ê¸°ì—<br>$&#x3D;\sqrt[n]{\frac{1}{(\frac{1}{6})^n}} &#x3D; 6$    &#x2F;&#x2F; ì£¼ì‚¬ìœ„ ë©´ì˜ ê°¯ìˆ˜</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Perplexityë¥¼ í•´ì„í•˜ëŠ” ë°©ë²•</p>
<ul>
<li>ì£¼ì‚¬ìœ„ PPL : ë§¤ time-step ê°€ëŠ¥í•œ ê°€ì§“ìˆ˜ì¸ 6</li>
<li>ë»—ì–´ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” branch(ê°€ì§€)ì˜ ìˆ«ìë¥¼ ì˜ë¯¸</li>
<li><strong>Time-step ë³„ í‰ê·  branchì˜ ìˆ˜</strong></li>
<li>PPLì´ <strong>ë‚®ì„ìˆ˜ë¡</strong> í™•ë¥  ë¶„í¬ê°€ <strong>Sharp</strong> í•˜ë‹¤.</li>
<li>PPLì´ <strong>ë†’ì„ìˆ˜ë¡</strong> í™•ë¥  ë¶„í¬ê°€ <strong>Flat</strong> í•˜ë‹¤.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>ì¢‹ì€ ì–¸ì–´ëª¨ë¸<ul>
<li>ì˜ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ì…‹ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë†’ì€ í™•ë¥ (&#x3D;ë‚®ì€ PPL)ì„ ê°–ëŠ” ëª¨ë¸</li>
</ul>
</li>
<li>Perplexity(PPL)<ul>
<li>Lower is better</li>
<li>í™•ë¥ ì˜ ì—­ìˆ˜ì— ë¬¸ì¥ ê¸¸ì´ë¡œ ê¸°í•˜ í‰ê· </li>
<li>ë§¤ time-stepë§ˆë‹¤ í‰ê· ì ìœ¼ë¡œ í—·ê°ˆë¦¬ê³ (no clue) ìˆëŠ” ë‹¨ì–´ì˜ ìˆ˜</li>
</ul>
</li>
</ul>
<h2 id="Perplexity-amp-Entropy"><a href="#Perplexity-amp-Entropy" class="headerlink" title="Perplexity &amp; Entropy"></a>Perplexity &amp; Entropy</h2><h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h3><ul>
<li><p>Sharp vs Flat distribution</p>
<ul>
<li>Perplexityê°€ ë†’ìœ¼ë©´ flatí•˜ê³ (ê³ ë¥´ë‹¤)</li>
<li>Perplexityê°€ ë‚®ì„ìˆ˜ë¡ sharpí•˜ë‹¤</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/aebe52a3-6fbe-4f36-8bf5-cc553d8fff1f" alt="Perplexity"></p>
</li>
</ul>
<h3 id="Information-and-Entropy"><a href="#Information-and-Entropy" class="headerlink" title="Information and Entropy"></a>Information and Entropy</h3><ul>
<li><p>ì •ë³´ì´ë¡ ì—ì„œ ì—”íŠ¸ë¡œí”¼ëŠ” ì–´ë–¤ ì •ë³´ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ëƒ„</p>
</li>
<li><p>ë¶ˆí™•ì‹¤ì„±ì€ ì¼ì–´ë‚  ê²ƒ ê°™ì€ ì‚¬ê±´(likely event)ì˜ í™•ë¥ </p>
<ul>
<li>ìì£¼ ë°œìƒí•˜ëŠ” (ì¼ì–´ë‚  í™•ë¥ ì´ ë†’ì€) ì‚¬ê±´ì€ ë‚®ì€ ì •ë³´ëŸ‰ì„ ê°€ì§</li>
<li>ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ” (ì¼ì–´ë‚  í™•ë¥ ì´ ë‚®ì€) ì‚¬ê±´ì€ ë†’ì€ ì •ë³´ëŸ‰ì„ ê°€ì§</li>
</ul>
</li>
<li><p>ë¶ˆí™•ì‹¤ì„± âˆ $\frac{ğŸ}{í™•ë¥ }$âˆ ì •ë³´ëŸ‰</p>
</li>
<li><p>ì •ë³´ëŸ‰ ìˆ˜ì‹</p>
<ul>
<li>$I(\text{x})&#x3D;-\log P(\text{x})$     #  xë¼ëŠ” random variableì— ëŒ€í•œ ì •ë³´<ul>
<li>0â‰¤ğ‘ƒ(ğ‘¥)â‰¤1</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/fa29fa22-1bd0-4cf4-8aae-98df4911ad74" alt="Information"></p>
</li>
<li><p>ì •ë³´ëŸ‰ ì˜ˆì œ</p>
<ul>
<li>ì˜ˆì œ1<ol>
<li>ë‚´ì¼ ì•„ì¹¨ í•´ëŠ” ë™ìª½ í•˜ëŠ˜ì—ì„œ ëœ¹ë‹ˆë‹¤. â†’ í™•ë¥ ì´ ë†’ì„ìˆ˜ë¡ ì •ë³´ëŸ‰ì´ ë‚®ë‹¤.</li>
<li>ë‚´ì¼ ì•„ì¹¨ í•´ëŠ” ì„œìª½ í•˜ëŠ˜ì—ì„œ ëœ¹ë‹ˆë‹¤. â†’ í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ì—„ì²­ë‚œ ì •ë³´ëŸ‰ì„ ê°€ì§€ê³  ìˆë‹¤.</li>
</ol>
</li>
<li>ì˜ˆì œ2<ol>
<li>ì˜¬  ì—¬ë¦„ ëŒ€í•œë¯¼êµ­ì˜ í‰ê·  ì—¬ë¦„ ê¸°ì˜¨ì€ 30ë„ ì…ë‹ˆë‹¤. â†’ ì •ë³´ëŸ‰ì´ ë‚®ìŒ</li>
<li>ì˜¬ ì—¬ë¦„ ëŒ€í•œë¯¼êµ­ì˜ í‰ê·  ì—¬ë¦„ ê¸°ì˜¨ì€ 10ë„ ì…ë‹ˆë‹¤.â†’ ì •ë³´ëŸ‰ì´ ë†’ìŒ</li>
</ol>
</li>
</ul>
</li>
<li><p>ì–¸ì–´ëª¨ë¸ ê´€ì  ì˜ˆì œ</p>
<ul>
<li>í”íˆ ë‚˜ì˜¬ ìˆ˜ ì—†ëŠ” ë¬¸ì¥(í™•ë¥ ì´ ë‚®ì€ ë¬¸ì¥)ì¼ìˆ˜ë¡ ë” ë†’ì€ ì •ë³´ëŸ‰</li>
</ul>
</li>
</ul>
<h3 id="Perplexity-amp-Entropy-1"><a href="#Perplexity-amp-Entropy-1" class="headerlink" title="Perplexity &amp; Entropy"></a>Perplexity &amp; Entropy</h3><ul>
<li><p>Cross Entropy</p>
<ul>
<li><p>$H(P, P_\theta) &#x3D; -E_{x_{1:n} \sim P}[\log P(x_{1:n}; \theta)]$  &#x2F;&#x2F; P(X)ì—ì„œ ì–´ë–¤ ë¬¸ì¥ì„ samplingí•˜ì—¬ ìš°ë¦¬ ëª¨ë¸ì— ë„£ì—ˆì„ ë•Œë¡œê·¸ í™•ë¥ ê°’ì„ í‰ê· ë‚´ê³  ë§ˆì´ë„ˆìŠ¤ë¥¼ ì·¨í•˜ëŠ” CE</p>
<p>$\approx -\frac{1}{n} \sum_{x_{1:n} \in X} P(x_{1:n}) \log P(x_{1:n}; \theta)\text{, defined as per-word entropy}$ &#x2F;&#x2F;P(x_{1:n})\log{P(x_{1:n}; \theta)}: GT  x Log-likelihood</p>
</li>
</ul>
<p>$\approx -\frac{1}{n \times N} \sum_{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta) \text{, by Monte-Carlo}\approx -\frac{1}{n} \log P(x_{1:n}; \theta)\text{, where N&#x3D;1}$ &#x2F;&#x2F; 1ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ CEë¥¼ êµ¬í•¨<br>$\approx -\frac{1}{n} \sum_{i&#x3D;1}^{N} \log P(x_i | x_{&lt;i}; \theta)$ &#x2F;&#x2F; by chain rule<br>$&#x3D;L(x_{1:n}; \theta)$</p>
<ul>
<li>$L(x_{1:n}; \theta) \approx -\frac{1}{n} \sum_{i&#x3D;1}^{N} \log P(x_i | x_{&lt;i}; \theta)&#x3D;-\frac{1}{n} \log \prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)&#x3D;\log\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}}&#x3D;\log{PPL(x_{1:n};\theta)}$</li>
</ul>
</li>
<li><p>ì¦‰ PPL exp(CE)ì™€ ê°™ë‹¤.</p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Objective : minimize perplexity<ul>
<li>equivalent to minimize cross entropy</li>
<li>is also same as minimizing negative log-likelihood</li>
</ul>
</li>
<li>ë¬¸ì¥ì˜ likelihoodë¥¼ maximizeí•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê³  ì‹¶ìŒ<ul>
<li>Ground-truth í™•ë¥  ë¶„í¬(ì‹¤ì œ ì‚¬ëŒì´ ê°€ì§„ ì–¸ì–´ ëª¨ë¸)ì— ì–¸ì–´ëª¨ë¸ì„ ê·¼ì‚¬(approximate)í•˜ê³  ì‹¶ìŒ</li>
</ul>
</li>
<li>GT ë¶„í¬ì™€ LM ë¶„í¬ ì‚¬ì´ì˜ cross entropyë¥¼ êµ¬í•˜ê³  minimize<ul>
<li>ë¬¸ì¥ì˜ perplexityë¥¼ minimize.</li>
</ul>
</li>
<li><strong>perplexityë¥¼ í†µí•´ í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ë“¤ì˜ ìˆ«ìì´ê¸°ì—, ë‚´ LMì´ ë§¤ time-stepë§ˆë‹¤ í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ë“¤ì˜ ìˆ«ìê°€ ëª‡ ê°œêµ¬ë‚˜ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ.</strong></li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/Deep-Learning/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/Deep-Learning/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/Deep-Learning/">1</a></li><li><a class="pagination-link" href="/categories/Deep-Learning/page/2/">2</a></li><li><a class="pagination-link" href="/categories/Deep-Learning/page/3/">3</a></li><li><a class="pagination-link" href="/categories/Deep-Learning/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">ë…¸ë ¥ ë°±ì¤Œ ì—´ì • ì²œì¤Œì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">130</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">65</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">78</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê¸°ë³¸ ê°œë…</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ìì—°ì–´ìƒì„± ê°œë…</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ì¤‘ê¸‰ ê°œë…</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD íŒŒì´í”„ë¼ì¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/"><span class="level-start"><span class="level-item">ë²„ì „ ê´€ë¦¬</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ElasticSearch/"><span class="level-start"><span class="level-item">ElasticSearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/JPA/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/JPA/Basic/"><span class="level-start"><span class="level-item">Basic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%81%B4%EB%A6%B0%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">í´ë¦°ì½”ë“œ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/OPS/"><span class="level-start"><span class="level-item">OPS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/%EC%84%A4%EC%B9%98/"><span class="level-start"><span class="level-item">ì„¤ì¹˜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/%ED%95%A8%EA%BB%98%EC%9E%90%EB%A6%AC%EA%B8%B0/"><span class="level-start"><span class="level-item">í•¨ê»˜ìë¦¬ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/Clean-Code/"><span class="level-start"><span class="level-item">Clean Code</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">ë‚´ ì½”ë“œê°€ ê·¸ë ‡ê²Œ ì´ìƒí•œê°€ìš”</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Advanced-Concept/"><span class="level-start"><span class="level-item">Advanced Concept</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B0%8F-%EB%B9%84%EB%8F%99%EA%B8%B0/"><span class="level-start"><span class="level-item">ë™ì‹œì„± ë° ë¹„ë™ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">ë¬¸ë²•</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/REST/"><span class="level-start"><span class="level-item">REST</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/Spring-Framework/"><span class="level-start"><span class="level-item">Spring Framework</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">í•µì‹¬ ì›ë¦¬ - ê¸°ë³¸í¸</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/TIL/1%EB%A7%8C-%EC%8B%9C%EA%B0%84%EC%9D%98-%EB%B2%95%EC%B9%99/"><span class="level-start"><span class="level-item">1ë§Œ ì‹œê°„ì˜ ë²•ì¹™</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/"><span class="level-start"><span class="level-item">ê¸°íƒ€</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/"><span class="level-start"><span class="level-item">HTTP í”„ë¡œí† ì½œ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">ë°ì´í„° ì•”í˜¸í™”</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"><span class="level-start"><span class="level-item">ì¸ê³µì§€ëŠ¥</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC/"><span class="level-start"><span class="level-item">ê°œë… ì •ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/"><span class="level-start"><span class="level-item">í´ë¼ìš°ë“œ ì»´í“¨íŒ…</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EB%8F%84%EC%BB%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"><span class="level-start"><span class="level-item">ë„ì»¤ &amp; ì¿ ë²„ë„¤í‹°ìŠ¤</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/"><span class="level-start"><span class="level-item">í†µê³„í•™</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/%EA%B8%B0%EB%B3%B8/"><span class="level-start"><span class="level-item">ê¸°ë³¸</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"><span class="level-start"><span class="level-item">íŒŒì´ì¬</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-03T13:08:34.000Z">2024-09-03</time></p><p class="title"><a href="/new/DevOps/CICD%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AB/CI-CD-%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AB/">CI/CD íŒŒì´í”„ë¼ì¸</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD íŒŒì´í”„ë¼ì¸</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T15:59:18.000Z">2024-09-02</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/AES-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA%E1%84%8B%E1%85%AA-RSA-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/">AES ì•”í˜¸í™”ì™€ RSA ì•”í˜¸í™”</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/">ë°ì´í„° ì•”í˜¸í™”</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-30T14:54:04.000Z">2024-08-30</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/HTTP%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%90%E1%85%A9%E1%84%8F%E1%85%A9%E1%86%AF/CORS/">CORS</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/">HTTP í”„ë¡œí† ì½œ</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-26T14:52:30.000Z">2024-08-26</time></p><p class="title"><a href="/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/">ëª¨ë‹ˆí„°ë§</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-19T14:22:16.000Z">2024-08-19</time></p><p class="title"><a href="/%EB%8F%99%EC%8B%9C%EC%84%B1-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-vs-%EB%B3%91%EB%A0%AC-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/">ë™ì‹œì„± í”„ë¡œê·¸ë˜ë° vs ë³‘ë ¬ í”„ë¡œê·¸ë˜ë°</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1ê¸‰ ì‹œë¯¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Springì´ë€</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python ì„¤ì¹˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">ê°ì²´ì§€í–¥</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">ë‹¤í˜•ì„±</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">ëŒë‹¤ì‹</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">ë²¡í„°ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">ì—”íŠ¸ë¡œí”¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">ì •ë³´ëŸ‰</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">ì •ë³´ì´ë¡ </span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/"><span class="tag">íŒŒë¼ë¯¸í„°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">í–‰ë ¬ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>