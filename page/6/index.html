<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="차분하고 겸손하지만 확실하게!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="차분하고 겸손하지만 확실하게!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"차분하고 겸손하지만 확실하게!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-01T15:03:48.000Z" title="8/2/2023, 12:03:48 AM">2023-08-02</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:39:13.000Z" title="12/21/2023, 12:39:13 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">5 minutes read (About 792 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Probabilistic-Perspective-MAP/">2장. Probabilistic Perspective - MAP</a></h1><div class="content"><h3 id="MAP-Maximum-A-Posterior-Estimation"><a href="#MAP-Maximum-A-Posterior-Estimation" class="headerlink" title="MAP(Maximum A Posterior) Estimation"></a>MAP(Maximum A Posterior) Estimation</h3><ul>
<li><p>Data가 주어졌을 때 가설 h를 maximize 해야한다. 이를 위해 Posterior을 maximize할 수도 있고 likelihood로 maximize할 수도 있음</p>
</li>
<li><p>likelihood를 maximize 한다면 MLE</p>
</li>
<li><p>이 시간에는 poeteriror 를 maximize해서 h를 찾도록 하겠음 → MAP</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/396e25bd-8a54-4aa6-baab-2ee597481af8" alt="BayesTheorem"></p>
</li>
<li><p>MAP를 이해하기 위한 예제</p>
<ul>
<li><p>절도 사건의 범인은 발자국을 남겼습니다.</p>
</li>
<li><p>신발 사이즈 240일 때, 범인은 남자일까? 여자일까?</p>
<ul>
<li>$P(\text{y}│\text{x} &#x3D;240)$</li>
</ul>
</li>
<li><p>지인 중에 신발 사이즈가 240이었던 사람들을 떠올려보자</p>
<ul>
<li>여자 중에 많을까? 남자 중에 많을까?<ul>
<li>여자 중에서 신발 사이즈가 240인 사람 이라고 생각하면 likelihood(가정이 들어간 것</li>
<li>$P(\text{x}&#x3D;240|\text{y})$</li>
</ul>
</li>
</ul>
</li>
<li><p>그런데 범행 장소가 군부대라면?</p>
<ul>
<li><p>$P(\text{y}&#x3D;\text{male}) &gt; P(\text{y}&#x3D;\text{female})$</p>
<p>&#x2F;&#x2F; 99% &gt; 1%</p>
</li>
</ul>
</li>
<li><p>Likelihood는 여자일 가능성이 높지만, Prior를 고려하였을 때 범인은 남자일 가능성이 높음</p>
<ul>
<li>$P(\text{y} | \text{x} &#x3D; 240) &#x3D; \frac{P(\text{x} &#x3D; 240 | \text{y})P(\text{y})}{P(\text{x} &#x3D; 240)}$</li>
<li>$\frac{P(\text{x} &#x3D; 240 | \text{y&#x3D;male})P(\text{y&#x3D;male})}{P(\text{x} &#x3D; 240)} &gt; \frac{P(\text{x} &#x3D; 240 | \text{y&#x3D;female})P(\text{y&#x3D;female})}{P(\text{x} &#x3D; 240)}$</li>
</ul>
</li>
</ul>
</li>
<li><p>MAP Estimation</p>
<ul>
<li><p>Find $\hat{h}$, which maximizes posterior</p>
<ul>
<li><p>$\hat{h} &#x3D; \text{argmax}_{h \in H} P(h|D)$</p>
<p>$&#x3D; \text{argmax}_{h \in H} \frac{P(D|h)P(h)}{P(D)}$  &#x2F;&#x2F; 밑변은 h와 상관 없어 날려버림</p>
<p>$&#x3D; \text{argmax}_{h \in H}P(D|h)P(h)$  &#x2F;&#x2F; 𝑃(𝐷|ℎ) : likelihood, 𝑃(ℎ) : prior</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>MAP Estimation (딥러닝이니 h를 𝜽로 바꿈)</p>
<ul>
<li><p>Bayesian 관점</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} P(\theta|D) &#x3D; \text{argmax}</em>{\theta \in \Theta} \frac{P(D|\theta)P(\theta)}{P(D)} &#x3D;  \text{argmax}_{\theta \in \Theta}P(D|\theta)P(\theta)$ &#x2F;&#x2F; Data가 주어졌을 때 𝜃가 궁금함</p>
<ul>
<li>파라미터 또한 Random Variable로 간주하며,</li>
<li>사전 정보(prior)를 통해 파라미터의 사전 분포를 설정 (prior에 대한 가정이 필요)</li>
<li>이후 관찰된 데이터를 통해 사후(posterior) 분포를 계산하며, 사후 분포가 최대가 되는 파라미터를 찾는 MAP 방법을 사용</li>
<li>미래의 uncertainty 까지 고려</li>
<li>likelihood를 maximize하는 동시에 prior까지 maximize 함</li>
</ul>
</li>
<li><p>Frequentist 관점</p>
<p>$\hat{\theta}  &#x3D;  \text{argmax}_{\theta \in \Theta}P(D;\theta)$ &#x2F;&#x2F;# 𝑃(𝜃,𝐷), likelihood를 maximize</p>
<ul>
<li>파라미터는 고정된 값이며 최적화의 대상으로  봄</li>
<li>관찰된 데이터를 기반으로 MLE 방법을 사용하여 파라미터를 추정</li>
<li>과적합(Overfitting)에 취약함</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>MAP를 통해 우리는 posterior를 최대화 하는 hypothesis를 찾을 수 있음<ul>
<li>마찬가지로 주어진 데이터셋에 대한 posterior를 최대화 하는 파라미터(𝜃)를 찾을 수 있음</li>
</ul>
</li>
<li>Bayesian 관점에서는 파라미터들을 랜덤 변수로 보고 prior에 대한 가정을 통해, 앞으로의 uncertainty 까지 고려<ul>
<li>이를 통해 overfitting 등의 문제도 해결할 수 있음</li>
</ul>
</li>
<li>Bayesian Deep Learning에 대한 다양한 시도들도 이어지고 있음<ul>
<li>베이지안 방법론은 계산량이 많이 필요하고 복잡한 딥러닝 모델에 적용하는 데에는 여전히 여러 도전적인 문제들이 존재</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-01T14:58:52.000Z" title="8/1/2023, 11:58:52 PM">2023-08-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:39:23.000Z" title="12/21/2023, 12:39:23 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">11 minutes read (About 1638 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Probabilistic-Perspective-%E1%84%89%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%86%E1%85%A1%E1%86%BC%E1%84%80%E1%85%AA-MLE/">2장. Probabilistic Perspective - 신경망과 MLE</a></h1><div class="content"><h3 id="Again-our-object-is"><a href="#Again-our-object-is" class="headerlink" title="Again, our object is"></a>Again, our object is</h3><ul>
<li>데이터를 넣었을 때 출력을 반환하는 가상의 함수를 모사하는 것</li>
<li>확률 분포로부터 샘플링하여 데이터를 넣었을 때, 확률 분포를 반환하는 가상의 함수를 모사하는 것<ul>
<li>출력 분포에서 샘플링하면 원하는 출력 값을 얻을 수 있다.</li>
</ul>
</li>
<li>Example: 손 글씨가 주어졌을 때, 글씨의 클래스의 확률 분포<ul>
<li>$P(c|x) \text{, where } x \sim P(x)$</li>
</ul>
</li>
</ul>
<h3 id="Before-we-start"><a href="#Before-we-start" class="headerlink" title="Before we start,"></a>Before we start,</h3><ul>
<li>모두 같은 표현 (𝜃 를 𝑅𝑎𝑑𝑜𝑚 𝑉𝑎𝑟𝑖𝑎𝑏𝑙𝑒로 취급)<ul>
<li>$P_{\theta}(x) &#x3D; P(x; \theta) &#x3D; P(x|\theta)$ 𝜃 라는 파라미터를 갖는 확률분포에서의 𝑥의 확률값</li>
<li>$P_{\theta}(y|x) &#x3D; P(y|x; \theta) &#x3D; P(y|x, \theta)$ 𝜃 라는 파라미터를 갖는 확률분포에서의 𝑥가 주어졌을 때 𝑦의 확률값(</li>
</ul>
</li>
</ul>
<h3 id="Parameters-for-Probability-Distribution"><a href="#Parameters-for-Probability-Distribution" class="headerlink" title="Parameters for Probability Distribution"></a>Parameters for Probability Distribution</h3><ul>
<li>Bernoulli Distribution<ul>
<li>𝜃&#x3D;{𝑝} (동전던지기의 확률 같은)</li>
</ul>
</li>
<li>Gaussian Distribution<ul>
<li>𝜃&#x3D;{𝜇,𝜎} (대한민국 키(신장)의 분포를 알고 싶어요)</li>
</ul>
</li>
<li>딥러닝에서는 파라미터가 W와 b 가 되는 것이다!! 이 W와 b를 통해 확률 분포 함수를 정의할 수 있음</li>
</ul>
<h3 id="Parameters-for-Deep-Neural-Networks"><a href="#Parameters-for-Deep-Neural-Networks" class="headerlink" title="Parameters for Deep Neural Networks"></a>Parameters for Deep Neural Networks</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/5f569c9f-d7f1-4df8-8745-be016e3fd5ff" alt="MLE-DNN"></p>
<ul>
<li>$\theta &#x3D; {W_1, b_1, W_2, b_2, \ldots, W_l, b_l}$</li>
<li>마찬가지로 Gradient Ascent를 통해 Likelihood를 최대로 하는 파라미터(𝜽)를 찾을 수 있다.<ul>
<li>$\sum_{i&#x3D;1}^{n} \log P(x_i | \theta)$ 를 Maximize 하는 𝜃를 찾을 수 있음</li>
</ul>
</li>
</ul>
<h3 id="Negative-Log-Likelihood-NLL"><a href="#Negative-Log-Likelihood-NLL" class="headerlink" title="Negative Log Likelihood(NLL)"></a>Negative Log Likelihood(NLL)</h3><ul>
<li>하지만 대부분의 딥러닝 프레임워크들은 Gradient Descent만 지원<ul>
<li>$\theta \leftarrow \theta - \alpha \cdot \frac{\partial \mathcal{L}(\theta)}{\partial \theta}$</li>
</ul>
</li>
<li>따라서 maximization 문제에서 minimization 문제로 접근 (-1만 곱하면 됨)</li>
</ul>
<h3 id="Deep-Neural-Networks-with-MLE"><a href="#Deep-Neural-Networks-with-MLE" class="headerlink" title="Deep Neural Networks with MLE"></a>Deep Neural Networks with MLE</h3><ul>
<li>MLE는 관측된 데이터를 가장 잘 설명하는 모델 파라미터를 찾는 방법으로, 모델의 손실 함수를 설계하는 데 사용되며, 일반척으로 cross-entropy loss function 및 NLL이 MLE를 기반으로 함. 이 손실 함수를 최소화 함으로써 모델은 데이터를 가장 잘 설명하는 파라미터 값을 찾아가는 과정을 수행</li>
<li>MLE는 특정 데이터를 가장 잘 설명하는 확률 모델의 매개변수를 추정하는 방법</li>
<li>관찰된 데이터에 대한 모델의 적합성을 측정</li>
<li>분포 $P(\text{x})$로부터 샘플링한 데이터 𝒙가 주어졌을 때, 파라미터 𝜃를 갖는 DNN은 조건부 확률 분포를 나타냄<ul>
<li>$P(\text{y}|x;\theta) \text{, where } x \sim P(\text{x})$</li>
</ul>
</li>
<li>이때, 우리는 Gradient Descent를 통해 NLL을 최소화하는 𝜽를 찾을 수 있음<ul>
<li>$\hat{\theta} &#x3D; \text{argmin}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} -\log P(y_i | x_i; \theta)$</li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>MLE를 통해 수집한 데이터셋을 잘 설명하는 확률 분포의 파라미터를 찾을 수 있음<ul>
<li>하지만 비선형 함수에서는 베르누이나 가우시안 확률분포로는 설명할 수 없음</li>
<li>분류 작업의 경우에는 네트워크의 출력을 softmax 함수에 통과시켜 각 클래스에 속할 확률을 나타내는 확률 분포를 얻을 수 있음</li>
<li>이진 분류 모델에서는 시그모이드 함수를 사용할 수 있음(출력 범위는 0~1)</li>
</ul>
</li>
<li>Neural Networks 또한 확률 분포 함수이므로, MLE를 통해 파라미터(𝝁, 𝝈)를 찾을 것<ul>
<li>최대한 대신 최소화를 위해 Negative Log-Likelihood(NLL)을 Gradient Descent</li>
</ul>
</li>
<li>Gradient Descent를 수행하기 위해선, 파라미터에 대한 미분이 필요함<ul>
<li>이를 효율적으로 수행하기 위해 back-propagation을 활용</li>
</ul>
</li>
</ul>
<p>딥러닝이란 확률 분포 함수인 동시에 낮은 차원으로 차원을 축소하자</p>
<h3 id="MLE-Equation"><a href="#MLE-Equation" class="headerlink" title="MLE Equation"></a>MLE Equation</h3><ul>
<li>$D&#x3D;{(x_i, y_i)}_{i&#x3D;1}^{N} \text{, where } x_i: \sim P(\text{x}) \text{, } y_i&#x3D; \sim P(\text{y} ,|x_i)$</li>
<li>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(y_i | x_i; \theta)$$&#x3D; \text{argmin}<em>{\theta \in \Theta} -\sum</em>{i&#x3D;1}^{N} \log P(y_i | x_i; \theta)$</li>
<li>$\theta \leftarrow \theta - \eta \nabla_\theta L(\theta)$</li>
</ul>
<h3 id="Connection-to-Deep-Neural-Networks"><a href="#Connection-to-Deep-Neural-Networks" class="headerlink" title="Connection to Deep Neural Networks"></a>Connection to Deep Neural Networks</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/612b11ed-5423-442c-bb79-2fbd01c9b250" alt="MLE-Softmax"></p>
<ul>
<li>$D&#x3D;{(x_i, y_i)}_{i&#x3D;1}^{N}$</li>
<li>$\hat{\theta} &#x3D; \text{argmin}<em>{\theta \in \Theta} -\sum</em>{i&#x3D;1}^{N} \log P(y_i | x_i; \theta)$</li>
<li>→  $\hat{y_i}&#x3D; f_\theta(x_i)$</li>
<li>$-\sum_{i&#x3D;1}^{N} \log P(y_i | x_i; \theta)&#x3D;-\sum_{i&#x3D;1}^{N} y_i^T \cdot \log\hat{y_i}$</li>
</ul>
<h3 id="MLE-NLL-amp-Cross-Entropy-Loss"><a href="#MLE-NLL-amp-Cross-Entropy-Loss" class="headerlink" title="MLE(NLL) &amp; Cross Entropy Loss"></a>MLE(NLL) &amp; Cross Entropy Loss</h3><ul>
<li><p>Minimizing Negative Log-Likelihood is equal to Minimizing Cross Entropy</p>
</li>
<li><p>$CE(y_{1:N},\hat{y}<em>{1:N}) &#x3D; -\frac{1}{N} \sum</em>{i&#x3D;1}^{N} y_i^T \cdot \log \hat{y}_i$   &#x2F;&#x2F; (1&#x2F;𝑁은 나중에 𝜃로 미분되어서 사라지기에 결국 MLE와 같음)</p>
<p>$&#x3D; -\frac{1}{N} \cdot \sum_{i&#x3D;1}^{N} \sum_{j&#x3D;1}^{d} y_{i,j} \times \log \hat{y}_{i,j}$</p>
<p>$&#x3D; -\frac{1}{N} \cdot \sum_{i&#x3D;1}^{N} \log P_\theta (y_i|x_i)$</p>
<p>$\text{where } y_{1:N} \in \mathbb{R}^{N \times d} \text{ and } \hat{y}_{1:N} \in \mathbb{R}^{N \times d}$</p>
</li>
<li><p>분류문제에서 Cross Entropy를 사용하고 CE Loss를 사용하여 최적화를 수행했는데, 이 모든 것은 결국 MLE를 수행하기 위한 것이다.(𝜽를 잘 찾는 과정(내가 수집한 데이터를 가장 잘 나타내기 위한 과정)을 하는 것)</p>
</li>
<li><p>Cross-Entropy 손실 함수는 두 확률 분포 사이의 차이를 측정</p>
<ul>
<li>딥러닝에서는 일반적으로 하나의 분포는 실제 레이블을 나타내고, 다른 하나는 모델의 예측을 나타냄</li>
<li>이 경우 Cross-Entropy 손실 함수는 모델의 예측이 실제 레이블을 얼마나 잘 반영하는지를 측정하는 데 사용</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2120b1fd-8916-459e-915e-57af2b4fef52" alt="MLE-Softmax2"></p>
</li>
</ul>
<blockquote>
<p>Negative Log-Likelihood (NLL)와 Cross-Entropy 손실 함수는 비슷한 개념을 포함하고 있지만, 엄밀히 말해서 동일한 것은 아님</p>
<p>이 둘의 차이점은 NLL이 단일 확률 분포에 대한 측정을 제공하는 반면, Cross-Entropy는 두 확률 분포 사이의 차이를 측정한다는 점입니다. 이 차이 때문에, 이 두 손실 함수는 다른 문맥에서 사용되며, 그 결과도 약간 다를 수 있음</p>
<p>그러나 분류 문제에서는 두 손실 함수가 동일한 결과를 제공하는 경우가 많습니다. 이는 각 클래스에 대한 실제 레이블 분포가 원-핫 인코딩 형식이기 때문 따라서 NLL과 Cross-Entropy 손실 함수는 종종 상호 교환적으로 사용</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-01T14:54:41.000Z" title="8/1/2023, 11:54:41 PM">2023-08-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:39:19.000Z" title="12/21/2023, 12:39:19 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">7 minutes read (About 1075 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Probabilistic-Perspective-Maximum-Likelihood-Estimation/">2장. Probabilistic Perspective - Maximum Likelihood Estimation</a></h1><div class="content"><h2 id="Maximum-Likelihood-Estimation-MLE"><a href="#Maximum-Likelihood-Estimation-MLE" class="headerlink" title="Maximum Likelihood Estimation(MLE)"></a>Maximum Likelihood Estimation(MLE)</h2><h3 id="Maximum-Likelihood-Estimation-란"><a href="#Maximum-Likelihood-Estimation-란" class="headerlink" title="Maximum Likelihood Estimation 란"></a>Maximum Likelihood Estimation 란</h3><ul>
<li><p>다음의 예시를 통해 왜 MLE가 필요한지 알아보자</p>
<ul>
<li><p>다음과 같이 대한민국 키의 평균을 얻기 위해 아래와 같은 샘플을 얻었다고 가정해보자. 이의 평균과 표준편차를 가장 잘 얻게 하려면 어떻게 해야할까?</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/abf815e8-2a1b-4ae7-a69a-ab6bb09ff5d3" alt="Gaussian01"></p>
</li>
<li><p>다음과 같이 3개의 가우시안 분포(Gaussian Distribution)를 살펴보자. 어떤 가우시안 분포가 가장 우리의 샘플을 잘 설명했다고 할 수 있을까? <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/dbbdb037-d4a8-4c2e-9e51-09c66d36b2c2" alt="Gaussian02"></p>
<ul>
<li>점선의 길이(Line’s length &#x3D; probabilty density)가 가장 긴 것이 제일 잘 표현한 것 같은데!(Approxmation 3) <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/aeca5859-2868-4efc-a179-ab3e83c008a8" alt="Gaussian03"></li>
</ul>
</li>
<li><p>따라서 우리의 샘플을 가장 잘 표현하는 가우시안 분포를 그리기 위한 𝜇와 𝜎를 찾자</p>
<ul>
<li>Likelihood 를 최대화 하는 MLE(Maximum Likelihood Estimation)을 구하자</li>
</ul>
</li>
</ul>
</li>
<li><p>Likelihood Function</p>
<ul>
<li>입력으로 <code>주어진 확률 분포(파라미터(𝜇,𝜎))가 데이터를 얼마나 잘 설명하는지 나타내는 점수(Likelihood)를 출력</code> 하는 함수<ul>
<li>입력 : 확률 분포를 표현하는 파라미터(𝜇,𝜎)</li>
<li>출력 : 데이터를 설명하는 정도 (Probability Density가 높아야)</li>
</ul>
</li>
<li>데이터를 잘 설명하는지 알 수 있는 방법<ul>
<li>데이터가 해당 확률 분포에서 <strong>높은 확률 값</strong>을 가질 것</li>
</ul>
</li>
<li>수식<ul>
<li>$L(\theta | x) &#x3D; P(x | \theta)$<ul>
<li>$x$ : 관찰된 데이터</li>
<li>$\theta$ : 모델의 파라미터</li>
<li>$P(x|\theta) : \theta$로 주어진 $x$의 확률</li>
<li>$L : \theta$ 에 대한 likjelihood function(우도 함수)</li>
</ul>
</li>
<li>$L(\theta | x_1, x_2, …, x_n) &#x3D; \prod_{i&#x3D;1}^{n} P(x_i | \theta)$ (주어진 데이터셋이 독립적이고 동일하게 분포(i.i.d)한 경우, 전체 데이터의 likelhood function은 각각의 데이터 포인트에 대한 확률의 곱으로 표현될 수 있음)<ul>
<li>하지만 실제 계산에서는 이렇게 곱셈 형태의 우도 함수는 계산이 어렵고, underflow 문제를 일으키기 때문에, 대부분의 경우 <code>로그 우도 함수(log-likelihood function)</code>을 사용 (중요)<ul>
<li>로그를 취하면 곱셈이 덧셈으로 바뀌어 계산이 쉬워짐 $\log L(\theta | x_1, x_2, …, x_n) &#x3D; \sum_{i&#x3D;1}^{n} \log P(x_i | \theta)$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>다음의 예제를 통해 MLE를 더 잘 이해해보자</p>
<ul>
<li>주사위의 확률 분포를 알고 싶다. <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/a01e5190-5346-4d60-b6f1-7ac23528230f" alt="MLE-EX01"><ul>
<li>점수(likelihood)가 가장 높은 것은 $\theta_3$이다. 따라서 위 3개 중에서는 데이터를 잘 설명하는 파라미터라고 할 수 있음</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Log-Likelihood"><a href="#Log-Likelihood" class="headerlink" title="Log-Likelihood"></a>Log-Likelihood</h3><ul>
<li>확률 분포의 가능성을 측정</li>
<li>앞에서 소개했다 싶이, Likelihood는 확률 곱으로 표현이 됨<ul>
<li>underflow의 가능성이 있음</li>
</ul>
</li>
<li>따라서 Log를 취하여 곱셈을 덧셈으로 바꾸고, Log Likelihood로 문제를 해결<ul>
<li>덧셈이 곱셈보다 연산도 빠름</li>
</ul>
</li>
<li>$\prod_{i&#x3D;1}^{n} P_{\theta}(\text{x} &#x3D; x_{i})$   → $\sum_{i&#x3D;1}^{n} \log P_{\theta}(\text{x} &#x3D; x_{i})$</li>
</ul>
<h3 id="MLE-via-Gradient-Ascent"><a href="#MLE-via-Gradient-Ascent" class="headerlink" title="MLE via Gradient Ascent"></a>MLE via Gradient Ascent</h3><ul>
<li><p>랜덤 생성 대신, Gradient Ascent를 통해 likelihood 값을 최대로 만드는 파라미터(𝜽)를 찾자</p>
<ul>
<li>$\theta \leftarrow \theta + \alpha \cdot \frac{\partial \mathcal{L}(\theta)}{\partial \theta}$</li>
</ul>
</li>
<li><p>예제</p>
<ul>
<li>n &#x3D; 100번 던졌을 때, k&#x3D;27번 앞면(True)이 나오는 동전이 있다. 이 동전의 확률 분포(파라미터 𝜽)를 추정하자.<ul>
<li>Binomial Distribution<ul>
<li>$\mathcal{L}(\theta) &#x3D; \frac{n!}{k!(n-k)!} \theta^k (1-\theta)^{n-k}$</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/03111cda-c739-44c4-bd54-e217e6367085" alt="MLE-GradientAscent"></p>
</li>
</ul>
<h3 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h3><ul>
<li>우리는 가상의 확률 분포를 모사하는 확률 분포의 파라미터(𝜽)를 찾고 싶다</li>
<li>목표 확률 분포로부터 데이터를 수집한 후, 데이터를 잘 설명하는 파라미터를 찾자<ul>
<li>Likelihood라는 값을 통해 얼마나 잘 설명하는지 알 수 있다</li>
<li>Likelihood function은 𝜃 을 입력으로 받아, 데이터들의 𝜃 에 대한 확률 값의 곱을 출력</li>
</ul>
</li>
<li>Likelihood를 최대화 하는 파라미터를 찾으면, 주어진 데이터를 가장 잘 설명한다.<ul>
<li>Gradient Ascent를 통해서 찾자.<ul>
<li>$\theta \leftarrow \theta + \alpha \cdot \frac{\partial \mathcal{L}(\theta)}{\partial \theta}$</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-29T14:59:01.000Z" title="7/29/2023, 11:59:01 PM">2023-07-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:38:48.000Z" title="12/21/2023, 12:38:48 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">18 minutes read (About 2713 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Probabilistic-Perspective-Basic-Statistics/">2장. Probabilistic Perspective - Basic Statistics</a></h1><div class="content"><h2 id="기본-통계학-Basic-Statistics"><a href="#기본-통계학-Basic-Statistics" class="headerlink" title="기본 통계학(Basic Statistics)"></a>기본 통계학(Basic Statistics)</h2><h3 id="Random-Variable-amp-Probability-Distribution"><a href="#Random-Variable-amp-Probability-Distribution" class="headerlink" title="Random Variable &amp; Probability Distribution"></a>Random Variable &amp; Probability Distribution</h3><ul>
<li>확률 변수(Random Variable)는 사건의 시행의 결과(확률)를 하나의 수치로 대응시킬 때의 확률 값, 일반적으로 대문자 X를 사용</li>
<li>어떤 변수(Random Variable) x가 𝒙 라는 값을 가질 확률<ul>
<li>$𝑃(\text{x}&#x3D;𝑥) &#x3D;𝑃(𝑥)$</li>
</ul>
</li>
<li>확률 분포 (함수)<ul>
<li>입력 : 확률 변수 x</li>
<li>출력 : x가 각 값에 해당될 때에 대한 확률값</li>
</ul>
</li>
<li>이산 확률 변수<ul>
<li>확률변수가 취할 수 있는 값의 수가 유한한 변수</li>
<li>ex) 동전 던지기, 주사위 던지기(X&#x3D;{0, 1, 2, 3})</li>
</ul>
</li>
<li>연속 확률 변수<ul>
<li>확률변수가 취할 수 있는 값의 수가 무한한 변수</li>
<li>ex) 키, 몸무게(P(50 ≤ X ≤ 60)) 등</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2aeefb28-c594-4c5c-806e-69d7d571f19f" alt="ProbabiltyDistibution"></p>
<h3 id="Function-or-Value"><a href="#Function-or-Value" class="headerlink" title="Function? or Value?"></a>Function? or Value?</h3><ul>
<li>확률값<ul>
<li>$𝑃(𝑥) &#x3D; P(\text{x}&#x3D;x)$</li>
</ul>
</li>
<li>확률 분포 함수<ul>
<li>$P(\text{x})$<br><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/47210d6e-73d3-4db3-8d14-817b51030869" alt="ProbabilityDensityFunction"></li>
<li>$P(y|x)$<ul>
<li>$P(y|x) &#x3D; P(\text{y}&#x3D;y|\text{x}&#x3D;x)$</li>
<li>Random Variable x가 𝑥 라는 값을 가졌을 때, Random Variable y가 𝑦일 확률 값</li>
</ul>
</li>
<li>$P(\text{y}|x)$<ul>
<li>$P(\text{y}|x) &#x3D; P(\text{y}|\text{x}&#x3D;x)$</li>
<li>Random Variable x가 𝑥 라는 값을 가졌을 때, Random Variable y의 분포</li>
</ul>
</li>
<li>$P(y|\text{x})$<ul>
<li>$P(y|\text{x})&#x3D;f(\text{x})&#x3D;P(\text{y}&#x3D;y|\text{x})$</li>
<li>어떤 Random Variable이 입력으로 주어졌을 때, Random Variable y가 𝑦일 확률 값을 뱉어내는 함수</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="확률-분포-Probability-Distribution"><a href="#확률-분포-Probability-Distribution" class="headerlink" title="확률 분포(Probability Distribution)"></a>확률 분포(Probability Distribution)</h3><p>확률 분포는 수치로 대응된 확률 변수의 개별 값들이 가지는 확률값의 분포</p>
<ul>
<li><p>이산 확률 분포(Discrete Probability Distribution) : 확률 변수가 취할 수 있는 값의 수가 유한한 확률 분포</p>
<ul>
<li><p>확률 질량함수(Probability Mass Function) : 확률 변수에서 특정 값에 대한 확률을 나타내는 함수</p>
<ul>
<li>확률값의 총 합은 1<ul>
<li>$\sum_{x} P(\text{x}&#x3D;x) &#x3D; 1, \text{ where } 0 \leq P(\text{x}&#x3D;x) \leq 1, \forall x \in \chi$</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c555ab55-2167-44ae-b5a1-f67a393b9f46" alt="ProbabilityMassFunction"></p>
</li>
<li><p>주사위가 예시가 될 수 있음(이산 확률 분포)</p>
</li>
</ul>
</li>
<li><p>연속 확률 분포(Continuous Probability Distribution) : 확률 변수가 취할 수 있는 값의 수가 무한한 확률 분포</p>
<ul>
<li><p>확률 밀도 함수(robability Density Function , PDF)  : 확률 변수의 분포를 나타내는 함수</p>
<ul>
<li>면적의 합이 1<ul>
<li>$\int P(x) , dx &#x3D; 1, \text{ where } P(x) \geq 0, \forall x \in \mathbb{R}$</li>
</ul>
</li>
<li>함수값이 1보다 클 수 있음</li>
</ul>
<p>※ 주사위는 확률질량함수(이산), 확률밀도함수는 연속함수</p>
</li>
<li><p>연속 확률 변수의 경우, 어떤 샘플이 주어졌을 때, <strong>확률값을 알 수 없다</strong>. (높이는 단지 확률 밀도)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/f5c4716d-50e0-4c88-bc30-3b24db0869bc" alt="ProbabilityDensityFunction"></p>
</li>
</ul>
</li>
<li><p>결합 확률 분포(Joint Probability Distribution)</p>
<ul>
<li><p>두 개 이상의 Random Variable이 결합되었을 때의 확률 분포</p>
</li>
<li><p>두 이벤트 A와 B가 동시에 발생할 확률을 의미합니다. 이를 기호로 나타내면 P(A ∩ B) 또는 P(A, B)로 표현</p>
</li>
<li><p>P(A, B) &#x3D; P(A|B) * P(B) &#x3D; P(B|A) * P(A)</p>
<ul>
<li>P(A, B) : 사건 A와 사건 B가 동시에 발생할 확률</li>
<li>P(A|B) : 사건 B가 발생한 조건 하에서 사건 A가 발생할 확률</li>
<li>P(B) : 사건 B가 발생할 확률</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2e67be1b-9289-44dc-a006-cd221bbec36c" alt="JointProbabilityDistribution"></p>
</li>
</ul>
</li>
</ul>
<h3 id="조건부-확률-Conditional-Probability"><a href="#조건부-확률-Conditional-Probability" class="headerlink" title="조건부 확률(Conditional Probability)"></a>조건부 확률(Conditional Probability)</h3><ul>
<li><p>어떤 사건 A가 일어났을 때 사건 B가 일어날 확률을 의미. 즉, 사건 A가 주어졌을 때의 사건 B의 확률</p>
</li>
<li><p>조건부 확률 분포</p>
<ul>
<li><p>랜덤 변수의 분포가 다른 랜덤 변수의 값에 의해 어떻게 영향을 받는지를 설명하는 확률 분포</p>
</li>
<li><p>즉, 하나의 랜덤 변수 X의 값이 주어졌을 때, 다른 랜덤 변수 Y의 분포를 의미</p>
</li>
<li><p>$P(\text{y}|\text{x}) &#x3D; \frac{P(\text{x}, \text{y})}{P(\text{x})}$ (x가 조건으로 주어졌을 때 y의 확률값)</p>
<p>P y given x 라고 읽음</p>
</li>
<li><p>조금더 친해져야할 형태(<strong>결합확률분포 형태</strong>)</p>
<ul>
<li>$<strong>P(\text{x}, \text{y}) &#x3D; P(\text{y} ,|, \text{x})P(\text{x})</strong>$</li>
</ul>
</li>
<li><p>예를 들어, 랜덤 변수 X가 ‘오늘 비가 올 확률’을 나타낸다고 할 때, 랜덤 변수 Y는 ‘비가 올 때 우산을 가지고 갈 확률’을 나타낼 수 있음. 이 경우, ‘우산을 가지고 갈 확률’은 ‘비가 올 확률’에 의해 영향을 받음. 이런 상황을 모델링한 것이 조건부 확률 분포이다.</p>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/cf745351-0dc1-492d-a970-9369752d8228" alt="CP"></p>
<h3 id="베이즈-정리-Bayes-Theorm"><a href="#베이즈-정리-Bayes-Theorm" class="headerlink" title="베이즈 정리(Bayes Theorm)"></a>베이즈 정리(Bayes Theorm)</h3><ul>
<li><p>베이즈 정리는 확률 이론과 통계학에서 굉장히 중요한 개념으로, 조건부 확률에 관한 정리</p>
</li>
<li><p>조건부 확률의 개념을 확장하고 이를 뒤집는 데 사용</p>
</li>
<li><p>주어진 사건 B가 발생했을 때, 사건 A가 발생할 확률을 알아내는 방법을 제공. 즉, 이미 알고 있는 정보에 기반하여 새로운 사건의 확률을 추정하는 방법</p>
</li>
<li><p>$P(A ,|, B) &#x3D; \frac{P(B,|,A)P(A)}{P(B)}$,</p>
<ul>
<li>(A|B)는 사건 B가 발생했을 때 사건 A가 발생할 조건부 확률을 의미하며, 이를 사후 확률(Posterior probability)이라고 함</li>
<li>P(B|A)는 사건 A가 발생했을 때 사건 B가 발생할 조건부 확률을 의미하며, 이를 가능도(Likelihood)라고 함</li>
<li>P(A)는 사건 A가 발생할 확률을 의미하며, 이를 사전 확률(Prior probability)라고 함</li>
<li>P(B)는 사건 B가 발생할 확률을 의미하며, 이를 증거(Evidence)라고 함</li>
</ul>
<blockquote>
<p>A를 “오늘 비가 올 것”이라는 사건, B를 “오늘 하늘이 흐림”이라는 사건이라고 가정합시다. 이 경우, 베이즈 정리는 다음과 같이 표현될 수 있습니다.</p>
<ul>
<li>사후 확률(P(A|B)), 즉 “하늘이 흐릴 때 비가 올 확률”은 알고 싶은 최종적인 확률입니다. 이는 우리가 이미 알고 있는 “하늘이 흐림”이라는 정보를 바탕으로 “오늘 비가 올 것”이라는 새로운 사건에 대한 확률을 업데이트하는 것을 의미합니다.</li>
<li>가능도(P(B|A)), 즉 “비가 올 때 하늘이 흐릴 확률”은 우리가 이미 알고 있는 “비가 올 것”이라는 사건이 주어졌을 때 “하늘이 흐림”이라는 사건의 확률입니다. 이는 사건 A가 주어졌을 때 사건 B가 발생할 확률을 나타냅니다.</li>
</ul>
</blockquote>
</li>
<li><p>$P(h ,|, D) &#x3D; \frac{P(D,|,h)P(h)}{P(D)}$</p>
<ul>
<li><p>$P(h ,|, D)P(D) &#x3D; P(D,|,h)P(h) &#x3D;P(h,D)$</p>
</li>
<li><p>가설이 있을 때 데이터가 있을 확률을 뒤집어서 알 수 있게 해준다.</p>
</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>조건부 확률과 베이즈 정리의 차이를 다음의 예시로 알아보자</strong>예시 : “비가 오는 날에 우산을 들고 나가는 확률”</p>
<p><strong>조건부 확률</strong> ‘비가 오는 날’이라는 사건이 이미 일어났을 때, 그 조건 하에서 ‘우산을 들고 나가는’ 사건이 일어날 확률을 계산하는 것이 조건부 확률</p>
<p><strong>베이즈 정리</strong> ”우산을 들고 나가는 사람 중에서 비가 오는 경우”</p>
</blockquote>
<h3 id="주변-분포-Marginal-Distribution"><a href="#주변-분포-Marginal-Distribution" class="headerlink" title="주변 분포(Marginal Distribution)"></a>주변 분포(Marginal Distribution)</h3><ul>
<li><p>여러 변수의 결합 확률 분포에서 한 개 또는 일부 변수의 분포를 나타냄, 이는 ‘주변화(marginalization)’라는 과정을 통해 얻어짐</p>
</li>
<li><p>주변화는 결합 확률 분포에서 관심 있는 변수를 제외한 나머지 변수들을 모두 합산(이산)하거나 적분(연속)하는 과정을 의미</p>
</li>
<li><p>주변 확률 분포를 통해, 특정 변수가 다른 변수들로부터 독립적으로 어떻게 분포하는지를 파악할 수 있음, 이를 통해 그 변수의 분포를 단독으로 볼 수 있게 됨</p>
</li>
<li><p>주변 분포는 확률론의 핵심 개념인 결합 확률, 조건부 확률, 그리고 이들의 관계를 연결해 보여주며, 주어진 데이터에서 특정 변수의 확률 분포를 독립적으로 파악하는 데 유용</p>
</li>
<li><p>Marginal Distribution의 공식</p>
<ul>
<li><p>$P(x) &#x3D; \int P(x,z) dz$ ( P(x, z)는 x와 z의 결합 확률 분포를 나타내고, 이를 z에 대해 적분하면 x의 주변 확률 분포 x를 얻게 됨)</p>
<p>$&#x3D; \int P(x|z)P(z) dz$ (결합 확률분포를 조건부 확률 P(x | z)와 z의 주변 확률 P(z)의 곱으로 분해하고 이를 z에 대해 적분하여 x의 주변확률 분포 P(x)를 얻게됨)</p>
<p>$&#x3D; \int P(z|x)P(x) dz &#x3D; P(x)\int P(z|x) dz &#x3D; P(x)$   $(∵\int P(z|x) dz&#x3D;1)$ (조건부 확률 $P(z | x)$가 z에 대해 적분하면 1이 됨, 왜냐하면 조건부 확률 P(z|x)는 z의 확률 분포를 나타내기 때문)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/5780265a-73fa-41ca-9c58-f82a57308cff" alt="MarginalDistribution"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Expectation-and-Sampling"><a href="#Expectation-and-Sampling" class="headerlink" title="Expectation and Sampling"></a>Expectation and Sampling</h3><ul>
<li><p>기대값(expectation)은 확률 분포와 그에 대응하는 함수의 가중평균을 의미</p>
</li>
<li><p>기대값의 수식 (앞으로 자주 보게될 수식)</p>
<ul>
<li><p>$\mathbb{E}</p>
<p>{\text{x} \sim P(\text{x})}[f(x)] &#x3D; \sum</p>
<p>{x \in \chi} P(x) \cdot f(x)$</p>
<ul>
<li>$\chi$는 모든 가능한  $x$의 집합, $f(x)$는 $x$에 대한 함수, $P(x)$는 $x$의 확률 분포</li>
</ul>
</li>
</ul>
</li>
<li><p>f(x)라는 어떤 함수가 있는데, P(x)에서 샘플링한 x를 함수에 넣어봄</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/16640675-e6f2-4514-810a-2ff446075b79" alt="Expectation"></p>
</li>
<li><p>주사위의 기대값은?</p>
<ul>
<li><p>$\mathbb{E}<em>{x \sim P(x)}[f(x)] &#x3D; \sum</em>{x \in {1,2,3,4,5,6}} P(x &#x3D; x) \cdot f(x)$</p>
<p>$&#x3D;\frac{1}{6}×(f(1)+f(2)+f(3)+f(4)+f(5)+f(6))$</p>
<p>$&#x3D; \frac{1}{6}×(1+2+3+4+5+6)&#x3D;3.5 \text{, where } f(x)&#x3D;x$</p>
</li>
</ul>
<p>cf) 모든 기대값이 같으면 uniform distribution 따라서 시그마 1&#x2F;n *f(x)</p>
</li>
<li><p>$P(x) &#x3D; \int P(x,z) dz$</p>
<p>$&#x3D; \int P(x|z)P(z) dz$</p>
<p>$&#x3D; \mathbb{E}_{\text{z} \sim P(\text{z})}[P(x|\text{z})]$  (P(x)를 z에 대한 P(x|z)의 기대값으로 표현)</p>
</li>
</ul>
<h3 id="Monte-Carlo-방법"><a href="#Monte-Carlo-방법" class="headerlink" title="Monte-Carlo 방법"></a>Monte-Carlo 방법</h3><ul>
<li>무작위 표본을 사용하여 수학적 문제를 해결하는 통계적인 방법</li>
<li>주로 다음과 같은 상황에서 사용됨<ul>
<li>강화 학습에서는 Monte Carlo 방법을 사용하여 에이전트의 정책(policy)을 평가하거나 업데이트</li>
<li>딥러닝에서 복잡한 확률 모델에서 샘플을 추출하기 위해 Monte Carlo 샘플링 기법을 사용</li>
<li>복잡한 수학적 문제 해결<ul>
<li>복잡한 수학적 문제를 직접 해결하는 것이 어려울 때, Monte Carlo 방법을 사용하여 근사적인 해답을 찾을 수 있음</li>
</ul>
</li>
</ul>
</li>
<li>확률 분포로부터 샘플링을 통해 𝒇의 가중 평균을 구해보자<ul>
<li>sample의 크기가 커질수록 보다 정확하게 구할 수 있음</li>
<li>$\mathbb{E}<em>{x \sim P(x)}[f(x)] \approx \frac{1}{n} \sum</em>{i&#x3D;1}^{n} f(x_i) \text{, where } x_i \sim P(x)$</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-27T14:59:02.000Z" title="7/27/2023, 11:59:02 PM">2023-07-27</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:38:57.000Z" title="12/21/2023, 12:38:57 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">2 minutes read (About 356 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/2%E1%84%8C%E1%85%A1%E1%86%BC-Probabilistic-Perspective-Introduction/">2장. Probabilistic Perspective - Introduction</a></h1><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h3 id="Again-our-objective-is"><a href="#Again-our-objective-is" class="headerlink" title="Again, our objective is"></a>Again, our objective is</h3><ul>
<li>가상의 함수를 모사하여, 원하는 출력값을 반환하는 신경망의 파라미터를 찾자.</li>
<li>그래서 우리는 Deep Neural Networks를 이야기할 때,<ul>
<li>Gradient Descent</li>
<li>Back-Propagation</li>
<li>Feature Vector</li>
<li>and blah blah..</li>
</ul>
</li>
<li>이제는 우리의 생각을 확장시켜야 할 때! → Probabilistic Perspective!</li>
</ul>
<h3 id="Probabilistic-Perspective"><a href="#Probabilistic-Perspective" class="headerlink" title="Probabilistic Perspective"></a>Probabilistic Perspective</h3><ul>
<li><p>이 세상은 확률에 기반</p>
<ul>
<li><p>아래의 그림에 대해서 모두가 같은 대답을 하지는 않을 것 <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702" alt="duckrabbit"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702">https://github.com/shchoice/shchoice.github.io/assets/100276387/e711d4ed-678f-4058-ae5b-fc6bff6fc702</a></p>
</li>
<li><p>우리의 새로운 목표: <code>확률 분포</code>를 학습하는 것</p>
</li>
</ul>
</li>
<li><p>Before vs After</p>
<ul>
<li>Before<ul>
<li>함수를 배우자(모사하자)</li>
</ul>
</li>
<li>After<ul>
<li>확률 분포 함수를 배우자<ul>
<li>수학적으로 더 설명이 가능해짐</li>
<li>불확실성까지 학습</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a" alt="BeforeAfter"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a">https://github.com/shchoice/shchoice.github.io/assets/100276387/172bd68c-53e9-4b00-8506-929d68b9ca1a</a></p>
</li>
</ul>
<h3 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h3><ul>
<li>Neural Networks는 확률 분포 함수를 모델링할 수 있음</li>
<li>이를 통해 가상의 확률 분포 함수 𝑃(𝑦 | 𝑥)를 근사(approximation)할 것</li>
<li>대부분의 최신 기술들은 이 관점에 기반을 두고 만들어짐</li>
<li>DNN을 확률 분포로 보았을 때, 가능한 이론들에 대해서 앞으로 이야기 할 것<ul>
<li>Likelihood</li>
<li>Maximum Likelihood Estimation(MLE)</li>
<li>Maximum A Posterior(MAP) Estimation</li>
<li>Cross Entropy &amp; KL-Divergence</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-26T14:21:28.000Z" title="7/26/2023, 11:21:28 PM">2023-07-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:38:32.000Z" title="12/21/2023, 12:38:32 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">7 minutes read (About 999 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/1%E1%84%8C%E1%85%A1%E1%86%BC-Representation-Learning-AutoEncoders/">1장. Representation Learning - AutoEncoders</a></h1><div class="content"><h2 id="AutoEncoders"><a href="#AutoEncoders" class="headerlink" title="AutoEncoders"></a>AutoEncoders</h2><ul>
<li><p>Overview</p>
<ul>
<li>인코더(encoder)와 디코더(decoder)를 통해 압축과 해제를 실행<ul>
<li>인코더는 입력(𝑥)의 정보를 최대한 보존하도록 손실 압축을 수행</li>
<li>디코더는 중간 결과물(𝑧)의 정보를 입력(𝑥)과 같아지도록 압축 해제(복원)를 수행</li>
</ul>
</li>
<li>복원을 성공적으로 하기 위해, autoencoder는 특<strong>징(feature)을 추출하는 방법을 자동으로 학습</strong></li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/f9947a9e-f1f4-4e4c-b8ab-bba2427ffa45" alt="Encoder-Decoder"></p>
</li>
<li><p>Encoder</p>
<ul>
<li><p>복원에 필요한 정보를 중심으로 손실 압축을 수행</p>
</li>
<li><p>필요없는 정보(뻔한 특징)는 버릴 수도 있음</p>
<ul>
<li><p>예시1) 일반적인 사람의 얼굴을 학습할 때: 사람의 얼굴에서 눈은 2개이다 등</p>
</li>
<li><p>예시2)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2e64e11e-6879-4644-bb6c-d416e8cb5ebc" alt="NoMeaningMNIST"></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Bottleneck(𝒛)</p>
<ul>
<li>입력(𝒙)에 비해 작은 차원으로 구성</li>
<li>따라서 정보의 선택과 압축이 발생, 차원에 따라 압축의 정도를 결정함<ul>
<li>집에 불이 나서 탈출할 때, 무엇을 들고 나갈 것인가?</li>
</ul>
</li>
<li>그러므로 𝒛 는 입력(𝒙)에 대한 feature vector라고 할 수 있다.</li>
<li>압축의 효율이 높아야 하므로, 입력에 비해 dense vector일 것</li>
</ul>
</li>
<li><p>Decoder</p>
<ul>
<li>압축된 중간 결과물(𝒙)을 바탕으로 최대한 입력(𝒛)과 비슷하게 복원 : $\hat{x}$</li>
<li>보통 MSELoss 를 통해 최적화 수행 ($MSE&#x3D;|\hat{x}-x|^2_2$)</li>
<li>뻔한 정보는 주어지지 않더라도 어차피 알 수 있기에 복원 가능</li>
</ul>
</li>
</ul>
<h2 id="Hidden-Representation"><a href="#Hidden-Representation" class="headerlink" title="Hidden Representation"></a>Hidden Representation</h2><h3 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h3><ul>
<li><p>인코더로부터 나온 중간 결과물(𝒛)은 입력(𝒙)에 대한 feature vector이다.</p>
</li>
<li><p>feature vector의 각 차원은 어떤 의미를 내포하고 있을까?</p>
<ul>
<li><p>인코더의 결과물 𝒛를 plot 하였을 때, 비슷한 샘플들은 비슷한 곳에 위치함을 확인</p>
</li>
<li><p>이 plot이 뿌려진 공간을 hidden(latent) space라고 부름(잠재공간, feature vector가 위치하는 곳)</p>
<ul>
<li>Input space의 MNIST 샘플이 latent space에 embedding 된 것</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c02a4df6-74c9-49f3-b269-87abd0764629" alt="LatentSpace"></p>
</li>
</ul>
</li>
</ul>
<h3 id="Mapping-to-Hidden-Latent-Space"><a href="#Mapping-to-Hidden-Latent-Space" class="headerlink" title="Mapping to Hidden(Latent) Space"></a>Mapping to Hidden(Latent) Space</h3><ul>
<li>각 <strong>레이어의 결과물</strong>을 <code>hidden vector</code> 라고 부름</li>
<li>모두 feature vector라고 볼 수 있음</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/118c8c4d-dd4d-41cf-bc22-e524f3c77867" alt="hiddenSpace"></p>
<h3 id="Hidden-Latent-Representation"><a href="#Hidden-Latent-Representation" class="headerlink" title="Hidden(Latent) Representation"></a>Hidden(Latent) Representation</h3><ul>
<li><p>Tabular data의 feature vector와 달리, hidden vector는 해석이 어려움</p>
<ul>
<li>해석하고자 하는 연구(XAI. Explainable AI)들이 이어지고 있으나, 아직 갈 길이 멀다.</li>
</ul>
</li>
<li><p>하지만, 비슷한 특징을 가진 샘플은 비슷한 hidden vector를 가질 것</p>
</li>
<li><p>만약 각 차원이 명확하게 하나의 의미를 지닌다면 각 차원의 숫자를 조절하여 원하는 이미지를 합성해 낼 수 있을 것</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/4acbea3d-5fa3-4503-8cd8-4662a03b798f" alt="hiddenSpace02"></p>
</li>
</ul>
<h3 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h3><ul>
<li>오토인코더(AE)는 압축과 해제를 반복하며 특징 추출을 자동으로 학습<ul>
<li>필요한 정보와 필요없는 정보를 구분할 수 있게되는 것</li>
</ul>
</li>
<li>인코더로부터 나온 중간 결과물(𝒛)은 입력(𝑥)에 대한 feature vector이다.<ul>
<li>a.k.a Embedding vector</li>
<li>인코더에 통과시키는 것은 feature vector에 대한 embedding 과정이라고 볼 수 있음</li>
</ul>
</li>
<li>Hidden layer의 결과값들을 hidden vectors라 부르며, 이들은 샘플의 feature를 담고 있음<ul>
<li>여러개의 hidden vector들을 feature vector라 부를 수 있음</li>
<li>딥러닝에서는 label을 classify하기 위한 feature 를 자동으로 추출하여 학습(전통적인 머신러닝과의 차이점)</li>
</ul>
</li>
<li>신경망(또는 레이어)을 통과시키는 것은 입력 공간(input space)에서 잠재 공간(latent space)로의 맵핑 과정<ul>
<li>고차원 공간(high-dimensional space) → 저차원 공간(lower-dimensional space)</li>
</ul>
</li>
<li>Hidden representaion을 해석하는 것은 매우 어려움<ul>
<li>하지만 비슷한 샘플은 비슷한 hidden representation을 지닐 것!</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-25T14:56:47.000Z" title="7/25/2023, 11:56:47 PM">2023-07-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:38:40.000Z" title="12/21/2023, 12:38:40 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">8 minutes read (About 1171 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/1%E1%84%8C%E1%85%A1%E1%86%BC-Representation-Learning-One-hot-Encoding-%E1%84%86%E1%85%B5%E1%86%BE-Embedding-Vector/">1장. Representation Learning - One-hot Encoding 및 Embedding Vector</a></h1><div class="content"><h2 id="One-hot-Encoding"><a href="#One-hot-Encoding" class="headerlink" title="One-hot Encoding"></a>One-hot Encoding</h2><h3 id="Categorical-Value-vs-Continuous-Value"><a href="#Categorical-Value-vs-Continuous-Value" class="headerlink" title="Categorical Value vs Continuous Value"></a>Categorical Value vs Continuous Value</h3><ul>
<li>Categorical Value<ul>
<li>보통은 discrete value</li>
<li>단어, 클래스</li>
</ul>
</li>
<li>Continuous Value<ul>
<li>키, 몸무게</li>
</ul>
</li>
<li>Categorical Value와 Continuous Value의 가장 결정적인 차이점<ul>
<li>Continous value는 비슷한 값은 비슷한 의미를 지니지만</li>
<li>Categorical value는 비슷한 값일지라도 상관없는 의미를 지닌다.</li>
</ul>
</li>
</ul>
<h3 id="One-hot-Encoding의-필요성"><a href="#One-hot-Encoding의-필요성" class="headerlink" title="One-hot Encoding의 필요성"></a>One-hot Encoding의 필요성</h3><ul>
<li><p>One-hot Encoding의 필요성을 느끼기 위해 아래의 단어를 사전 순으로 index에 mapping 해보자</p>
<table>
<thead>
<tr>
<th>0</th>
<th>1</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
</tr>
</thead>
<tbody><tr>
<td>공책</td>
<td>딱풀</td>
<td>볼펜</td>
<td>샤프</td>
<td>연필</td>
<td>자</td>
<td>필기장</td>
</tr>
</tbody></table>
<ul>
<li>상식적으로는<ul>
<li>distance(연필, 볼펜) &lt; distance(연필, 자)</li>
<li>distance(공책, 필기장) &lt; distance(공책, 딱풀)</li>
</ul>
</li>
<li>하지만 이 테이블에서는 아래와 같은 결과가 나온다.<ul>
<li>|연필 - 볼펜| &#x3D; 2	&gt;	1 &#x3D; |연필 - 자|</li>
<li>|공책 - 필기장| &#x3D; 6	&gt;	1 &#x3D; |공책 - 딱풀|</li>
</ul>
</li>
<li>즉, 범주형 데이터를 임의의 숫자로 표현하게 되면, 텍스트 간에 원래 존재하지 않았던 ‘크기’나 ‘순서’의 개념이 부여됨. 이로 인해 범주형 데이터 간에 실제로는 없는 거리 혹은 차이가 존재하는 것처럼 해석되어, 불필요하거나 잘못된 정보를 학습하는 결과를 초래할 수 있음</li>
</ul>
</li>
</ul>
<h3 id="One-hot-Encoding-이란"><a href="#One-hot-Encoding-이란" class="headerlink" title="One-hot Encoding 이란"></a>One-hot Encoding 이란</h3><ul>
<li><p>One-hot 인코딩은 범주형 데이터를 컴퓨터가 이해할 수 있는 형태로 변환하는 방법</p>
</li>
<li><p>각각의 범주를 벡터의 형태로 표현하며, 각 범주의 위치에 해당하는 인덱스만 1로 표시하고 나머지는 0으로 표시</p>
</li>
<li><p>크기가 의미를 갖는 integer 값 대신, 1개의 1과 n-1개의 0으로 이루어진 n차원의 벡터</p>
<table>
<thead>
<tr>
<th></th>
<th>index</th>
<th>공책</th>
<th>딱풀</th>
<th>볼펜</th>
<th>샤프</th>
<th>연필</th>
<th>자</th>
</tr>
</thead>
<tbody><tr>
<td>딱풀</td>
<td>1</td>
<td>0</td>
<td>1</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>연필</td>
<td>4</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>자</td>
<td>5</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
</tbody></table>
<ul>
<li>n개의 항목 → n차원</li>
<li>즉, 6개의 항목 → 6차원</li>
</ul>
</li>
<li><p>Vector의 대부분의 element가 0인 경우 Sparse Vector라고 부름</p>
<ul>
<li>반대 개념 : Dense Vector ↔ Sparse Vector</li>
</ul>
</li>
<li><p>One-hot Encoding의 장점</p>
<ul>
<li>범주형 데이터를 숫자로 변환</li>
<li>범주 간의 순서 없음</li>
<li>특성 간의 독립성 보장</li>
</ul>
</li>
<li><p>One-hot Encoding의 단점</p>
<ul>
<li>서로 다른 두 벡터는 항상 직교(orthogonal)한다. (element-wise 곱 &#x3D; 0)<ul>
<li>Cosine Similarity가 0, 따라서 두 샘플 사이의 유사도(거리)를 구할 수 없음</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Embedding-Vectors"><a href="#Embedding-Vectors" class="headerlink" title="Embedding Vectors"></a>Embedding Vectors</h2><h3 id="Motivation-of-Embedding-Vectors"><a href="#Motivation-of-Embedding-Vectors" class="headerlink" title="Motivation of Embedding Vectors"></a>Motivation of Embedding Vectors</h3><ul>
<li><p>NLP에서 단어는 categorical value &amp; discrete value의 속성을 갖음</p>
<ul>
<li>따라서 one-hot representation으로 표현</li>
<li>하지만 이는 실제 존재하는 단어 사이의 유사도를 표현할 수 없음</li>
<li>따라서 실제적으로는 좀더 고급화된 Embedding 기법을 사용</li>
</ul>
</li>
<li><p>다른 Embedding Vectors 표현 기법</p>
<ul>
<li><p>Contextual Word Embedding (문맥적 단어 임베딩)</p>
<ul>
<li><p>기존의 단어 임베딩 방법은 단어의 의미가 문맥에 따라 달라질 수 있다는 점을 고려하지 못했는데 이를 해결하기 위해 등장</p>
</li>
<li><p>단어를 임베딩할 때 주변 문맥을 고려해 동일한 단어라도 다른 문맥에서는 다른 임베딩 벡터를 갖게함</p>
</li>
<li><p>BERT, ELMO 등이 해당됨</p>
</li>
<li><p>코드로 구현하기</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertTokenizer, BertModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment"># BERT 모델과 토크나이저 초기화</span></span><br><span class="line">tokenizer = BertTokenizer.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line">model = BertModel.from_pretrained(<span class="string">&#x27;bert-base-uncased&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 입력 문장</span></span><br><span class="line">sentences = [<span class="string">&quot;I went to the store&quot;</span>, <span class="string">&quot;I went to the school&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 토큰화 및 임베딩</span></span><br><span class="line">inputs = tokenizer(sentences, padding=<span class="literal">True</span>, truncation=<span class="literal">True</span>, return_tensors=<span class="string">&quot;pt&quot;</span>)</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    outputs = model(**inputs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 각 문장의 [CLS] 토큰에 대한 임베딩 가져오기</span></span><br><span class="line">embeddings = outputs.last_hidden_state[:, <span class="number">0</span>, :]</span><br><span class="line"><span class="built_in">print</span>(embeddings)</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>Subword Embedding (서브워드 임베딩)</p>
<ul>
<li>특정 언어들은 단어를 더 작은 의미 단위로 분리할 수 있음</li>
<li>이런 경우, 서브워드 임베딩을 사용하여 작은 단위들을 학습할 수 있음</li>
<li>BPE(Byte Pair Encoding), SentencePiece 등이 해당됨</li>
</ul>
</li>
<li><p>Document Embedding (문서 임베딩)</p>
<ul>
<li>문서 전체를 하나의 벡터로 표현하는 방법</li>
<li>문서 임베딩은 문서의 전체적인 의미를 이해하는데 도움이 됨</li>
<li>Doc2Vec, FastText 등이 해당</li>
</ul>
</li>
<li><p>Word Embedding (단어 임베딩)</p>
<ul>
<li>고차원의 One-hot 벡터를 저차원의 실수 벡터로 변환하는 기법</li>
<li>비슷한 의미를 가진 단어들이 벡터 공간에서 가까이 위치하도록 학습</li>
<li>Word2Vec, GloVe 등이 해당됨</li>
</ul>
</li>
</ul>
</li>
<li><p>개인적인 경험으로는 Contextual Word Embedding + Subword Embedding을 결합해서 가장 많이 사용하는 것 같으며, Word Embedding은 김기현 님의 말씀에 의하면 Embedding에 적합하지 않다고 말씀해주신 것으로 알고 있다.</p>
</li>
</ul>
<h3 id="요약"><a href="#요약" class="headerlink" title="요약"></a>요약</h3><ul>
<li>Categorical Value는 One-hot Encoding을 통해 벡터로 표현됨</li>
<li>Sparse Vector는 벡터 간 유사도 계산이 어려움 → One-hot의 단점</li>
<li>따라서 Dense Vector로 표현할 필요가 있음 → Contextual Embedding 등을 사용!</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-24T14:40:25.000Z" title="7/24/2023, 11:40:25 PM">2023-07-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:38:35.000Z" title="12/21/2023, 12:38:35 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/">중급 개념</a></span><span class="level-item">6 minutes read (About 889 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%8C%E1%85%AE%E1%86%BC%E1%84%80%E1%85%B3%E1%86%B8%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/1%E1%84%8C%E1%85%A1%E1%86%BC-Representation-Learning-Feature-Vector/">1장. Representation Learning - Feature Vector</a></h1><div class="content"><h2 id="Representation-Learning-표현-학습"><a href="#Representation-Learning-표현-학습" class="headerlink" title="Representation Learning (표현 학습)"></a>Representation Learning (표현 학습)</h2><ul>
<li>머신러닝의 하위 분야로서, 데이터의 숨겨진 구조를 학습하여 복잡한 데이터를 효율적이고 쉽게 이해할 수 있는 표현 형태로 변환하는 방법을 연구하는 분야</li>
<li>이 변환된 형태를 통해 원본 데이터의 중요한 특성이나 패턴을 찾아내고, 이를 사용해 효과적으로 학습 및 예측을 수행</li>
<li>원본 데이터의 복잡성을 줄이고, 노이즈를 제거하며, 데이터의 중요한 특성을 보다 명확하게 강조하는 역할, 이를 통해 머신러닝 모델의 성능을 향상시키고, 학습 과정을 단순화</li>
<li>오토인코더, 딥 비지도 학습, 임베딩 학습 등은 표현 학습의 대표적인 예시<ul>
<li>원본 데이터에서 중요한 특성을 추출하고</li>
<li>차원 공간에서 표현하는 방법을 학습하며</li>
<li>결과적으로 데이터의 가장 핵심적인 특성만을 잘 보존하는 표현을 찾아냄</li>
</ul>
</li>
</ul>
<h2 id="Feature-특징"><a href="#Feature-특징" class="headerlink" title="Feature(특징)"></a>Feature(특징)</h2><h3 id="Feature란"><a href="#Feature란" class="headerlink" title="Feature란?"></a>Feature란?</h3><ul>
<li>샘플을 잘 설명하는 특징</li>
<li>사람을 설명할 때 좋은 특징<ul>
<li>Continuous: 나이, 키, 몸무게, 소득</li>
<li>Categorical: 성별, 직업, 거주지, 출신 학교&#x2F;학과</li>
</ul>
</li>
<li>나쁜 특징<ul>
<li>(생물 분류학적) 종<ul>
<li>모두가 호모 사피엔스이므로 구분이 불가능</li>
</ul>
</li>
<li>주민등록번호, 이름<ul>
<li>전 국민의 수 만큼 momory가 필요할 것</li>
<li>주민등록번호만으로는 (비록 일부 특징이 유사하여도) 두 사람의 유사도를 알 수 없음</li>
<li>Categorical value로 볼 수 있음</li>
</ul>
</li>
</ul>
</li>
<li><strong>특징을 통해 우리는 특정 샘플을 수치화</strong> 할 수 있음</li>
<li>현실에서의 대표적인 Feature의 예 - 몽타주(Montage)<ul>
<li>범인의 얼굴을 특정하기 위해서, 목격자들에게 물어서 나온 특징들을 합쳐 만든 것<ul>
<li>좋은 단서<ul>
<li>뺨에 큰 붉은 반점</li>
<li>쳐진 눈</li>
<li>긴 생머리</li>
</ul>
</li>
<li>나쁜 단서<ul>
<li>눈이 2개</li>
<li>귀가 2개</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Feature-in-Machine-Learning"><a href="#Feature-in-Machine-Learning" class="headerlink" title="Feature in Machine Learning"></a>Feature in Machine Learning</h3><ul>
<li>MNIST Classifcation<ul>
<li>특정 위치에 곧은(휘어진) 선이 얼마나 있는가?</li>
<li>특정 위치에 선이 얼마나 굵은가?</li>
<li>특정 위치에 선이 얼마나 기울어져 있는가?</li>
</ul>
</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de">https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de</a></p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/7b2f4861-9861-41c1-b00b-a9f519e4c5de" alt="MNIST"></p>
<h3 id="No-Need-of-Hand-crafted-Feature-in-Deep-Learning"><a href="#No-Need-of-Hand-crafted-Feature-in-Deep-Learning" class="headerlink" title="No Need of Hand-crafted Feature in Deep Learning"></a>No Need of Hand-crafted Feature in Deep Learning</h3><ul>
<li>Traditional Machine Learning<ul>
<li>사람이 데이터를 면밀히 분석 후, 가정을 세움</li>
<li>가정에 따라 전처리를 하여 feature를 추출</li>
<li>추출된 feature를 model에 넣어 학습</li>
<li>장점 : 사람이 해석하기 쉬움</li>
<li>단점 : 사람이 미처 생각하지 못한 특징의 존재 가능성</li>
</ul>
</li>
<li>Current Deep Learning<ul>
<li>Raw 데이터에 <strong>최소한의 전처리</strong>(e.g. scale)를 수행</li>
<li>데이터를 model에 넣어 학습</li>
<li>장점 : 구현이 용이함, 미처 발견하지 못한 특징도 활용</li>
<li>단점 : 사람이 해석하기 어려움</li>
</ul>
</li>
</ul>
<h3 id="Feature-Vector"><a href="#Feature-Vector" class="headerlink" title="Feature Vector"></a>Feature Vector</h3><ul>
<li>각 <code>특징들을 모아서 하나의 vector</code>로 만든 것<ul>
<li>Tabular Dataset의 각 row도 이에 해당</li>
</ul>
</li>
<li>각 차원(dimension)은 어떤 속성에 대한 level을 나타냄<ul>
<li>각 속성에 대한 level이 비슷할수록 비슷한 샘플이라고 볼 수 있음</li>
</ul>
</li>
<li>우리는 feature vector를 통해 샘플 사이의 거리(유사도)를 계산할 수 있음</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>키</th>
<th>몸무게</th>
<th>나이</th>
<th>월 소득</th>
<th>출신</th>
</tr>
</thead>
<tbody><tr>
<td>로버트</td>
<td>174cm</td>
<td>78kg</td>
<td>42</td>
<td>100</td>
<td>미국 매사추세츠</td>
</tr>
<tr>
<td>캡틴아메리카</td>
<td>183cm</td>
<td>88kg</td>
<td>58</td>
<td>1000</td>
<td>미국 뉴욕</td>
</tr>
</tbody></table>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-23T14:44:53.000Z" title="7/23/2023, 11:44:53 PM">2023-07-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-12-20T15:32:49.000Z" title="12/21/2023, 12:32:49 AM">2023-12-21</time></span><span class="level-item"><a class="link-muted" href="/categories/Deep-Learning/">Deep Learning</a><span> / </span><a class="link-muted" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">기본 개념</a></span><span class="level-item">4 minutes read (About 565 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/Deep%20Learning/%E1%84%80%E1%85%B5%E1%84%87%E1%85%A9%E1%86%AB%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%80%E1%85%B5%E1%86%B7%E1%84%80%E1%85%B5%E1%84%92%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%B4%20%E1%84%8E%E1%85%A5%E1%84%8B%E1%85%B3%E1%86%B7%E1%84%87%E1%85%AE%E1%84%90%E1%85%A5%20%E1%84%89%E1%85%B5%E1%84%8C%E1%85%A1%E1%86%A8%E1%84%92%E1%85%A1%E1%84%82%E1%85%B3%E1%86%AB%20%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC/7%EC%9E%A5-%EA%B8%B0%EC%B4%88-%EC%B5%9C%EC%A0%81%ED%99%94-%EB%B0%A9%EB%B2%95-Gradient-Descent-Learning-Rate/">7장. 기초 최적화 방법 Gradient Descent - Learning Rate</a></h1><div class="content"><h2 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h2><h3 id="Learning-Rate-in-Gradient-Descent"><a href="#Learning-Rate-in-Gradient-Descent" class="headerlink" title="Learning Rate in Gradient Descent"></a>Learning Rate in Gradient Descent</h3><ul>
<li>파라미터가 업데이트 될 때, gradient의 크기에 영향을 받게 됨<ul>
<li>이 때, learning rate가 step-size를 정해주게 됨</li>
</ul>
</li>
<li>Equation<ul>
<li>$\theta \gets \theta - \eta \frac{\partial L(\theta)}{\partial \theta} &#x3D; \theta - \eta \nabla_\theta L(\theta)$</li>
</ul>
</li>
</ul>
<h3 id="Learning-Rate-에-따른-최적화-데이터나-모델-아키텍처에-따라-lr은-변함"><a href="#Learning-Rate-에-따른-최적화-데이터나-모델-아키텍처에-따라-lr은-변함" class="headerlink" title="Learning Rate 에 따른 최적화 (데이터나 모델 아키텍처에 따라 lr은 변함)"></a>Learning Rate 에 따른 최적화 (데이터나 모델 아키텍처에 따라 lr은 변함)</h3><ul>
<li>Large LR<ul>
<li>너무 큰 Loss가 발산할 수 있음</li>
</ul>
</li>
<li>Small LR<ul>
<li>너무 작은 LR은 수렴이 늦음</li>
<li>자칫 local minima에 빠질 수 있음</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589" alt="LearningRate"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589">https://github.com/shchoice/shchoice.github.io/assets/100276387/045601bd-7157-43fd-9d93-d9eaacbc7589</a></p>
<h3 id="Learning-Rate-는-중요한-하이퍼파라미터"><a href="#Learning-Rate-는-중요한-하이퍼파라미터" class="headerlink" title="Learning Rate 는 중요한 하이퍼파라미터"></a>Learning Rate 는 중요한 하이퍼파라미터</h3><ul>
<li><strong>실험을 통해 최적화</strong>하는 것이 필요</li>
<li>초보자들은 처음에 어떤 값을 정해야 할지 난감<ul>
<li>고민할 바에 그냥 아주 작은 값(eg. 1e-4)으로 오래 돌려도 괜찮음</li>
</ul>
</li>
<li>나중에 Adam Optimizer를 통해 Learning Rate에 대한 고민을 없앨 수 있음</li>
</ul>
<p>※ 하이퍼파라미터 : 모델 성능에 영향을 끼치지만, 데이터를 통해 학습할 수 없는 파라미터 (우리가 직접 테스트하고 튜닝을 해야함)</p>
<h3 id="코드로-구현하기"><a href="#코드로-구현하기" class="headerlink" title="코드로 구현하기"></a>코드로 구현하기</h3><ul>
<li><p>Gradient Descent + Learning Rate 실습</p>
<ul>
<li>$L(x)&#x3D;| targert - x |_2^2$</li>
<li>$x \gets x - \eta \nabla_x L(x)$<ul>
<li>cf) $\nabla_x L(x) &#x3D; x.grad$</li>
</ul>
</li>
<li>$\hat{x} &#x3D; \text{argmin}L(x)$, $x \in \mathbb{R}^{3,3}$</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">target = torch.FloatTensor([[<span class="number">.1</span>, <span class="number">.2</span>, <span class="number">.3</span>],</span><br><span class="line">                            [<span class="number">.4</span>, <span class="number">.5</span>, <span class="number">.6</span>],</span><br><span class="line">                            [<span class="number">.7</span>, <span class="number">.8</span>, <span class="number">.9</span>]])</span><br><span class="line"></span><br><span class="line">x = torch.rand_like(target)</span><br><span class="line"><span class="comment"># This means the final scalar will be differentiate by x.</span></span><br><span class="line">x.requires_grad = <span class="literal">True</span></span><br><span class="line"><span class="comment"># You can get gradient of x, after differentiation.</span></span><br><span class="line"><span class="built_in">print</span>(x)</span><br><span class="line"><span class="comment"># tensor([[0.4176, 0.6465, 0.3522],</span></span><br><span class="line"><span class="comment">#         [0.9164, 0.7576, 0.0892],</span></span><br><span class="line"><span class="comment">#         [0.4854, 0.0136, 0.9467]], requires_grad=True)</span></span><br><span class="line"></span><br><span class="line">loss = F.mse_loss(x, target)</span><br><span class="line"><span class="built_in">print</span>(loss) <span class="comment"># tensor(0.1737, grad_fn=&lt;MseLossBackward&gt;)</span></span><br><span class="line"></span><br><span class="line">threshold = <span class="number">1e-5</span></span><br><span class="line">learning_rate = <span class="number">1.</span></span><br><span class="line">iter_cnt = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> loss &gt; threshold:</span><br><span class="line">    iter_cnt += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    loss.backward() <span class="comment"># Calculate gradients.</span></span><br><span class="line"></span><br><span class="line">    x = x - learning_rate * x.grad</span><br><span class="line">    </span><br><span class="line">    x.detach_()</span><br><span class="line">    x.requires_grad_(<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    loss = F.mse_loss(x, target)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;%d-th Loss: %.4e&#x27;</span> % (iter_cnt, loss))</span><br><span class="line">    <span class="built_in">print</span>(x)</span><br><span class="line"></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    1 - th Loss: 1.0510e-01</span></span><br><span class="line"><span class="string">    tensor([[0.3470, 0.5473, 0.3406],</span></span><br><span class="line"><span class="string">            [0.8016, 0.7003, 0.2027],</span></span><br><span class="line"><span class="string">            [0.5331, 0.1883, 0.9363]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    2 - th Loss: 6.3576e-02</span></span><br><span class="line"><span class="string">    tensor([[0.2921, 0.4701, 0.3316],</span></span><br><span class="line"><span class="string">            [0.7124, 0.6558, 0.2910],</span></span><br><span class="line"><span class="string">            [0.5702, 0.3242, 0.9282]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    3 - th Loss: 3.8460e-02</span></span><br><span class="line"><span class="string">    tensor([[0.2494, 0.4101, 0.3246],</span></span><br><span class="line"><span class="string">            [0.6430, 0.6212, 0.3597],</span></span><br><span class="line"><span class="string">            [0.5990, 0.4300, 0.9220]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    19 - th Loss: 1.2370e-05</span></span><br><span class="line"><span class="string">    tensor([[0.1027, 0.2038, 0.3004],</span></span><br><span class="line"><span class="string">            [0.4044, 0.5022, 0.5957],</span></span><br><span class="line"><span class="string">            [0.6982, 0.7934, 0.9004]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    20 - th Loss: 7.4833e-06</span></span><br><span class="line"><span class="string">    tensor([[0.1021, 0.2029, 0.3003],</span></span><br><span class="line"><span class="string">            [0.4034, 0.5017, 0.5966],</span></span><br><span class="line"><span class="string">            [0.6986, 0.7948, 0.9003]],  requires_grad = True)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="7장-Wrap-up"><a href="#7장-Wrap-up" class="headerlink" title="7장 Wrap up"></a>7장 Wrap up</h2><h3 id="Why-we-do-gradient-descent"><a href="#Why-we-do-gradient-descent" class="headerlink" title="Why we do gradient descent?"></a>Why we do gradient descent?</h3><ul>
<li>실재하지만 알 수 없는 함수 $f^*$를 근사하고 싶음</li>
<li>나의 모델(함수)의 $f_\theta$ 파라미터 𝜽를 조절</li>
<li><strong>손실 함수(Loss Function)를 최소화 하도록 파라미터 𝜽를 조절</strong></li>
<li>미분을 통해 gradient($\frac{\partial Loss}{\partial \theta}$)를 얻고, loss를 낮추는 방향으로 파라미터를 업데이트</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-07-22T17:25:07.000Z" title="7/23/2023, 2:25:07 AM">2023-07-23</time></span><span class="level-item">Updated&nbsp;<time dateTime="2023-07-22T17:25:07.000Z" title="7/23/2023, 2:25:07 AM">2023-07-23</time></span><span class="level-item">41 minutes read (About 6189 words)</span></div></div><div class="content"><h2 id="프로세스와-쓰레드란-무엇인가요"><a href="#프로세스와-쓰레드란-무엇인가요" class="headerlink" title="프로세스와 쓰레드란 무엇인가요??"></a>프로세스와 쓰레드란 무엇인가요??</h2><p>프로세스와 쓰레드는 컴퓨터에서 실행되는 작업의 실행 단위로 모두 동시성(concurrency)을 다룹니다.</p>
<h2 id="프로세스와-쓰레드의-차이는-어떻게-되나요"><a href="#프로세스와-쓰레드의-차이는-어떻게-되나요" class="headerlink" title="프로세스와 쓰레드의 차이는 어떻게 되나요??"></a>프로세스와 쓰레드의 차이는 어떻게 되나요??</h2><ul>
<li>프로세스<ul>
<li>운영체제에서 실행 중인 프로그램을 의미</li>
<li>독립적인 메모리 공간과 시스템 자원(CPU, 메모리 등)을 할당받음</li>
<li>따라서 각각의 프로세스는 완전히 분리되어 서로 영향을 미치지 않음</li>
<li>즉, 프로세스 간에는 메모리를 공유할 수 없음(직접적인 접근이 불가능)</li>
<li>만약에 하나의 프로세스에서 다른 프로세스에 접근하려면 IPC(Inter-Process Communication)를 사용</li>
<li>Java에서는 <code>java.lang.Process</code> 클래스를 통해 프로세스를 생성 및 제어</li>
<li>Python에서는 <code>multiprocessing</code> 모듈을 통해 프로세스를 생성 및 제어</li>
</ul>
</li>
<li>쓰레드<ul>
<li>프로세스 내에서 실행되는 작은 실행 단위</li>
<li>하나의 프로세스 내에서 여러 개의 쓰레드를 생성하여 실행할 수 있음</li>
<li>쓰레드는 각각 자신의 실행 스택을 가지고 있지만, 프로세스 내의 다른 쓰레드와 메모리 공간을 공유하며 실행(부모 프로세스의 메모리 공간과 자원을 공유)</li>
<li>따라서 쓰레드는 프로세스보다 가볍고 실행 속도가 빠름(자원의 효율적인 활용 가능)</li>
<li>하지만 여러 쓰레드가 공유된 메모리 공간을 사용하기에 데이터 불일치 문제를 고려해야함<ul>
<li>Java에서는 동기화(synchronization)를 통해 문제를 해결</li>
</ul>
</li>
<li>Java에서는 <code>java.lang.Thread</code> 클래스를 사용하여 쓰레드를 생성 및 제어</li>
<li>Python에서는 <code>threading</code> 모듈을 통해 쓰레드를 생성 및 제어 </li>
<li>모든 Java 프로그램은 기본적으로 하나의 쓰레드(메인 쓰레드)를 갖음, main method를 실행하고, 프로그램이 종료될 때까지 실행됨</li>
</ul>
</li>
</ul>
<h2 id="프로세스와-쓰레드의-공통점은-어떻게-되나요"><a href="#프로세스와-쓰레드의-공통점은-어떻게-되나요" class="headerlink" title="프로세스와 쓰레드의 공통점은 어떻게 되나요??"></a>프로세스와 쓰레드의 공통점은 어떻게 되나요??</h2><ol>
<li>실행 흐름 : 모두 실행 흐름을 나타냄. 즉 프로그램이 실행되어 작업을 처리하는 단위</li>
<li>자원 공유 : CPU, Memory, 파일, 네트워크 등의 시스템 자원을 공유<ul>
<li>다만 Memory의 경우 프로세스는 독립된 메모리 공간을 사용하고, 쓰레드는 프로세스의 메모리 공간을 공유</li>
</ul>
</li>
<li>스케줄링 : 모두 스케줄링의 대상이 됨, 즉 운영체제가 자원을 할당하는 대상이 됨</li>
<li>동시성 : 프로세스와 쓰레드는 모두 동시에 실행될 수 있으며, 이는 멀티태스킹을 구현하기 위한 필수적인 기능</li>
<li>컨텍스트 스위칭 : 실행중인 프로세스나 쓰레드를 일시 중단하고, 다른 프로세스나 쓰레드를 실행할 수 있음</li>
</ol>
<h2 id="동시성-프로그래밍-Concurrency-Programming-이란-무엇인가요"><a href="#동시성-프로그래밍-Concurrency-Programming-이란-무엇인가요" class="headerlink" title="동시성 프로그래밍(Concurrency Programming)이란 무엇인가요??"></a>동시성 프로그래밍(Concurrency Programming)이란 무엇인가요??</h2><ul>
<li>하나의 컴퓨터 시스템에서 여러 개의 작업(task)이 동시에 실행되는 프로그래밍 기법, 즉 여러 작업을 동시에 처리해 시스템의 활용도를 향상시킬 수 있습니다.</li>
<li>동시성 프로그래밍에서는 동시에 실행되는 작업들이 서로 영향을 주지 않도록 관리해야 합니다.<ul>
<li>세마포어(Semaphore), 뮤텍스(Mutex), 락(Lock) 등 동기화 기법을 사용하여 공유 데이터에 대한 접근을 제어해야 합니다.</li>
</ul>
</li>
<li>멀티쓰레드, 멀티프로세싱, 비동기 프로그래밍 등 다양한 기법이 사용됩니다.</li>
</ul>
<h2 id="동시성-프로그맹과-병렬-프로그래밍은-어떠한-차이가-있나요"><a href="#동시성-프로그맹과-병렬-프로그래밍은-어떠한-차이가-있나요" class="headerlink" title="동시성 프로그맹과 병렬 프로그래밍은 어떠한 차이가 있나요??"></a>동시성 프로그맹과 병렬 프로그래밍은 어떠한 차이가 있나요??</h2><p>네. 비슷한 개념으로 생각할 수 있지만, 약간의 차이가 있습니다.</p>
<ul>
<li>병렬 프로그래밍<ul>
<li>여러 개의 프로세서(코어)를 사용하여 한 작업을 분할하여 동시에 실행</li>
<li>하나의 큰 작업을 작은 작업으로 분할하여 각각의 작은 작업을 병렬적으로 실행</li>
<li>병렬 프로그래밍은 대규모 컴퓨팅 자원이 필요하며, 여러 개의 CPU나 GPU를 사용하여 구현됨</li>
</ul>
</li>
<li>동시성 프로그래밍<ul>
<li>단일 프로세서에서 여러 작업을 동시에 실행하는 것</li>
<li>따라서 여러 개의 작업이 빠르게 번갈아 가며 실행되어 실제로는 작업들이 서로 영향을 주지 않도록 관리되어 동시에 실행</li>
</ul>
</li>
</ul>
<h2 id="동시성-프로그래밍에서-멀티쓰레드-멀티프로세싱-비동기-프로그래밍의-차이는-무엇인가요"><a href="#동시성-프로그래밍에서-멀티쓰레드-멀티프로세싱-비동기-프로그래밍의-차이는-무엇인가요" class="headerlink" title="동시성 프로그래밍에서 멀티쓰레드, 멀티프로세싱, 비동기 프로그래밍의 차이는 무엇인가요??"></a>동시성 프로그래밍에서 멀티쓰레드, 멀티프로세싱, 비동기 프로그래밍의 차이는 무엇인가요??</h2><ul>
<li>비동기 프로그래밍<ul>
<li>작업이 완료될 때까지 기다리지 않고 다른 작업을 수행할 수 있는 기술</li>
<li>콜백(callback)함수나 프로미스(promise) 등을 사용하여 작업 완료 시점에 처리를 수행</li>
<li>입출력이 느린 작업이나 네트워크 작업 등에서 더 나은 성능을 얻을 수 있는 이점이 있음</li>
</ul>
</li>
<li>멀티쓰레드<ul>
<li>하나의 프로세스 내에서 여러 개의 쓰레드를 생성하여, 각 쓰레드가 병렬로 작업을 수행</li>
<li>쓰레드는 같은 메모리 공간을 공유하기에, 데이터를 공유할 때 동기화 문제를 고려해야함</li>
</ul>
</li>
<li>멀티프로세싱<ul>
<li>여러 개의 프로세스를 생성하여 각 프로세스가 병렬로 작업을 수행하는 것</li>
<li>각 프로세스는 독립적인 메모리 공간을 가지므로, 데이터를 공유하기 위해서는 IPC를 사용해야 함</li>
<li>멀티쓰레드 보다는 안정적이지만 더 많은 리소스를 사용한다는 단점이 있음</li>
</ul>
</li>
</ul>
<h2 id="자바에서-비동기-프로그래밍은-어떻게-구현하나요"><a href="#자바에서-비동기-프로그래밍은-어떻게-구현하나요" class="headerlink" title="자바에서 비동기 프로그래밍은 어떻게 구현하나요??"></a>자바에서 비동기 프로그래밍은 어떻게 구현하나요??</h2><ol>
<li>콜백(Callback) 기반의 비동기 프로그래밍을 주로 사용<ul>
<li>콜반 기반의 프로그래밍은 콜백 함수를 등록하여 비동기식 작업이 완료되면 해당 콜백 함수가 호출되도록 하는 것</li>
<li>이를 위해 자바에서는 Future나 CompletableFuture 클래스를 사용하여 비동기식 작업을 수행<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// supplyAsync() 메서드를 사용하여 비동기 작업을 수행하고, thenAccept() 메서드를 사용하여 작업이 완료된 후 호출될 콜백 함수를 등록</span></span><br><span class="line"><span class="comment">// 이러한 방식으로 콜백 함수를 등록하여 비동기식 작업을 처리</span></span><br><span class="line">CompletableFuture&lt;String&gt; future = CompletableFuture.supplyAsync(() -&gt; &#123;</span><br><span class="line">    <span class="comment">// 비동기 작업을 수행하는 코드</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;result&quot;</span>;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line">future.thenAccept(result -&gt; &#123;</span><br><span class="line">    <span class="comment">// 비동기 작업이 완료된 후 호출될 콜백 함수</span></span><br><span class="line">    System.out.println(<span class="string">&quot;Result: &quot;</span> + result);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Stream API를 사용<ul>
<li>Stream API는 병렬 처리를 지원하므로 멀티코어 CPU에서 더욱 효과적으로 동작<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parallelStream() 메서드를 사용하여 리스트의 항목을 병렬로 처리하고, forEach() 메서드를 사용하여 각 항목에 대한 비동기식 작업을 수행</span></span><br><span class="line">List&lt;String&gt; list = Arrays.asList(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>);</span><br><span class="line"></span><br><span class="line">list.parallelStream().forEach(item -&gt; &#123;</span><br><span class="line">    <span class="comment">// 비동기 작업을 수행하는 코드</span></span><br><span class="line">    System.out.println(<span class="string">&quot;Item: &quot;</span> + item);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h2 id="동기식-처리와-비동기식-처리의-차이점은-무엇인가요"><a href="#동기식-처리와-비동기식-처리의-차이점은-무엇인가요" class="headerlink" title="동기식 처리와 비동기식 처리의 차이점은 무엇인가요??"></a>동기식 처리와 비동기식 처리의 차이점은 무엇인가요??</h2><ul>
<li>프로그램에서 작업이 실행되는 방식의 차이점에 따라 구분이 됨<ul>
<li>동기식 처리<ul>
<li>작업이 순차적으로 실행되어 결과가 반환되기 전까지 다음 작업이 실행되지 않는 방식</li>
<li>즉, 어떤 작업이 완료될 때까지 다음 작업을 기다리는 방식</li>
<li>예를 들면, 웹 서버에서 동기식으로 작성된 코드는 한 번에 하나의 요청만 처리할 수 있음</li>
</ul>
</li>
<li>비동기식 처리<ul>
<li>작업이 동시에 실행되어 결과가 반환되기를 기다리지 않고 다음 작업을 실행할 수 있는 방식</li>
<li>즉, 어떤 작업이 완료되기를 기다리지 않고, 다음 작업을 실행하는 방식</li>
<li>예를 들면 웹 서버에서 비동기식으로 작성된 코드는 여러 요청을 동시에 처리할 수 있음</li>
<li>또 다른 예로 웹 페이지에서 이미지를 로드되는 동안 텍스트 작업을 수행할 수 있음</li>
</ul>
</li>
</ul>
</li>
<li>비동기식 처리는 작업이 완료될 때까지 기다리지 않고 다른 작업을 처리하므로, 더 높은 처리량을 얻을 수 있으나</li>
<li>코드가 복잡해지고 처리 결과를 조합하는 작업이 필요할 경우 처리 방식이 복잡해질 수 있음</li>
<li>반면 동기식 처리는 간단하고 직관적이지만, 대규모의 작업을 처리하는 데 부적합할 수 있음</li>
</ul>
<h2 id="파이썬에서-비동기식-처리를-수행할-때-처리하는-원리가-어떻게-되나요"><a href="#파이썬에서-비동기식-처리를-수행할-때-처리하는-원리가-어떻게-되나요" class="headerlink" title="파이썬에서 비동기식 처리를 수행할 때 처리하는 원리가 어떻게 되나요??"></a>파이썬에서 비동기식 처리를 수행할 때 처리하는 원리가 어떻게 되나요??</h2><blockquote>
<p>파이썬에서 비동기식 처리를 수행할 때, asyncio 라이브러리를 이용하여 이벤트 루프(event loop)를 생성하고, 코루틴(coroutine)을 이용하여 비동기식 처리를 수행합니다.  </p>
<p>이벤트 루프는 이벤트 발생을 대기하다가, 이벤트가 발생하면 그에 대응하는 작업을 처리하는 루프입니다. 즉, 이벤트 루프는 코루틴을 실행하고, I&#x2F;O 작업이 완료될 때까지 기다린 후, 결과를 반환합니다. 이벤트 루프는 코루틴을 실행할 때, 작업을 블로킹하지 않고 비동기적으로 실행합니다.  </p>
<p>코루틴은 제너레이터(generator)와 비슷한 개념으로, 함수 실행 중에 일시 중지하고 다른 작업을 수행한 후, 다시 원래 작업을 재개하는 것을 가능하게 합니다. 이러한 특징을 이용하여 비동기식 처리를 수행할 수 있습니다. 비동기식 작업은 코루틴으로 구현되어, 이벤트 루프에 의해 실행되며, 작업이 완료되기 전에 다른 작업을 실행할 수 있습니다.  </p>
<p>이러한 방식으로 비동기식 처리를 수행하면, I&#x2F;O 작업이 많은 네트워크 프로그램에서 효과적으로 CPU 자원을 활용할 수 있습니다. I&#x2F;O 작업이 끝날 때까지 대기하는 대신, 다른 작업을 실행할 수 있기 때문입니다. 이러한 방식은 네트워크 프로그램뿐만 아니라, 다양한 분야에서 활용할 수 있으며, 파이썬에서는 asyncio 라이브러리를 이용하여 비동기식 처리를 수행할 수 있습니다.</p>
</blockquote>
<ul>
<li>파이썬의 asyncio 라이브러리르 이용하여 Echo 서버를 비동기식으로 구현한 예시 코드<ul>
<li><p>여러 개의 클라이언트의 요청을 동시에 처리하여 Throughput(처리량)을 향상시킬 수 있음</p>
</li>
<li><p>Echo 서버용 코드</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def handle_echo(reader, writer):</span><br><span class="line">    data = await reader.read(100)</span><br><span class="line">    message = data.decode()</span><br><span class="line">    addr = writer.get_extra_info(&#x27;peername&#x27;)</span><br><span class="line">    print(f&quot;Received &#123;message!r&#125; from &#123;addr!r&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    writer.write(data)</span><br><span class="line">    await writer.drain()</span><br><span class="line">    print(f&quot;Send &#123;message!r&#125; to &#123;addr!r&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line">async def main():</span><br><span class="line">    server = await asyncio.start_server(handle_echo, &#x27;127.0.0.1&#x27;, 8888)</span><br><span class="line">    print(f&quot;Serving on &#123;server.sockets[0].getsockname()&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    async with server:</span><br><span class="line">        await server.serve_forever()</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure>
<blockquote>
<p>위 코드는 asyncio 모듈의 start_server() 함수를 이용하여 Echo 서버를 구현한 코드입니다. 클라이언트가 연결되면, handle_echo() 코루틴이 실행되어 클라이언트 요청을 처리합니다. 이 코드에서는 클라이언트 요청이 처리될 때마다 새로운 코루틴을 생성하여 요청을 처리하므로, 다수의 클라이언트 요청을 동시에 처리할 수 있습니다.</p>
</blockquote>
</li>
<li><p>클라이언트 요청을 보내는 코드</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def tcp_echo_client(message):</span><br><span class="line">    reader, writer = await asyncio.open_connection(&#x27;127.0.0.1&#x27;, 8888)</span><br><span class="line"></span><br><span class="line">    print(f&quot;Send &#123;message!r&#125;&quot;)</span><br><span class="line">    writer.write(message.encode())</span><br><span class="line"></span><br><span class="line">    data = await reader.read(100)</span><br><span class="line">    print(f&quot;Received &#123;data.decode()!r&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    writer.close()</span><br><span class="line">    await writer.wait_closed()</span><br><span class="line"></span><br><span class="line">asyncio.run(tcp_echo_client(&quot;Hello, World!&quot;))</span><br></pre></td></tr></table></figure>
<blockquote>
<p>위 코드는 asyncio 모듈의 open_connection() 함수를 이용하여 Echo 서버에 접속하는 코드입니다. 클라이언트가 요청을 보내면, 서버에서는 새로운 코루틴을 생성하여 요청을 처리하고, 클라이언트에 응답을 보냅니다. 이러한 방식으로 비동기식 처리를 수행하면, 다수의 클라이언트 요청을 효율적으로 처리할 수 있습니다.</p>
</blockquote>
</li>
</ul>
</li>
</ul>
<h2 id="자바에서-쓰레드를-구현하는-방법은-어떻게-될까요"><a href="#자바에서-쓰레드를-구현하는-방법은-어떻게-될까요" class="headerlink" title="자바에서 쓰레드를 구현하는 방법은 어떻게 될까요??"></a>자바에서 쓰레드를 구현하는 방법은 어떻게 될까요??</h2><ol>
<li>Thread 클래스 상속 <ul>
<li>Runnable을 상속하여 만들어진 클래스이며, 클래스 객체를 생성하고 start() 메소드를 호출함으로써 Thread가 독립적으로 실행</li>
<li>이러한 Thread 클래스를 상속받아서 run() 메서드를 오버라이드하여 구현하는 방법</li>
<li>어떤 객체도 리턴하지 않음</li>
<li>가장 기본적인 쓰레드 구현 방법 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyThread</span> <span class="keyword">extends</span> <span class="title class_">Thread</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 쓰레드에서 수행할 작업 구현</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Runnable 인터페이스 구현<ul>
<li>Runnable 인터페이스를 구현하여 run() 메서드를 오버라이드하여 구현하는 방법</li>
<li>상속을 사용하지 않기 때문에 코드 재사용성이 더 높음</li>
<li>따라서 다른 클래스를 확장하거나 다른 인터페이스를 구현하고 있는 경우에 사용</li>
<li>어떤 객체도 리턴하지 않음</li>
<li>ExecutorService의 submit() 메소드로 작업을 실행하고 결과 값을 받을 수 있음 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyRunnable</span> <span class="keyword">implements</span> <span class="title class_">Runnable</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 쓰레드에서 수행할 작업 구현</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>Callable 인터페이스 구현<ul>
<li>Callable 인터페이스를 구현하여 call() 메서드를 오버라이드하여 구현하는 방법</li>
<li>Runnable과 비슷하지만, 작업 결과인 특정 타입의 객체를 반환할 수 있음</li>
<li>ExecutorService의 submit() 메소드로 작업을 전달하고 작업이 완료되면 Future 객체를 반환해 결과값을 받을 수 있음 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MyCallable</span> <span class="keyword">implements</span> <span class="title class_">Callable</span>&lt;Integer&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 쓰레드에서 수행할 작업 구현</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>ExecutorService 를 이용한 쓰레드 풀 사용<ul>
<li><p>ExecutorService 인터페이스를 사용하여 쓰레드 풀을 생성하고, 큐에 작업을 추가하고 실행</p>
</li>
<li><p>여러 쓰레드를 동시에 실행할 수 있음</p>
</li>
<li><p>주로 비동기적인 작업을 수행할 때 사용</p>
</li>
<li><p>submit() 메소드로 작업을 전달하고 작업이 완료되면 Future 객체를 반환해 결과값을 받을 수 있음</p>
 <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">ExecutorService</span> <span class="variable">executorService</span> <span class="operator">=</span> Executors.newFixedThreadPool(<span class="number">10</span>);</span><br><span class="line"><span class="type">Runnable</span> <span class="variable">myRunnable</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MyRunnable</span>();</span><br><span class="line">executorService.execute(myRunnable);</span><br></pre></td></tr></table></figure>
</li>
<li><p>ExecutorService의 여러 쓰레드 풀 생성 방법</p>
<ul>
<li><code>new FixedThreadPool(int)</code><ul>
<li>인자 개수만큼 고정된 쓰레드풀 생성</li>
</ul>
</li>
<li><code>new CachedThreadPoll()</code><ul>
<li>필요할 때, 필요한 만큼 쓰레드풀 생성</li>
<li>이미 생성된 쓰레드를 재활용할 수 있어 성능상 이점이 있을 수 있다.</li>
</ul>
</li>
<li><code>new ScheduledThreadPool(int)</code> <ul>
<li>일정 시간 뒤 실행되는 작업이나, 주기적으로 수행되는 작업이 있을 때 고려</li>
</ul>
</li>
<li><code>new SingleThreadExecutor()</code><ul>
<li>쓰레드 한 개인 <code>ExecutorService</code>를 리턴한다.</li>
<li>싱글 쓰레드에서 동작해야 하는 작업을 처리할 때 사용</li>
</ul>
</li>
</ul>
</li>
<li><p><code>submit()</code>메서드를 통해 <code>Callable</code>을 실행하고 <code>Future&lt;V&gt;</code>를 반환 받을 수 있음</p>
</li>
<li><p>실행된 Callable의 반환값을 받는 Future의 메소드 소개</p>
<ul>
<li>get()<ul>
<li>비동기 작업이 완료될 때까지 대기하고 결과를 가져옴<ul>
<li>&#x3D; get() 메소드 호출 시 Blocking Call이 발생하여 반환값을 가지고 올 때까지 멈춤</li>
</ul>
</li>
</ul>
</li>
<li>isDone()<ul>
<li>비동기 작업이 완료되었는지 여부를 확인 </li>
<li>Thread Pool에 submit되어 실행 중인 Callable 작업이 언제 끝난 지를 확인할 수 있음</li>
</ul>
</li>
<li>cancel()<ul>
<li>비동기 작업을 멈춤</li>
</ul>
</li>
<li>invokeAll()<ul>
<li>모든 작업이 완료될 때까지 대기하고 모든 작업의 결과를 가져옴</li>
</ul>
</li>
<li>invokeAny()<ul>
<li>작업 중 하나라도 완료되면 대기를 취소하고 완료된 작업 중 하나의 결과를 가져옴</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Thread-Runnable-Callable-ExecutorService-는-어떠한-경우에-사용하는-것이-좋을까요"><a href="#Thread-Runnable-Callable-ExecutorService-는-어떠한-경우에-사용하는-것이-좋을까요" class="headerlink" title="Thread(), Runnable(), Callable(), ExecutorService() 는 어떠한 경우에 사용하는 것이 좋을까요??"></a>Thread(), Runnable(), Callable(), ExecutorService() 는 어떠한 경우에 사용하는 것이 좋을까요??</h2><ul>
<li>일반적으로는 <code>Runnable</code>을 구현한 객체를 <code>Thread</code> 생성자의 인자로 전달하는 방식으로 새로운 쓰레드를 생성</li>
<li><code>Callable</code> 은 작업 수행 결과가 필요한 경우에 사용</li>
<li><code>ExecutorService</code>는 쓰레드 풀을 생성하고 비동기 작업을 수행</li>
</ul>
<h2 id="파이썬에서-쓰레드를-구현하는-방법은-어떻게-될까요"><a href="#파이썬에서-쓰레드를-구현하는-방법은-어떻게-될까요" class="headerlink" title="파이썬에서 쓰레드를 구현하는 방법은 어떻게 될까요??"></a>파이썬에서 쓰레드를 구현하는 방법은 어떻게 될까요??</h2><ol>
<li><p>threading 모듈 사용: 파이썬에서는 threading 모듈을 사용하여 쓰레드를 구현할 수 있습니다. Thread 클래스를 상속하거나, Runnable 인터페이스와 비슷한 역할을 하는 target 매개변수를 사용하여 쓰레드를 생성할 수 있습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyThread</span>(threading.Thread):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 쓰레드에서 수행할 작업 구현</span></span><br><span class="line"></span><br><span class="line">my_thread = MyThread()</span><br><span class="line">my_thread.start()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>():</span><br><span class="line">    <span class="comment"># 쓰레드에서 수행할 작업 구현</span></span><br><span class="line"></span><br><span class="line">my_thread = threading.Thread(target=my_function)</span><br><span class="line">my_thread.start()</span><br></pre></td></tr></table></figure></li>
<li><p>concurrent.futures 모듈 사용: concurrent.futures 모듈을 사용하여 ThreadPoolExecutor나 ProcessPoolExecutor 클래스를 이용하여 쓰레드 풀을 생성하고, 여러 쓰레드를 동시에 실행할 수 있습니다. ThreadPoolExecutor는 쓰레드 기반, ProcessPoolExecutor는 프로세스 기반으로 쓰레드를 실행합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>():</span><br><span class="line">    <span class="comment"># 쓰레드에서 수행할 작업 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ThreadPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    future = executor.submit(my_function)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> concurrent.futures</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">my_function</span>():</span><br><span class="line">    <span class="comment"># 쓰레드에서 수행할 작업 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> concurrent.futures.ProcessPoolExecutor() <span class="keyword">as</span> executor:</span><br><span class="line">    future = executor.submit(my_function)</span><br></pre></td></tr></table></figure>
</li>
<li><p>asyncio 모듈 사용: asyncio 모듈을 사용하여 코루틴 기반의 비동기 쓰레드를 구현할 수 있습니다. 이 방법은 비동기 I&#x2F;O 작업에 특화되어 있으며, 단일 스레드에서 여러 작업을 동시에 처리할 수 있습니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">my_coroutine</span>():</span><br><span class="line">    <span class="comment"># 비동기적으로 수행할 작업 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="keyword">await</span> asyncio.gather(my_coroutine())</span><br><span class="line"></span><br><span class="line">asyncio.run(main())</span><br></pre></td></tr></table></figure></li>
<li><p>queue 모듈을 이용한 Producer-Consumer 패턴 사용: queue 모듈을 사용하여 여러 쓰레드 간에 데이터를 공유하고, Producer-Consumer 패턴을 구현할 수 있습니다. 이 방법은 여러 쓰레드가 동시에 작업을 처리해야 하는 경우에 유용합니다.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> queue</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">producer</span>(<span class="params">q</span>):</span><br><span class="line">    <span class="comment"># 데이터를 생산하여 큐에 추가하는 작업 구현</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">consumer</span>(<span class="params">q</span>):</span><br><span class="line">    <span class="comment"># 큐에서 데이터를 가져와서 처리하는 작업 구현</span></span><br><span class="line"></span><br><span class="line">q = queue.Queue()</span><br><span class="line">p = threading.Thread(target=producer, args=(q,))</span><br><span class="line">c = threading.Thread(target=consumer, args=(q,))</span><br><span class="line">p.start()</span><br><span class="line">c.start()</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="쓰레드를-사용하면서-주의해야할-점은-어떻게-되나요"><a href="#쓰레드를-사용하면서-주의해야할-점은-어떻게-되나요" class="headerlink" title="쓰레드를 사용하면서 주의해야할 점은 어떻게 되나요??"></a>쓰레드를 사용하면서 주의해야할 점은 어떻게 되나요??</h2><ol>
<li>Race Condition(경쟁 상태)<ul>
<li>2개 이상의 쓰레드가 공유 데이터에 접근하여 변경하는 경우 경쟁 상태가 발생할 수 있음<ul>
<li>자료의 일관성을 해치는 결과가 나타날 수 있기 때문</li>
</ul>
</li>
<li>이를 해결하기 위해서는 동기화 기법을 사용</li>
</ul>
</li>
<li>DeadLock(교착 상태)<ul>
<li>2개 이상의 쓰레드가 서로 대기하며 무한정 기다리는 상황</li>
<li>교착 상태를 방지하기 위해서는 상호배제, 점유대기, 비선점, 순환 대기 등의 조건 중 하나가 만족되지 않도록 해야함</li>
</ul>
</li>
<li>Thread.stop() 메소드 사용 금지<ul>
<li>Thread.stop() 메소드는 쓰레드를 강제로 종료시키는 메소드이지만 안정적으로 쓰레드를 종료시키지 못하고 데이터 불일치(Data Inconsistency) 등의 문제를 발생시킬 수 있음</li>
<li>대신 쓰레드를 종료시키기 위해서는 플래그 변수나 interrupt() 메소드를 사용하는 것이 좋음</li>
</ul>
</li>
<li>Thread 우선순위 지정 주의<ul>
<li>Thread 우선순위는 시스템마다 다를 수 있음</li>
<li>우선순위에 따라 쓰레드가 실행되는 것을 보장하지 않음</li>
</ul>
</li>
<li>ThreadLocal 사용 주의<ul>
<li>쓰레드별로 독립적인 데이터를 저장하는데 사용되는 ThreadLocal을 남발하면 쓰레드 간에 데이터 불일치 문제가 발생할 수 있음</li>
</ul>
</li>
<li>성능 문제<ul>
<li>쓰레드를 사용하면 Context Switching과 메모리 사용량 등의 부가적인 성능 문제가 발생할 수 있음<ul>
<li>Context Switching을 할 때는 현재 진행 중인 작업의 상태(ex. 다음에 실행해야할 위치(Program Counter)) 등의 정보를 저장하고 읽어오는 시간이 소요</li>
</ul>
</li>
<li>따라서 필요한 만큼의 Thread만 생성하고 Thread의 생명주기를 관리하여 성능 문제를 최소화해야함</li>
<li>단순한 작업일 경우에는 Single Thread로 프로그래밍 하는 것이 더 효율적</li>
</ul>
</li>
</ol>
<h2 id="그렇다면-경쟁상태를-해소하기-위해-쓰레드-동기화는-어떻게-동작하나요"><a href="#그렇다면-경쟁상태를-해소하기-위해-쓰레드-동기화는-어떻게-동작하나요" class="headerlink" title="그렇다면 경쟁상태를 해소하기 위해 쓰레드 동기화는 어떻게 동작하나요"></a>그렇다면 경쟁상태를 해소하기 위해 쓰레드 동기화는 어떻게 동작하나요</h2><p><code>Critical Section(임계영역)</code>, <code>Lock(잠금)</code></p>
<ul>
<li>한 Thread가 진행 중인 작업을 다른 Thread가 간섭하지 못하도록 막는 것을 쓰레드의 동기화라 함</li>
<li>공유 데이터를 사용하는 코드 영역을 임계영역으로 지정해놓고, 공유 데이터(객체)가 가지고 있는 lock을 획득한 단 하나의 쓰레드만 이 영역 내의 코드를 수행할 수 있도록 함</li>
<li>해당 쓰레드가 임계 영역 내의 모든 코드를 수행하고 벗어나서 lock을 반납해야 비로소 다른 쓰레드가 반납된 lock을 획득하여 임계 영역의 코드를 수행할 수 있음<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 메소드 전체를 임계 영역으로 지정</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title function_">sum</span><span class="params">()</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 특정한 영역을 임계 영역으로 지정</span></span><br><span class="line">synchronzied(객체의 참조변수) &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="자바에서의-프로세스와-쓰레드의-동시성-문제를-어떻게-해결하나요"><a href="#자바에서의-프로세스와-쓰레드의-동시성-문제를-어떻게-해결하나요" class="headerlink" title="자바에서의 프로세스와 쓰레드의 동시성 문제를 어떻게 해결하나요??"></a>자바에서의 프로세스와 쓰레드의 동시성 문제를 어떻게 해결하나요??</h2><ol>
<li>Lock, Semaphore 등의 동기화 기법<ul>
<li>java.util.concurrent 패키지의 Lock, ReentrantLock, Semaphore, Condition 등을 이용 (Synchronized 키워드 보다 더욱 세밀한 동기화 제어 제공)</li>
</ul>
</li>
<li>Thread-safe한 자료구조를 이용<ul>
<li>java.util.concurrent 패키지의 BlockingQueue, ConcurrentHashMap, CopyOnWriteArrayList 등</li>
</ul>
</li>
<li>쓰레드 풀(Thread pool)을 이용하여 쓰레드 생성 비용을 줄이고 작업을 분배</li>
</ol>
<ul>
<li>java.util.concurrent 패키지의 ThreadPoolExecutor</li>
</ul>
<ol start="4">
<li>비동기식 처리를 이용(I&#x2F;O 작업이 많은 경우에 효과적으로 CPU 자원을 활용)<ul>
<li>java.util.concurrent 패키지의 CompletableFuture, Executor 등</li>
</ul>
</li>
<li>Synchronized : Synchronized 키워드는 메서드나 블록 단위에서 사용할 수 있음</li>
<li>java.util.concurrent 패키지의 Atomic  사용</li>
<li>Fork&#x2F;Join 프레임워크 : 병렬 처리를 위한 고수준의 도구로, RecursiveTask나 RecursiveAction 클래스를 사용하여 작업을 분할하고, 각각의 작업을 병렬로 처리한 후 결과를 합쳐서 반환</li>
</ol>
<h2 id="파이썬에서의-프로세스와-쓰레드의-동시성-문제를-어떻게-해결하나요"><a href="#파이썬에서의-프로세스와-쓰레드의-동시성-문제를-어떻게-해결하나요" class="headerlink" title="파이썬에서의 프로세스와 쓰레드의 동시성 문제를 어떻게 해결하나요??"></a>파이썬에서의 프로세스와 쓰레드의 동시성 문제를 어떻게 해결하나요??</h2><ol>
<li>Lock, Semaphore 등의 동기화 기법<ul>
<li>threading 모듈의 Lock, RLock, Semaphore, Condition, Event 등의 클래스를 제공</li>
</ul>
</li>
<li>Thread-safe한 자료구조를 이용<ul>
<li>queue 모듈의 Queue, LifoQueue, PriorityQueue 등의 클래스를 제공</li>
</ul>
</li>
<li>쓰레드 풀(Thread pool)을 이용하여 쓰레드 생성 비용을 줄임</li>
</ol>
<ul>
<li>concurrent.futures 모듈의 ThreadPoolExecutor, ProcessPoolExecutor 등의 클래스</li>
</ul>
<ol start="4">
<li>비동기식 처리를 이용 (I&#x2F;O 작업이 많은 경우에 효과적으로 CPU 자원을 활용)</li>
</ol>
<ul>
<li>asyncio 라이브러리를 이용<ul>
<li>코루틴 기반의 비동기 프로그래밍을 구현할 수 있음</li>
<li>여러 작업을 동시에 처리할 수 있으며, IO 작업이 많은 프로그램에서 성능을 향상</li>
</ul>
</li>
</ul>
<ol start="5">
<li>Queue 모듈을 사용한 작업자 스레드 패턴 <ul>
<li>Queue 모듈을 사용하여 여러 쓰레드가 공유하는 작업 큐를 생성하고, 작업자 스레드들이 이 큐에서 작업을 꺼내어 처리하도록 하는 방법</li>
<li>이를 사용하여 작업을 분산 처리하고, 쓰레드 간의 경쟁을 방지</li>
</ul>
</li>
<li>multiprocessing 모듈을 사용한 프로세스 기반 병렬 처리<ul>
<li>여러 개의 프로세스를 생성하고, 이들 간에 작업을 분산하여 병렬 처리</li>
<li>이를 사용하여 여러 코어를 활용하여 작업을 처리</li>
</ul>
</li>
<li>concurrent.futures 모듈을 사용한 스레드나 프로세스 기반 병렬 처리<ul>
<li>concurrent.futures 모듈을 사용하여 스레드나 프로세스 기반의 병렬 처리를 구현</li>
<li>이를 사용하여 여러 작업을 동시에 처리하고, 블로킹 작업을 효율적으로 처리할 수 있음</li>
</ul>
</li>
</ol>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/5/">Previous</a></div><div class="pagination-next"><a href="/page/7/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li><li><a class="pagination-link is-current" href="/page/6/">6</a></li><li><a class="pagination-link" href="/page/7/">7</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/13/">13</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">노력 백줌 열정 천줌의 소프트웨어 개발자</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">130</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">65</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">78</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">40</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">기본 개념</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">자연어생성 개념</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/categories/Deep-Learning/%EC%A4%91%EA%B8%89-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">중급 개념</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD 파이프라인</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/"><span class="level-start"><span class="level-item">버전 관리</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/ElasticSearch/"><span class="level-start"><span class="level-item">ElasticSearch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/JPA/"><span class="level-start"><span class="level-item">JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/JPA/Basic/"><span class="level-start"><span class="level-item">Basic</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">16</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%81%B4%EB%A6%B0%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">클린코드</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">함수형 프로그래밍</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/OPS/"><span class="level-start"><span class="level-item">OPS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/%EC%84%A4%EC%B9%98/"><span class="level-start"><span class="level-item">설치</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/%ED%95%A8%EA%BB%98%EC%9E%90%EB%A6%AC%EA%B8%B0/"><span class="level-start"><span class="level-item">함께자리기</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/Clean-Code/"><span class="level-start"><span class="level-item">Clean Code</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Programming/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">내 코드가 그렇게 이상한가요</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Advanced-Concept/"><span class="level-start"><span class="level-item">Advanced Concept</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">객체지향 프로그래밍</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B0%8F-%EB%B9%84%EB%8F%99%EA%B8%B0/"><span class="level-start"><span class="level-item">동시성 및 비동기</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">문법</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">함수형 프로그래밍</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/REST/"><span class="level-start"><span class="level-item">REST</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/Spring-Framework/"><span class="level-start"><span class="level-item">Spring Framework</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">핵심 원리 - 기본편</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/TIL/1%EB%A7%8C-%EC%8B%9C%EA%B0%84%EC%9D%98-%EB%B2%95%EC%B9%99/"><span class="level-start"><span class="level-item">1만 시간의 법칙</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/"><span class="level-start"><span class="level-item">기타</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">네트워크 &amp; 보안</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/"><span class="level-start"><span class="level-item">HTTP 프로토콜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">데이터 암호화</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">딥러닝</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">자연어처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"><span class="level-start"><span class="level-item">인공지능</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC/"><span class="level-start"><span class="level-item">개념 정리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">자연어 처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">자연어처리</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/"><span class="level-start"><span class="level-item">클라우드 컴퓨팅</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EB%8F%84%EC%BB%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"><span class="level-start"><span class="level-item">도커 &amp; 쿠버네티스</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/"><span class="level-start"><span class="level-item">통계학</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%86%B5%EA%B3%84%ED%95%99/%EA%B8%B0%EB%B3%B8/"><span class="level-start"><span class="level-item">기본</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"><span class="level-start"><span class="level-item">파이썬</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">개념</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-03T13:08:34.000Z">2024-09-03</time></p><p class="title"><a href="/new/DevOps/CICD%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AB/CI-CD-%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%91%E1%85%B3%E1%84%85%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AB/">CI/CD 파이프라인</a></p><p class="categories"><a href="/categories/DevOps/">DevOps</a> / <a href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/">CI/CD 파이프라인</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-01T15:59:18.000Z">2024-09-02</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%20%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/AES-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA%E1%84%8B%E1%85%AA-RSA-%E1%84%8B%E1%85%A1%E1%86%B7%E1%84%92%E1%85%A9%E1%84%92%E1%85%AA/">AES 암호화와 RSA 암호화</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">네트워크 &amp; 보안</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/">데이터 암호화</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-30T14:54:04.000Z">2024-08-30</time></p><p class="title"><a href="/new/%E1%84%82%E1%85%A6%E1%84%90%E1%85%B3%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3%20&amp;%20%E1%84%87%E1%85%A9%E1%84%8B%E1%85%A1%E1%86%AB/HTTP%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%90%E1%85%A9%E1%84%8F%E1%85%A9%E1%86%AF/CORS/">CORS</a></p><p class="categories"><a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/">네트워크 &amp; 보안</a> / <a href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/">HTTP 프로토콜</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-26T14:52:30.000Z">2024-08-26</time></p><p class="title"><a href="/%EB%AA%A8%EB%8B%88%ED%84%B0%EB%A7%81/">모니터링</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-19T14:22:16.000Z">2024-08-19</time></p><p class="title"><a href="/%EB%8F%99%EC%8B%9C%EC%84%B1-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D-vs-%EB%B3%91%EB%A0%AC-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/">동시성 프로그래밍 vs 병렬 프로그래밍</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">21</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">17</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1급 시민</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Spring이란</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python 설치</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">객체지향</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">다형성</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">람다식</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">벡터의 곱셈</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">엔트로피</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">정보량</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">정보이론</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">클래스 다이어그램</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0/"><span class="tag">파라미터</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">함수형 인터페이스</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">함수형 프로그래밍</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">행렬의 곱셈</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>