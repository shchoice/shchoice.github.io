<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Shawn&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Shawn&#039;s Blog"><meta name="msapplication-TileImage" content="/img/favicon_sh.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Shawn&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:type" content="blog"><meta property="og:title" content="Shawn&#039;s Blog"><meta property="og:url" content="http://example.com/"><meta property="og:site_name" content="Shawn&#039;s Blog"><meta property="og:description" content="ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:author" content="Seohwan Choi"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"Shawn's Blog","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"Seohwan Choi"},"publisher":{"@type":"Organization","name":"Shawn's Blog","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"ì°¨ë¶„í•˜ê³  ê²¸ì†í•˜ì§€ë§Œ í™•ì‹¤í•˜ê²Œ!!"}</script><link rel="icon" href="/img/favicon_sh.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-D7QRVGYDET" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-D7QRVGYDET');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.2.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-25T14:56:56.000Z" title="8/25/2023, 11:56:56â€¯PM">2023-08-25</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:06:03.677Z" title="9/6/2024, 12:06:03â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">4 minutes read (About 549 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/3%EC%9E%A5-Data-Preparation/">3ì¥. Data Preparation</a></h1><div class="content"><h3 id="NLP-Project-Workflow"><a href="#NLP-Project-Workflow" class="headerlink" title="NLP Project Workflow"></a>NLP Project Workflow</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/ab4e691c-23c6-4c4a-bdfa-b1b0fb895eba" alt="NLPProjectWorlflow"></p>
<h3 id="Preprocessing-Workflow"><a href="#Preprocessing-Workflow" class="headerlink" title="Preprocessing Workflow"></a>Preprocessing Workflow</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/93fccf0c-13e9-42ac-81a3-1e877a07bc41" alt="PreprocessingWorkflow"></p>
<ul>
<li><p>Cleaning</p>
<ul>
<li>ê¸°ê³„ì ì¸ ë…¸ì´ì¦ˆ ì œê±°(ë¬´ì¡°ê±´ì ìœ¼ë¡œ ì œê±°, Tableì— ë”°ë¼)<ul>
<li>ì „ê°ë¬¸ì ë³€í™˜</li>
<li>Taskì— ë”°ë¥¸ (ì „í˜•ì ì¸) ë…¸ì´ì¦ˆ ì œê±°<ul>
<li>ìŒì„± ì¸ì‹ì˜ ê²½ìš°, â€œë‚˜ëŠ” (ë§¤ìš°) ê¸°ë¶„ì´ ë‚˜ì˜ë‹¤â™¡â€<ul>
<li>(ë§¤ìš°) ë‚ ë¦¬ê¸°</li>
<li>í•˜íŠ¸ ë‚ ë¦¬ê¸°</li>
</ul>
</li>
<li>ê¸°ê³„ ë²ˆì—­ì˜ ê²½ìš°, â€œë‚˜ëŠ” (ë§¤ìš°) ê¸°ë¶„ì´ ë‚˜ì˜ë‹¤â™¡â€<ul>
<li>Iâ€™m (very) upset â™¡ (ë‚ ë¦´ê²Œ ì—†ë‹¤)</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ ì´ëª¨í‹°ì½˜ì˜ ê²½ìš°ëŠ” ë§¤ìš° ì¤‘ìš”</li>
</ul>
</li>
</ul>
</li>
<li>Interactive ë…¸ì´ì¦ˆ ì œê±°<ul>
<li>ì½”í¼ìŠ¤ì˜ íŠ¹ì„±(í¬ë¡¤ë§ í•œê³³ë§ˆë‹¤, ì™¸ì£¼ ë§ˆë‹¤ ë‹¤ë¥´ë‹¤)ì— ë”°ë¥¸ ë…¸ì´ì¦ˆ ì œê±°</li>
<li>ì‘ì—…ìê°€ ìƒí™©ì„ í™•ì¸í•˜ë©° ì‘ì—… ìˆ˜í–‰</li>
</ul>
</li>
<li>Therefore<ul>
<li>ì „ì²˜ë¦¬ ê³¼ì •ì€ Taskì™€ ì–¸ì–´, ë„ë©”ì¸ê³¼ ì½”í¼ìŠ¤ì˜ íŠ¹ì„±ì— ë”°ë¼ ë‹¤ë¥´ë‹¤.</li>
<li>ì‹œê°„ê³¼ í’ˆì§ˆ ì‚¬ì´ì˜ Trade-off</li>
<li>ë”°ë¼ì„œ ì „ì²˜ë¦¬ ì¤‘ì—ì„œë„ íŠ¹íˆ ë°ì´í„° ë…¸ì´ì¦ˆ ì œê±°ì˜ ê²½ìš°, ë§ì€ ë…¸í•˜ìš°ê°€ í•„ìš”</li>
</ul>
</li>
</ul>
</li>
<li><p>Tokenization</p>
<ul>
<li>í•œêµ­ì–´ì˜ ê²½ìš°<ul>
<li>ì ‘ì‚¬ë¥¼ ë¶„ë¦¬í•˜ì—¬ í¬ì†Œì„±ì„ ë‚®ì¶”ê³ ,</li>
<li>ë„ì–´ì“°ê¸°ë¥¼ í†µì¼í•˜ê¸° ìœ„í•´ tokenizationì„ ìˆ˜í–‰</li>
</ul>
</li>
<li>êµ‰ì¥íˆ ë§ì€ POS Taggerê°€ ì¡´ì¬í•˜ëŠ”ë°,<ul>
<li>ì „í˜•ì ì¸ ì‰¬ìš´ ë¬¸ì¥(í‘œì¤€ ë¬¸ë²•ì„ ë”°ë¥´ë©°, êµ¬ì¡°ê°€ ëª…í™•í•œ ë¬¸ì¥)ì˜ ê²½ìš°, ì„±ëŠ¥ì´ ë¹„ìŠ·í•¨</li>
<li>í•˜ì§€ë§Œ ì‹ ì¡°ì–´ë‚˜ ê³ ìœ ëª…ì‚¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” ëŠ¥ë ¥ì´ ë‹¤ë¦„</li>
<li>ë”°ë¼ì„œ, ì£¼ì–´ì§„ ë¬¸ì œì— ë§ëŠ” ì •ì±…ì„ ê°€ì§„ taggerë¥¼ ì„ íƒí•˜ì—¬ ì‚¬ìš©í•´ì•¼í•¨</li>
</ul>
</li>
</ul>
</li>
<li><p>Subword Segmentation</p>
<ul>
<li>BPE ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ í†µê³„ì ìœ¼ë¡œ ë” ì‘ì€ ì˜ë¯¸ ë‹¨ìœ„(subword)ë¡œ ë¶„ì ˆ ìˆ˜í–‰</li>
<li>BPEë¥¼ í†µí•´ OoVë¥¼ ì—†ì•¨ ìˆ˜ ìˆìœ¼ë©°, ì´ëŠ” ì„±ëŠ¥ìƒ ë§¤ìš° í° ì´ì ìœ¼ë¡œ ì‘ìš©</li>
<li>í•œêµ­ì–´ì˜ ê²½ìš°<ul>
<li>ë„ì–´ì“°ê¸°ê°€ ì œë©‹ëŒ€ë¡œì¸ ê²½ìš°ê°€ ë§ìœ¼ë¯€ë¡œ, normalization ì—†ì´ ë°”ë¡œ subword segmentationì„ ì ìš©í•˜ëŠ” ê²ƒì€ ìœ„í—˜</li>
<li>ë”°ë¼ì„œ í˜•íƒœì†Œ ë¶„ì„ê¸°ë¥¼ í†µí•œ tokenizationì„ ì§„í–‰í•œ ì´í›„ subword segmentationì„ ì ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥</li>
</ul>
</li>
</ul>
</li>
<li><p>Batchify</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9ea340d3-cd00-4f17-b825-fb0671c4ce69" alt="Batchify"></p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-24T14:49:45.000Z" title="8/24/2023, 11:49:45â€¯PM">2023-08-24</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:58.808Z" title="9/6/2024, 12:05:58â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">3 minutes read (About 491 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-Wrap-up/">2ì¥ Language Modeling - Wrap up</a></h1><div class="content"><h3 id="Language-Model-ì´ë€"><a href="#Language-Model-ì´ë€" class="headerlink" title="Language Model ì´ë€"></a>Language Model ì´ë€</h3><ul>
<li><p>ì‹¤ì œ ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” (or íƒ€ê¹ƒ ë„ë©”ì¸) ì–¸ì–´ì˜ ë¶„í¬ë¥¼ í™•ë¥  ëª¨ë¸ë¡œ ëª¨ë¸ë§í•œ ê²ƒ</p>
<ul>
<li><p>Chain Ruleì— ì˜í•´ì„œ ë¬¸ì¥ì˜ í™•ë¥ ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì€ ë‹¨ì–´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒê³¼ ê°™ìŒ</p>
<ul>
<li><p>$P(x_{1:n}) &#x3D; P(x_1, \ldots, x_n)$</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$= P(x_n | x_&#123;1&#125;, \\ldots, x_&#123;n-1&#125;) \\ldots P(x_2| x_1)P(x_1)$. </span><br><span class="line">      </span><br><span class="line">$= \\prod_&#123;i=1&#125;^n P(x_i | x_&#123;&lt;i&#125;)$</span><br></pre></td></tr></table></figure>

<p>$\log P(x_{1:n}) &#x3D; \sum_{i&#x3D;1}^N \log P(x_i | x_{&lt;i})$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>ì–¸ì–´ ëª¨ë¸ì„ í†µí•´ ìš°ë¦¬ëŠ” ì•„ë˜ì˜ taskë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŒ</strong></p>
<ul>
<li>ì£¼ì–´ì§„ ë¬¸ì¥ë“¤ ì¤‘ì—ì„œ ê°€ì¥ fluentí•œ ë¬¸ì¥ì„ ê³¨ë¼ë‚¼ ìˆ˜ ìˆìŒ</li>
<li>ë‹¨ì–´ë“¤ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ë¥¼ í™•ë¥ ì ìœ¼ë¡œ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
</ul>
<h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h3><ul>
<li>ë§¤ time-step ë§ˆë‹¤ ëª¨ë¸ì´ ë™ë“±í•˜ê²Œ í—·ê°ˆë¦¬ê³  ìˆëŠ” í‰ê·  ë‹¨ì–´ ìˆ˜<ul>
<li>í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ê°€ ì ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
</ul>
</li>
<li>ë¬¸ì¥ì˜ í™•ë¥ ì˜ ì—­ìˆ˜ì— ë‹¨ì–´ ìˆ˜ ë§Œí¼ ê¸°í•˜ í‰ê· ì„ ì·¨í•œ ê²ƒ (10ì´ë©´ 10ê°œ ë‹¨ì–´ë¥¼ í—·ê°ˆë¦¬ëŠ” ê²ƒ, 6:4 ìˆ˜ì¤€ì´ ì•„ë‹ˆë¼ 5:5 ìˆ˜ì¤€ìœ¼ë¡œ ì°ê¸° ìˆ˜ì¤€ìœ¼ë¡œ í—·ê°ˆë¦¬ëŠ” ê²ƒ. 100ê°œë©´ 100ë¶„ì˜ 1 í™•ë¥ )<ul>
<li>ë¬¸ì¥ì˜ likelihoodê°€ ë†’ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
</ul>
</li>
<li>Cross Entropyì— exponentialì„ ì·¨í•œ ê²ƒ (&#x3D;perplexityì— logë¥¼ ì·¨í•œ ê²ƒ!)<ul>
<li>GT ë¶„í¬ì™€ ëª¨ë¸ì˜ ë¶„í¬ê°€ ë¹„ìŠ·í• ìˆ˜ë¡ ì¢‹ì€ ê²ƒ &#x3D;&#x3D; lower is better</li>
<li>ì¦‰ ìš°ë¦¬ëŠ” perplexityë¥¼ minimizeí•´ì•¼í•˜ëŠ”ë°, CEë¥¼ minimizeí•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤!(CEê°€ ë‚®ìœ¼ë©´ PPLë„ ë‚®ìŒ)</li>
</ul>
</li>
</ul>
<h3 id="n-gram-and-Neural-Network-Language-Model"><a href="#n-gram-and-Neural-Network-Language-Model" class="headerlink" title="n-gram and Neural Network Language Model"></a><strong>n-gram and Neural Network Language Model</strong></h3><ul>
<li>n-gram<ul>
<li>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ì¸ì‹<ul>
<li>Exact Matchingì— ëŒ€í•´ì„œë§Œ count</li>
</ul>
</li>
<li>í•™ìŠµ ì½”í¼ìŠ¤ì— word sequenceê°€ ì¡´ì¬í•´ì•¼ë§Œ í™•ë¥  ê°’ì„ ì¶”ì • ê°€ëŠ¥<ul>
<li>Markov Assumption ë„ì…</li>
</ul>
</li>
<li>ì‰½ê³  ì§ê´€ì ì¸ êµ¬í˜„<ul>
<li>í•™ìŠµ(counting) í›„, ì¶”ë¡ (table look-up)</li>
<li>Scalable í•˜ë©°, ì €ë ´í•œ ê³„ì‚° ë¹„ìš©ã…œ</li>
</ul>
</li>
</ul>
</li>
<li>NNLM<ul>
<li>ë‹¨ì–´ë¥¼ continuous vectorë¡œ ë³€í™˜<ul>
<li>unseen word sequenceì— ëŒ€ì²˜ ê°€ëŠ¥</li>
<li>Generalizationì— ê°•ì </li>
</ul>
</li>
<li>ë¹„ì‹¸ê³  ëŠë¦° ì—°ì‚° ì¶”ë¡  ê³¼ì •</li>
<li>Generation taskì— êµ‰ì¥íˆ ê°•í•¨</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-21T14:48:34.000Z" title="8/21/2023, 11:48:34â€¯PM">2023-08-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:33.955Z" title="9/6/2024, 12:05:33â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">3 minutes read (About 508 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-Auto-regressive-Teacher-Forcing/">2ì¥. Language Modeling - Auto-regressive &amp; Teacher Forcing</a></h1><div class="content"><h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/1d84b7d5-81d2-468d-99a3-b0034e0045f8" alt="seq2seqApplication"></p>
<h3 id="Two-Approaches"><a href="#Two-Approaches" class="headerlink" title="Two Approaches"></a>Two Approaches</h3><ul>
<li>Non-autoregressive (Non-generative)<ul>
<li>í˜„ì¬ ìƒíƒœê°€ ì•&#x2F;ë’¤ ìƒíƒœë¥¼ í†µí•´ ì •í•´ì§€ëŠ” ê²½ìš° (sequenceì˜ ëª¨ë“  timestampë¥¼ ë³´ê³  ì •í•´ì§)<ul>
<li>e.g. Part of Speech(POS) Tagging, Text Classification</li>
</ul>
</li>
<li>Bidirectional RNN ì‚¬ìš© ê¶Œì¥</li>
</ul>
</li>
<li>Autoregressive (Generative)<ul>
<li>í˜„ì¬ ìƒíƒœê°€ ê³¼ê±° ìƒíƒœì— ì˜ì¡´í•˜ì—¬ ì •í•´ì§€ëŠ” ê²½ìš° (ê³¼ê±°ì—ì„œ í˜„ì¬ë¡œ ë°©í–¥ì„±ì´ ìˆìŒ)<ul>
<li>e.g. Natural Language Generation, Machine Translation</li>
</ul>
</li>
<li>One-to-Many case í•´ë‹¹</li>
<li>Bidirectional RNN ì‚¬ìš© ë¶ˆê°€!(ë°©í–¥ì„±ì´ ìˆìœ¼ë‹ˆê¹Œ! ì•-&gt; ë’¤ í˜¹ì€ ë’¤-&gt; ì• í•˜ë‚˜ë§Œ ì‚¬ìš© ê°€ëŠ¥)</li>
</ul>
</li>
</ul>
<h3 id="Auto-regressive"><a href="#Auto-regressive" class="headerlink" title="Auto-regressive"></a><strong>Auto-regressive</strong></h3><ul>
<li><p>Inference</p>
<ul>
<li>$\hat{x}<em>t &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_t | \hat{x}{&lt;t}; \theta)$</li>
</ul>
</li>
<li><p>Auto-regressive</p>
<ul>
<li><p>ê³¼ê±° ìì‹ ì˜ ìƒíƒœë¥¼ ì°¸ì¡°í•˜ì—¬ í˜„ì¬ ìì‹ ì˜ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸</p>
<ul>
<li><p>$\hat{x}<em>{t&#x3D;1} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;1} | x_0; \theta)$  $\text{ where } x_0 &#x3D;$ <BOS></p>
<p>$\hat{x}<em>{t&#x3D;2} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;2} | x_0,\hat{x}_1; \theta)$</p>
<p>$\hat{x}<em>{t&#x3D;3} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t&#x3D;3} | x_0,\hat{x}_1, \hat{x}_2; \theta)$</p>
<p>â€¦</p>
<p>$\hat{x}<em>{t} &#x3D; \text{argmax}</em>{x_t \in \chi} \log P(x_{t} | x_0,\hat{x}_{x&lt;t}; \theta)$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Teacher-Forcing"><a href="#Teacher-Forcing" class="headerlink" title="Teacher-Forcing"></a>Teacher-Forcing</h3><ul>
<li><p>MLEì˜ ìˆ˜ì‹ìƒ, ì •ë‹µ $x_{t-1}$ì„ RNNì˜ ì—½ë ¥ìœ¼ë¡œ ë„£ì–´ì¤˜ì•¼ í•¨</p>
<ul>
<li><p>$D&#x3D;{x^i }_{i&#x3D;1}^N$ .         &#x2F;&#x2F; $x^i \sim P(x)$ : $P(x)$ë¼ëŠ” ë¶„í¬ì—ì„œ ë¬¸ì¥ì„ ìƒ˜í”Œë§ í•¨($x^i$)</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$ &#x2F;&#x2F; log-likelihoodë¥¼ ìµœëŒ€ë¡œ í•˜ëŠ” $\theta$ë¥¼ ì°¾ìŒ</p>
<p>   $&#x3D; \text{argmax}<em>{\theta \in \heta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i}|x_{&lt;j}^i; \theta)$ &#x2F;&#x2F; by chain-rule, ê·¼ë° ë¬¸ì œëŠ” hatì´ ì—†ìŒ</p>
<p>â€‹       $\text{where } x_{1:n} &#x3D; {x_1, â€¦, x_n}$</p>
</li>
</ul>
</li>
</ul>
<h3 id="Auto-regressive-amp-Teacher-Forcing"><a href="#Auto-regressive-amp-Teacher-Forcing" class="headerlink" title="Auto-regressive &amp; Teacher Forcing"></a><strong>Auto-regressive &amp; Teacher Forcing</strong></h3><ul>
<li><p>Inference Mode</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0" alt="InferenceMode"></p>
<p><a target="_blank" rel="noopener" href="https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0">https://github.com/shchoice/shchoice.github.io/assets/100276387/8af48ef4-7112-4545-b656-8486681d78e0</a></p>
<ul>
<li>í•™ìŠµì€ ì´ë ‡ê²Œ ëª»í•œë‹¤. ì™œëƒí•˜ë©´ lossë¥¼ êµ¬í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ë‹¤ìŒí˜ì´ì§€ì™€ ë¹„êµ! ê·¸ë˜ì„œ ë‚˜ì˜¨ ê²ƒì´ Teacher forcing,ì¦‰ Auto-regressive ì†ì„±ì„ ê°€ì§„ sequentialí•œ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë°©ë²•</li>
</ul>
</li>
<li><p>Training Mode</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9bc7ee8b-c8fb-4e75-a9e3-e6b05a446de6" alt="TrainingMode"></p>
<ul>
<li>ë§Œì•½ì— hatì´ ë“¤ì–´ê°€ë©´ <EOS>ê°€ ë“¤ì–´ê°ˆ ë•Œê¹Œì§€ì˜ ê°¯ìˆ˜ ì´ê¸°ì—, 5ë‹¨ì–´ë¥¼ ë„£ì–´ë„ 5ê°œì´ìƒì˜ ë‹¨ì–´ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” ë¬¸ì œ ë°œìƒ</li>
</ul>
</li>
</ul>
<h3 id="ê³ í†µì˜-ì‹œì‘-NLG-is-Auto-regressive-Task"><a href="#ê³ í†µì˜-ì‹œì‘-NLG-is-Auto-regressive-Task" class="headerlink" title="ê³ í†µì˜ ì‹œì‘ : NLG is Auto-regressive Task"></a><strong>ê³ í†µì˜ ì‹œì‘ : NLG is Auto-regressive Task</strong></h3><ul>
<li>Auto-regressive taskì—ì„œëŠ” ë³´í†µ ì´ì „ time-stepì˜ ëª¨ë¸ì„ ì¶œë ¥(x Ì‚_(t-1))ì„ ë‹¤ìŒ time-stepì˜ ì…ë ¥ìœ¼ë¡œ ë„£ì–´ì¤Œ<ul>
<li>ì´ì „ time-stepì˜ ì¶œë ¥ì— ë”°ë¼ í˜„ì¬ ëª¨ë¸ì˜ stateê°€ ë°”ë€Œê²Œ ë  ê²ƒ</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ ì ì ˆí•œ í•™ìŠµì„ ìœ„í•´ì„œëŠ” í•™ìŠµ ì‹œì—ëŠ” ì´ì „ time-stepì˜ ì¶œë ¥ ê°’ì´ ì•„ë‹Œ**, ì‹¤ì œ ì •ë‹µì„ ë„£ì–´ì¤Œ**</li>
<li>ë”°ë¼ì„œ í•™ìŠµê³¼ ì¶”ë¡ ì„ ìœ„í•œ ë°©ë²•ì´ ë‹¤ë¥´ê²Œ ë˜ì–´ ì—¬ëŸ¬ê°€ì§€ ë¬¸ì œê°€ ë°œìƒ<ul>
<li>í•™ìŠµì„ ìœ„í•œ ì½”ë“œì™€ ì¶”ë¡ ì„ ìœ„í•œ ì½”ë“œë¥¼ ë”°ë¡œ ì§œì•¼ í•¨</li>
<li>í•™ìŠµê³¼ ì¶”ë¡  ë°©ë²•ì˜ ê´´ë¦¬(discrepancy)ê°€ ë°œìƒí•˜ì—¬ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆìŒ<ul>
<li>ì™œëƒí•˜ë©´ trainì¼ë•ŒëŠ” ì •ë‹µ xê°€ time-stampë§ˆë‹¤ ë“¤ì–´ì™€ì„œ hidden stateì—ì„œ ë„˜ê²¨ì£¼ëŠ” ê°’ë³´ë‹¤ ì •ë‹µì„ ë” ì¤‘ìš”ì‹œ í•  ìˆ˜ ìˆì–´ ì´ì „ stateë¥¼ ì¤‘ì‹œ ì•ˆí•¨ í•˜ì§€ë§Œ inference ì‹œì—ëŠ” ì •ë‹µì´ ì•„ë‹ˆë¼ ì •ë‹µ ì˜ˆì¸¡ê°’ì´ ë„˜ì–´ì˜¤ê¸°ì— ê´´ë¦¬ê°€ ë°œìƒ..</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-20T14:36:24.000Z" title="8/20/2023, 11:36:24â€¯PM">2023-08-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:20.029Z" title="9/6/2024, 12:05:20â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">4 minutes read (About 669 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-%E2%80%93-RNN%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-LM/">2ì¥. Language Modeling â€“ RNNì„ í™œìš©í•œ LM</a></h1><div class="content"><h2 id="Language-Modeling"><a href="#Language-Modeling" class="headerlink" title="Language Modeling"></a>Language Modeling</h2><h3 id="Neural-Language-Model"><a href="#Neural-Language-Model" class="headerlink" title="Neural Language Model"></a>Neural Language Model</h3><ul>
<li><p>Resolve Sparsity</p>
<ul>
<li>Training Set<ul>
<li>ê³ ì–‘ì´ëŠ” ì¢‹ì€ ë°˜ë ¤ë™ë¬¼ ì…ë‹ˆë‹¤.</li>
</ul>
</li>
<li>Test set<ul>
<li>ê°•ì•„ì§€ëŠ” í›Œë¥­í•œ ì• ì™„ë™ë¬¼ ì…ë‹ˆë‹¤. (Unseen word sequenceë¼ ê°€ì •í•˜ì)</li>
</ul>
</li>
</ul>
</li>
<li><p>Because we know (and we can </p>
<p>approximate</p>
<p> that)</p>
<ul>
<li>ê³ ì–‘ì´ â‰ˆ ê°•ì•„ì§€</li>
<li>ì¢‹ì€ â‰ˆ í›Œë¥­í•œ</li>
<li>ë°˜ë ¤ë™ë¬¼ â‰ˆ ì• ì™„ë™ë¬¼</li>
</ul>
</li>
<li><p>But n-gram <strong>CANNOT</strong>, because words are <strong>discrete</strong> symbols</p>
</li>
</ul>
<h3 id="Neural-Language-Model-1"><a href="#Neural-Language-Model-1" class="headerlink" title="Neural Language Model"></a>Neural Language Model</h3><ul>
<li><p>Find parameter that maximize likelihood for given training corpus</p>
<ul>
<li><p>$D&#x3D;{x^i }_{i&#x3D;1}^N$ .</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$ &#x2F;&#x2F; ë°ì´í„°ì— ëŒ€í•´ log-likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì</p>
<p>$&#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i}|x_{&lt;j}^i; \theta)$<br>&#x2F;&#x2F; by chain-rule<br>$\text{where } x_{1:n} &#x3D; {x_1, â€¦, x_n}$</p>
</li>
</ul>
</li>
<li><p>Take a step of gradient descent to minimize negative log-likelihood</p>
<ul>
<li><p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N}\sum_{j&#x3D;1}^{n} \log P(x_{j}^{i},|P(x_{&lt;j}^i; \theta)$</p>
<p>$\theta \leftarrow \theta - \eta\nabla_\theta L(\theta)$<br>$\log P(x_t | x_{&lt;t}; \theta) &#x3D; x_t^T \cdot \log f_\theta(x_{t-1}, h_{t-1})$ &#x2F;&#x2F; softmax layerë¥¼ í†µê³¼í•˜ëŠ” ê²½ìš°,<br>                                            &#x2F;&#x2F; $x_t^T$ : GT (One-hot vector, ì‹¤ì œ ì˜ˆì¸¡ ë‹¨ì–´)<br>                                           &#x2F;&#x2F; $\log f_\theta(x_{t-1}, h_{t-1})$ : LM(softmax layerì— log ì”Œìš´ í™•ë¥ ê°’)</p>
</li>
</ul>
<p>$\text{where } x_t \text{ is one-hot vector, and }f_Î¸ \text{ is model with parameter Î¸.}$</p>
<ul>
<li><p>ë” ì„¸ë¶€ì ìœ¼ë¡œ ë³´ë©´.</p>
<ul>
<li><p>$f(x_{t-1}, h_{t-1}) &#x3D; \text{softmax}(RNN(\text{emb}(x_{t-1}), h_{t-1}) \cdot W)$ $\text{, where W} \in \mathbb{R}^{hidden-size \times |V|}$   &#x2F;&#x2F; WëŠ” softmax ì „ì— ìƒëµëœ linear layer<br>$&#x3D;\text{softmax}(h_t \cdot W)\text{, where } W \in \mathbb{R}^{hidden-size \times |V|}$</p>
<p>$&#x3D;\hat{x_t}$</p>
<p>$\text{where } \hat{x_t} \text{ is a probability distribution that } P(\cdot|x_{&lt;t};\theta)$</p>
<ul>
<li>$\hat{ğ‘¥_ğ‘¡}$ : mini-batch ë‚´ ë¬¸ì¥ë³„ ë‹¨ì–´ë³„ í™•ë¥ ê°’, ì´ì „ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ ì„¸íƒ€ì—ì„œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°–ì€ í™•ë¥  ë¶„í¬</li>
</ul>
<ul>
<li><p>|w| &#x3D; (hs, |V|)</p>
</li>
<li><p>|$h_t$|&#x3D;(ğ‘ğ‘ , â„ğ‘ ) &#x3D; (bs,1, hs)</p>
</li>
<li><p>|$\hat{x_t}$| &#x3D; (bs,1,hs) x (hs, |V|) &#x3D; (bs, |V|)</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/6eb9dd73-dda7-401c-b574-3c6acbc1a5f3" alt="NeuralLanguageMode"></p>
<ul>
<li>softmaxëŠ” ë‹¤ìŒ time-stepì— ë‚˜ì˜¬ ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ë¥¼ ë‚˜íƒ€ëƒ„ ì¦‰, softmax layerì˜ ê° elementëŠ” ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ê°’(ë¶„í¬)(discrete multinomial distribution)</li>
</ul>
<h3 id="Loss-Function-of-NNLM"><a href="#Loss-Function-of-NNLM" class="headerlink" title="Loss Function of NNLM"></a>Loss Function of NNLM</h3><ul>
<li>Find theta that minimize negative log-likelihood.</li>
<li>Find theta that minimize cross entropy with ground-truth probability distribution.<ul>
<li><strong>softmaxë¥¼ ì‚¬ìš©í•˜ë©´ loss functionìœ¼ë¡œ CrossEntropyë¥¼ ì‚¬ìš©í•˜ê³ </strong></li>
<li><strong>log-softmaxë¥¼ ì‚¬ìš©í•˜ë©´ NLLì„ ì‚¬ìš©í•˜ì—¬ë¼(log-likelihoodë¥¼ maximzieí•˜ë©´ NLL ì‚¬ìš©)</strong></li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>n-gram  (previous method)<ul>
<li>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ì·¨ê¸‰<ul>
<li>exact matchinì— ëŒ€í•´ì„œë§Œ count</li>
</ul>
</li>
<li>ë”°ë¼ì„œ generalization issue ë°œìƒ<ul>
<li>Markov Assumption ë„ì…(n-gram)</li>
<li>Smoothing &amp; Discounting</li>
<li>Interpolation &amp; Back-off</li>
<li>Unseen sequenceì— ëŒ€í•œ ëŒ€ì²˜ ë¯¸í¡</li>
</ul>
</li>
<li>ë¹ ë¥¸ ì—°ì‚° &amp; ì‰½ê³  ì§ê´€ì <ul>
<li>ë‹¨ìˆœí•œ look-up table ë°©ì‹</li>
<li>ë¬¸ì¥ fluency ë¹„êµ taskì—ì„œëŠ” ê´œì°®ìŒ</li>
</ul>
</li>
</ul>
</li>
<li>Neural Network Language Model<ul>
<li>Word Embeddingì„ í†µí•´, unseen sequenceì— ëŒ€í•´ ëŒ€ì²˜ ê°€ëŠ¥</li>
<li>Generation taskì—ì„œ íŠ¹íˆ ê°•ì </li>
<li>ì—°ì‚°ëŸ‰ ë§ìŒ(feed forward ì—°ì‚°)<ul>
<li>í•´ì„(XAI) ë‚œì´ë„ ì¦ê°€</li>
</ul>
</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-18T14:56:21.000Z" title="8/18/2023, 11:56:21â€¯PM">2023-08-18</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:26.037Z" title="9/6/2024, 12:05:26â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">10 minutes read (About 1455 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-How-to-evaluate-LM-Perplexity/">2ì¥. Language Modeling - How to evaluate LM(Perplexity)</a></h1><div class="content"><h2 id="How-to-evaluate-LM-Perplexity"><a href="#How-to-evaluate-LM-Perplexity" class="headerlink" title="How to evaluate LM - Perplexity"></a>How to evaluate LM - Perplexity</h2><h3 id="How-to-Evaluate"><a href="#How-to-Evaluate" class="headerlink" title="How to Evaluate"></a>How to Evaluate</h3><ul>
<li>Test set<ol>
<li>ë‚˜ëŠ” í•™êµì— ê°‘ë‹ˆë‹¤</li>
<li>ë‚˜ëŠ” í•™êµë¥¼ ê°‘ë‹ˆë‹¤.</li>
</ol>
</li>
<li>Intrinsic evaluation(ì •ì„± í‰ê°€)<ul>
<li>ì •í™•í•¨</li>
<li>ì‹œê°„ê³¼ ë¹„ìš©ì´ ë§ì´ ë“¤ì–´ê°</li>
</ul>
</li>
<li>Extrinsic evaluation(ì •ëŸ‰ í‰ê°€)<ul>
<li>ì‹œê°„ê³¼ ë¹„ìš©ì„ ì•„ë‚„ ìˆ˜ ìˆìŒ</li>
<li><strong>Intrinsic evaluation</strong>ê³¼ ë¹„ìŠ·í• ìˆ˜ë¡ ì¢‹ì€ ë°©ë²•!</li>
</ul>
</li>
</ul>
<h3 id="What-is-Good-Language-Model"><a href="#What-is-Good-Language-Model" class="headerlink" title="What is Good Language Model?"></a>What is Good Language Model?</h3><ul>
<li>ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ì˜ ë¶„í¬ë¥¼ ê°€ì¥ ì˜ ê·¼ì‚¬í•œ ëª¨ë¸<ul>
<li>ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ â†’ í…ŒìŠ¤íŠ¸ ì‹œì˜ ì…ë ¥ ë¬¸ì¥ë“¤</li>
<li>ë¶„í¬ë¥¼ ì˜ ê·¼ì‚¬ â†’ ë¬¸ì¥ì˜ likelihoodê°€ ë†’ì„ ê²ƒ</li>
</ul>
</li>
<li>ì˜ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ì…‹ì˜ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë†’ì€ í™•ë¥ ì„ ë°˜í™˜í•˜ëŠ” ì–¸ì–´ëª¨ë¸ì´ ì¢‹ì€ ëª¨ë¸!</li>
</ul>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><ul>
<li><p>Perplexity (PPL) ë€</p>
<ul>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•´ì„œ ì–¸ì–´ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ í™•ë¥ (likelihood)ì„ êµ¬í•˜ê³ </p>
</li>
<li><p>PPL ìˆ˜ì‹ì— ë„£ì–´ ì–¸ì–´ëª¨ë¸ì˜ ì„±ëŠ¥ ì¸¡ì •</p>
<ul>
<li><p>ë¬¸ì¥ì˜ í™•ë¥ ì„ ê¸¸ì´ì— ëŒ€í•´ì„œ normalization (ê¸°í•˜í‰ê· )</p>
<ul>
<li><p>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D; \sqrt[n]{ \frac{1}{P(x_1, \ldots, x_n; \theta)}}$</p>
<ul>
<li>ë‹¨ì–´ë“¤ì˜ Chain Rule ì´ê¸°ì— ë¬¸ì¥ì´ ê¸¸ìˆ˜ë¡ í™•ë¥ ê³±ìœ¼ë¡œ ê°’ì´ ì‘ì•„ì§(1ë³´ë‹¤ ì‘ì€ ê°’ì´ê¸° ë•Œë¬¸)</li>
<li>ì§§ì€ ë¬¸ì¥ì— ë¹„í•´ ê¸´ ë¬¸ì¥ì€ í™•ë¥ ì´ ì‘ì•„ì§€ê³  ê¸¸ì´ì— ë”°ë¥¸ ê¸°í•˜í‰ê· ì„ í•˜ê¸°ì—(-1&#x2F;n) ê¸¸ì´ì— ìƒê´€ì—†ì´ normalizeí•  ìˆ˜ ìˆìŒ</li>
<li>í™•ë¥ ì— ì—­ìˆ˜ë¥¼ ì·¨í–ˆìœ¼ë¯€ë¡œ PPLì€ ì‘ì„ìˆ˜ë¡ ì„±ëŠ¥ì´ ì¢‹ìŒì„ ì˜ë¯¸</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Chain Ruleì— ì˜í•´ì„œ</p>
<ul>
<li>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D;\sqrt[n]{\frac{1}{P(x_1, \ldots, x_n; \theta)}} &#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}}$</li>
</ul>
</li>
<li><p>Markov assumptionì´ ì ìš© ë  ê²½ìš°</p>
<ul>
<li>$PPL(x_1, \ldots, x_n; \theta) &#x3D; P(x_1, \ldots, x_n; \theta)^{-\frac{1}{n}} &#x3D; \sqrt[n]{ \frac{1}{P(x_1, \ldots, x_n; \theta)}} &#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}} \approx \sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{i-1}, \ldots, x_{i-k}; \theta)}}$</li>
</ul>
</li>
<li><p>Perplexity</p>
<ul>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•´ì„œ <strong>í™•ë¥ ì„ ë†’ê²Œ ë°˜í™˜í• ìˆ˜ë¡</strong> ì¢‹ì€ ì–¸ì–´ëª¨ë¸</p>
</li>
<li><p>í…ŒìŠ¤íŠ¸ ë¬¸ì¥ì— ëŒ€í•œ <strong>PPLì´ ì‘ì„ìˆ˜ë¡</strong> ì¢‹ì€ ì–¸ì–´ëª¨ë¸</p>
</li>
<li><p>ì˜ˆì œ</p>
<ul>
<li><p>ì£¼ì‚¬ìœ„ë¥¼ ë˜ì ¸ë´…ì‹œë‹¤.</p>
<ul>
<li>1ë¶€í„° 6ê¹Œì§€ì˜ 6ê°œì˜ ìˆ«ìë¡œ ì´ë£¨ì–´ì§„ ìˆ˜ì—´</li>
<li>1ë¶€í„° 6ê¹Œì§€ 6ê°œì˜ ìˆ«ìì˜ ì¶œí˜„ í™•ë¥ ì€ ëª¨ë‘ ê°™ìŒ</li>
</ul>
</li>
<li><p>uniform distribution</p>
<ul>
<li><p>$D&#x3D;{x^i}_{i&#x3D;1}^{N} \text{, where } x_i \sim P(x) \text{ and } \forall x \in {1, 2, 3, 4, 5, 6}$</p>
<p>$PPL(x_1, \ldots, x_n; \theta) &#x3D;\sqrt[n]{\frac{1}{P(x_1, \ldots, x_n; \theta)}}&#x3D;\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i)}}$    &#x2F;&#x2F; ë…ë¦½ì‹œí–‰ì´ê¸°ì—<br>$&#x3D;\sqrt[n]{\frac{1}{(\frac{1}{6})^n}} &#x3D; 6$    &#x2F;&#x2F; ì£¼ì‚¬ìœ„ ë©´ì˜ ê°¯ìˆ˜</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Perplexityë¥¼ í•´ì„í•˜ëŠ” ë°©ë²•</p>
<ul>
<li>ì£¼ì‚¬ìœ„ PPL : ë§¤ time-step ê°€ëŠ¥í•œ ê°€ì§“ìˆ˜ì¸ 6</li>
<li>ë»—ì–´ë‚˜ê°ˆ ìˆ˜ ìˆëŠ” branch(ê°€ì§€)ì˜ ìˆ«ìë¥¼ ì˜ë¯¸</li>
<li><strong>Time-step ë³„ í‰ê·  branchì˜ ìˆ˜</strong></li>
<li>PPLì´ <strong>ë‚®ì„ìˆ˜ë¡</strong> í™•ë¥  ë¶„í¬ê°€ <strong>Sharp</strong> í•˜ë‹¤.</li>
<li>PPLì´ <strong>ë†’ì„ìˆ˜ë¡</strong> í™•ë¥  ë¶„í¬ê°€ <strong>Flat</strong> í•˜ë‹¤.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>ì¢‹ì€ ì–¸ì–´ëª¨ë¸<ul>
<li>ì˜ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ì…‹ ë¬¸ì¥ì— ëŒ€í•´ì„œ ë†’ì€ í™•ë¥ (&#x3D;ë‚®ì€ PPL)ì„ ê°–ëŠ” ëª¨ë¸</li>
</ul>
</li>
<li>Perplexity(PPL)<ul>
<li>Lower is better</li>
<li>í™•ë¥ ì˜ ì—­ìˆ˜ì— ë¬¸ì¥ ê¸¸ì´ë¡œ ê¸°í•˜ í‰ê· </li>
<li>ë§¤ time-stepë§ˆë‹¤ í‰ê· ì ìœ¼ë¡œ í—·ê°ˆë¦¬ê³ (no clue) ìˆëŠ” ë‹¨ì–´ì˜ ìˆ˜</li>
</ul>
</li>
</ul>
<h2 id="Perplexity-amp-Entropy"><a href="#Perplexity-amp-Entropy" class="headerlink" title="Perplexity &amp; Entropy"></a>Perplexity &amp; Entropy</h2><h3 id="Perplexity"><a href="#Perplexity" class="headerlink" title="Perplexity"></a>Perplexity</h3><ul>
<li><p>Sharp vs Flat distribution</p>
<ul>
<li>Perplexityê°€ ë†’ìœ¼ë©´ flatí•˜ê³ (ê³ ë¥´ë‹¤)</li>
<li>Perplexityê°€ ë‚®ì„ìˆ˜ë¡ sharpí•˜ë‹¤</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/aebe52a3-6fbe-4f36-8bf5-cc553d8fff1f" alt="Perplexity"></p>
</li>
</ul>
<h3 id="Information-and-Entropy"><a href="#Information-and-Entropy" class="headerlink" title="Information and Entropy"></a>Information and Entropy</h3><ul>
<li><p>ì •ë³´ì´ë¡ ì—ì„œ ì—”íŠ¸ë¡œí”¼ëŠ” ì–´ë–¤ ì •ë³´ì˜ ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ëƒ„</p>
</li>
<li><p>ë¶ˆí™•ì‹¤ì„±ì€ ì¼ì–´ë‚  ê²ƒ ê°™ì€ ì‚¬ê±´(likely event)ì˜ í™•ë¥ </p>
<ul>
<li>ìì£¼ ë°œìƒí•˜ëŠ” (ì¼ì–´ë‚  í™•ë¥ ì´ ë†’ì€) ì‚¬ê±´ì€ ë‚®ì€ ì •ë³´ëŸ‰ì„ ê°€ì§</li>
<li>ë“œë¬¼ê²Œ ë°œìƒí•˜ëŠ” (ì¼ì–´ë‚  í™•ë¥ ì´ ë‚®ì€) ì‚¬ê±´ì€ ë†’ì€ ì •ë³´ëŸ‰ì„ ê°€ì§</li>
</ul>
</li>
<li><p>ë¶ˆí™•ì‹¤ì„± âˆ $\frac{ğŸ}{í™•ë¥ }$âˆ ì •ë³´ëŸ‰</p>
</li>
<li><p>ì •ë³´ëŸ‰ ìˆ˜ì‹</p>
<ul>
<li>$I(\text{x})&#x3D;-\log P(\text{x})$     #  xë¼ëŠ” random variableì— ëŒ€í•œ ì •ë³´<ul>
<li>0â‰¤ğ‘ƒ(ğ‘¥)â‰¤1</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/fa29fa22-1bd0-4cf4-8aae-98df4911ad74" alt="Information"></p>
</li>
<li><p>ì •ë³´ëŸ‰ ì˜ˆì œ</p>
<ul>
<li>ì˜ˆì œ1<ol>
<li>ë‚´ì¼ ì•„ì¹¨ í•´ëŠ” ë™ìª½ í•˜ëŠ˜ì—ì„œ ëœ¹ë‹ˆë‹¤. â†’ í™•ë¥ ì´ ë†’ì„ìˆ˜ë¡ ì •ë³´ëŸ‰ì´ ë‚®ë‹¤.</li>
<li>ë‚´ì¼ ì•„ì¹¨ í•´ëŠ” ì„œìª½ í•˜ëŠ˜ì—ì„œ ëœ¹ë‹ˆë‹¤. â†’ í™•ë¥ ì´ ë‚®ì„ìˆ˜ë¡ ì—„ì²­ë‚œ ì •ë³´ëŸ‰ì„ ê°€ì§€ê³  ìˆë‹¤.</li>
</ol>
</li>
<li>ì˜ˆì œ2<ol>
<li>ì˜¬  ì—¬ë¦„ ëŒ€í•œë¯¼êµ­ì˜ í‰ê·  ì—¬ë¦„ ê¸°ì˜¨ì€ 30ë„ ì…ë‹ˆë‹¤. â†’ ì •ë³´ëŸ‰ì´ ë‚®ìŒ</li>
<li>ì˜¬ ì—¬ë¦„ ëŒ€í•œë¯¼êµ­ì˜ í‰ê·  ì—¬ë¦„ ê¸°ì˜¨ì€ 10ë„ ì…ë‹ˆë‹¤.â†’ ì •ë³´ëŸ‰ì´ ë†’ìŒ</li>
</ol>
</li>
</ul>
</li>
<li><p>ì–¸ì–´ëª¨ë¸ ê´€ì  ì˜ˆì œ</p>
<ul>
<li>í”íˆ ë‚˜ì˜¬ ìˆ˜ ì—†ëŠ” ë¬¸ì¥(í™•ë¥ ì´ ë‚®ì€ ë¬¸ì¥)ì¼ìˆ˜ë¡ ë” ë†’ì€ ì •ë³´ëŸ‰</li>
</ul>
</li>
</ul>
<h3 id="Perplexity-amp-Entropy-1"><a href="#Perplexity-amp-Entropy-1" class="headerlink" title="Perplexity &amp; Entropy"></a>Perplexity &amp; Entropy</h3><ul>
<li><p>Cross Entropy</p>
<ul>
<li><p>$H(P, P_\theta) &#x3D; -E_{x_{1:n} \sim P}[\log P(x_{1:n}; \theta)]$  &#x2F;&#x2F; P(X)ì—ì„œ ì–´ë–¤ ë¬¸ì¥ì„ samplingí•˜ì—¬ ìš°ë¦¬ ëª¨ë¸ì— ë„£ì—ˆì„ ë•Œë¡œê·¸ í™•ë¥ ê°’ì„ í‰ê· ë‚´ê³  ë§ˆì´ë„ˆìŠ¤ë¥¼ ì·¨í•˜ëŠ” CE</p>
<p>$\approx -\frac{1}{n} \sum_{x_{1:n} \in X} P(x_{1:n}) \log P(x_{1:n}; \theta)\text{, defined as per-word entropy}$ &#x2F;&#x2F;P(x_{1:n})\log{P(x_{1:n}; \theta)}: GT  x Log-likelihood</p>
</li>
</ul>
<p>$\approx -\frac{1}{n \times N} \sum_{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta) \text{, by Monte-Carlo}\approx -\frac{1}{n} \log P(x_{1:n}; \theta)\text{, where N&#x3D;1}$ &#x2F;&#x2F; 1ê°œì˜ ë¬¸ì¥ìœ¼ë¡œ CEë¥¼ êµ¬í•¨<br>$\approx -\frac{1}{n} \sum_{i&#x3D;1}^{N} \log P(x_i | x_{&lt;i}; \theta)$ &#x2F;&#x2F; by chain rule<br>$&#x3D;L(x_{1:n}; \theta)$</p>
<ul>
<li>$L(x_{1:n}; \theta) \approx -\frac{1}{n} \sum_{i&#x3D;1}^{N} \log P(x_i | x_{&lt;i}; \theta)&#x3D;-\frac{1}{n} \log \prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)&#x3D;\log\sqrt[n]{\frac{1}{\prod_{i&#x3D;1}^{n} P(x_i | x_{&lt;i}; \theta)}}&#x3D;\log{PPL(x_{1:n};\theta)}$</li>
</ul>
</li>
<li><p>ì¦‰ PPL exp(CE)ì™€ ê°™ë‹¤.</p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Objective : minimize perplexity<ul>
<li>equivalent to minimize cross entropy</li>
<li>is also same as minimizing negative log-likelihood</li>
</ul>
</li>
<li>ë¬¸ì¥ì˜ likelihoodë¥¼ maximizeí•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ê³  ì‹¶ìŒ<ul>
<li>Ground-truth í™•ë¥  ë¶„í¬(ì‹¤ì œ ì‚¬ëŒì´ ê°€ì§„ ì–¸ì–´ ëª¨ë¸)ì— ì–¸ì–´ëª¨ë¸ì„ ê·¼ì‚¬(approximate)í•˜ê³  ì‹¶ìŒ</li>
</ul>
</li>
<li>GT ë¶„í¬ì™€ LM ë¶„í¬ ì‚¬ì´ì˜ cross entropyë¥¼ êµ¬í•˜ê³  minimize<ul>
<li>ë¬¸ì¥ì˜ perplexityë¥¼ minimize.</li>
</ul>
</li>
<li><strong>perplexityë¥¼ í†µí•´ í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ë“¤ì˜ ìˆ«ìì´ê¸°ì—, ë‚´ LMì´ ë§¤ time-stepë§ˆë‹¤ í—·ê°ˆë¦¬ëŠ” ë‹¨ì–´ë“¤ì˜ ìˆ«ìê°€ ëª‡ ê°œêµ¬ë‚˜ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŒ.</strong></li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-17T14:27:24.000Z" title="8/17/2023, 11:27:24â€¯PM">2023-08-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:52.606Z" title="9/6/2024, 12:05:52â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">9 minutes read (About 1395 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-N-gram-Language-Model/">2ì¥. Language Modeling - N-gram Language Model</a></h1><div class="content"><h2 id="N-gram-Language-Model"><a href="#N-gram-Language-Model" class="headerlink" title="N-gram Language Model"></a>N-gram Language Model</h2><h3 id="ì¢‹ì€-ëª¨ë¸ì´ë€-ë¬´ì—‡ì¸ê°€"><a href="#ì¢‹ì€-ëª¨ë¸ì´ë€-ë¬´ì—‡ì¸ê°€" class="headerlink" title="ì¢‹ì€ ëª¨ë¸ì´ë€ ë¬´ì—‡ì¸ê°€"></a>ì¢‹ì€ ëª¨ë¸ì´ë€ ë¬´ì—‡ì¸ê°€</h3><ul>
<li>Generalization (ì¼ë°˜í™”ë¥¼ ì˜ í•˜ëŠ” ëª¨ë¸)<ul>
<li>Training(seen) dataë¥¼ í†µí•´ì„œ test(unseen) dataì— ëŒ€í•´ í›Œë¥­í•œ predictionì„ í•  ìˆ˜ ìˆëŠ”ê°€</li>
</ul>
</li>
<li>ë§Œì•½ ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ì— ëŒ€í•´ í•™ìŠµ ë°ì´í„°ë¥¼ ëª¨ì„ ìˆ˜ ìˆë‹¤ë©´, table look-up(DB)ìœ¼ë¡œ ëª¨ë“  ë¬¸ì œë¥¼ í’€ ìˆ˜ ìˆì„ ê²ƒ<ul>
<li>í•˜ì§€ë§Œ ê·¸ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ generalization ëŠ¥ë ¥ì´ ì¤‘ìš” (ì‚¬ëŒì€ ì´ ëŠ¥ë ¥ì´ ë›°ì–´ë‚¨, ë³´ì§€ëª»í•œ ê±¸ ê¸°ì¡´ì— ë³¸ ê²ƒìœ¼ë¡œ ì˜ ì˜ˆì¸¡ í•¨)</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/abccf694-61f2-407c-af95-cc1ede8dc544" alt="Generalization"></p>
<h3 id="Count-based-Approximation"><a href="#Count-based-Approximation" class="headerlink" title="Count based Approximation"></a>Count based Approximation</h3><ul>
<li><p>ì£¼ì–´ì§„ ë¬¸ì¥ì´ ë‹¤ìŒê³¼ ê°™ë‹¤ë©´</p>
<ul>
<li><p>P(<BOS>,I, Love, to, play, <EOS>)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(<BOS>,I, Love, to, play)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(<BOS>,I, Love, to) &#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(<BOS>,I, Love)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(Love|<BOS>,I)P(<BOS>,I) &#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(Love|<BOS>,I)P(I|<BOS>)P(<BOS>)</p>
</li>
</ul>
</li>
<li><p>ìš°ë¦¬ëŠ” Word Sequnceì˜ countì— ê¸°ë°˜í•œ ì¡°ê±´ë¶€ í™•ë¥ ì„ í†µí•´ ê·¼ì‚¬í•  ìˆ˜ ìˆìŒ(We can approximate conditional probability by counting word sequence)</p>
<ul>
<li>P(<BOS>,I, Love, to, play, <EOS>) $\approx \frac{COUNT(<BOS>,I, Love, to, play, <EOS>)}{COUNT(<BOS>,I, Love, to, play)}$</li>
</ul>
</li>
<li><p>ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´</p>
<ul>
<li>$P(x_n|x_{&lt;n}) \approx \frac{COUNT(x_1,â‹¯,x_{n})}{COUNT(x_1,â‹¯,x_{n-1})}$</li>
</ul>
</li>
<li><p>ë¬¸ì œì </p>
<ul>
<li>ë§Œì•½ì— ë¬¸ì¥ì˜ ë¹ˆë„ìˆ˜ê°€ 0ì¸ ê²ƒì´ ìˆë‹¤ë©´, chain ruleì— ë”°ë¼ ëª¨ë‘ê°€ 0ì´ ë˜ì–´ì„œ í° ë¬¸ì œê°€ ë°œìƒ</li>
<li>ì‹¬ì§€ì–´ëŠ” ë¶„ëª¨ê°€ 0ì´ ë  ìˆ˜ë„ ìˆìŒ</li>
</ul>
</li>
</ul>
<h3 id="Markov-Assumptionì„-ì ìš©í•˜ë©´"><a href="#Markov-Assumptionì„-ì ìš©í•˜ë©´" class="headerlink" title="Markov Assumptionì„ ì ìš©í•˜ë©´"></a>Markov Assumptionì„ ì ìš©í•˜ë©´</h3><ul>
<li><p>Apporximate with counting only previous k tokens (ëª¨ë“  ë‹¨ì–´ë¥¼ ë³´ì§€ ì•Šê³  kê°œë§Œ ë´„)</p>
<ul>
<li>$P(x_n|x_{&lt;n}) \approx P(x_n|x_1,â‹¯,x_{n-k}) \approx \frac{COUNT(x_{n-k},â‹¯,x_{n})}{COUNT(x_{n-k},â‹¯,x_{n-1})}$</li>
</ul>
</li>
<li><p>if k &#x3D; 2</p>
<ul>
<li>$P(x_n|x_{&lt;n}) \approx P(x_n|x_{n-2},x_{n-1},x_{n}) \approx \frac{COUNT(x_{n-2},x_{n-1},x_{n})}{COUNT(x_{n-2},x_{n-1})}$</li>
</ul>
</li>
</ul>
<h3 id="ë§Œì•½ì—-ì´ë¥¼-Sentence-levelì—-ê¹Œì§€-ì ìš©í•œë‹¤ë©´"><a href="#ë§Œì•½ì—-ì´ë¥¼-Sentence-levelì—-ê¹Œì§€-ì ìš©í•œë‹¤ë©´" class="headerlink" title="ë§Œì•½ì— ì´ë¥¼ Sentence levelì— ê¹Œì§€ ì ìš©í•œë‹¤ë©´"></a>ë§Œì•½ì— ì´ë¥¼ Sentence levelì— ê¹Œì§€ ì ìš©í•œë‹¤ë©´</h3><ul>
<li><p>training corpusì—ì„œ ë³´ì§€ ëª»í•œ word sequnceê¹Œì§€ ëŒ€ì²˜í•  ìˆ˜ ìˆìŒ</p>
<ul>
<li>$\log P(x_{1:n}) &#x3D; \sum_{i&#x3D;1}^N \log P(x_i | x_{&lt;i}) approx \sum_{i&#x3D;1}^N \log P(x_i | x_{i-1},â‹¯,x_{i-k})$</li>
</ul>
</li>
</ul>
<h3 id="N-gram"><a href="#N-gram" class="headerlink" title="N-gram"></a>N-gram</h3><ul>
<li><p>nì´ ì»¤ì§ˆìˆ˜ë¡ ì˜¤íˆë ¤ í™•ë¥ ì´ ì •í™•í•˜ê²Œ í‘œí˜„ë˜ëŠ”ë° ì–´ë ¤ì›€</p>
<ul>
<li>Markov assumptionì´ ì•½í•˜ê²Œ ë“¤ì–´ê°€ê¸°ì—, countê°€ ì¦ê°€í•˜ê¸° ì‰½ì§€ ì•ŠìŒ ë°˜ëŒ€ë¡œ nì´ ë„ˆë¬´ ì‘ìœ¼ë©´ Markov assumptionì´ ê°•í•˜ê²Œ ë“¤ì–´ê°€ í™•ë¥ ì´ ì™œê³¡ì´ ì‹¬í•´ì§</li>
<li>ì ì ˆí•œ nì„ ì‚¬ìš©í•´ì•¼ í•¨</li>
</ul>
</li>
<li><p>ë³´í†µ 3-gramì„ ê°€ì¥ ë§ì´ ì‚¬ìš©</p>
</li>
<li><p>corpus(ë§ë­‰ì¹˜)ì˜ ì–‘ì´ ë§ì„ ë•ŒëŠ” 4-gramì„ ì‚¬ìš©í•˜ê¸°ë„ í•¨</p>
<ul>
<li>ì–¸ì–´ëª¨ë¸ì˜ ì„±ëŠ¥ì€ í¬ê²Œ ì˜¤ë¥´ì§€ ì•ŠëŠ”ë° ë°˜í•´</li>
<li>ë‹¨ì–´ ì¡°í•©ì˜ ê²½ìš°ì˜ ìˆ˜ëŠ” exponentialí•˜ê²Œ ì¦ê°€í•˜ë¯€ë¡œ íš¨ìœ¨ì„±ì´ ì—†ìŒ</li>
</ul>
</li>
<li><p>n &#x3D; k + 1</p>
<table>
<thead>
<tr>
<th>k</th>
<th>n-gram</th>
<th>ëª…ì¹­</th>
</tr>
</thead>
<tbody><tr>
<td>0</td>
<td>1-gram</td>
<td>uni-gram</td>
</tr>
<tr>
<td>1</td>
<td>2-gram</td>
<td>bi-gram</td>
</tr>
<tr>
<td>2</td>
<td>3-gram</td>
<td>tri-gram</td>
</tr>
<tr>
<td>3</td>
<td>4-gram</td>
<td>four-gram</td>
</tr>
</tbody></table>
</li>
<li><p>N-gram LMì„ ì–´ë–»ê²Œ í›ˆë ¨ ë° ì¶”ë¡ í•˜ëŠ” ë°©ë²•</p>
<ul>
<li>SRILM<ul>
<li>download : <a target="_blank" rel="noopener" href="http://www.speech.sri.com/projects/srilm/download.html">http://www.speech.sri.com/projects/srilm/download.html</a></li>
</ul>
</li>
<li>ngram-count: LMì„ í›ˆë ¨ (ê·¸ ê²°ê³¼ model fileì´ ë‚˜ì˜¤ê²Œ ë¨)<ul>
<li>vocab : lexicon file name</li>
<li>text : training corpus file name</li>
<li>order : n-gram count</li>
<li>write : output countfile file name</li>
<li>unk : mark OOV as</li>
<li>kndiscount : Use Kneser-Ney discounting for N-grams of order n</li>
</ul>
</li>
<li>ngram : LMì„ í™œìš©<ul>
<li>ppl : calculate perplexity for test file name</li>
<li>order : n-gram count</li>
<li>lm : language model file name</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>í™•ë¥ ê°’ì„ ê·¼ì‚¬í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ ì½”í¼ìŠ¤ì—ì„œ ë¹ˆë„ë¥¼ ì„¸ëŠ” ê²ƒ<ul>
<li>í•˜ì§€ë§Œ ë³µì¡í•œ ë¬¸ì¥ì¼ìˆ˜ë¡ ì½”í¼ìŠ¤ì—ì„œ ì¶œí˜„ ë¹ˆë„ê°€ ë‚®ì•„, ë¶€ì •í™•í•œ ê·¼ì‚¬ê°€ ì´ë£¨ì–´ì§ˆ ê²ƒ</li>
</ul>
</li>
<li>ë”°ë¼ì„œ Markov assumptionì„ ë„ì…í•˜ì—¬ í™•ë¥ ê°’ì„ ê·¼ì‚¬í•˜ì<ul>
<li>ì´ì œ í•™ìŠµ ì½”í¼ìŠ¤ì—ì„œ ë³´ì§€ ëª»í•œ ë¬¸ì¥ì— ëŒ€í•´ì„œë„ í™•ë¥ ê°’ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.</li>
<li>nì˜ í¬ê¸°ê°€ ì¤‘ìš”í•¨<ul>
<li>n &#x3D; 3~4 ê°€ ì ë‹¹</li>
</ul>
</li>
</ul>
</li>
<li>í•˜ì§€ë§Œ Markov assumptionì„ ë„ì…í•´ë„ 0ì´ ë‚˜ì˜¬ ìˆ˜ê°€ ìˆìŒ</li>
</ul>
<h2 id="Smoothing-amp-Discounting"><a href="#Smoothing-amp-Discounting" class="headerlink" title="Smoothing &amp; Discounting"></a>Smoothing &amp; Discounting</h2><ul>
<li>Smoothing<ul>
<li>Markov assumptionì„ ë„ì…í•˜ì˜€ì§€ë§Œ ì—¬ì „íˆ ë¬¸ì œëŠ” ë‚¨ì•„ìˆìŒ</li>
<li>Training corpusì— ì—†ëŠ” unseen word sequenceì˜ í™•ë¥ ì€ 0?</li>
<li>Unseen word sequenceì— ëŒ€í•œ ëŒ€ì²˜<ul>
<li>Smoothing or Discounting</li>
</ul>
</li>
<li>Popular algorithm<ul>
<li>Modified Kneser-Ney Discounting</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/7e0288d0-6a58-42e3-b579-93a4652cba71" alt="smoothing"></p>
<ul>
<li><p>Add One Smoothing</p>
<ul>
<li><p>To prevent count becomes zero</p>
<ul>
<li>$P(w_t|w_{&lt;t}) \approx \frac{C(w_{1:t})}{C(w_{1:t-1})}$             &#x2F;&#x2F; t time-stepì˜ ì‹œì ì¼ ë•Œê¹Œì§€ì˜ t time-stepì˜ ì–¸ì–´ì˜ í™•ë¥  ë¶„í¬(í™•ë¥ ê°’) $\approx \frac{C(w_{1:t}) + 1}{C(w_{1:t-1}) + ,|V,|} text{where } |V| \text{ is a size of vocabulary}$</li>
</ul>
</li>
<li><p>Generalization of Add One Smoothing</p>
<ul>
<li><p>If we generalize this :</p>
<ul>
<li>$P(w_t|w_{&lt;t}) \approx \frac{C(w_{1:t})}{C(w_{1:t-1})} \approx \frac{C(w_{1:t}) + 1}{C(w_{1:t-1}) + ,|V,|} \approx \frac{C(w_{1:t}) + k}{C(w_{1:t-1}) + k \times ,|V,|} \approx \frac{C(w_{1:t}) + \frac{m}{,|V,|}}{C(w_{1:t-1}) + m} \text{where } |V| \text{ is a size of vocabulary}$</li>
</ul>
</li>
<li><p>Take more generailzation :</p>
<ul>
<li><p>$P(w_t|w_{&lt;t}) \approx \frac{C(w_{1:t}) + m \times P(w_t)}{C(w_{1:t-1}) + m}$</p>
<p>$\text{where } P(w_t) \text{ is unigram probability}$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Kneser-Ney-Discounting"><a href="#Kneser-Ney-Discounting" class="headerlink" title="Kneser-Ney Discounting"></a>Kneser-Ney Discounting</h3><ul>
<li><p>In this lecture</p>
<ul>
<li>C(learning) &gt; C(laptop)</li>
<li>Because of â€œdeep learningâ€, â€œmachine learningâ€</li>
</ul>
</li>
<li><p>ë‹¤ì–‘í•œ ë‹¨ì–´ ë’¤ì— ë‚˜íƒ€ë‚˜ëŠ” ë‹¨ì–´ì¼ìˆ˜ë¡ unseen word sequenceì— ë“±ì¥í•  í™•ë¥ ì´ ë†’ì§€ ì•Šì„ê¹Œ?</p>
<ul>
<li><p>ì•ì— ë“±ì¥í•œ ë‹¨ì–´ì˜ ì¢…ë¥˜ê°€ ë‹¤ì–‘í• ìˆ˜ë¡ í•´ë‹¹ í™•ë¥ ì´ ë†’ì„ ê²ƒ ê°™ìŒ</p>
<p>$P_{continuation} (w) \propto | {v : C(v, w) &gt; 0} |$</p>
<ul>
<li>$P_{continuation}$ : ë‹¨ì–´ $w$ ì´í›„ì— ê³„ì†ë˜ëŠ” ë‹¨ì–´ì˜ í™•ë¥ ì„ ë‚˜íƒ€ëƒ„</li>
<li>$C(v, w)$ : ë‹¨ì–´ $v$ì™€ $w$ ê°€ í•¨ê»˜ ë“±ì¥í•˜ëŠ” íšŸìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„</li>
<li>$\propto$ : ë¹„ë¡€</li>
<li>$| {v : C(v, w) &gt; 0} |$ëŠ” $w$ì™€ í•¨ê»˜ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ $v$ì˜ ìˆ˜ë¥¼ ë‚˜íƒ€ëƒ„</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½-1"><a href="#ìš”ì•½-1" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>Markov Assumption<ul>
<li>Count ê¸°ë°˜ì˜ approximation</li>
<li>ê¸´ word sequenceëŠ” í•™ìŠµ ì½”í¼ìŠ¤ì— ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ<ul>
<li>í™•ë¥  ê°’ì´ 0ìœ¼ë¡œ ë§µí•‘</li>
</ul>
</li>
<li>Markov assumptionì„ í†µí•´ ê·¼ê±°ë¦¬ì˜ ë‹¨ì–´ë§Œ ê³ ë ¤</li>
</ul>
</li>
<li>Smoothing and Discounting<ul>
<li>Markov assumptionì„ í†µí•´ì„œë„ ì—¬ì „íˆ í™•ë¥ ê°’ì´ 0ì´ ë  ìˆ˜ ìˆìŒ</li>
<li>Smoothing ë˜ëŠ” discountingì„ í†µí•´ í˜„ìƒì„ ì™„í™”</li>
<li>ì—¬ì „íˆ unseen word sequenceì— ëŒ€í•œ ëŒ€ì²˜ëŠ” ë¯¸í¡</li>
</ul>
</li>
</ul>
<h2 id="Interpolation-amp-Back-off"><a href="#Interpolation-amp-Back-off" class="headerlink" title="Interpolation &amp; Back-off"></a>Interpolation &amp; Back-off</h2><h3 id="Interpolation-ë³´ê°„ë²•"><a href="#Interpolation-ë³´ê°„ë²•" class="headerlink" title="Interpolation (ë³´ê°„ë²•)"></a>Interpolation (ë³´ê°„ë²•)</h3><ul>
<li>ë‹¤ë¥¸ Language Modelì„ linearí•˜ê²Œ ì¼ì • ë¹„ìœ¨(ğ€)ë¡œ ì„ëŠ” ê²ƒ</li>
<li>general domain LM + domain specific LM &#x3D; general domainì—ì„œ ì˜ ë™ì‘í•˜ëŠ” domain adapted LM</li>
<li>domain specific LMExamples<ul>
<li>ì˜ë£Œ domain ASR, MT system</li>
<li>ë²•ë¥  domain ASR, MT system</li>
<li>íŠ¹í—ˆ domain MT system</li>
</ul>
</li>
<li>ìˆ˜ì‹<ul>
<li>$\tilde{P}(w_n | w_{n-k}, \ldots, w_{n-1}) &#x3D; \lambda P_1(w_n | w_{n-k}, \ldots, w_{n-1}) + (1 - \lambda) P_2(w_n | w_{n-k}, \ldots, w_{n-1})$<ul>
<li>$P_1(w_n | w_{n-k}, \ldots, w_{n-1})$ : ì²«ë²ˆì§¸ LM</li>
<li>$P_2(w_n | w_{n-k}, \ldots, w_{n-1})$ : ë‘ë²ˆì§¸ LM</li>
</ul>
</li>
</ul>
</li>
<li>ê·¸ëƒ¥ domain specific corpusë¡œ LMì„ ë§Œë“¤ë©´ ì¥ë•¡ ì•„ë‹Œê°€?<ul>
<li>ê·¸ëŸ¼ unseen word sequenceê°€ ë„ˆë¬´ ë§ì„ ìˆ˜ ìˆìŒ</li>
</ul>
</li>
<li>ê·¸ëƒ¥ ì „ì²´ corpusë¥¼ í•©ì³ì„œ LMì„ ë§Œë“¤ë©´ ì¥ë•¡ ì•„ë‹Œê°€?<ul>
<li>Domain Specific corpusì˜ ì–‘ì´ ë„ˆë¬´ ì ì–´ì„œ ë°˜ì˜ì´ ì•ˆë  ìˆ˜ ìˆìŒ</li>
</ul>
</li>
<li>Interpolationì—ì„œ ratio(ğ€)ë¥¼ ì¡°ì ˆí•˜ì—¬ ì¤‘ìš”ë„(weight)ë¥¼ ì¡°ì ˆ<ul>
<li>ëª…ì‹œì (explicit)ìœ¼ë¡œ ì„ì„ ìˆ˜ ìˆë‹¤.</li>
<li>General domain test setê³¼ Domain specific test set ëª¨ë‘ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ì°¾ëŠ” hyper-parameter ğœ†ë¥¼ ì°¾ì•„ì•¼ í•œë‹¤.</li>
</ul>
</li>
<li>ì˜ˆì œ<ul>
<li>â€œì¤€ë¹„ ëœ ì§„ì •ì œ ë¥¼ íˆ¬ì—¬ í•© ì‹œë‹¤â€œ</li>
<li>General domain<ul>
<li>P(ì§„ì •ì œ | ì¤€ë¹„, ëœ) &#x3D; 0.00001</li>
<li>P(ì‚¬ë‚˜ì´ | ì¤€ë¹„, ëœ) &#x3D; 0.01</li>
</ul>
</li>
<li>Domain Specialized<ul>
<li>P(ì§„ì •ì œ | ì¤€ë¹„, ëœ) &#x3D; 0.09</li>
<li>P(ì•½ | ì¤€ë¹„, ëœ) &#x3D; 0.04</li>
</ul>
</li>
<li>P(ì§„ì •ì œ | ì¤€ë¹„, ëœ) &#x3D; 0.5 * 0.09 + (1 â€“ 0.5) * 0.00001 &#x3D; 0.045005</li>
</ul>
</li>
</ul>
<h3 id="Back-off-tri-gram-bi-gram-uni-gram-ëª¨ë¸ë“¤ì„-ë‹¤-interpolation"><a href="#Back-off-tri-gram-bi-gram-uni-gram-ëª¨ë¸ë“¤ì„-ë‹¤-interpolation" class="headerlink" title="Back-off (tri-gram, bi-gram, uni-gram ëª¨ë¸ë“¤ì„ ë‹¤ interpolation)"></a>Back-off (tri-gram, bi-gram, uni-gram ëª¨ë¸ë“¤ì„ ë‹¤ interpolation)</h3><ul>
<li><p>í¬ì†Œì„±ì— ëŒ€ì²˜í•˜ëŠ” ë°©ë²•</p>
<ul>
<li><p>Markov assumption ì²˜ëŸ¼ nì„ ì ì  ì¤„ì—¬ê°€ë©´?</p>
<ul>
<li>ì¡°ê±´ë¶€ í™•ë¥ ì—ì„œ ì¡°ê±´ë¶€ word sequenceë¥¼ ì¤„ì—¬ê°€ë©´,</li>
<li>Unknown(UNK) wordê°€ ì—†ë‹¤ë©´ ì–¸ì  ê°€ëŠ” í™•ë¥ ì„ êµ¬í•  ìˆ˜ ìˆë‹¤. (uni-gramì—ì„œëŠ” ê±¸ë¦¼!!)</li>
</ul>
</li>
<li><p>$\tilde{P}(w_n | w_{n-k}, \ldots, w_{n-1}) &#x3D; \lambda_1 P_1(w_n | w_{n-k}, \ldots, w_{n-1}) + \lambda_2 P_2(w_n | w_{n-k}, \ldots, w_{n-1}) + \ldots+\lambda_kP_k(w_n)$</p>
<p>$\text {where } \sum_i\lambda_i&#x3D;1$</p>
</li>
</ul>
</li>
<li><p>Example</p>
<ul>
<li>P(ë¶„ì„í–ˆë‹¤ | ë¹„í•µí™”, ì„ ì–¸ê³¼ëŠ”, ê±°ë¦¬ê°€, ë©€ë‹¤ê³ )<ul>
<li>C(ë¹„í•µí™”, ì„ ì–¸ê³¼ëŠ”, ê±°ë¦¬ê°€, ë©€ë‹¤ê³ , ë¶„ì„í–ˆë‹¤) &gt; 0?</li>
</ul>
</li>
<li>P(ë¶„ì„í–ˆë‹¤ | ê±°ë¦¬ê°€, ë©€ë‹¤ê³ )<ul>
<li>C(ê±°ë¦¬ê°€, ë©€ë‹¤ê³ , ë¶„ì„í–ˆë‹¤) &gt; 0?</li>
</ul>
</li>
<li>P(ë¶„ì„í–ˆë‹¤ | ë©€ë‹¤ê³ )</li>
<li>P(ë¶„ì„í–ˆë‹¤) &#x2F;&#x2F; ë‹¨ì–´ê°€ ì—†ì–´ì„œ 0ì´ë©´ uni-gramê¹Œì§€ ë‚´ë ¤ê°</li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½-2"><a href="#ìš”ì•½-2" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li><p>Back-offë¥¼ í†µí•´ í™•ë¥ ê°’ì´ 0ì´ ë˜ëŠ” í˜„ìƒì€ ë°©ì§€í•  ìˆ˜ ìˆìŒ â€“ OOV ì œì™¸</p>
<ul>
<li>í•˜ì§€ë§Œ unseen word sequenceë¥¼ ìœ„í•´ back-offë¥¼ ê±°ì¹˜ëŠ” ìˆœê°„ í™•ë¥ ê°’ì´ ë§¤ìš° ë‚®ì•„ì ¸ ë²„ë¦¼</li>
<li>ì—¬ì „íˆ ìŒì„±ì¸ì‹(ASR) ë“±ì˜ í™œìš©ì—ì„œ ì–´ë ¤ì›€ì´ ë‚¨ìŒ</li>
</ul>
</li>
<li><p>ì „í†µì ì¸ ë°©ì‹ì˜ NLP</p>
<p>ì—ì„œëŠ” </p>
<p>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ë³´ê¸° ë•Œë¬¸ì—</p>
<p> ë¬¸ì œ ë°œìƒ</p>
<ul>
<li><p><strong>Exact matchingì— ëŒ€í•´ì„œë§Œ count</strong>ë¥¼ í•˜ì—¬, í™•ë¥ ê°’ì„ approximation</p>
</li>
<li><p>ë‹¤ì–‘í•œ ë°©ë²•ì„ í†µí•´ ë¬¸ì œë¥¼ ì™„í™”í•˜ë ¤ í•˜ì§€ë§Œ </p>
<p>ê·¼ë³¸ì ì¸ í•´ê²°ì±…ì€ ì•„ë‹˜</p>
<ul>
<li>Markov Assumption</li>
<li>Smoothing and Discounting</li>
<li>Interpolation and Back-off</li>
</ul>
</li>
</ul>
</li>
<li><p>Pros</p>
<ul>
<li>Scalable : ì‰½ê²Œ(large vocabulary ë“±ì˜) ëŒ€í˜• ì‹œìŠ¤í…œì— ì ìš© ê°€ëŠ¥</li>
<li>n-gram í›ˆë ¨ ë° ì¶”ë¡  ë°©ì‹ì´ êµ‰ì¥íˆ <strong>ì‰½ê³  ê°„í¸</strong></li>
</ul>
</li>
<li><p>Cons</p>
<ul>
<li><p>Poor generalization</p>
<p> : ë“±ì¥í•˜ì§€ ì•Šì€ ë‹¨ì–´ ì¡°í•©ì— ëŒ€ì²˜ ë¯¸í¡(Count ê¸°ë°˜ì´ê¸°ì—, exact matching)</p>
<ul>
<li>ë‹¨ì–´ë¥¼ discrete symbolë¡œ ì·¨ê¸‰</li>
<li>ë”°ë¼ì„œ ë¹„ìŠ·í•œ ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥ ì„ ì´ìš©(leverage, exploit)í•˜ì§€ ëª»í•¨</li>
<li>Smoothingê³¼ Back-off ë°©ì‹ì„ í†µí•´ì„œ ë‹¨ì ì„ ë³´ì™„í•˜ë ¤ í–ˆìœ¼ë‚˜, ê·¼ë³¸ì ì¸ í•´ê²°ì±…ì´ ì•„ë‹˜</li>
</ul>
</li>
<li><p>Poor with long dependency : ë©€ë¦¬ìˆëŠ” ë‹¨ì–´ì— ëŒ€í•´ ëŒ€ì²˜ ë¶ˆê°€</p>
</li>
<li><p>nì´ ì»¤ì§ˆìˆ˜ë¡ ìš©ëŸ‰ë„ ì»¤ì§</p>
</li>
</ul>
</li>
<li><p>ì‹¤ì œë¡œ ì–´í”Œë¦¬ì¼€ì´ì…˜ ì ìš©(ASR, SMT ìŒì„±ì¸ì‹&#x2F;í†µê³„ê¸°ë°˜ë²ˆì—­)ì— ìˆì–´ì„œ í° ê³¼ì œ</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-14T14:53:24.000Z" title="8/14/2023, 11:53:24â€¯PM">2023-08-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:38.338Z" title="9/6/2024, 12:05:38â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">6 minutes read (About 881 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/2%EC%9E%A5-Language-Modeling-Introduction-to-LM/">2ì¥. Language Modeling - Introduction to LM</a></h1><div class="content"><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ul>
<li><p>ìš°ë¦¬ì˜ ë¨¸ë¦¿ì†ì—ëŠ” ë‹¨ì–´ì™€ ë‹¨ì–´ ì‚¬ì´ì˜ í™•ë¥ ì´ ìš°ë¦¬ë„ ëª¨ë¥´ê²Œ í•™ìŠµë˜ì–´ ìˆìŒ</p>
<ul>
<li>ëŒ€í™”ë¥¼ í•˜ë‹¤ê°€ ì •í™•í•˜ê²Œ ë“£ì§€ ëª»í•˜ì—¬ë„ ëŒ€í™”ì— ì§€ì¥ì´ ì—†ìŒ</li>
</ul>
</li>
<li><p>ë§ì€ ë¬¸ì¥ë“¤ì„ ìˆ˜ì§‘í•˜ì—¬, ë‹¨ì–´ì™€ ë‹¨ì–´ ì‚¬ì´ì˜ ì¶œí˜„ ë¹ˆë„ë¥¼ ì„¸ì–´ í™•ë¥ ì„ ê³„ì‚°</p>
</li>
<li><p>ê¶ê·¹ì ì¸ ëª©í‘œëŠ” ìš°ë¦¬ê°€ ì¼ìƒ ìƒí™œì—ì„œ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ì˜ ë¬¸ì¥ ë¶„í¬ë¥¼ ì •í™•í•˜ê²Œ ëª¨ë¸ë§ í•˜ëŠ” ê²ƒ(ê·¸ê²ƒì„ í†µí•´ ìš°ë¦¬ì˜ ë¨¸ë¦¿ì†ì— ìˆëŠ” í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ì˜ ê·¼ì‚¬í•´ì•¼ í•¨!)</p>
<ul>
<li>íŠ¹ì • ë¶„ì•¼(domain)ì˜ ë¬¸ì¥ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œ í•´ë‹¹ ë¶„ì•¼ì˜ ë§ë­‰ì¹˜ë¥¼ ìˆ˜ì§‘í•˜ê¸°ë„</li>
</ul>
</li>
<li><p>Again, Korean is Hell</p>
<ul>
<li><strong>ë‹¨ì–´ì™€ ë‹¨ì–´ ì‚¬ì´ì˜ í™•ë¥ ì„ ê³„ì‚°í•˜ëŠ”ë° ë¶ˆë¦¬í•˜ê²Œ ì‘ìš©</strong></li>
<li>ë‹¨ì–´ì˜ ì–´ìˆœì´ ì¤‘ìš”í•˜ì§€ ì•Šê¸° ë•Œë¬¸</li>
<li>ë˜ëŠ” ìƒëµ ê°€ëŠ¥í•˜ê¸° ë•Œë¬¸</li>
</ul>
</li>
<li><p>Example</p>
<ul>
<li>ë‚˜ëŠ” í•™êµì— ê°‘ë‹ˆë‹¤ ë²„ìŠ¤ë¥¼ íƒ€ê³ .</li>
<li>ë‚˜ëŠ” ë²„ìŠ¤ë¥¼ íƒ€ê³  í•™êµì— ê°‘ë‹ˆë‹¤.</li>
<li>ë²„ìŠ¤ë¥¼ íƒ€ê³  ë‚˜ëŠ” í•™êµì— ê°‘ë‹ˆë‹¤.</li>
<li>(ë‚˜ëŠ”) ë²„ìŠ¤ë¥¼ íƒ€ê³  í•™êµì— ê°‘ë‹ˆë‹¤.</li>
</ul>
</li>
<li><p>í™•ë¥ ì´ í¼ì§€ëŠ” í˜„ìƒ</p>
<ul>
<li>â€˜íƒ€ê³ â€™ ë‹¤ìŒì— ë‚˜íƒ€ë‚  ìˆ˜ ìˆëŠ” ë‹¨ì–´ë“¤ì€ â€˜.â€™, â€˜í•™êµì—â€˜ â€˜ë‚˜ëŠ”â€˜ 3ê°œì´ê¸° ë•Œë¬¸</li>
</ul>
</li>
<li><p>ì ‘ì‚¬ë¥¼ ë”°ë¡œ ë¶„ë¦¬í•´ì£¼ì§€ ì•Šìœ¼ë©´ ì–´íœ˜ì˜ ìˆ˜ê°€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ëŠ˜ì–´ë‚˜ í¬ì†Œì„±ì´ ë”ìš± ë†’ì•„ì§</p>
</li>
<li><p>Applicartions</p>
<ul>
<li><p>Natural Language Generation</p>
<table>
<thead>
<tr>
<th>Task</th>
<th>Description</th>
</tr>
</thead>
<tbody><tr>
<td>Speech Recognition</td>
<td>Acoustic Modelê³¼ ê²°í•©í•˜ì—¬, ì¸ì‹ëœ phone(ìŒì†Œ)ì˜ sequenceì— ëŒ€í•´ì„œ ì¢€ ë” ë†’ì€ í™•ë¥ ì„ ê°–ëŠ” sequenceë¡œ ë³´ì™„</td>
</tr>
<tr>
<td>Machine Translation</td>
<td>ë²ˆì—­ ëª¨ë¸ê³¼ ê²°í•©í•˜ì—¬, ë²ˆì—­ëœ ê²°ê³¼ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¬</td>
</tr>
<tr>
<td>Optical Character Recognition</td>
<td>ì¸ì‹ëœ character candidate sequenceì— ëŒ€í•´ì„œ ì¢€ ë” ë†’ì€ í™•ë¥ ì„ ê°–ëŠ” sequenceë¥¼ ì„ íƒí•˜ë„ë¡ ë„ì›€</td>
</tr>
<tr>
<td>Other NLG Tasks</td>
<td>ë‰´ìŠ¤ ê¸°ì‚¬ ìƒì„±, chat-bot ë“±</td>
</tr>
<tr>
<td>Others</td>
<td>ê²€ìƒ‰ì–´ ìë™ ì™„ì„± ë“±</td>
</tr>
</tbody></table>
</li>
</ul>
</li>
</ul>
<h3 id="Chain-Rule"><a href="#Chain-Rule" class="headerlink" title="Chain Rule"></a>Chain Rule</h3><ul>
<li><p>We can convert joint probability yo conditional probability</p>
<ul>
<li><p>$P(A,B,C,D)&#x3D;P(D|A,B,C)P(A,B,C)<br>&#x3D;P(D|A,B,C)P(C|A,B)<br>&#x3D;P(D|A,B,C)P(C|A,B)P(B|A)P(A)$</p>
</li>
<li><p>P(<BOS>,I, Love, to, play, <EOS>)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(<BOS>,I, Love, to, play)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(<BOS>,I, Love, to) &#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(<BOS>,I, Love)</p>
<p>&#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(Love|<BOS>,I)P(<BOS>,I) &#x3D; P(<EOS>|<BOS>,I, Love, to, play) P(play|<BOS>,I, Love, to) P(to|<BOS>,I, Love)P(Love|<BOS>,I)P(I|<BOS>)P(<BOS>)</p>
</li>
</ul>
</li>
<li><p>By Chain Rule,</p>
<ul>
<li>$P(x_{1:n}) &#x3D; P(x_1, \ldots, x_n)<br>&#x3D; P(x_n | x_{1}, \ldots, x_{n-1}) \ldots P(x_2| x_1)P(x_1)<br>&#x3D; \prod_{i&#x3D;1}^n P(x_i | x_{&lt;i})$        &#x2F;&#x2F; $x_i$ ì´ì „ê¹Œì§€ì˜ ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, iì˜ í™•ë¥ ê°’ì˜ ê³± <ul>
<li>$\log P(x_{1:n}) &#x3D; \sum_{i&#x3D;1}^N \log P(x_i | x_{&lt;i})$</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="ì–¸ì–´ëª¨ë¸-Language-Model"><a href="#ì–¸ì–´ëª¨ë¸-Language-Model" class="headerlink" title="ì–¸ì–´ëª¨ë¸(Language Model)"></a>ì–¸ì–´ëª¨ë¸(Language Model)</h3><ul>
<li><p>language modelingì€ ë¬¸ì¥ì˜ ì¶œí˜„ í™•ë¥ ì„ ëª¨ë¸ë§ì„ í•˜ëŠ” ë™ì‹œì— ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì˜ ì¶œí˜„ í™•ë¥ ì„ ëª¨ë¸ë§í•˜ëŠ” ê²ƒ</p>
</li>
<li><p>Chain Ruleì„ í†µí•´ ë¬¸ì¥ì˜ í™•ë¥ ì„ ëª¨ë¸ë§ì„ í•˜ê²Œ ë˜ë©´, ë¬¸ì¥ ë‚´ ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥ ì„ ì•Œ ìˆ˜ ìˆê²Œë¨</p>
</li>
<li><p>ì–¸ì–´ ëª¨ë¸ ìˆ˜ì‹</p>
<ul>
<li><p>$D&#x3D;{x^i }_{i&#x3D;1}^N$ .         &#x2F;&#x2F; $x \sim P(x)$, $x^i$ ëŠ” ë¬¸ì¥, ì¦‰ ëŒ€ë¬¸ì Nê°œì˜ ë¬¸ì¥</p>
<p>$\hat{\theta} &#x3D; \text{argmax}<em>{\theta \in \Theta} \sum</em>{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$ &#x2F;&#x2F; log-likelihood ê°’ì„ ë‹¤ ë”í•´ì„œ ìµœëŒ€ë¡œ í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ êµ¬í•˜ì</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$= \\text&#123;argmax&#125;_&#123;\\theta \\in \\Theta&#125; \\sum_&#123;i=1&#125;^&#123;N&#125;\\sum_&#123;j=1&#125;^&#123;n&#125; \\log P(x_&#123;j&#125;^&#123;i&#125;|x_&#123;&lt;j&#125;^i; \\theta)$</span><br></pre></td></tr></table></figure>

<p>&#x2F;&#x2F; chain ruleì— ì˜í•´ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•  ìˆ˜ ìˆìŒ</p>
<p>$\text{where } x_{1:n} &#x3D; {x_1, â€¦, x_n}$ &#x2F;&#x2F; ë¬¸ì¥ì€  nê°œì˜ ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§</p>
<p>$L(\theta) &#x3D; -\sum_{i&#x3D;1}^{N} \log P(x_{1:n}^{i}; \theta)$</p>
<p>$\theta \leftarrow \theta - \eta\nabla_\theta L(\theta)$</p>
</li>
</ul>
</li>
<li><p>ë” ì¢‹ì€ ë¬¸ì¥ì´ ë¬´ì—‡ì¸ì§€ ì„ íƒí•  ìˆ˜ ìˆìŒ(Pick better&#x2F;fluent sentece)</p>
<ul>
<li>$x^1, x^2$ (ë¬¸ì¥1ê³¼ ë¬¸ì¥2) ê°€ ìˆì„ ë•Œ ë” ë†’ì€ í™•ë¥ ê°’ì„ ê³ ë¥´ë©´ ëœë‹¤. $P_Î¸(x^1) &gt; P_Î¸(x^2)$</li>
</ul>
</li>
<li><p>ì´ì „ ë‹¨ì–´ë“¤ì„ í†µí•´ ë‹¤ìŒ ë‹¨ì–´ë“¤ì„ ì˜ˆì¸¡ í•  ìˆ˜ ìˆìŒ(Predict next word given previous words)</p>
<ul>
<li>$\hat{x_t}&#x3D; \text{argmax}<em>{x_t \in \Chi}  \log P(x</em>{t}|x_{&lt;t}; \theta)$</li>
</ul>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>ì–¸ì–´ëª¨ë¸ì€ ì£¼ì–´ì§„ ì½”í¼ìŠ¤ ë¬¸ì¥ë“¤ì˜ likelihoodë¥¼ ìµœëŒ€í™” í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ì•„ë‚´, ì£¼ì–´ì§„ ì½”í¼ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¸ì–´ì˜ ë¶„í¬ë¥¼ í•™ìŠµí•œë‹¤.<ul>
<li>ì¦‰, ì½”í¼ìŠ¤ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ë“¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ê·¼ì‚¬(approximate)í•œë‹¤.</li>
</ul>
</li>
<li>ë¬¸ì¥ì˜ í™•ë¥ ì€ ë‹¨ì–´ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” í™•ë¥ ì„ ì°¨ë¡€ëŒ€ë¡œ ê³±í•œ ê²ƒê³¼ ê°™ìŒ</li>
<li>ë”°ë¼ì„œ ì–¸ì–´ëª¨ë¸ë§ì€ ì£¼ì–´ì§„ ë‹¨ì–´ê°€ ìˆì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì˜ likelihoodë¥¼ ìµœëŒ€í™”í•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì°¾ëŠ” ê³¼ì •ì´ë¼ ë³¼ ìˆ˜ ìˆë‹¤.<ul>
<li>ì£¼ì–´ì§„ ë‹¨ì–´ë“¤ì´ ìˆì„ ë•Œ, ë‹¤ìŒ ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ê·¼ì‚¬í•˜ëŠ” ê³¼ì •</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-13T13:12:18.000Z" title="8/13/2023, 10:12:18â€¯PM">2023-08-13</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:10.841Z" title="9/6/2024, 12:05:10â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">3 minutes read (About 471 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/1%EC%9E%A5-Orientation-Introduction-to-NLG/">1ì¥ Orientation - Introduction to NLG</a></h1><div class="content"><ul>
<li><p>Our Objective</p>
<ul>
<li>ì»´í“¨í„°ê°€ ì¸ê°„ì´ ë§Œë“¤ì–´ë†“ì€ ëŒ€ëŸ‰ì˜ ë¬¸ì„œë¥¼ í†µí•´ ì •ë³´ë¥¼ ì–»ê³ (NLU)</li>
<li>ì–»ì–´ë‚¸ ì •ë³´ë¥¼ ì‚¬ëŒì´ ì´í•´í•  ìˆ˜ ìˆê²Œ ì‚¬ëŒì˜ ì–¸ì–´ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒ(NLG)</li>
</ul>
</li>
<li><p>Before Sequence-to-Sequence</p>
<ul>
<li>ë‹¨ì§€ ë‹¨ì–´&#x2F;ë¬¸ì¥(text)ì„ ë²¡í„°ë¡œ(numeric)ìœ¼ë¡œ ë°”ê¿€ ë¿ì´ì—ˆìŒ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/1a5a7037-4ff7-4fa4-8810-70322e084559" alt="BeforeSeq2Seq"></p>
</li>
<li><p>After Sequence-to-Sequence With Attention</p>
<ul>
<li><p>Beyond â€œnumeric to textâ€</p>
<ul>
<li>ì´ì œëŠ” ìˆ«ìë¥¼ ë„˜ì–´ textë¡œ í‘œí˜„ì´ ê°€ëŠ¥í•´ì§, ê¸€ì„ ë„£ìœ¼ë©´ ìˆ«ìë¡œ ë°”ë€Œì—ˆë˜ ê²ƒì´ ìˆ«ìë¥¼ ë„£ìœ¼ë©´ ê¸€ë¡œ ë°”ë€œ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/7d5cd395-a01f-46cd-87ee-495643ebae48" alt="AfterSeq2Seq"></p>
</li>
</ul>
</li>
<li><p>Era of Attention</p>
<ul>
<li><p>Transformerì˜ ë“±ì¥ìœ¼ë¡œ ì¸í•´ ì—°êµ¬ëŠ” ë”ë”ìš± ê°€ì†ë¨</p>
<ul>
<li>PLMì˜ ìœ í–‰ìœ¼ë¡œ ì¸í•´ NLG ë¿ë§Œ ì•„ë‹ˆë¼ NLPì˜ ë‹¤ë¥¸ ì˜ì—­ì—ë„ í° ì˜í–¥</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/9442a465-0565-4682-809b-25bc184701aa" alt="Transformer"></p>
</li>
<li><p>ê±°ìŠ¤ë¥¼ ìˆ˜ ì—†ëŠ” ëŒ€ì„¸, PLM</p>
<ul>
<li>ì´ ìˆ˜ì—…ì€ PLMì„ ì œëŒ€ë¡œ ì´ë£¨ê¸° ìœ„í•œ Step-stone</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/1e9d6e9c-b161-4042-a138-e9e450ebc218" alt="StepStone"></p>
</li>
</ul>
</li>
<li><p>In this class,</p>
<ul>
<li>NMT(í•œë•Œ ìì—°ì–´ ì²˜ë¦¬ì˜ ê½ƒì´ì—ˆë˜)ë¥¼ í†µí•´ ìì—°ì–´ ìƒì„±ì˜ ê·¼ë³¸ë¶€í„° ë‹¤ì§ˆ ìˆ˜ ìˆë„ë¡ êµ¬ì„±<ul>
<li>ë°˜ë³µëœ í•™ìŠµì„ í†µí•´ Auto-regressive íŠ¹ì„±ì„ ëª¸ìœ¼ë¡œ ìµíˆê³ ,</li>
<li>ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì—¬ëŸ¬ê°€ì§€(Empirical + Mathematica, ê²½í—˜&#x2F;ìˆ˜í•™ì ) ë°©ë²•ë“¤ì„ ë‹¤ë£¸</li>
</ul>
</li>
<li>Sequence-to-Sequence w&#x2F; Attentionë¿ë§Œ ì•„ë‹ˆë¼, Transformerë„ nano ë‹¨ìœ„ë¡œ detailí•˜ê²Œ ë¶„í•´í•˜ì—¬ ì´í•´&#x2F; êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±<ul>
<li>ì§§ì€ ì‹¤ìŠµì„ í†µí•´ ë‹¨ìˆœíˆ êµ¬í˜„í•˜ëŠ” ê²ƒì— ê·¸ì¹˜ëŠ” ê²ƒì´ ì•„ë‹Œ,</li>
<li>ì‹¤ì œ ì—…ë¬´&#x2F;ì—°êµ¬ì™€ ê°™ì´ í”„ë¡œì íŠ¸ ì„¤ê³„ë¶€í„° ê°ê´€ì ì¸ í‰ê°€ë°©ë²•ê¹Œì§€ A to Zë¥¼ ê²½í—˜í•˜ë„ë¡ êµ¬ì„±</li>
</ul>
</li>
<li>ì´ë¥¼ í†µí•´ ì¶”í›„ PLMì„ í™œìš©í•œ NLP ì‹¬í™” ê³¼ì •ì„ ì–´ë ¤ì›€ ì—†ì´ ë°›ì•„ë“¤ì´ë„ë¡ êµ¬ì„±</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-12T14:55:02.000Z" title="8/12/2023, 11:55:02â€¯PM">2023-08-12</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:05:15.612Z" title="9/6/2024, 12:05:15â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</a></span><span class="level-item">6 minutes read (About 942 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%E1%84%8B%E1%85%B3%E1%86%AF%20%E1%84%92%E1%85%AA%E1%86%AF%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%86%AB%20%E1%84%8C%E1%85%A1%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%8B%E1%85%A5%20%E1%84%8E%E1%85%A5%E1%84%85%E1%85%B5%20(NLP)%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%9E%90%EC%97%B0%EC%96%B4%EC%83%9D%EC%84%B1%20%EA%B0%9C%EB%85%90/1%EC%9E%A5-Orientation-Review-NLP-Introduction-Class/">1ì¥. Orientation - Review NLP Introduction Class</a></h1><div class="content"><h2 id="Review-Statistical-amp-Geometric-Perspective-for-Deep-Learning"><a href="#Review-Statistical-amp-Geometric-Perspective-for-Deep-Learning" class="headerlink" title="Review Statistical &amp; Geometric Perspective for Deep Learning"></a><strong>Review Statistical &amp; Geometric Perspective for Deep Learning</strong></h2><h3 id="Before-this-class"><a href="#Before-this-class" class="headerlink" title="Before this class"></a>Before this class</h3><ul>
<li>Our Objective is<ul>
<li>ì„¸ìƒì— ì¡´ì¬í•˜ëŠ” ì–´ë–¤ ë¯¸ì§€ì˜ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬í•˜ì</li>
</ul>
</li>
<li>ì£¼ì–´ì§„ ì…ë ¥(ğ’™)ì— ëŒ€í•´ì„œ ì›í•˜ëŠ” ì¶œë ¥(ğ’š)ì„ ë°˜í™˜í•˜ë„ë¡, ì†ì‹¤í•¨ìˆ˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” íŒŒë¼ë¯¸í„°(ğœ½)ë¥¼ ì°¾ì.</li>
<li>Gradient Descentë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ back-propagationì„ ìˆ˜í–‰í•˜ì</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/2fa0ded5-cfea-441c-a838-3c6ef923b038" alt="UMM"></p>
<h3 id="After-this-class"><a href="#After-this-class" class="headerlink" title="After this class"></a>After this class</h3><ul>
<li>Our Ojbective becomes<ul>
<li>ì„¸ìƒì— ì¡´ì¬í•˜ëŠ” ì–´ë–¤ ë¯¸ì§€ì˜ í™•ë¥  ë¶„í¬ í•¨ìˆ˜ë¥¼ ëª¨ì‚¬(approximate)í•˜ì</li>
</ul>
</li>
<li><ul>
<li>Probablistice Perspective<ul>
<li>í™•ë¥  ë¶„í¬ ğ‘ƒ(ğ‘¥) ì™€ ğ‘ƒ(ğ‘¦|ğ‘¥)ë¡œë¶€í„° ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬</li>
<li>í•´ë‹¹ ë°ì´í„°ë¥¼ ê°€ì¥ ì˜ ì„¤ëª…í•˜ëŠ” í™•ë¥  ë¶„í¬ í•¨ìˆ˜ì˜ íŒŒë¼ë¯¸í„°(ğœƒ)ë¥¼ ì°¾ì: ğ‘™ğ‘œğ‘”ğ‘ƒ(ğ‘¦â”‚ğ‘¥;ğœƒ)<ul>
<li>Maximum Likelihood Estimation (í•´ë‹¹ ë°ì´í„°ë¥¼ ì˜ ì„¤ëª…í•˜ëŠ” score!, í™•ë¥  ë¶„í¬í•¨ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ê³  ì‹¶ìŒ)</li>
<li>Gradient Descent using Back-propagation (Likelihoodë¥¼ maximizeí•˜ê¸° ìœ„í•¨)</li>
</ul>
</li>
<li>ë˜ëŠ” ë‘ í™•ë¥  ë¶„í¬ë¥¼ ë¹„ìŠ·í•˜ê²Œ ë§Œë“¤ì<ul>
<li>Minimize Cross Entropy (or KL-Divergence) # $P(y|x) \approx P_\theta (y|x)$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>Geometric Perspective<ul>
<li>ë°ì´í„°ë€ ì €ì°¨ì›ì˜ manifoldì— ë¶„í¬ë˜ì–´ ìˆìœ¼ë©°, ì—¬ê¸°ì— ì•½ê°„ì˜ ë…¸ì´ì¦ˆê°€ ì¶”ê°€ë˜ì–´ ìˆëŠ” ê²ƒ<ul>
<li>ë…¸ì´ì¦ˆë€ task(x -&gt; y)ì— ë”°ë¼ì„œ ë‹¤ì–‘í•˜ê²Œ í•´ì„ ê°€ëŠ¥í•  ê²ƒ</li>
</ul>
</li>
<li>ë”°ë¼ì„œ í•´ë‹¹ manifoldë¥¼ ë°°ìš¸ìˆ˜ ìˆë‹¤ë©´, ë” ë‚®ì€ ì°¨ì›ìœ¼ë¡œ íš¨ìœ¨ì ì¸ ë§µí•‘(or project)ì´ ê°€ëŠ¥</li>
<li>Non-Linear dimension reduction (AutoEncoder ë“±)</li>
</ul>
</li>
</ul>
</li>
<li><ul>
<li>Representation Learning<ul>
<li>ë‚®ì€ ì°¨ì›ìœ¼ë¡œì˜ í‘œí˜„ì„ í†µí•´, ì°¨ì›ì˜ ì €ì£¼(curse of dimensionality)ë¥¼ ë²—ì–´ë‚˜ íš¨ê³¼ì ì¸ í•™ìŠµì´ ê°€ëŠ¥</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/c9947ab8-dc59-46d9-a04e-6f93ed2f5286" alt="COOOOOL"></p>
<h3 id="ê²°ë¡ "><a href="#ê²°ë¡ " class="headerlink" title="ê²°ë¡ "></a>ê²°ë¡ </h3><ul>
<li><strong>ë”¥ëŸ¬ë‹ì´ë€ í™•ë¥  ë¶„í¬ í•¨ìˆ˜ì¸ ë™ì‹œì— ë¹„ì„ í˜•ì˜ ë‚®ì€ ì°¨ì›ìœ¼ë¡œ ì°¨ì›ì„ ì¶•ì†Œ(Gemetric ê´€ì  + ì •ë³´ì´ë¡ )í•˜ëŠ” ê²ƒ</strong></li>
<li>DNNì€ êµ‰ì¥íˆ ìœ ì—°í•œ(flexible)í•œ í•¨ìˆ˜ì´ê¸° ë•Œë¬¸ì— ë‹¤ì–‘í•œ ê´€ì ì—ì„œ í•´ì„ì´ ê°€ëŠ¥</li>
<li>ë”°ë¼ì„œ ëŒ€ë¶€ë¶„ì˜ ìƒˆë¡­ê²Œ ì œì‹œë˜ëŠ” ë°©ë²•ë“¤ì€ ìœ„ì˜ ê´€ì ì—ì„œ ì„¤ê³„ë˜ê³  ì œì•ˆëœ ê²ƒ</li>
<li>ìœ„ì˜ ê´€ì ì—ì„œ ë”¥ëŸ¬ë‹ì„ ë°”ë¼ë³¸ë‹¤ë©´, í›¨ì”¬ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆìŒ</li>
</ul>
<h2 id="Review-NLP-Introduction-Class"><a href="#Review-NLP-Introduction-Class" class="headerlink" title="Review NLP Introduction Class"></a>Review NLP Introduction Class</h2><h3 id="Review-AutoEncoder"><a href="#Review-AutoEncoder" class="headerlink" title="Review : AutoEncoder"></a>Review : AutoEncoder</h3><ul>
<li>ì¸ì½”ë”(encoder)ì™€ ë””ì½”ë”(decoder)ë¥¼ í†µí•´ ì••ì¶•ê³¼ í•´ì œë¥¼ ì‹¤í–‰<ul>
<li>ì¸ì½”ë”ëŠ” ì…ë ¥(x)ì˜ ì •ë³´ë¥¼ ìµœëŒ€í•œ ë³´ì¡´í•˜ë„ë¡ ì†ì‹¤ ì••ì¶•ì„ ìˆ˜í–‰</li>
<li>ë””ì½”ë”ëŠ” ì¤‘ê°„ ê²°ê³¼ë¬¼(z)ì˜ ì •ë³´ë¥¼ ì…ë ¥(x)ê³¼ ê°™ì•„ì§€ë„ë¡ ì••ì¶• í•´ì œ(ë³µì›)ë¥¼ ìˆ˜í–‰</li>
</ul>
</li>
<li>ë³µì›ì„ ì„±ê³µì ìœ¼ë¡œ í•˜ê¸° ìœ„í•´, autoencoderëŠ” íŠ¹ì§•(feature)ì„ ì¶”ì¶œí•˜ëŠ” ë°©ë²•ì„ ìë™ìœ¼ë¡œ í•™ìŠµ</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/b7ef85e3-c8ea-4e93-9014-3afeb89d26b1" alt="AutoEncoder"></p>
<h3 id="In-Word2Vec"><a href="#In-Word2Vec" class="headerlink" title="In Word2Vec"></a>I<strong>n Word2Vec</strong></h3><ul>
<li>objective : ì£¼ì–´ì§„ ë‹¨ì–´ë¡œ ì£¼ë³€ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ì</li>
<li>yë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì •ë³´ zê°€ ìˆì–´ì•¼ í•œë‹¤.<ul>
<li>ì£¼ë³€ ë‹¨ì–´ë¥¼ ì˜ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ xë¥¼ ì˜ ì••ì¶•í•˜ì.</li>
</ul>
</li>
<li>ì˜ˆì œ<ul>
<li>|V| &#x3D; 30000 ì„ 256ì°¨ì›ìœ¼ë¡œ ì••ì¶•</li>
</ul>
</li>
</ul>
<h3 id="In-Text-Classification"><a href="#In-Text-Classification" class="headerlink" title="In Text Classification"></a>In Text Classification</h3><ul>
<li><p>Using RNN &amp; CNN</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/e31f8e02-55a6-476a-9b58-5fe59d735e60" alt="ReviewTextClassifcation"></p>
</li>
</ul>
<h3 id="ìš”ì•½"><a href="#ìš”ì•½" class="headerlink" title="ìš”ì•½"></a>ìš”ì•½</h3><ul>
<li>ì‹ ê²½ë§ì€ $x$ì™€ $y$ ì‚¬ì´ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œ featureë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•™ìŠµ<ul>
<li>íŠ¹íˆ ì €ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ(ì••ì¶•)ë˜ëŠ” ê³¼ì •ì—ì„œ ì •ë³´ì˜ ì·¨ì‚¬&#x2F;ì„ íƒì´ ì´ë£¨ì–´ì§<ul>
<li>ê°ì„±ë¶„ì„ì—ì„œ ì‚¬ìš©í•˜ëŠ” featureì™€ ê¸°ê³„ë²ˆì—­&#x2F;ìš”ì•½ì—ì„œ ì‚¬ìš©í•˜ëŠ” featureëŠ” ì„œë¡œ ë‹¤ë¦„</li>
</ul>
</li>
</ul>
</li>
<li>Word Embedding(Skip-gram)<ul>
<li>ì£¼ë³€ ë‹¨ì–´(y)ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì •ë³´ë¥¼ í˜„ì¬ ë‹¨ì–´($x$)ì—ì„œ ì¶”ì¶œí•˜ì—¬ ì••ì¶•</li>
</ul>
</li>
<li>Sentence Embedding(Text Classification)<ul>
<li>Label($y$ )ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì •ë³´ë¥¼ ë‹¨ì–´ë“¤ì˜ ì‹œí€€ìŠ¤($x$)ë¡œë¶€í„° ì¶”ì¶œí•˜ì—¬ ì••ì¶•</li>
</ul>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2023-08-08T15:00:31.000Z" title="8/9/2023, 12:00:31â€¯AM">2023-08-09</time></span><span class="level-item">Updated&nbsp;<time dateTime="2024-09-05T15:04:52.788Z" title="9/6/2024, 12:04:52â€¯AM">2024-09-06</time></span><span class="level-item"><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/">ë”¥ëŸ¬ë‹</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê°œë…</a><span>Â /Â </span><a class="link-muted" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</a></span><span class="level-item">4 minutes read (About 637 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/new/%EB%94%A5%EB%9F%AC%EB%8B%9D/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%E1%84%83%E1%85%B5%E1%86%B8%E1%84%85%E1%85%A5%E1%84%82%E1%85%B5%E1%86%BC%20%E1%84%80%E1%85%B5%E1%84%8E%E1%85%A9%20%E1%84%80%E1%85%A2%E1%84%82%E1%85%A7%E1%86%B7/%EC%A4%91%EA%B8%89%20%EA%B0%9C%EB%85%90/3%EC%9E%A5-Geometric-Perspective-Manifold-Hypothesis/">3ì¥. Geometric Perspective - Manifold Hypothesis</a></h1><div class="content"><h2 id="Manifold-ê°€ì„¤"><a href="#Manifold-ê°€ì„¤" class="headerlink" title="Manifold ê°€ì„¤"></a>Manifold ê°€ì„¤</h2><h3 id="ë°ì´í„°ì˜-ë¶„í¬"><a href="#ë°ì´í„°ì˜-ë¶„í¬" class="headerlink" title="ë°ì´í„°ì˜ ë¶„í¬"></a>ë°ì´í„°ì˜ ë¶„í¬</h3><ul>
<li>MNISTëŠ” 784(28x28) ì°¨ì›ì˜ ë²¡í„°ë¡œ ë‚˜íƒ€ë‚´ì–´ ì§„ë‹¤.<ul>
<li>784 ì°¨ì›ì˜ ê³µê°„ì— ì¡´ì¬í•˜ëŠ” ë°ì´í„°</li>
</ul>
</li>
<li>ìƒ˜í”Œë“¤ì´ uniform í•˜ê²Œ ë¶„í¬ë˜ì–´ ìˆì„ê¹Œ?<ul>
<li>Not uniform, í•œ êµ°ë°ì— ëª°ë ¤ìˆì„ í™•ë¥ ì´ ë†’ìŒ</li>
</ul>
</li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/102a2208-d355-484d-99f5-7a63e518147d" alt="Manifold00"></p>
<h3 id="Manifold-Hypothesis-ì•„ì§-ì¦ëª…ë˜ì§€-ì•ŠìŒ"><a href="#Manifold-Hypothesis-ì•„ì§-ì¦ëª…ë˜ì§€-ì•ŠìŒ" class="headerlink" title="Manifold Hypothesis (ì•„ì§ ì¦ëª…ë˜ì§€ ì•ŠìŒ)"></a>Manifold Hypothesis (ì•„ì§ ì¦ëª…ë˜ì§€ ì•ŠìŒ)</h3><ul>
<li><p>ì‹¤ìƒí™œì—ì„œì˜ Manifold</p>
<ul>
<li>ìš°ë¦¬ëŠ” 3ì°¨ì›ì˜ ì¢Œí‘œê³„ì— ì‚´ì§€ë§Œ, 2ì°¨ì› ì¢Œí‘œê³„ë¡œ ì„¸ìƒì„ ì¸ì‹ (Mapping to Lower Dimensional Space) <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/aa171e80-a180-4b62-b3b9-d45ac513b1e6" alt="manifold02"></li>
</ul>
</li>
<li><p>ê³ ì°¨ì› ê³µê°„ì˜ ìƒ˜í”Œë“¤ì´ ë‹¤ì–‘ì²´(manifold)ì˜ í˜•íƒœë¡œ ë¶„í¬í•´ ìˆë‹¤ëŠ” ê°€ì •</p>
<ul>
<li><p>ë”°ë¼ì„œ ë‹¤ì–‘ì²´ë¥¼ í•´ë‹¹ ì°¨ì›ì˜ ê³µê°„ì— mapping í•  ìˆ˜ ìˆìŒ</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/49cf6d71-984a-4116-a5c7-8ed0771f0e51" alt="manifold01"></p>
</li>
<li><p>ê³ ì°¨ì› ê³µê°„ì—ì„œì˜ ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ëŠ” ì €ì°¨ì› ê³µê°„ìœ¼ë¡œì˜ ë§µí•‘ í›„ ê±°ë¦¬ì™€ ë‹¤ë¦„ <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/86b931b9-afe3-48cf-b1b9-d5b2de0a8d95" alt="manifold03"></p>
</li>
</ul>
</li>
<li><p>MNIST ì˜ˆì œ</p>
<ul>
<li>796 ì°¨ì›ì˜ ìƒ˜í”Œë“¤ì´ 2D ê³µê°„ ì•ˆì— ë§µí•‘ì´ ë¨ <img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/8d1299c6-d941-4299-9d02-1894a5fdbcd3" alt="manifold-MNIST01"></li>
</ul>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/664b794d-0ac1-4c79-98f4-956eafe65160" alt="manifold-MNIST02"></p>
<ul>
<li><p>Non-linear Dimension Reduction ì˜ˆì œ(Binary Classification ind 2-D)</p>
<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/f425bf37-0252-4beb-97bd-bd6eda06852c" alt="Manifold-NonLinear">]</p>
</li>
</ul>
</li>
<li><p>ì½”ë“œë¡œ í™•ì¸í•´ë³´ê¸°</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> load_mnist</span><br><span class="line"><span class="keyword">from</span> trainer <span class="keyword">import</span> Trainer</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_image</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">if</span> x.dim() == <span class="number">1</span>:</span><br><span class="line">        x = x.view(<span class="built_in">int</span>(x.size(<span class="number">0</span>) ** <span class="number">.5</span>), -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    plt.imshow(x, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> argparse <span class="keyword">import</span> Namespace</span><br><span class="line"></span><br><span class="line">config = &#123;</span><br><span class="line">    <span class="string">&#x27;train_ratio&#x27;</span>: <span class="number">.8</span>,</span><br><span class="line">    <span class="string">&#x27;batch_size&#x27;</span>: <span class="number">256</span>,</span><br><span class="line">    <span class="string">&#x27;n_epochs&#x27;</span>: <span class="number">50</span>,</span><br><span class="line">    <span class="string">&#x27;verbose&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">    <span class="string">&#x27;btl_size&#x27;</span>: <span class="number">2</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">config = Namespace(**config)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(config)</span><br><span class="line"></span><br><span class="line">train_x, train_y = load_mnist(flatten=<span class="literal">True</span>)</span><br><span class="line">test_x, test_y = load_mnist(is_train=<span class="literal">False</span>, flatten=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">train_cnt = <span class="built_in">int</span>(train_x.size(<span class="number">0</span>) * config.train_ratio)</span><br><span class="line">valid_cnt = train_x.size(<span class="number">0</span>) - train_cnt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Shuffle dataset to split into train/valid set.</span></span><br><span class="line">indices = torch.randperm(train_x.size(<span class="number">0</span>))</span><br><span class="line">train_x, valid_x = torch.index_select(</span><br><span class="line">    train_x,</span><br><span class="line">    dim=<span class="number">0</span>,</span><br><span class="line">    index=indices</span><br><span class="line">).split([train_cnt, valid_cnt], dim=<span class="number">0</span>)</span><br><span class="line">train_y, valid_y = torch.index_select(</span><br><span class="line">    train_y,</span><br><span class="line">    dim=<span class="number">0</span>,</span><br><span class="line">    index=indices</span><br><span class="line">).split([train_cnt, valid_cnt], dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train:&quot;</span>, train_x.shape, train_y.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Valid:&quot;</span>, valid_x.shape, valid_y.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test:&quot;</span>, test_x.shape, test_y.shape)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model <span class="keyword">import</span> Autoencoder</span><br><span class="line">model = Autoencoder(btl_size=config.btl_size)</span><br><span class="line">optimizer = optim.Adam(model.parameters())</span><br><span class="line">crit = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">trainer = Trainer(model, optimizer, crit)</span><br><span class="line">trainer.train((train_x, train_x), (valid_x, valid_x), config)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">    index1 = <span class="built_in">int</span>(random.random() * test_x.size(<span class="number">0</span>))</span><br><span class="line">    index2 = <span class="built_in">int</span>(random.random() * test_x.size(<span class="number">0</span>))</span><br><span class="line">    </span><br><span class="line">    z1 = model.encoder(test_x[index1].view(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line">    z2 = model.encoder(test_x[index2].view(<span class="number">1</span>, -<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    recon = model.decoder((z1 + z2) / <span class="number">2</span>).squeeze()</span><br><span class="line"></span><br><span class="line">    show_image(test_x[index1])</span><br><span class="line">    show_image(test_x[index2])</span><br><span class="line">    show_image((test_x[index1] + test_x[index2]) / <span class="number">2</span>)</span><br><span class="line">    show_image(recon)</span><br></pre></td></tr></table></figure>

<p><img src="https://github.com/shchoice/shchoice.github.io/assets/100276387/194b7f53-93df-4458-9054-97554886bed1" alt="manifold-MNIST03"></p>
</li>
</ul>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/4/">Previous</a></div><div class="pagination-next"><a href="/page/6/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/4/">4</a></li><li><a class="pagination-link is-current" href="/page/5/">5</a></li><li><a class="pagination-link" href="/page/6/">6</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/13/">13</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/matterhorn.jpg" alt="Shawn Choi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Shawn Choi</p><p class="is-size-6 is-block">ë…¸ë ¥ ë°±ì¤Œ ì—´ì • ì²œì¤Œì˜ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œì</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Seoul, Republic of Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">129</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">69</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">93</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/shchoice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/shchoice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/"><span class="level-start"><span class="level-item">Transformers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Deep-Learning/Transformers/TainingArugments/"><span class="level-start"><span class="level-item">TainingArugments</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/DevOps/"><span class="level-start"><span class="level-item">DevOps</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/CI-CD-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8/"><span class="level-start"><span class="level-item">CI/CD íŒŒì´í”„ë¼ì¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/"><span class="level-start"><span class="level-item">ë²„ì „ ê´€ë¦¬</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/DevOps/%EB%B2%84%EC%A0%84-%EA%B4%80%EB%A6%AC/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul><li><a class="level is-mobile" href="/categories/Java/Java8/"><span class="level-start"><span class="level-item">Java8</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/categories/Java/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/MLOps/"><span class="level-start"><span class="level-item">MLOps</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/MLOps/MLflow/"><span class="level-start"><span class="level-item">MLflow</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/OPS/"><span class="level-start"><span class="level-item">OPS</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Ops/Windows-CMD/"><span class="level-start"><span class="level-item">Windows CMD</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/Ops/%EC%84%A4%EC%B9%98/"><span class="level-start"><span class="level-item">ì„¤ì¹˜</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/"><span class="level-start"><span class="level-item">Programming</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/"><span class="level-start"><span class="level-item">Agile</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Programming/Agile/%ED%95%A8%EA%BB%98%EC%9E%90%EB%A6%AC%EA%B8%B0/"><span class="level-start"><span class="level-item">í•¨ê»˜ìë¦¬ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Programming/%EB%82%B4-%EC%BD%94%EB%93%9C%EA%B0%80-%EA%B7%B8%EB%A0%87%EA%B2%8C-%EC%9D%B4%EC%83%81%ED%95%9C%EA%B0%80%EC%9A%94/"><span class="level-start"><span class="level-item">ë‚´ ì½”ë“œê°€ ê·¸ë ‡ê²Œ ì´ìƒí•œê°€ìš”</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">10</span></span></a><ul><li><a class="level is-mobile" href="/categories/Python/Advanced-Concept/"><span class="level-start"><span class="level-item">Advanced Concept</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%8F%99%EC%8B%9C%EC%84%B1-%EB%B0%8F-%EB%B9%84%EB%8F%99%EA%B8%B0/"><span class="level-start"><span class="level-item">ë™ì‹œì„± ë° ë¹„ë™ê¸°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%EB%AC%B8%EB%B2%95/"><span class="level-start"><span class="level-item">ë¬¸ë²•</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Python/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Spring/%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/"><span class="level-start"><span class="level-item">í•µì‹¬ ì›ë¦¬ - ê¸°ë³¸í¸</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/"><span class="level-start"><span class="level-item">ê¸°íƒ€</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/Github-Pages/"><span class="level-start"><span class="level-item">Github Pages</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EA%B8%B0%ED%83%80/TIL/"><span class="level-start"><span class="level-item">TIL</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/"><span class="level-start"><span class="level-item">ë„¤íŠ¸ì›Œí¬ &amp; ë³´ì•ˆ</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/HTTP-%ED%94%84%EB%A1%9C%ED%86%A0%EC%BD%9C/"><span class="level-start"><span class="level-item">HTTP í”„ë¡œí† ì½œ</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%88/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%95%94%ED%98%B8%ED%99%94/"><span class="level-start"><span class="level-item">ë°ì´í„° ì•”í˜¸í™”</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/"><span class="level-start"><span class="level-item">ë°ì´í„°ë² ì´ìŠ¤ &amp; ê²€ìƒ‰ì—”ì§„</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B2%A0%EC%9D%B4%EC%8A%A4-%EA%B2%80%EC%83%89%EC%97%94%EC%A7%84/OpenSearch/"><span class="level-start"><span class="level-item">OpenSearch</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/NLP/Text-Summarization/"><span class="level-start"><span class="level-item">Text Summarization</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/"><span class="level-start"><span class="level-item">ë…¼ë¬¸ ë¦¬ë·°</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ ê°œë…</span></span><span class="level-end"><span class="level-item tag">36</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B8%B0%EB%B3%B8-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ ê¸°ë³¸ ê°œë…</span></span><span class="level-end"><span class="level-item tag">24</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EA%B0%9C%EB%85%90/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC-NLP-%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ìì—°ì–´ ì²˜ë¦¬(NLP) ê°œë…</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9D%84-%EC%9C%84%ED%95%9C-%ED%86%B5%EA%B3%84%ED%95%99-%EB%B0%8F-%EC%88%98%ED%95%99/"><span class="level-start"><span class="level-item">ë”¥ëŸ¬ë‹ì„ ìœ„í•œ í†µê³„í•™ ë° ìˆ˜í•™</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%EB%94%A5%EB%9F%AC%EB%8B%9D/%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/"><span class="level-start"><span class="level-item">ì„±ëŠ¥ê³¼ íŠœë‹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%84%B1%EB%8A%A5%EA%B3%BC-%ED%8A%9C%EB%8B%9D/%ED%85%8C%EC%8A%A4%ED%8A%B8-%EB%B0%8F-%EB%B2%A4%EC%B9%98%EB%A7%88%ED%82%B9/"><span class="level-start"><span class="level-item">í…ŒìŠ¤íŠ¸ ë° ë²¤ì¹˜ë§ˆí‚¹</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/"><span class="level-start"><span class="level-item">ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EA%B3%B5%ED%95%99/UML/"><span class="level-start"><span class="level-item">UML</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">ì†Œí”„íŠ¸ì›¨ì–´ ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/API-%EC%84%A4%EA%B3%84-%EB%B0%8F-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/"><span class="level-start"><span class="level-item">API ì„¤ê³„ ë° ì•„í‚¤í…ì²˜</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">ì›¹ í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/FastAPI/"><span class="level-start"><span class="level-item">FastAPI</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Core/"><span class="level-start"><span class="level-item">Spring Core</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-Data-JPA/"><span class="level-start"><span class="level-item">Spring Data JPA</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9B%B9-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/Spring/Spring-MVC/"><span class="level-start"><span class="level-item">Spring MVC</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/"><span class="level-start"><span class="level-item">ì¸ê³µì§€ëŠ¥</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EA%B0%9C%EB%85%90-%EC%A0%95%EB%A6%AC/"><span class="level-start"><span class="level-item">ê°œë… ì •ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%9E%90%EC%97%B0%EC%96%B4-%EC%B2%98%EB%A6%AC/"><span class="level-start"><span class="level-item">ìì—°ì–´ ì²˜ë¦¬</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/"><span class="level-start"><span class="level-item">í´ë¼ìš°ë“œ ì»´í“¨íŒ…</span></span><span class="level-end"><span class="level-item tag">6</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%BB%B4%ED%93%A8%ED%8C%85/%EB%8F%84%EC%BB%A4-%EC%BF%A0%EB%B2%84%EB%84%A4%ED%8B%B0%EC%8A%A4/"><span class="level-start"><span class="level-item">ë„ì»¤ &amp; ì¿ ë²„ë„¤í‹°ìŠ¤</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/"><span class="level-start"><span class="level-item">íŒŒì´ì¬</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%8C%8C%EC%9D%B4%EC%8D%AC/%EA%B0%9C%EB%85%90/"><span class="level-start"><span class="level-item">ê°œë…</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="level-start"><span class="level-item">í”„ë¡œê·¸ë˜ë°</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/%ED%81%B4%EB%A6%B0-%EC%BD%94%EB%93%9C/"><span class="level-start"><span class="level-item">í´ë¦° ì½”ë“œ</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-04T14:49:11.000Z">2024-09-04</time></p><p class="title"><a href="/%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D/">ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-04T14:48:00.000Z">2024-09-04</time></p><p class="title"><a href="/Stateless/">Stateless</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-04T14:47:50.000Z">2024-09-04</time></p><p class="title"><a href="/%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/">ì„œë²„ë¦¬ìŠ¤ ì•„í‚¤í…ì²˜</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-04T14:39:45.000Z">2024-09-04</time></p><p class="title"><a href="/Jenkins/">Jenkins</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-04T14:37:37.000Z">2024-09-04</time></p><p class="title"><a href="/%EB%A6%AC%EB%B2%84%EC%8A%A4-%ED%94%84%EB%A1%9D%EC%8B%9C/">ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">September 2024</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">August 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">March 2024</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/02/"><span class="level-start"><span class="level-item">February 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/01/"><span class="level-start"><span class="level-item">January 2024</span></span><span class="level-end"><span class="level-item tag">12</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/11/"><span class="level-start"><span class="level-item">November 2023</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/10/"><span class="level-start"><span class="level-item">October 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/09/"><span class="level-start"><span class="level-item">September 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/08/"><span class="level-start"><span class="level-item">August 2023</span></span><span class="level-end"><span class="level-item tag">19</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/07/"><span class="level-start"><span class="level-item">July 2023</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/06/"><span class="level-start"><span class="level-item">June 2023</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/04/"><span class="level-start"><span class="level-item">April 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/03/"><span class="level-start"><span class="level-item">March 2023</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/02/"><span class="level-start"><span class="level-item">February 2023</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">January 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/12/"><span class="level-start"><span class="level-item">December 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/11/"><span class="level-start"><span class="level-item">November 2022</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">October 2022</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/08/"><span class="level-start"><span class="level-item">August 2022</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/07/"><span class="level-start"><span class="level-item">July 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/1%EA%B8%89-%EC%8B%9C%EB%AF%BC/"><span class="tag">1ê¸‰ ì‹œë¯¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AES/"><span class="tag">AES</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ASGI/"><span class="tag">ASGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Anonymous-Class/"><span class="tag">Anonymous Class</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/AutoEncoder/"><span class="tag">AutoEncoder</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BERT/"><span class="tag">BERT</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Bind-Mounts/"><span class="tag">Bind Mounts</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CGI/"><span class="tag">CGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CORS/"><span class="tag">CORS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Classification/"><span class="tag">Classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Cross-Entropy-Loss/"><span class="tag">Cross Entropy Loss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Curse-of-Dimensionality/"><span class="tag">Curse of Dimensionality</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Volume/"><span class="tag">Data Volume</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker-Orchestration-Tools/"><span class="tag">Docker Orchestration Tools</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Document-Embedding/"><span class="tag">Document Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-Vectors/"><span class="tag">Embedding Vectors</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedding-vector/"><span class="tag">Embedding vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Entropy/"><span class="tag">Entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FLAN/"><span class="tag">FLAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FastAPI/"><span class="tag">FastAPI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Feature-Vector/"><span class="tag">Feature Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Function-Interface/"><span class="tag">Function Interface</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT/"><span class="tag">GPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gradient-Descent/"><span class="tag">Gradient Descent</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gunicorn/"><span class="tag">Gunicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hidden-Representation/"><span class="tag">Hidden Representation</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Instruction-Finetuning/"><span class="tag">Instruction Finetuning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KL-Divergence/"><span class="tag">KL Divergence</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KoNLPy/"><span class="tag">KoNLPy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Lambda-Expression/"><span class="tag">Lambda Expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Latent-Space/"><span class="tag">Latent Space</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Learning-Rate/"><span class="tag">Learning Rate</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Layer/"><span class="tag">Linear Layer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Load-Testing/"><span class="tag">Load Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Log-Likelihood/"><span class="tag">Log-Likelihood</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MAP/"><span class="tag">MAP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MLE/"><span class="tag">MLE</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Manifold-hypothesis/"><span class="tag">Manifold hypothesis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Matrix/"><span class="tag">Matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mecab/"><span class="tag">Mecab</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Multi-Stage-Build/"><span class="tag">Multi Stage Build&quot;</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLL/"><span class="tag">NLL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Persistence-Data/"><span class="tag">Persistence Data</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Probabilistic-Perspective/"><span class="tag">Probabilistic Perspective</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RPS/"><span class="tag">RPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RSA/"><span class="tag">RSA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Representation-Learning/"><span class="tag">Representation Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Response-Time/"><span class="tag">Response Time</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/SOLID/"><span class="tag">SOLID</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scalar/"><span class="tag">Scalar</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring%EC%9D%B4%EB%9E%80/"><span class="tag">Springì´ë€</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stress-Testing/"><span class="tag">Stress Testing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Subword-Embedding/"><span class="tag">Subword Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TPS/"><span class="tag">TPS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensor/"><span class="tag">Tensor</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Testing-Types/"><span class="tag">Testing Types</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Throughput/"><span class="tag">Throughput</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tramsformers/"><span class="tag">Tramsformers</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/UML/"><span class="tag">UML</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Ubuntu/"><span class="tag">Ubuntu</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Uvicorn/"><span class="tag">Uvicorn</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vector/"><span class="tag">Vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WAS/"><span class="tag">WAS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/WSGI/"><span class="tag">WSGI</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/What-to-do/"><span class="tag">What to do</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Word-Embedding/"><span class="tag">Word Embedding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/cross-entropy/"><span class="tag">cross entropy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/default-method/"><span class="tag">default method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/max-length/"><span class="tag">max_length</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mlflow/"><span class="tag">mlflow</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/one-hot-Encoding/"><span class="tag">one-hot Encoding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/packing/"><span class="tag">packing</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/padding/"><span class="tag">padding</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python-%EC%84%A4%EC%B9%98/"><span class="tag">python ì„¤ì¹˜</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/static-method/"><span class="tag">static method</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unpacking/"><span class="tag">unpacking</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5/"><span class="tag">ê°ì²´ì§€í–¥</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%8B%A4%ED%98%95%EC%84%B1/"><span class="tag">ë‹¤í˜•ì„±</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%9E%8C%EB%8B%A4%EC%8B%9D/"><span class="tag">ëŒë‹¤ì‹</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EB%B2%A1%ED%84%B0%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">ë²¡í„°ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%EC%A7%80%ED%91%9C/"><span class="tag">ì„±ëŠ¥ ì§€í‘œ</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%84%B1%EB%8A%A5-%ED%85%8C%EC%8A%A4%ED%8A%B8/"><span class="tag">ì„±ëŠ¥ í…ŒìŠ¤íŠ¸</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC/"><span class="tag">ì—”íŠ¸ë¡œí”¼</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EB%9F%89/"><span class="tag">ì •ë³´ëŸ‰</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%EC%A0%95%EB%B3%B4%EC%9D%B4%EB%A1%A0/"><span class="tag">ì •ë³´ì´ë¡ </span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%81%B4%EB%9E%98%EC%8A%A4-%EB%8B%A4%EC%9D%B4%EC%96%B4%EA%B7%B8%EB%9E%A8/"><span class="tag">í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/"><span class="tag">í•¨ìˆ˜í˜• ì¸í„°í˜ì´ìŠ¤</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%95%A8%EC%88%98%ED%98%95-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/"><span class="tag">í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%ED%96%89%EB%A0%AC%EC%9D%98-%EA%B3%B1%EC%85%88/"><span class="tag">í–‰ë ¬ì˜ ê³±ì…ˆ</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Shawn&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2024 Seohwan Choi</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">Visited by <span id="busuanzi_value_site_uv">0</span> users</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>